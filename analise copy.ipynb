{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дефолтные настройки Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# устанавливаем дефолтные размеры шрифтов\n",
    "plt.rc('font', size=14)\n",
    "plt.rc('axes', labelsize=14, titlesize=14)\n",
    "plt.rc('legend', fontsize=14)\n",
    "plt.rc('xtick', labelsize=10)\n",
    "plt.rc('ytick', labelsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_type_dict = {'parameter1': float,\n",
    "                    'parameter2': float,\n",
    "                    'criteria1': float,\n",
    "                    'criteria2': float,\n",
    "                    'constraint1': bool,\n",
    "                    'constraint2': bool,\n",
    "                    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path: Path):\n",
    "    print(\"Read data set from path {path}\".format(path=path))\n",
    "    df = pd.read_csv(path).astype(convert_type_dict)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Непосредственно загрузка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read data set from path data\\DataSet900.csv\n",
      "Read data set from path data\\DataSet1000.csv\n",
      "Read data set from path data\\DataSet100000.csv\n",
      "Read data set from path data\\DataSet129600.csv\n"
     ]
    }
   ],
   "source": [
    "data_1_path = Path(\"data/DataSet900.csv\")\n",
    "data_2_path = Path(\"data/DataSet1000.csv\")\n",
    "data_3_path = Path(\"data/DataSet100000.csv\")\n",
    "data_4_path = Path(\"data/DataSet129600.csv\")\n",
    "\n",
    "data_1 = load_data(data_1_path)\n",
    "data_2 = load_data(data_2_path)\n",
    "data_3 = load_data(data_3_path)\n",
    "data_4 = load_data(data_4_path)\n",
    "\n",
    "dataset = data_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Шапка датасета, первые 5 записей  набора данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parameter1</th>\n",
       "      <th>parameter2</th>\n",
       "      <th>criteria1</th>\n",
       "      <th>criteria2</th>\n",
       "      <th>constraint1</th>\n",
       "      <th>constraint2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.012</td>\n",
       "      <td>12.817</td>\n",
       "      <td>100.829</td>\n",
       "      <td>-23819.000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56.818</td>\n",
       "      <td>49.060</td>\n",
       "      <td>105.878</td>\n",
       "      <td>-2580.510</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.049</td>\n",
       "      <td>31.159</td>\n",
       "      <td>64.208</td>\n",
       "      <td>-381.242</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51.229</td>\n",
       "      <td>50.554</td>\n",
       "      <td>101.783</td>\n",
       "      <td>-215.838</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59.320</td>\n",
       "      <td>23.653</td>\n",
       "      <td>82.973</td>\n",
       "      <td>-9297.220</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   parameter1  parameter2  criteria1  criteria2  constraint1  constraint2\n",
       "0      88.012      12.817    100.829 -23819.000         True        False\n",
       "1      56.818      49.060    105.878  -2580.510         True        False\n",
       "2      33.049      31.159     64.208   -381.242         True        False\n",
       "3      51.229      50.554    101.783   -215.838         True        False\n",
       "4      59.320      23.653     82.973  -9297.220         True        False"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Информация по колонкам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   parameter1   100000 non-null  float64\n",
      " 1   parameter2   100000 non-null  float64\n",
      " 2   criteria1    100000 non-null  float64\n",
      " 3   criteria2    100000 non-null  float64\n",
      " 4   constraint1  100000 non-null  bool   \n",
      " 5   constraint2  100000 non-null  bool   \n",
      "dtypes: bool(2), float64(4)\n",
      "memory usage: 3.2 MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основная статистическая информация по колонкам "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parameter1</th>\n",
       "      <th>parameter2</th>\n",
       "      <th>criteria1</th>\n",
       "      <th>criteria2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>55.016958</td>\n",
       "      <td>54.983437</td>\n",
       "      <td>110.000395</td>\n",
       "      <td>-21.315351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>26.017546</td>\n",
       "      <td>25.957948</td>\n",
       "      <td>36.758778</td>\n",
       "      <td>12985.033086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>20.459000</td>\n",
       "      <td>-31002.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>32.419000</td>\n",
       "      <td>32.527000</td>\n",
       "      <td>83.861750</td>\n",
       "      <td>-8846.925000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>55.103500</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>110.009000</td>\n",
       "      <td>-19.349650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>77.491000</td>\n",
       "      <td>77.392000</td>\n",
       "      <td>136.442000</td>\n",
       "      <td>8785.945000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>99.991000</td>\n",
       "      <td>99.991000</td>\n",
       "      <td>199.613000</td>\n",
       "      <td>30980.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          parameter1     parameter2      criteria1      criteria2\n",
       "count  100000.000000  100000.000000  100000.000000  100000.000000\n",
       "mean       55.016958      54.983437     110.000395     -21.315351\n",
       "std        26.017546      25.957948      36.758778   12985.033086\n",
       "min        10.000000      10.000000      20.459000  -31002.000000\n",
       "25%        32.419000      32.527000      83.861750   -8846.925000\n",
       "50%        55.103500      55.000000     110.009000     -19.349650\n",
       "75%        77.491000      77.392000     136.442000    8785.945000\n",
       "max        99.991000      99.991000     199.613000   30980.100000"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Количество встречающихся значений `constraint1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "constraint1\n",
       "True     74194\n",
       "False    25806\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"constraint1\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Количество встречающихся значений `constraint2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "constraint2\n",
       "False    50097\n",
       "True     49903\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"constraint2\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код описывающий сохранение графиков и рисунков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH = Path() / \"imgs\"\n",
    "IMAGES_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = IMAGES_PATH / f\"{fig_id}.{fig_extension}\"\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Представление о данных.\n",
    "- по вертикали количество повторений\n",
    "- по горизонтали величина значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.hist(bins=50, figsize=(12, 8))\n",
    "save_fig(\"attribute_histogram_plots\")  # extra code\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Устанавливаем параметр рандомизации (что бы значения повторялись при запуске)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тренировочный датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(dataset, test_size=0.2, random_state=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Корреляция параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parameter1</th>\n",
       "      <th>parameter2</th>\n",
       "      <th>criteria1</th>\n",
       "      <th>criteria2</th>\n",
       "      <th>constraint1</th>\n",
       "      <th>constraint2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>parameter1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>0.708042</td>\n",
       "      <td>-0.692405</td>\n",
       "      <td>0.643041</td>\n",
       "      <td>-0.577238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parameter2</th>\n",
       "      <td>0.000355</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.706422</td>\n",
       "      <td>0.691070</td>\n",
       "      <td>-0.388953</td>\n",
       "      <td>0.577137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>criteria1</th>\n",
       "      <td>0.708042</td>\n",
       "      <td>0.706422</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.002065</td>\n",
       "      <td>0.180472</td>\n",
       "      <td>-0.001007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>criteria2</th>\n",
       "      <td>-0.692405</td>\n",
       "      <td>0.691070</td>\n",
       "      <td>-0.002065</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.677332</td>\n",
       "      <td>0.798745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>constraint1</th>\n",
       "      <td>0.643041</td>\n",
       "      <td>-0.388953</td>\n",
       "      <td>0.180472</td>\n",
       "      <td>-0.677332</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.590906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>constraint2</th>\n",
       "      <td>-0.577238</td>\n",
       "      <td>0.577137</td>\n",
       "      <td>-0.001007</td>\n",
       "      <td>0.798745</td>\n",
       "      <td>-0.590906</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             parameter1  parameter2  criteria1  criteria2  constraint1  \\\n",
       "parameter1     1.000000    0.000355   0.708042  -0.692405     0.643041   \n",
       "parameter2     0.000355    1.000000   0.706422   0.691070    -0.388953   \n",
       "criteria1      0.708042    0.706422   1.000000  -0.002065     0.180472   \n",
       "criteria2     -0.692405    0.691070  -0.002065   1.000000    -0.677332   \n",
       "constraint1    0.643041   -0.388953   0.180472  -0.677332     1.000000   \n",
       "constraint2   -0.577238    0.577137  -0.001007   0.798745    -0.590906   \n",
       "\n",
       "             constraint2  \n",
       "parameter1     -0.577238  \n",
       "parameter2      0.577137  \n",
       "criteria1      -0.001007  \n",
       "criteria2       0.798745  \n",
       "constraint1    -0.590906  \n",
       "constraint2     1.000000  "
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = dataset.corr()\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "attributes = [\"parameter1\", \"parameter2\", \"criteria1\",\n",
    "              \"criteria2\"]\n",
    "scatter_matrix(dataset[attributes], figsize=(12, 8))\n",
    "save_fig(\"scatter_matrix_plot\")  # extra code\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Эксперименты с атрибутами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data[\"criteria2_parameter1\"] = train_data[\"criteria2\"] / train_data[\"parameter1\"]\n",
    "# train_data[\"criteria2_parameter2\"] = train_data[\"criteria2\"] / train_data[\"parameter2\"]\n",
    "# train_data[\"parameter1_parameter2\"] = train_data[\"parameter1\"] * train_data[\"parameter2\"]\n",
    "\n",
    "# corr_matrix = train_data.corr()\n",
    "# corr_matrix[\"criteria1\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Новый критерий сильно коррелирует с нашим параметром"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Общие функции\n",
    "\n",
    "Описание модели обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "class MyModel():\n",
    "    def  __init__(self,\n",
    "                  data:pd.DataFrame,\n",
    "                  features: list,\n",
    "                  predict_label_name: str,\n",
    "                  model):\n",
    "        self.data = data\n",
    "        self.features = features\n",
    "        self.predict_label_name = predict_label_name\n",
    "        self.model: LinearRegression = model\n",
    "        \n",
    "        self.split_data()\n",
    "    \n",
    "    def split_data(self):\n",
    "        self.train_data, self.test_data = train_test_split(\n",
    "            self.data, test_size=0.95, random_state=30)\n",
    "        \n",
    "        self.train_data_values = self.train_data[self.features]\n",
    "        self.train_data_labels = self.train_data[self.predict_label_name]\n",
    "        \n",
    "        self.test_data_values = self.test_data[self.features]\n",
    "        self.test_data_labels = self.test_data[self.predict_label_name]\n",
    "    \n",
    "    def fit(self):\n",
    "        self.model = self.model.fit(self.train_data_values, self.train_data_labels)\n",
    "    \n",
    "    def get_predict(self):\n",
    "        return self.model.predict(self.test_data_values)\n",
    "    \n",
    "    def get_test_labels(self):\n",
    "        return self.test_data_labels \n",
    "    \n",
    "    def get_model(self):   \n",
    "        return self.model\n",
    "\n",
    "    def save_model(self):\n",
    "        name = '_'.join(self.features+[self.predict_label_name])\n",
    "        pkl_filename = \"saved_model/\"+name+\".pkl\" \n",
    "        with open(pkl_filename, 'wb') as file: \n",
    "            pickle.dump(self.model, file) \n",
    "    \n",
    "    def load_model(self, pkl_filename):\n",
    "        with open(pkl_filename, 'rb') as file: \n",
    "            self.model = pickle.load(file)\n",
    "        \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создаём модели и обучаем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.linear_model import (\n",
    "    LinearRegression, \n",
    "    SGDRegressor,\n",
    "    SGDClassifier\n",
    ") \n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    RandomForestRegressor\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    accuracy_score, \n",
    ")\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "принцип именования сначала критерий который нужно предсказать, следом параметры по которым обучается модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE_metric(parameters_list, model, data):\n",
    "    models: List[MyModel] = []\n",
    "    for parameters in parameters_list:\n",
    "        models.append(\n",
    "            MyModel(\n",
    "                data=data,\n",
    "                features=parameters[0],\n",
    "                predict_label_name=parameters[1],\n",
    "                model=deepcopy(model),\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    for model in models:\n",
    "        print('''\n",
    "              ***************************************''')\n",
    "        print(\"Begin predict {} from {}\".format(model.predict_label_name,\n",
    "                                               '_'.join(model.features)))\n",
    "        model.fit()\n",
    "        \n",
    "        predict = model.get_predict()\n",
    "        print('Predict:', predict[:6])\n",
    "        labels = model.get_test_labels()\n",
    "        print('Test:', labels[:6].tolist())\n",
    "        score = mean_squared_error(\n",
    "            labels,\n",
    "            predict,\n",
    "            squared=False\n",
    "        )        \n",
    "        print(\"Score MSE {}\".format(score))\n",
    "        model.save_model()\n",
    "  \n",
    "    \n",
    "calculation_list_1 = [\n",
    "    [['parameter1', 'parameter2'], 'criteria1'],\n",
    "    [['parameter1', 'parameter2'], 'criteria2'],\n",
    "    [['criteria1', 'criteria2'], 'parameter1'],\n",
    "    [['criteria1', 'criteria2'], 'parameter2'],\n",
    "    [['criteria1', 'criteria2', 'constraint1', 'constraint2'], 'parameter1'],\n",
    "    [['criteria1', 'criteria2', 'constraint1', 'constraint2'], 'parameter2'],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AC_metric(parameters_list, model, data):\n",
    "    models: List[MyModel] = []\n",
    "    for parameters in parameters_list:\n",
    "        models.append(\n",
    "            MyModel(\n",
    "                data=data,\n",
    "                features=parameters[0],\n",
    "                predict_label_name=parameters[1],\n",
    "                model=deepcopy(model),\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    for model in models:\n",
    "        print('''\n",
    "              ***************************************''')\n",
    "        print(\"Begin predict {} from {}\".format(model.predict_label_name,\n",
    "                                               '_'.join(model.features)))\n",
    "        model.fit()\n",
    "        ml_model = model.get_model()\n",
    "        predict = model.get_predict()\n",
    "        # print('Predict:', predict[:6])\n",
    "        labels = model.get_test_labels()\n",
    "        # print('Test:', labels[:6].tolist())\n",
    "        \n",
    "        score = accuracy_score(\n",
    "            predict,\n",
    "            labels\n",
    "        )\n",
    "        print(\"Score CVS {}\".format(score))\n",
    "        \n",
    "calculation_list_2 = [  \n",
    "    [['criteria1', 'criteria2'], 'constraint1'],\n",
    "    [['criteria1', 'criteria2'], 'constraint2'],\n",
    "    [['parameter1', 'parameter2'], 'constraint1'],\n",
    "    [['parameter1', 'parameter2'], 'constraint2'],\n",
    "    [['criteria1', 'criteria2', 'parameter1', 'parameter2'], 'constraint1'],\n",
    "    [['criteria1', 'criteria2', 'parameter1', 'parameter2'], 'constraint2'],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метрика СКО\n",
    "принцип именования сначала критерий который нужно предсказать, следом параметры по которым обучается модель\n",
    "\n",
    "Модель обучения  - лес регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next random_forest_model_regressor >>>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      "              ***************************************\n",
      "Begin predict criteria1 from parameter1_parameter2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict: [123.25529 109.15976 145.93844  95.04704 136.12916 126.76628]\n",
      "Test: [122.888, 109.289, 145.694, 95.456, 136.397, 126.56]\n",
      "Score MSE 0.514912180124154\n",
      "\n",
      "              ***************************************\n",
      "Begin predict criteria2 from parameter1_parameter2\n",
      "Predict: [ 23343.904  26839.494  15814.007  18111.583  23023.671 -14280.362]\n",
      "Test: [23453.4, 26806.4, 15966.8, 17926.5, 22927.1, -14048.8]\n",
      "Score MSE 175.62282686182434\n",
      "\n",
      "              ***************************************\n",
      "Begin predict parameter1 from criteria1_criteria2\n",
      "Predict: [31.24    16.09606 55.60381 18.11206 41.77261 80.8012 ]\n",
      "Test: [31.069, 15.607, 55.405, 17.839, 41.446, 80.947]\n",
      "Score MSE 0.37296979110665857\n",
      "\n",
      "              ***************************************\n",
      "Begin predict parameter2 from criteria1_criteria2\n",
      "Predict: [91.63477 93.745   90.388   77.43178 95.07817 45.94312]\n",
      "Test: [91.819, 93.682, 90.289, 77.617, 94.951, 45.613]\n",
      "Score MSE 0.33591224900128963\n",
      "\n",
      "              ***************************************\n",
      "Begin predict parameter1 from criteria1_criteria2_constraint1_constraint2\n",
      "Predict: [31.34395 16.04773 55.82233 18.38035 41.8384  80.74603]\n",
      "Test: [31.069, 15.607, 55.405, 17.839, 41.446, 80.947]\n",
      "Score MSE 0.4219257176201768\n",
      "\n",
      "              ***************************************\n",
      "Begin predict parameter2 from criteria1_criteria2_constraint1_constraint2\n",
      "Predict: [91.67968 93.7774  90.43606 77.27014 94.95262 45.98452]\n",
      "Test: [91.819, 93.682, 90.289, 77.617, 94.951, 45.613]\n",
      "Score MSE 0.3395442715006616\n"
     ]
    }
   ],
   "source": [
    "random_forest_model_regressor = RandomForestRegressor()\n",
    "SGD_model = SGDRegressor()\n",
    "linear_regression_model = LinearRegression()\n",
    "\n",
    "print('Next random_forest_model_regressor >>>>>>>>>>>>>>>>>>>>>>')\n",
    "MSE_metric(calculation_list_1, random_forest_model_regressor, dataset)\n",
    "\n",
    "# print('Next linear_regression_model >>>>>>>>>>>>>>>>>>>>>>')\n",
    "# MSE_metric(calculation_list_1, linear_regression_model, dataset)\n",
    "\n",
    "# print('Next SGD_model >>>>>>>>>>>>>>>>>>>>>>')\n",
    "# MSE_metric(calculation_list_1, SGD_model, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Простая метрика\n",
    "Модель обучения  - лес классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next random_forest_model_classifier >>>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      "              ***************************************\n",
      "Begin predict constraint1 from criteria1_criteria2\n",
      "Score CVS 0.9932\n",
      "\n",
      "              ***************************************\n",
      "Begin predict constraint2 from criteria1_criteria2\n",
      "Score CVS 0.9996842105263158\n",
      "\n",
      "              ***************************************\n",
      "Begin predict constraint1 from parameter1_parameter2\n",
      "Score CVS 0.9934631578947368\n",
      "\n",
      "              ***************************************\n",
      "Begin predict constraint2 from parameter1_parameter2\n",
      "Score CVS 0.9908526315789473\n",
      "\n",
      "              ***************************************\n",
      "Begin predict constraint1 from criteria1_criteria2_parameter1_parameter2\n",
      "Score CVS 0.9946\n",
      "\n",
      "              ***************************************\n",
      "Begin predict constraint2 from criteria1_criteria2_parameter1_parameter2\n",
      "Score CVS 0.9996947368421053\n"
     ]
    }
   ],
   "source": [
    "random_forest_model_classifier = RandomForestClassifier()\n",
    "SGD_model = SGDClassifier()\n",
    "\n",
    "print('Next random_forest_model_classifier >>>>>>>>>>>>>>>>>>>>>>')\n",
    "AC_metric(calculation_list_2, random_forest_model_classifier, dataset)\n",
    "\n",
    "# print('Next SGD_model >>>>>>>>>>>>>>>>>>>>>>')\n",
    "# AC_metric(calculation_list_2, SGD_model, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вывод:\n",
    "Результаты говорят что прогнозирование constraint1 и constraint2 весьма просто, так как там бинарный предикт. Остальные значения тоже можно прогнозировать однако с некоторой ошибкой, можно настроить гипперпараметры и тогда возможно результат улучшится."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Применение нейронных сетей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Установить роботу с куда или нна цп"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    '''\n",
    "    Dataset:\n",
    "    '''\n",
    "    def __init__(self, \n",
    "                 data:pd.DataFrame,\n",
    "                 input_colums: List[str],\n",
    "                 output_colums: List[str]) -> None:\n",
    "        self.input_colums = input_colums\n",
    "        self.output_colums = output_colums\n",
    "        \n",
    "        x = data[self.input_colums].values\n",
    "        y = data[self.output_colums].values\n",
    "        \n",
    "        self.x_train = torch.tensor(x, dtype=torch.float32)\n",
    "        self.y_train = torch.tensor(y, dtype=torch.float32)      \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y_train)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.x_train[index], self.y_train[index]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=128, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    '''\n",
    "    Define neural network model:\n",
    "    '''\n",
    "    def __init__(self, inputs, outputs, middle_layers=128):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(            \n",
    "            nn.Linear(inputs, middle_layers),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(middle_layers, middle_layers),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(middle_layers, middle_layers),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(middle_layers, outputs)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "test = NeuralNetwork(2,2).to(device)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing the Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from sympy import prime\n",
    "from torch.nn import MSELoss\n",
    "from torch.optim import SGD\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "class Trainer():\n",
    "    '''\n",
    "    Trainer:\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 data:pd.DataFrame,\n",
    "                 input_colums:List[str],\n",
    "                 output_colums:List[str],\n",
    "                 batch_size=32,\n",
    "                 learning_rate=0.005,\n",
    "                 shuffle=False,\n",
    "                 test_size=0.2,\n",
    "                 random_state=None,\n",
    "                 save_path='saved_model/',\n",
    "                 model_middle_layers=512):\n",
    "        \n",
    "        self.save_path = save_path\n",
    "        \n",
    "        self.input_colums = input_colums\n",
    "        self.output_colums = output_colums\n",
    "        \n",
    "        self.uniq_name = '_'.join(input_colums + output_colums)\n",
    "        \n",
    "        self.data = data.copy()\n",
    "        self.normalize_param = self._normalize_data(self.data, input_colums+output_colums)\n",
    "        with open(save_path+self.uniq_name+'_normalize_params.pkl', 'wb') as file: \n",
    "            pickle.dump(self.normalize_param, file)\n",
    "\n",
    "        train_set, test_set = train_test_split(self.data, test_size=test_size, random_state=random_state)\n",
    "                \n",
    "        self.train_dataloader = DataLoader(\n",
    "            MyDataset(train_set, input_colums, output_colums),\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle\n",
    "        )\n",
    "        self.test_dataloader = DataLoader(\n",
    "            MyDataset(test_set, input_colums, output_colums),\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False\n",
    "        )\n",
    "        \n",
    "        self.model = NeuralNetwork(\n",
    "            inputs=len(input_colums),\n",
    "            outputs=len(output_colums),\n",
    "            middle_layers=model_middle_layers\n",
    "        ).to(device)\n",
    "        \n",
    "        self.loss_func = MSELoss()\n",
    "        self.optimizer = SGD(self.model.parameters(), lr=learning_rate)  \n",
    "        \n",
    "        self.validate_loss_list = []     \n",
    "        self.train_loss_list = []\n",
    "    \n",
    "    def train(self):\n",
    "        size = len(self.train_dataloader.dataset)\n",
    "        self.model.train()\n",
    "        train_loss = 0.\n",
    "        for batch, (X, y) in enumerate(self.train_dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # Compute prediction error\n",
    "            pred = self.model(X)\n",
    "            loss: torch.Tensor = self.loss_func(pred, y)\n",
    "\n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        avg_loss = train_loss/len(self.train_dataloader)\n",
    "        self.train_loss_list.append(avg_loss)\n",
    "        return avg_loss\n",
    "                \n",
    "    def validate(self):\n",
    "        num_batches = len(self.test_dataloader)\n",
    "        self.model.eval()\n",
    "        val_loss_sum = 0\n",
    "        with torch.no_grad():\n",
    "            for X, y in self.test_dataloader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                pred = self.model(X)\n",
    "                val_loss_sum += self.loss_func(pred, y).item()\n",
    "        avg_loss = val_loss_sum/self.test_dataloader.batch_size\n",
    "        self.validate_loss_list.append(avg_loss)\n",
    "        return avg_loss        \n",
    "        \n",
    "    def run(self,  epochs=10):\n",
    "        for t in range(epochs):\n",
    "            train_avg_loss = self.train()\n",
    "            print(f'Epoch [{t + 1:03}/{epochs:03}] | Train Loss: {train_avg_loss:.6f}')\n",
    "            \n",
    "            val_avg_loss = self.validate()\n",
    "            print(f\"Validation AVG Loss: {val_avg_loss:>12f} \\n\")\n",
    "            \n",
    "        print(\"Done!\")\n",
    "    \n",
    "    # def predict(self, input: np.array):\n",
    "    #     print('Входные данные:', input)\n",
    "    #     for index, item in enumerate(self.input_colums):\n",
    "    #         input[index] = (input[index] - self.normalize_param[item]['mean']) /\\\n",
    "    #             self.normalize_param[item]['std']\n",
    "    #     print('Нормализованные:', input)\n",
    "    #     pred:torch.Tensor = self.model(torch.tensor(input, dtype=torch.float32))        \n",
    "    #     pred = pred.detach().numpy()\n",
    "    #     print('Вывод модели:', pred)\n",
    "    #     for index, item in enumerate(self.output_colums):\n",
    "    #         # pred[index] = pred[index] * self.normalize_param[item]['lenght']\n",
    "    #         pred[index] = pred[index] * self.normalize_param[item]['std'] +\\\n",
    "    #             self.normalize_param[item]['mean']\n",
    "    #     print('Денормализованные данные:', pred)\n",
    "    #     return pred  \n",
    "    \n",
    "    def predict(self, input: np.array):\n",
    "        input.astype(float)\n",
    "        print('Входные данные:', input)\n",
    "        for index, item in enumerate(self.input_colums):\n",
    "            input[index] = 2 * ((input[index] - self.normalize_param[item]['min']) /\\\n",
    "                (self.normalize_param[item]['max'] - self.normalize_param[item]['min'])) -1\n",
    "        print('Нормализованные:', input)\n",
    "        pred:torch.Tensor = self.model(torch.tensor(input, dtype=torch.float32))        \n",
    "        pred = pred.detach().numpy()\n",
    "        print('Вывод модели:', pred)\n",
    "        for index, item in enumerate(self.output_colums):\n",
    "            pred[index] = (1 + pred[index]) / 2 * \\\n",
    "                (self.normalize_param[item]['max'] - self.normalize_param[item]['min']) +\\\n",
    "                    self.normalize_param[item]['min']\n",
    "        print('Денормализованные данные:', pred)\n",
    "        return pred  \n",
    "    \n",
    "    def _normalize(self,\n",
    "                   data: pd.DataFrame,\n",
    "                   colum: str) -> torch.Tensor:\n",
    "        max_val = data[colum].max()\n",
    "        min_val = data[colum].min()\n",
    "        data[colum] = 2 * ((data[colum] - min_val) / (max_val - min_val)) -1\n",
    "        return {'max': max_val, 'min': min_val}\n",
    "    \n",
    "    # def _normalize(self,\n",
    "    #                data: pd.DataFrame,\n",
    "    #                colum: str) -> torch.Tensor:\n",
    "    #     mean = data[colum].mean()\n",
    "    #     std = data[colum].std()\n",
    "    #     data[colum] = (data[colum] - mean) / std  \n",
    "    #     return {'mean': mean, 'std': std}\n",
    "    \n",
    "    def save_model(self):\n",
    "        torch.save(self.model, self.save_path+self.uniq_name+'_model_weights.pth')       \n",
    "    \n",
    "    def _normalize_data(self, data, colums):\n",
    "        params = {}\n",
    "        for colum in colums:\n",
    "            params[colum] = self._normalize(data, colum)\n",
    "        return params\n",
    "    \n",
    "    def _denormalize(self, tensor, mean, std) -> torch.Tensor:\n",
    "        return tensor * std\n",
    "    \n",
    "    def plot_train_result(self):\n",
    "        plt.plot(range(len(self.train_loss_list)), self.train_loss_list, self.validate_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadModel():\n",
    "    def __init__(self, model_path, normalize_params_path, input_colums, output_colums) -> None:\n",
    "        self.input_colums = input_colums\n",
    "        self.output_colums = output_colums\n",
    "        self._model_path = model_path\n",
    "        with open(normalize_params_path, 'rb') as file: \n",
    "            self.normalize_params = pickle.load(file)\n",
    "        self.model = torch.load(model_path)\n",
    "        self.model.eval()\n",
    "    \n",
    "    def predict(self, input):\n",
    "        # print('Входные данные:', input)\n",
    "        for index, item in enumerate(self.input_colums):\n",
    "            input[index] = (input[index] - self.normalize_params[item]['mean']) /\\\n",
    "                self.normalize_params[item]['std']\n",
    "        # print('Нормализованные:', input)\n",
    "        pred:torch.Tensor = self.model(torch.tensor(input, dtype=torch.float32))        \n",
    "        pred = pred.detach().numpy()\n",
    "        # print('Вывод модели:', pred)\n",
    "        for index, item in enumerate(self.output_colums):\n",
    "            pred[index] = pred[index] * self.normalize_params[item]['std'] +\\\n",
    "                self.normalize_params[item]['mean']\n",
    "        # print('Денормализованные данные:', pred)\n",
    "        return pred "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Анализ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read data set from path data\\DataSet900.csv\n"
     ]
    }
   ],
   "source": [
    "# First star\n",
    "data_1_path = Path(\"data/DataSet900.csv\")\n",
    "data_2_path = Path(\"data/DataSet1000.csv\")\n",
    "data_3_path = Path(\"data/DataSet100000.csv\")\n",
    "data_4_path = Path(\"data/DataSet129600.csv\")\n",
    "\n",
    "dataset = load_data(data_1_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parameter1</th>\n",
       "      <th>parameter2</th>\n",
       "      <th>criteria1</th>\n",
       "      <th>criteria2</th>\n",
       "      <th>constraint1</th>\n",
       "      <th>constraint2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>216.770</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>490.088</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>819.956</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1206.370</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   parameter1  parameter2  criteria1  criteria2  constraint1  constraint2\n",
       "0        10.0        10.0       20.0      0.000         True        False\n",
       "1        10.0        13.0       23.0    216.770         True         True\n",
       "2        10.0        16.0       26.0    490.088         True         True\n",
       "3        10.0        19.0       29.0    819.956        False         True\n",
       "4        10.0        22.0       32.0   1206.370        False         True"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проверка 1 \n",
    "input_colums=['criteria1', 'criteria2'],\n",
    "\n",
    "output_colums=['parameter1', 'parameter2'],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [001/5000] | Train Loss: 0.365508\n",
      "Validation AVG Loss:     0.000342 \n",
      "\n",
      "Epoch [002/5000] | Train Loss: 0.365362\n",
      "Validation AVG Loss:     0.000342 \n",
      "\n",
      "Epoch [003/5000] | Train Loss: 0.365215\n",
      "Validation AVG Loss:     0.000341 \n",
      "\n",
      "Epoch [004/5000] | Train Loss: 0.365069\n",
      "Validation AVG Loss:     0.000341 \n",
      "\n",
      "Epoch [005/5000] | Train Loss: 0.364923\n",
      "Validation AVG Loss:     0.000341 \n",
      "\n",
      "Epoch [006/5000] | Train Loss: 0.364777\n",
      "Validation AVG Loss:     0.000341 \n",
      "\n",
      "Epoch [007/5000] | Train Loss: 0.364632\n",
      "Validation AVG Loss:     0.000341 \n",
      "\n",
      "Epoch [008/5000] | Train Loss: 0.364486\n",
      "Validation AVG Loss:     0.000341 \n",
      "\n",
      "Epoch [009/5000] | Train Loss: 0.364341\n",
      "Validation AVG Loss:     0.000341 \n",
      "\n",
      "Epoch [010/5000] | Train Loss: 0.364196\n",
      "Validation AVG Loss:     0.000341 \n",
      "\n",
      "Epoch [011/5000] | Train Loss: 0.364051\n",
      "Validation AVG Loss:     0.000340 \n",
      "\n",
      "Epoch [012/5000] | Train Loss: 0.363907\n",
      "Validation AVG Loss:     0.000340 \n",
      "\n",
      "Epoch [013/5000] | Train Loss: 0.363762\n",
      "Validation AVG Loss:     0.000340 \n",
      "\n",
      "Epoch [014/5000] | Train Loss: 0.363618\n",
      "Validation AVG Loss:     0.000340 \n",
      "\n",
      "Epoch [015/5000] | Train Loss: 0.363474\n",
      "Validation AVG Loss:     0.000340 \n",
      "\n",
      "Epoch [016/5000] | Train Loss: 0.363330\n",
      "Validation AVG Loss:     0.000340 \n",
      "\n",
      "Epoch [017/5000] | Train Loss: 0.363187\n",
      "Validation AVG Loss:     0.000340 \n",
      "\n",
      "Epoch [018/5000] | Train Loss: 0.363044\n",
      "Validation AVG Loss:     0.000340 \n",
      "\n",
      "Epoch [019/5000] | Train Loss: 0.362900\n",
      "Validation AVG Loss:     0.000339 \n",
      "\n",
      "Epoch [020/5000] | Train Loss: 0.362757\n",
      "Validation AVG Loss:     0.000339 \n",
      "\n",
      "Epoch [021/5000] | Train Loss: 0.362614\n",
      "Validation AVG Loss:     0.000339 \n",
      "\n",
      "Epoch [022/5000] | Train Loss: 0.362472\n",
      "Validation AVG Loss:     0.000339 \n",
      "\n",
      "Epoch [023/5000] | Train Loss: 0.362329\n",
      "Validation AVG Loss:     0.000339 \n",
      "\n",
      "Epoch [024/5000] | Train Loss: 0.362187\n",
      "Validation AVG Loss:     0.000339 \n",
      "\n",
      "Epoch [025/5000] | Train Loss: 0.362045\n",
      "Validation AVG Loss:     0.000339 \n",
      "\n",
      "Epoch [026/5000] | Train Loss: 0.361903\n",
      "Validation AVG Loss:     0.000339 \n",
      "\n",
      "Epoch [027/5000] | Train Loss: 0.361762\n",
      "Validation AVG Loss:     0.000338 \n",
      "\n",
      "Epoch [028/5000] | Train Loss: 0.361620\n",
      "Validation AVG Loss:     0.000338 \n",
      "\n",
      "Epoch [029/5000] | Train Loss: 0.361479\n",
      "Validation AVG Loss:     0.000338 \n",
      "\n",
      "Epoch [030/5000] | Train Loss: 0.361338\n",
      "Validation AVG Loss:     0.000338 \n",
      "\n",
      "Epoch [031/5000] | Train Loss: 0.361197\n",
      "Validation AVG Loss:     0.000338 \n",
      "\n",
      "Epoch [032/5000] | Train Loss: 0.361056\n",
      "Validation AVG Loss:     0.000338 \n",
      "\n",
      "Epoch [033/5000] | Train Loss: 0.360915\n",
      "Validation AVG Loss:     0.000338 \n",
      "\n",
      "Epoch [034/5000] | Train Loss: 0.360775\n",
      "Validation AVG Loss:     0.000338 \n",
      "\n",
      "Epoch [035/5000] | Train Loss: 0.360635\n",
      "Validation AVG Loss:     0.000337 \n",
      "\n",
      "Epoch [036/5000] | Train Loss: 0.360495\n",
      "Validation AVG Loss:     0.000337 \n",
      "\n",
      "Epoch [037/5000] | Train Loss: 0.360355\n",
      "Validation AVG Loss:     0.000337 \n",
      "\n",
      "Epoch [038/5000] | Train Loss: 0.360215\n",
      "Validation AVG Loss:     0.000337 \n",
      "\n",
      "Epoch [039/5000] | Train Loss: 0.360076\n",
      "Validation AVG Loss:     0.000337 \n",
      "\n",
      "Epoch [040/5000] | Train Loss: 0.359936\n",
      "Validation AVG Loss:     0.000337 \n",
      "\n",
      "Epoch [041/5000] | Train Loss: 0.359797\n",
      "Validation AVG Loss:     0.000337 \n",
      "\n",
      "Epoch [042/5000] | Train Loss: 0.359658\n",
      "Validation AVG Loss:     0.000337 \n",
      "\n",
      "Epoch [043/5000] | Train Loss: 0.359519\n",
      "Validation AVG Loss:     0.000336 \n",
      "\n",
      "Epoch [044/5000] | Train Loss: 0.359380\n",
      "Validation AVG Loss:     0.000336 \n",
      "\n",
      "Epoch [045/5000] | Train Loss: 0.359242\n",
      "Validation AVG Loss:     0.000336 \n",
      "\n",
      "Epoch [046/5000] | Train Loss: 0.359104\n",
      "Validation AVG Loss:     0.000336 \n",
      "\n",
      "Epoch [047/5000] | Train Loss: 0.358965\n",
      "Validation AVG Loss:     0.000336 \n",
      "\n",
      "Epoch [048/5000] | Train Loss: 0.358827\n",
      "Validation AVG Loss:     0.000336 \n",
      "\n",
      "Epoch [049/5000] | Train Loss: 0.358690\n",
      "Validation AVG Loss:     0.000336 \n",
      "\n",
      "Epoch [050/5000] | Train Loss: 0.358552\n",
      "Validation AVG Loss:     0.000336 \n",
      "\n",
      "Epoch [051/5000] | Train Loss: 0.358415\n",
      "Validation AVG Loss:     0.000335 \n",
      "\n",
      "Epoch [052/5000] | Train Loss: 0.358277\n",
      "Validation AVG Loss:     0.000335 \n",
      "\n",
      "Epoch [053/5000] | Train Loss: 0.358140\n",
      "Validation AVG Loss:     0.000335 \n",
      "\n",
      "Epoch [054/5000] | Train Loss: 0.358003\n",
      "Validation AVG Loss:     0.000335 \n",
      "\n",
      "Epoch [055/5000] | Train Loss: 0.357867\n",
      "Validation AVG Loss:     0.000335 \n",
      "\n",
      "Epoch [056/5000] | Train Loss: 0.357730\n",
      "Validation AVG Loss:     0.000335 \n",
      "\n",
      "Epoch [057/5000] | Train Loss: 0.357594\n",
      "Validation AVG Loss:     0.000335 \n",
      "\n",
      "Epoch [058/5000] | Train Loss: 0.357458\n",
      "Validation AVG Loss:     0.000335 \n",
      "\n",
      "Epoch [059/5000] | Train Loss: 0.357322\n",
      "Validation AVG Loss:     0.000335 \n",
      "\n",
      "Epoch [060/5000] | Train Loss: 0.357186\n",
      "Validation AVG Loss:     0.000334 \n",
      "\n",
      "Epoch [061/5000] | Train Loss: 0.357050\n",
      "Validation AVG Loss:     0.000334 \n",
      "\n",
      "Epoch [062/5000] | Train Loss: 0.356915\n",
      "Validation AVG Loss:     0.000334 \n",
      "\n",
      "Epoch [063/5000] | Train Loss: 0.356780\n",
      "Validation AVG Loss:     0.000334 \n",
      "\n",
      "Epoch [064/5000] | Train Loss: 0.356644\n",
      "Validation AVG Loss:     0.000334 \n",
      "\n",
      "Epoch [065/5000] | Train Loss: 0.356509\n",
      "Validation AVG Loss:     0.000334 \n",
      "\n",
      "Epoch [066/5000] | Train Loss: 0.356375\n",
      "Validation AVG Loss:     0.000334 \n",
      "\n",
      "Epoch [067/5000] | Train Loss: 0.356240\n",
      "Validation AVG Loss:     0.000334 \n",
      "\n",
      "Epoch [068/5000] | Train Loss: 0.356106\n",
      "Validation AVG Loss:     0.000333 \n",
      "\n",
      "Epoch [069/5000] | Train Loss: 0.355971\n",
      "Validation AVG Loss:     0.000333 \n",
      "\n",
      "Epoch [070/5000] | Train Loss: 0.355837\n",
      "Validation AVG Loss:     0.000333 \n",
      "\n",
      "Epoch [071/5000] | Train Loss: 0.355703\n",
      "Validation AVG Loss:     0.000333 \n",
      "\n",
      "Epoch [072/5000] | Train Loss: 0.355569\n",
      "Validation AVG Loss:     0.000333 \n",
      "\n",
      "Epoch [073/5000] | Train Loss: 0.355436\n",
      "Validation AVG Loss:     0.000333 \n",
      "\n",
      "Epoch [074/5000] | Train Loss: 0.355302\n",
      "Validation AVG Loss:     0.000333 \n",
      "\n",
      "Epoch [075/5000] | Train Loss: 0.355169\n",
      "Validation AVG Loss:     0.000333 \n",
      "\n",
      "Epoch [076/5000] | Train Loss: 0.355036\n",
      "Validation AVG Loss:     0.000332 \n",
      "\n",
      "Epoch [077/5000] | Train Loss: 0.354902\n",
      "Validation AVG Loss:     0.000332 \n",
      "\n",
      "Epoch [078/5000] | Train Loss: 0.354770\n",
      "Validation AVG Loss:     0.000332 \n",
      "\n",
      "Epoch [079/5000] | Train Loss: 0.354637\n",
      "Validation AVG Loss:     0.000332 \n",
      "\n",
      "Epoch [080/5000] | Train Loss: 0.354504\n",
      "Validation AVG Loss:     0.000332 \n",
      "\n",
      "Epoch [081/5000] | Train Loss: 0.354372\n",
      "Validation AVG Loss:     0.000332 \n",
      "\n",
      "Epoch [082/5000] | Train Loss: 0.354240\n",
      "Validation AVG Loss:     0.000332 \n",
      "\n",
      "Epoch [083/5000] | Train Loss: 0.354108\n",
      "Validation AVG Loss:     0.000332 \n",
      "\n",
      "Epoch [084/5000] | Train Loss: 0.353976\n",
      "Validation AVG Loss:     0.000332 \n",
      "\n",
      "Epoch [085/5000] | Train Loss: 0.353844\n",
      "Validation AVG Loss:     0.000331 \n",
      "\n",
      "Epoch [086/5000] | Train Loss: 0.353712\n",
      "Validation AVG Loss:     0.000331 \n",
      "\n",
      "Epoch [087/5000] | Train Loss: 0.353580\n",
      "Validation AVG Loss:     0.000331 \n",
      "\n",
      "Epoch [088/5000] | Train Loss: 0.353449\n",
      "Validation AVG Loss:     0.000331 \n",
      "\n",
      "Epoch [089/5000] | Train Loss: 0.353318\n",
      "Validation AVG Loss:     0.000331 \n",
      "\n",
      "Epoch [090/5000] | Train Loss: 0.353187\n",
      "Validation AVG Loss:     0.000331 \n",
      "\n",
      "Epoch [091/5000] | Train Loss: 0.353056\n",
      "Validation AVG Loss:     0.000331 \n",
      "\n",
      "Epoch [092/5000] | Train Loss: 0.352925\n",
      "Validation AVG Loss:     0.000331 \n",
      "\n",
      "Epoch [093/5000] | Train Loss: 0.352794\n",
      "Validation AVG Loss:     0.000331 \n",
      "\n",
      "Epoch [094/5000] | Train Loss: 0.352664\n",
      "Validation AVG Loss:     0.000330 \n",
      "\n",
      "Epoch [095/5000] | Train Loss: 0.352534\n",
      "Validation AVG Loss:     0.000330 \n",
      "\n",
      "Epoch [096/5000] | Train Loss: 0.352404\n",
      "Validation AVG Loss:     0.000330 \n",
      "\n",
      "Epoch [097/5000] | Train Loss: 0.352274\n",
      "Validation AVG Loss:     0.000330 \n",
      "\n",
      "Epoch [098/5000] | Train Loss: 0.352144\n",
      "Validation AVG Loss:     0.000330 \n",
      "\n",
      "Epoch [099/5000] | Train Loss: 0.352015\n",
      "Validation AVG Loss:     0.000330 \n",
      "\n",
      "Epoch [100/5000] | Train Loss: 0.351885\n",
      "Validation AVG Loss:     0.000330 \n",
      "\n",
      "Epoch [101/5000] | Train Loss: 0.351756\n",
      "Validation AVG Loss:     0.000330 \n",
      "\n",
      "Epoch [102/5000] | Train Loss: 0.351627\n",
      "Validation AVG Loss:     0.000329 \n",
      "\n",
      "Epoch [103/5000] | Train Loss: 0.351498\n",
      "Validation AVG Loss:     0.000329 \n",
      "\n",
      "Epoch [104/5000] | Train Loss: 0.351369\n",
      "Validation AVG Loss:     0.000329 \n",
      "\n",
      "Epoch [105/5000] | Train Loss: 0.351241\n",
      "Validation AVG Loss:     0.000329 \n",
      "\n",
      "Epoch [106/5000] | Train Loss: 0.351113\n",
      "Validation AVG Loss:     0.000329 \n",
      "\n",
      "Epoch [107/5000] | Train Loss: 0.350984\n",
      "Validation AVG Loss:     0.000329 \n",
      "\n",
      "Epoch [108/5000] | Train Loss: 0.350856\n",
      "Validation AVG Loss:     0.000329 \n",
      "\n",
      "Epoch [109/5000] | Train Loss: 0.350728\n",
      "Validation AVG Loss:     0.000329 \n",
      "\n",
      "Epoch [110/5000] | Train Loss: 0.350601\n",
      "Validation AVG Loss:     0.000329 \n",
      "\n",
      "Epoch [111/5000] | Train Loss: 0.350473\n",
      "Validation AVG Loss:     0.000328 \n",
      "\n",
      "Epoch [112/5000] | Train Loss: 0.350346\n",
      "Validation AVG Loss:     0.000328 \n",
      "\n",
      "Epoch [113/5000] | Train Loss: 0.350218\n",
      "Validation AVG Loss:     0.000328 \n",
      "\n",
      "Epoch [114/5000] | Train Loss: 0.350091\n",
      "Validation AVG Loss:     0.000328 \n",
      "\n",
      "Epoch [115/5000] | Train Loss: 0.349964\n",
      "Validation AVG Loss:     0.000328 \n",
      "\n",
      "Epoch [116/5000] | Train Loss: 0.349837\n",
      "Validation AVG Loss:     0.000328 \n",
      "\n",
      "Epoch [117/5000] | Train Loss: 0.349710\n",
      "Validation AVG Loss:     0.000328 \n",
      "\n",
      "Epoch [118/5000] | Train Loss: 0.349584\n",
      "Validation AVG Loss:     0.000328 \n",
      "\n",
      "Epoch [119/5000] | Train Loss: 0.349457\n",
      "Validation AVG Loss:     0.000328 \n",
      "\n",
      "Epoch [120/5000] | Train Loss: 0.349331\n",
      "Validation AVG Loss:     0.000327 \n",
      "\n",
      "Epoch [121/5000] | Train Loss: 0.349205\n",
      "Validation AVG Loss:     0.000327 \n",
      "\n",
      "Epoch [122/5000] | Train Loss: 0.349079\n",
      "Validation AVG Loss:     0.000327 \n",
      "\n",
      "Epoch [123/5000] | Train Loss: 0.348953\n",
      "Validation AVG Loss:     0.000327 \n",
      "\n",
      "Epoch [124/5000] | Train Loss: 0.348828\n",
      "Validation AVG Loss:     0.000327 \n",
      "\n",
      "Epoch [125/5000] | Train Loss: 0.348702\n",
      "Validation AVG Loss:     0.000327 \n",
      "\n",
      "Epoch [126/5000] | Train Loss: 0.348577\n",
      "Validation AVG Loss:     0.000327 \n",
      "\n",
      "Epoch [127/5000] | Train Loss: 0.348452\n",
      "Validation AVG Loss:     0.000327 \n",
      "\n",
      "Epoch [128/5000] | Train Loss: 0.348327\n",
      "Validation AVG Loss:     0.000327 \n",
      "\n",
      "Epoch [129/5000] | Train Loss: 0.348202\n",
      "Validation AVG Loss:     0.000326 \n",
      "\n",
      "Epoch [130/5000] | Train Loss: 0.348077\n",
      "Validation AVG Loss:     0.000326 \n",
      "\n",
      "Epoch [131/5000] | Train Loss: 0.347953\n",
      "Validation AVG Loss:     0.000326 \n",
      "\n",
      "Epoch [132/5000] | Train Loss: 0.347829\n",
      "Validation AVG Loss:     0.000326 \n",
      "\n",
      "Epoch [133/5000] | Train Loss: 0.347704\n",
      "Validation AVG Loss:     0.000326 \n",
      "\n",
      "Epoch [134/5000] | Train Loss: 0.347580\n",
      "Validation AVG Loss:     0.000326 \n",
      "\n",
      "Epoch [135/5000] | Train Loss: 0.347456\n",
      "Validation AVG Loss:     0.000326 \n",
      "\n",
      "Epoch [136/5000] | Train Loss: 0.347332\n",
      "Validation AVG Loss:     0.000326 \n",
      "\n",
      "Epoch [137/5000] | Train Loss: 0.347209\n",
      "Validation AVG Loss:     0.000326 \n",
      "\n",
      "Epoch [138/5000] | Train Loss: 0.347085\n",
      "Validation AVG Loss:     0.000325 \n",
      "\n",
      "Epoch [139/5000] | Train Loss: 0.346962\n",
      "Validation AVG Loss:     0.000325 \n",
      "\n",
      "Epoch [140/5000] | Train Loss: 0.346839\n",
      "Validation AVG Loss:     0.000325 \n",
      "\n",
      "Epoch [141/5000] | Train Loss: 0.346716\n",
      "Validation AVG Loss:     0.000325 \n",
      "\n",
      "Epoch [142/5000] | Train Loss: 0.346593\n",
      "Validation AVG Loss:     0.000325 \n",
      "\n",
      "Epoch [143/5000] | Train Loss: 0.346470\n",
      "Validation AVG Loss:     0.000325 \n",
      "\n",
      "Epoch [144/5000] | Train Loss: 0.346348\n",
      "Validation AVG Loss:     0.000325 \n",
      "\n",
      "Epoch [145/5000] | Train Loss: 0.346225\n",
      "Validation AVG Loss:     0.000325 \n",
      "\n",
      "Epoch [146/5000] | Train Loss: 0.346103\n",
      "Validation AVG Loss:     0.000325 \n",
      "\n",
      "Epoch [147/5000] | Train Loss: 0.345981\n",
      "Validation AVG Loss:     0.000324 \n",
      "\n",
      "Epoch [148/5000] | Train Loss: 0.345859\n",
      "Validation AVG Loss:     0.000324 \n",
      "\n",
      "Epoch [149/5000] | Train Loss: 0.345737\n",
      "Validation AVG Loss:     0.000324 \n",
      "\n",
      "Epoch [150/5000] | Train Loss: 0.345615\n",
      "Validation AVG Loss:     0.000324 \n",
      "\n",
      "Epoch [151/5000] | Train Loss: 0.345493\n",
      "Validation AVG Loss:     0.000324 \n",
      "\n",
      "Epoch [152/5000] | Train Loss: 0.345372\n",
      "Validation AVG Loss:     0.000324 \n",
      "\n",
      "Epoch [153/5000] | Train Loss: 0.345250\n",
      "Validation AVG Loss:     0.000324 \n",
      "\n",
      "Epoch [154/5000] | Train Loss: 0.345129\n",
      "Validation AVG Loss:     0.000324 \n",
      "\n",
      "Epoch [155/5000] | Train Loss: 0.345008\n",
      "Validation AVG Loss:     0.000324 \n",
      "\n",
      "Epoch [156/5000] | Train Loss: 0.344887\n",
      "Validation AVG Loss:     0.000324 \n",
      "\n",
      "Epoch [157/5000] | Train Loss: 0.344766\n",
      "Validation AVG Loss:     0.000323 \n",
      "\n",
      "Epoch [158/5000] | Train Loss: 0.344645\n",
      "Validation AVG Loss:     0.000323 \n",
      "\n",
      "Epoch [159/5000] | Train Loss: 0.344525\n",
      "Validation AVG Loss:     0.000323 \n",
      "\n",
      "Epoch [160/5000] | Train Loss: 0.344404\n",
      "Validation AVG Loss:     0.000323 \n",
      "\n",
      "Epoch [161/5000] | Train Loss: 0.344284\n",
      "Validation AVG Loss:     0.000323 \n",
      "\n",
      "Epoch [162/5000] | Train Loss: 0.344164\n",
      "Validation AVG Loss:     0.000323 \n",
      "\n",
      "Epoch [163/5000] | Train Loss: 0.344044\n",
      "Validation AVG Loss:     0.000323 \n",
      "\n",
      "Epoch [164/5000] | Train Loss: 0.343924\n",
      "Validation AVG Loss:     0.000323 \n",
      "\n",
      "Epoch [165/5000] | Train Loss: 0.343804\n",
      "Validation AVG Loss:     0.000323 \n",
      "\n",
      "Epoch [166/5000] | Train Loss: 0.343684\n",
      "Validation AVG Loss:     0.000322 \n",
      "\n",
      "Epoch [167/5000] | Train Loss: 0.343565\n",
      "Validation AVG Loss:     0.000322 \n",
      "\n",
      "Epoch [168/5000] | Train Loss: 0.343445\n",
      "Validation AVG Loss:     0.000322 \n",
      "\n",
      "Epoch [169/5000] | Train Loss: 0.343326\n",
      "Validation AVG Loss:     0.000322 \n",
      "\n",
      "Epoch [170/5000] | Train Loss: 0.343207\n",
      "Validation AVG Loss:     0.000322 \n",
      "\n",
      "Epoch [171/5000] | Train Loss: 0.343088\n",
      "Validation AVG Loss:     0.000322 \n",
      "\n",
      "Epoch [172/5000] | Train Loss: 0.342969\n",
      "Validation AVG Loss:     0.000322 \n",
      "\n",
      "Epoch [173/5000] | Train Loss: 0.342850\n",
      "Validation AVG Loss:     0.000322 \n",
      "\n",
      "Epoch [174/5000] | Train Loss: 0.342731\n",
      "Validation AVG Loss:     0.000322 \n",
      "\n",
      "Epoch [175/5000] | Train Loss: 0.342613\n",
      "Validation AVG Loss:     0.000321 \n",
      "\n",
      "Epoch [176/5000] | Train Loss: 0.342494\n",
      "Validation AVG Loss:     0.000321 \n",
      "\n",
      "Epoch [177/5000] | Train Loss: 0.342376\n",
      "Validation AVG Loss:     0.000321 \n",
      "\n",
      "Epoch [178/5000] | Train Loss: 0.342258\n",
      "Validation AVG Loss:     0.000321 \n",
      "\n",
      "Epoch [179/5000] | Train Loss: 0.342140\n",
      "Validation AVG Loss:     0.000321 \n",
      "\n",
      "Epoch [180/5000] | Train Loss: 0.342022\n",
      "Validation AVG Loss:     0.000321 \n",
      "\n",
      "Epoch [181/5000] | Train Loss: 0.341904\n",
      "Validation AVG Loss:     0.000321 \n",
      "\n",
      "Epoch [182/5000] | Train Loss: 0.341786\n",
      "Validation AVG Loss:     0.000321 \n",
      "\n",
      "Epoch [183/5000] | Train Loss: 0.341669\n",
      "Validation AVG Loss:     0.000321 \n",
      "\n",
      "Epoch [184/5000] | Train Loss: 0.341551\n",
      "Validation AVG Loss:     0.000321 \n",
      "\n",
      "Epoch [185/5000] | Train Loss: 0.341434\n",
      "Validation AVG Loss:     0.000320 \n",
      "\n",
      "Epoch [186/5000] | Train Loss: 0.341316\n",
      "Validation AVG Loss:     0.000320 \n",
      "\n",
      "Epoch [187/5000] | Train Loss: 0.341199\n",
      "Validation AVG Loss:     0.000320 \n",
      "\n",
      "Epoch [188/5000] | Train Loss: 0.341082\n",
      "Validation AVG Loss:     0.000320 \n",
      "\n",
      "Epoch [189/5000] | Train Loss: 0.340965\n",
      "Validation AVG Loss:     0.000320 \n",
      "\n",
      "Epoch [190/5000] | Train Loss: 0.340848\n",
      "Validation AVG Loss:     0.000320 \n",
      "\n",
      "Epoch [191/5000] | Train Loss: 0.340731\n",
      "Validation AVG Loss:     0.000320 \n",
      "\n",
      "Epoch [192/5000] | Train Loss: 0.340615\n",
      "Validation AVG Loss:     0.000320 \n",
      "\n",
      "Epoch [193/5000] | Train Loss: 0.340498\n",
      "Validation AVG Loss:     0.000320 \n",
      "\n",
      "Epoch [194/5000] | Train Loss: 0.340381\n",
      "Validation AVG Loss:     0.000319 \n",
      "\n",
      "Epoch [195/5000] | Train Loss: 0.340265\n",
      "Validation AVG Loss:     0.000319 \n",
      "\n",
      "Epoch [196/5000] | Train Loss: 0.340149\n",
      "Validation AVG Loss:     0.000319 \n",
      "\n",
      "Epoch [197/5000] | Train Loss: 0.340032\n",
      "Validation AVG Loss:     0.000319 \n",
      "\n",
      "Epoch [198/5000] | Train Loss: 0.339916\n",
      "Validation AVG Loss:     0.000319 \n",
      "\n",
      "Epoch [199/5000] | Train Loss: 0.339800\n",
      "Validation AVG Loss:     0.000319 \n",
      "\n",
      "Epoch [200/5000] | Train Loss: 0.339684\n",
      "Validation AVG Loss:     0.000319 \n",
      "\n",
      "Epoch [201/5000] | Train Loss: 0.339568\n",
      "Validation AVG Loss:     0.000319 \n",
      "\n",
      "Epoch [202/5000] | Train Loss: 0.339453\n",
      "Validation AVG Loss:     0.000319 \n",
      "\n",
      "Epoch [203/5000] | Train Loss: 0.339337\n",
      "Validation AVG Loss:     0.000319 \n",
      "\n",
      "Epoch [204/5000] | Train Loss: 0.339221\n",
      "Validation AVG Loss:     0.000318 \n",
      "\n",
      "Epoch [205/5000] | Train Loss: 0.339106\n",
      "Validation AVG Loss:     0.000318 \n",
      "\n",
      "Epoch [206/5000] | Train Loss: 0.338991\n",
      "Validation AVG Loss:     0.000318 \n",
      "\n",
      "Epoch [207/5000] | Train Loss: 0.338875\n",
      "Validation AVG Loss:     0.000318 \n",
      "\n",
      "Epoch [208/5000] | Train Loss: 0.338760\n",
      "Validation AVG Loss:     0.000318 \n",
      "\n",
      "Epoch [209/5000] | Train Loss: 0.338645\n",
      "Validation AVG Loss:     0.000318 \n",
      "\n",
      "Epoch [210/5000] | Train Loss: 0.338530\n",
      "Validation AVG Loss:     0.000318 \n",
      "\n",
      "Epoch [211/5000] | Train Loss: 0.338415\n",
      "Validation AVG Loss:     0.000318 \n",
      "\n",
      "Epoch [212/5000] | Train Loss: 0.338301\n",
      "Validation AVG Loss:     0.000318 \n",
      "\n",
      "Epoch [213/5000] | Train Loss: 0.338186\n",
      "Validation AVG Loss:     0.000318 \n",
      "\n",
      "Epoch [214/5000] | Train Loss: 0.338072\n",
      "Validation AVG Loss:     0.000317 \n",
      "\n",
      "Epoch [215/5000] | Train Loss: 0.337957\n",
      "Validation AVG Loss:     0.000317 \n",
      "\n",
      "Epoch [216/5000] | Train Loss: 0.337843\n",
      "Validation AVG Loss:     0.000317 \n",
      "\n",
      "Epoch [217/5000] | Train Loss: 0.337729\n",
      "Validation AVG Loss:     0.000317 \n",
      "\n",
      "Epoch [218/5000] | Train Loss: 0.337614\n",
      "Validation AVG Loss:     0.000317 \n",
      "\n",
      "Epoch [219/5000] | Train Loss: 0.337500\n",
      "Validation AVG Loss:     0.000317 \n",
      "\n",
      "Epoch [220/5000] | Train Loss: 0.337386\n",
      "Validation AVG Loss:     0.000317 \n",
      "\n",
      "Epoch [221/5000] | Train Loss: 0.337273\n",
      "Validation AVG Loss:     0.000317 \n",
      "\n",
      "Epoch [222/5000] | Train Loss: 0.337159\n",
      "Validation AVG Loss:     0.000317 \n",
      "\n",
      "Epoch [223/5000] | Train Loss: 0.337045\n",
      "Validation AVG Loss:     0.000316 \n",
      "\n",
      "Epoch [224/5000] | Train Loss: 0.336931\n",
      "Validation AVG Loss:     0.000316 \n",
      "\n",
      "Epoch [225/5000] | Train Loss: 0.336818\n",
      "Validation AVG Loss:     0.000316 \n",
      "\n",
      "Epoch [226/5000] | Train Loss: 0.336705\n",
      "Validation AVG Loss:     0.000316 \n",
      "\n",
      "Epoch [227/5000] | Train Loss: 0.336591\n",
      "Validation AVG Loss:     0.000316 \n",
      "\n",
      "Epoch [228/5000] | Train Loss: 0.336478\n",
      "Validation AVG Loss:     0.000316 \n",
      "\n",
      "Epoch [229/5000] | Train Loss: 0.336365\n",
      "Validation AVG Loss:     0.000316 \n",
      "\n",
      "Epoch [230/5000] | Train Loss: 0.336252\n",
      "Validation AVG Loss:     0.000316 \n",
      "\n",
      "Epoch [231/5000] | Train Loss: 0.336139\n",
      "Validation AVG Loss:     0.000316 \n",
      "\n",
      "Epoch [232/5000] | Train Loss: 0.336026\n",
      "Validation AVG Loss:     0.000316 \n",
      "\n",
      "Epoch [233/5000] | Train Loss: 0.335913\n",
      "Validation AVG Loss:     0.000315 \n",
      "\n",
      "Epoch [234/5000] | Train Loss: 0.335800\n",
      "Validation AVG Loss:     0.000315 \n",
      "\n",
      "Epoch [235/5000] | Train Loss: 0.335688\n",
      "Validation AVG Loss:     0.000315 \n",
      "\n",
      "Epoch [236/5000] | Train Loss: 0.335575\n",
      "Validation AVG Loss:     0.000315 \n",
      "\n",
      "Epoch [237/5000] | Train Loss: 0.335463\n",
      "Validation AVG Loss:     0.000315 \n",
      "\n",
      "Epoch [238/5000] | Train Loss: 0.335351\n",
      "Validation AVG Loss:     0.000315 \n",
      "\n",
      "Epoch [239/5000] | Train Loss: 0.335238\n",
      "Validation AVG Loss:     0.000315 \n",
      "\n",
      "Epoch [240/5000] | Train Loss: 0.335126\n",
      "Validation AVG Loss:     0.000315 \n",
      "\n",
      "Epoch [241/5000] | Train Loss: 0.335014\n",
      "Validation AVG Loss:     0.000315 \n",
      "\n",
      "Epoch [242/5000] | Train Loss: 0.334902\n",
      "Validation AVG Loss:     0.000315 \n",
      "\n",
      "Epoch [243/5000] | Train Loss: 0.334790\n",
      "Validation AVG Loss:     0.000314 \n",
      "\n",
      "Epoch [244/5000] | Train Loss: 0.334679\n",
      "Validation AVG Loss:     0.000314 \n",
      "\n",
      "Epoch [245/5000] | Train Loss: 0.334567\n",
      "Validation AVG Loss:     0.000314 \n",
      "\n",
      "Epoch [246/5000] | Train Loss: 0.334456\n",
      "Validation AVG Loss:     0.000314 \n",
      "\n",
      "Epoch [247/5000] | Train Loss: 0.334344\n",
      "Validation AVG Loss:     0.000314 \n",
      "\n",
      "Epoch [248/5000] | Train Loss: 0.334233\n",
      "Validation AVG Loss:     0.000314 \n",
      "\n",
      "Epoch [249/5000] | Train Loss: 0.334121\n",
      "Validation AVG Loss:     0.000314 \n",
      "\n",
      "Epoch [250/5000] | Train Loss: 0.334010\n",
      "Validation AVG Loss:     0.000314 \n",
      "\n",
      "Epoch [251/5000] | Train Loss: 0.333899\n",
      "Validation AVG Loss:     0.000314 \n",
      "\n",
      "Epoch [252/5000] | Train Loss: 0.333788\n",
      "Validation AVG Loss:     0.000314 \n",
      "\n",
      "Epoch [253/5000] | Train Loss: 0.333677\n",
      "Validation AVG Loss:     0.000313 \n",
      "\n",
      "Epoch [254/5000] | Train Loss: 0.333566\n",
      "Validation AVG Loss:     0.000313 \n",
      "\n",
      "Epoch [255/5000] | Train Loss: 0.333455\n",
      "Validation AVG Loss:     0.000313 \n",
      "\n",
      "Epoch [256/5000] | Train Loss: 0.333344\n",
      "Validation AVG Loss:     0.000313 \n",
      "\n",
      "Epoch [257/5000] | Train Loss: 0.333234\n",
      "Validation AVG Loss:     0.000313 \n",
      "\n",
      "Epoch [258/5000] | Train Loss: 0.333123\n",
      "Validation AVG Loss:     0.000313 \n",
      "\n",
      "Epoch [259/5000] | Train Loss: 0.333012\n",
      "Validation AVG Loss:     0.000313 \n",
      "\n",
      "Epoch [260/5000] | Train Loss: 0.332902\n",
      "Validation AVG Loss:     0.000313 \n",
      "\n",
      "Epoch [261/5000] | Train Loss: 0.332791\n",
      "Validation AVG Loss:     0.000313 \n",
      "\n",
      "Epoch [262/5000] | Train Loss: 0.332681\n",
      "Validation AVG Loss:     0.000313 \n",
      "\n",
      "Epoch [263/5000] | Train Loss: 0.332571\n",
      "Validation AVG Loss:     0.000312 \n",
      "\n",
      "Epoch [264/5000] | Train Loss: 0.332461\n",
      "Validation AVG Loss:     0.000312 \n",
      "\n",
      "Epoch [265/5000] | Train Loss: 0.332350\n",
      "Validation AVG Loss:     0.000312 \n",
      "\n",
      "Epoch [266/5000] | Train Loss: 0.332240\n",
      "Validation AVG Loss:     0.000312 \n",
      "\n",
      "Epoch [267/5000] | Train Loss: 0.332130\n",
      "Validation AVG Loss:     0.000312 \n",
      "\n",
      "Epoch [268/5000] | Train Loss: 0.332021\n",
      "Validation AVG Loss:     0.000312 \n",
      "\n",
      "Epoch [269/5000] | Train Loss: 0.331911\n",
      "Validation AVG Loss:     0.000312 \n",
      "\n",
      "Epoch [270/5000] | Train Loss: 0.331801\n",
      "Validation AVG Loss:     0.000312 \n",
      "\n",
      "Epoch [271/5000] | Train Loss: 0.331691\n",
      "Validation AVG Loss:     0.000312 \n",
      "\n",
      "Epoch [272/5000] | Train Loss: 0.331582\n",
      "Validation AVG Loss:     0.000312 \n",
      "\n",
      "Epoch [273/5000] | Train Loss: 0.331472\n",
      "Validation AVG Loss:     0.000311 \n",
      "\n",
      "Epoch [274/5000] | Train Loss: 0.331363\n",
      "Validation AVG Loss:     0.000311 \n",
      "\n",
      "Epoch [275/5000] | Train Loss: 0.331254\n",
      "Validation AVG Loss:     0.000311 \n",
      "\n",
      "Epoch [276/5000] | Train Loss: 0.331145\n",
      "Validation AVG Loss:     0.000311 \n",
      "\n",
      "Epoch [277/5000] | Train Loss: 0.331035\n",
      "Validation AVG Loss:     0.000311 \n",
      "\n",
      "Epoch [278/5000] | Train Loss: 0.330926\n",
      "Validation AVG Loss:     0.000311 \n",
      "\n",
      "Epoch [279/5000] | Train Loss: 0.330817\n",
      "Validation AVG Loss:     0.000311 \n",
      "\n",
      "Epoch [280/5000] | Train Loss: 0.330709\n",
      "Validation AVG Loss:     0.000311 \n",
      "\n",
      "Epoch [281/5000] | Train Loss: 0.330600\n",
      "Validation AVG Loss:     0.000311 \n",
      "\n",
      "Epoch [282/5000] | Train Loss: 0.330491\n",
      "Validation AVG Loss:     0.000311 \n",
      "\n",
      "Epoch [283/5000] | Train Loss: 0.330383\n",
      "Validation AVG Loss:     0.000310 \n",
      "\n",
      "Epoch [284/5000] | Train Loss: 0.330274\n",
      "Validation AVG Loss:     0.000310 \n",
      "\n",
      "Epoch [285/5000] | Train Loss: 0.330166\n",
      "Validation AVG Loss:     0.000310 \n",
      "\n",
      "Epoch [286/5000] | Train Loss: 0.330057\n",
      "Validation AVG Loss:     0.000310 \n",
      "\n",
      "Epoch [287/5000] | Train Loss: 0.329949\n",
      "Validation AVG Loss:     0.000310 \n",
      "\n",
      "Epoch [288/5000] | Train Loss: 0.329841\n",
      "Validation AVG Loss:     0.000310 \n",
      "\n",
      "Epoch [289/5000] | Train Loss: 0.329732\n",
      "Validation AVG Loss:     0.000310 \n",
      "\n",
      "Epoch [290/5000] | Train Loss: 0.329624\n",
      "Validation AVG Loss:     0.000310 \n",
      "\n",
      "Epoch [291/5000] | Train Loss: 0.329516\n",
      "Validation AVG Loss:     0.000310 \n",
      "\n",
      "Epoch [292/5000] | Train Loss: 0.329408\n",
      "Validation AVG Loss:     0.000310 \n",
      "\n",
      "Epoch [293/5000] | Train Loss: 0.329300\n",
      "Validation AVG Loss:     0.000309 \n",
      "\n",
      "Epoch [294/5000] | Train Loss: 0.329193\n",
      "Validation AVG Loss:     0.000309 \n",
      "\n",
      "Epoch [295/5000] | Train Loss: 0.329085\n",
      "Validation AVG Loss:     0.000309 \n",
      "\n",
      "Epoch [296/5000] | Train Loss: 0.328977\n",
      "Validation AVG Loss:     0.000309 \n",
      "\n",
      "Epoch [297/5000] | Train Loss: 0.328869\n",
      "Validation AVG Loss:     0.000309 \n",
      "\n",
      "Epoch [298/5000] | Train Loss: 0.328762\n",
      "Validation AVG Loss:     0.000309 \n",
      "\n",
      "Epoch [299/5000] | Train Loss: 0.328654\n",
      "Validation AVG Loss:     0.000309 \n",
      "\n",
      "Epoch [300/5000] | Train Loss: 0.328547\n",
      "Validation AVG Loss:     0.000309 \n",
      "\n",
      "Epoch [301/5000] | Train Loss: 0.328440\n",
      "Validation AVG Loss:     0.000309 \n",
      "\n",
      "Epoch [302/5000] | Train Loss: 0.328332\n",
      "Validation AVG Loss:     0.000309 \n",
      "\n",
      "Epoch [303/5000] | Train Loss: 0.328225\n",
      "Validation AVG Loss:     0.000309 \n",
      "\n",
      "Epoch [304/5000] | Train Loss: 0.328118\n",
      "Validation AVG Loss:     0.000308 \n",
      "\n",
      "Epoch [305/5000] | Train Loss: 0.328011\n",
      "Validation AVG Loss:     0.000308 \n",
      "\n",
      "Epoch [306/5000] | Train Loss: 0.327904\n",
      "Validation AVG Loss:     0.000308 \n",
      "\n",
      "Epoch [307/5000] | Train Loss: 0.327798\n",
      "Validation AVG Loss:     0.000308 \n",
      "\n",
      "Epoch [308/5000] | Train Loss: 0.327691\n",
      "Validation AVG Loss:     0.000308 \n",
      "\n",
      "Epoch [309/5000] | Train Loss: 0.327584\n",
      "Validation AVG Loss:     0.000308 \n",
      "\n",
      "Epoch [310/5000] | Train Loss: 0.327478\n",
      "Validation AVG Loss:     0.000308 \n",
      "\n",
      "Epoch [311/5000] | Train Loss: 0.327371\n",
      "Validation AVG Loss:     0.000308 \n",
      "\n",
      "Epoch [312/5000] | Train Loss: 0.327265\n",
      "Validation AVG Loss:     0.000308 \n",
      "\n",
      "Epoch [313/5000] | Train Loss: 0.327158\n",
      "Validation AVG Loss:     0.000308 \n",
      "\n",
      "Epoch [314/5000] | Train Loss: 0.327052\n",
      "Validation AVG Loss:     0.000307 \n",
      "\n",
      "Epoch [315/5000] | Train Loss: 0.326946\n",
      "Validation AVG Loss:     0.000307 \n",
      "\n",
      "Epoch [316/5000] | Train Loss: 0.326840\n",
      "Validation AVG Loss:     0.000307 \n",
      "\n",
      "Epoch [317/5000] | Train Loss: 0.326734\n",
      "Validation AVG Loss:     0.000307 \n",
      "\n",
      "Epoch [318/5000] | Train Loss: 0.326628\n",
      "Validation AVG Loss:     0.000307 \n",
      "\n",
      "Epoch [319/5000] | Train Loss: 0.326522\n",
      "Validation AVG Loss:     0.000307 \n",
      "\n",
      "Epoch [320/5000] | Train Loss: 0.326416\n",
      "Validation AVG Loss:     0.000307 \n",
      "\n",
      "Epoch [321/5000] | Train Loss: 0.326310\n",
      "Validation AVG Loss:     0.000307 \n",
      "\n",
      "Epoch [322/5000] | Train Loss: 0.326204\n",
      "Validation AVG Loss:     0.000307 \n",
      "\n",
      "Epoch [323/5000] | Train Loss: 0.326098\n",
      "Validation AVG Loss:     0.000307 \n",
      "\n",
      "Epoch [324/5000] | Train Loss: 0.325993\n",
      "Validation AVG Loss:     0.000306 \n",
      "\n",
      "Epoch [325/5000] | Train Loss: 0.325887\n",
      "Validation AVG Loss:     0.000306 \n",
      "\n",
      "Epoch [326/5000] | Train Loss: 0.325782\n",
      "Validation AVG Loss:     0.000306 \n",
      "\n",
      "Epoch [327/5000] | Train Loss: 0.325676\n",
      "Validation AVG Loss:     0.000306 \n",
      "\n",
      "Epoch [328/5000] | Train Loss: 0.325571\n",
      "Validation AVG Loss:     0.000306 \n",
      "\n",
      "Epoch [329/5000] | Train Loss: 0.325465\n",
      "Validation AVG Loss:     0.000306 \n",
      "\n",
      "Epoch [330/5000] | Train Loss: 0.325360\n",
      "Validation AVG Loss:     0.000306 \n",
      "\n",
      "Epoch [331/5000] | Train Loss: 0.325255\n",
      "Validation AVG Loss:     0.000306 \n",
      "\n",
      "Epoch [332/5000] | Train Loss: 0.325150\n",
      "Validation AVG Loss:     0.000306 \n",
      "\n",
      "Epoch [333/5000] | Train Loss: 0.325045\n",
      "Validation AVG Loss:     0.000306 \n",
      "\n",
      "Epoch [334/5000] | Train Loss: 0.324940\n",
      "Validation AVG Loss:     0.000306 \n",
      "\n",
      "Epoch [335/5000] | Train Loss: 0.324835\n",
      "Validation AVG Loss:     0.000305 \n",
      "\n",
      "Epoch [336/5000] | Train Loss: 0.324730\n",
      "Validation AVG Loss:     0.000305 \n",
      "\n",
      "Epoch [337/5000] | Train Loss: 0.324625\n",
      "Validation AVG Loss:     0.000305 \n",
      "\n",
      "Epoch [338/5000] | Train Loss: 0.324520\n",
      "Validation AVG Loss:     0.000305 \n",
      "\n",
      "Epoch [339/5000] | Train Loss: 0.324416\n",
      "Validation AVG Loss:     0.000305 \n",
      "\n",
      "Epoch [340/5000] | Train Loss: 0.324311\n",
      "Validation AVG Loss:     0.000305 \n",
      "\n",
      "Epoch [341/5000] | Train Loss: 0.324207\n",
      "Validation AVG Loss:     0.000305 \n",
      "\n",
      "Epoch [342/5000] | Train Loss: 0.324102\n",
      "Validation AVG Loss:     0.000305 \n",
      "\n",
      "Epoch [343/5000] | Train Loss: 0.323998\n",
      "Validation AVG Loss:     0.000305 \n",
      "\n",
      "Epoch [344/5000] | Train Loss: 0.323893\n",
      "Validation AVG Loss:     0.000305 \n",
      "\n",
      "Epoch [345/5000] | Train Loss: 0.323789\n",
      "Validation AVG Loss:     0.000304 \n",
      "\n",
      "Epoch [346/5000] | Train Loss: 0.323685\n",
      "Validation AVG Loss:     0.000304 \n",
      "\n",
      "Epoch [347/5000] | Train Loss: 0.323580\n",
      "Validation AVG Loss:     0.000304 \n",
      "\n",
      "Epoch [348/5000] | Train Loss: 0.323476\n",
      "Validation AVG Loss:     0.000304 \n",
      "\n",
      "Epoch [349/5000] | Train Loss: 0.323372\n",
      "Validation AVG Loss:     0.000304 \n",
      "\n",
      "Epoch [350/5000] | Train Loss: 0.323268\n",
      "Validation AVG Loss:     0.000304 \n",
      "\n",
      "Epoch [351/5000] | Train Loss: 0.323164\n",
      "Validation AVG Loss:     0.000304 \n",
      "\n",
      "Epoch [352/5000] | Train Loss: 0.323060\n",
      "Validation AVG Loss:     0.000304 \n",
      "\n",
      "Epoch [353/5000] | Train Loss: 0.322956\n",
      "Validation AVG Loss:     0.000304 \n",
      "\n",
      "Epoch [354/5000] | Train Loss: 0.322852\n",
      "Validation AVG Loss:     0.000304 \n",
      "\n",
      "Epoch [355/5000] | Train Loss: 0.322749\n",
      "Validation AVG Loss:     0.000303 \n",
      "\n",
      "Epoch [356/5000] | Train Loss: 0.322645\n",
      "Validation AVG Loss:     0.000303 \n",
      "\n",
      "Epoch [357/5000] | Train Loss: 0.322541\n",
      "Validation AVG Loss:     0.000303 \n",
      "\n",
      "Epoch [358/5000] | Train Loss: 0.322438\n",
      "Validation AVG Loss:     0.000303 \n",
      "\n",
      "Epoch [359/5000] | Train Loss: 0.322334\n",
      "Validation AVG Loss:     0.000303 \n",
      "\n",
      "Epoch [360/5000] | Train Loss: 0.322231\n",
      "Validation AVG Loss:     0.000303 \n",
      "\n",
      "Epoch [361/5000] | Train Loss: 0.322127\n",
      "Validation AVG Loss:     0.000303 \n",
      "\n",
      "Epoch [362/5000] | Train Loss: 0.322024\n",
      "Validation AVG Loss:     0.000303 \n",
      "\n",
      "Epoch [363/5000] | Train Loss: 0.321921\n",
      "Validation AVG Loss:     0.000303 \n",
      "\n",
      "Epoch [364/5000] | Train Loss: 0.321818\n",
      "Validation AVG Loss:     0.000303 \n",
      "\n",
      "Epoch [365/5000] | Train Loss: 0.321714\n",
      "Validation AVG Loss:     0.000303 \n",
      "\n",
      "Epoch [366/5000] | Train Loss: 0.321611\n",
      "Validation AVG Loss:     0.000302 \n",
      "\n",
      "Epoch [367/5000] | Train Loss: 0.321508\n",
      "Validation AVG Loss:     0.000302 \n",
      "\n",
      "Epoch [368/5000] | Train Loss: 0.321405\n",
      "Validation AVG Loss:     0.000302 \n",
      "\n",
      "Epoch [369/5000] | Train Loss: 0.321302\n",
      "Validation AVG Loss:     0.000302 \n",
      "\n",
      "Epoch [370/5000] | Train Loss: 0.321199\n",
      "Validation AVG Loss:     0.000302 \n",
      "\n",
      "Epoch [371/5000] | Train Loss: 0.321097\n",
      "Validation AVG Loss:     0.000302 \n",
      "\n",
      "Epoch [372/5000] | Train Loss: 0.320994\n",
      "Validation AVG Loss:     0.000302 \n",
      "\n",
      "Epoch [373/5000] | Train Loss: 0.320891\n",
      "Validation AVG Loss:     0.000302 \n",
      "\n",
      "Epoch [374/5000] | Train Loss: 0.320788\n",
      "Validation AVG Loss:     0.000302 \n",
      "\n",
      "Epoch [375/5000] | Train Loss: 0.320686\n",
      "Validation AVG Loss:     0.000302 \n",
      "\n",
      "Epoch [376/5000] | Train Loss: 0.320583\n",
      "Validation AVG Loss:     0.000302 \n",
      "\n",
      "Epoch [377/5000] | Train Loss: 0.320480\n",
      "Validation AVG Loss:     0.000301 \n",
      "\n",
      "Epoch [378/5000] | Train Loss: 0.320378\n",
      "Validation AVG Loss:     0.000301 \n",
      "\n",
      "Epoch [379/5000] | Train Loss: 0.320275\n",
      "Validation AVG Loss:     0.000301 \n",
      "\n",
      "Epoch [380/5000] | Train Loss: 0.320173\n",
      "Validation AVG Loss:     0.000301 \n",
      "\n",
      "Epoch [381/5000] | Train Loss: 0.320071\n",
      "Validation AVG Loss:     0.000301 \n",
      "\n",
      "Epoch [382/5000] | Train Loss: 0.319968\n",
      "Validation AVG Loss:     0.000301 \n",
      "\n",
      "Epoch [383/5000] | Train Loss: 0.319866\n",
      "Validation AVG Loss:     0.000301 \n",
      "\n",
      "Epoch [384/5000] | Train Loss: 0.319764\n",
      "Validation AVG Loss:     0.000301 \n",
      "\n",
      "Epoch [385/5000] | Train Loss: 0.319662\n",
      "Validation AVG Loss:     0.000301 \n",
      "\n",
      "Epoch [386/5000] | Train Loss: 0.319560\n",
      "Validation AVG Loss:     0.000301 \n",
      "\n",
      "Epoch [387/5000] | Train Loss: 0.319458\n",
      "Validation AVG Loss:     0.000300 \n",
      "\n",
      "Epoch [388/5000] | Train Loss: 0.319356\n",
      "Validation AVG Loss:     0.000300 \n",
      "\n",
      "Epoch [389/5000] | Train Loss: 0.319254\n",
      "Validation AVG Loss:     0.000300 \n",
      "\n",
      "Epoch [390/5000] | Train Loss: 0.319152\n",
      "Validation AVG Loss:     0.000300 \n",
      "\n",
      "Epoch [391/5000] | Train Loss: 0.319050\n",
      "Validation AVG Loss:     0.000300 \n",
      "\n",
      "Epoch [392/5000] | Train Loss: 0.318949\n",
      "Validation AVG Loss:     0.000300 \n",
      "\n",
      "Epoch [393/5000] | Train Loss: 0.318847\n",
      "Validation AVG Loss:     0.000300 \n",
      "\n",
      "Epoch [394/5000] | Train Loss: 0.318745\n",
      "Validation AVG Loss:     0.000300 \n",
      "\n",
      "Epoch [395/5000] | Train Loss: 0.318644\n",
      "Validation AVG Loss:     0.000300 \n",
      "\n",
      "Epoch [396/5000] | Train Loss: 0.318542\n",
      "Validation AVG Loss:     0.000300 \n",
      "\n",
      "Epoch [397/5000] | Train Loss: 0.318441\n",
      "Validation AVG Loss:     0.000300 \n",
      "\n",
      "Epoch [398/5000] | Train Loss: 0.318339\n",
      "Validation AVG Loss:     0.000299 \n",
      "\n",
      "Epoch [399/5000] | Train Loss: 0.318238\n",
      "Validation AVG Loss:     0.000299 \n",
      "\n",
      "Epoch [400/5000] | Train Loss: 0.318136\n",
      "Validation AVG Loss:     0.000299 \n",
      "\n",
      "Epoch [401/5000] | Train Loss: 0.318035\n",
      "Validation AVG Loss:     0.000299 \n",
      "\n",
      "Epoch [402/5000] | Train Loss: 0.317934\n",
      "Validation AVG Loss:     0.000299 \n",
      "\n",
      "Epoch [403/5000] | Train Loss: 0.317833\n",
      "Validation AVG Loss:     0.000299 \n",
      "\n",
      "Epoch [404/5000] | Train Loss: 0.317732\n",
      "Validation AVG Loss:     0.000299 \n",
      "\n",
      "Epoch [405/5000] | Train Loss: 0.317630\n",
      "Validation AVG Loss:     0.000299 \n",
      "\n",
      "Epoch [406/5000] | Train Loss: 0.317529\n",
      "Validation AVG Loss:     0.000299 \n",
      "\n",
      "Epoch [407/5000] | Train Loss: 0.317428\n",
      "Validation AVG Loss:     0.000299 \n",
      "\n",
      "Epoch [408/5000] | Train Loss: 0.317327\n",
      "Validation AVG Loss:     0.000299 \n",
      "\n",
      "Epoch [409/5000] | Train Loss: 0.317226\n",
      "Validation AVG Loss:     0.000298 \n",
      "\n",
      "Epoch [410/5000] | Train Loss: 0.317125\n",
      "Validation AVG Loss:     0.000298 \n",
      "\n",
      "Epoch [411/5000] | Train Loss: 0.317025\n",
      "Validation AVG Loss:     0.000298 \n",
      "\n",
      "Epoch [412/5000] | Train Loss: 0.316924\n",
      "Validation AVG Loss:     0.000298 \n",
      "\n",
      "Epoch [413/5000] | Train Loss: 0.316823\n",
      "Validation AVG Loss:     0.000298 \n",
      "\n",
      "Epoch [414/5000] | Train Loss: 0.316722\n",
      "Validation AVG Loss:     0.000298 \n",
      "\n",
      "Epoch [415/5000] | Train Loss: 0.316621\n",
      "Validation AVG Loss:     0.000298 \n",
      "\n",
      "Epoch [416/5000] | Train Loss: 0.316521\n",
      "Validation AVG Loss:     0.000298 \n",
      "\n",
      "Epoch [417/5000] | Train Loss: 0.316420\n",
      "Validation AVG Loss:     0.000298 \n",
      "\n",
      "Epoch [418/5000] | Train Loss: 0.316320\n",
      "Validation AVG Loss:     0.000298 \n",
      "\n",
      "Epoch [419/5000] | Train Loss: 0.316219\n",
      "Validation AVG Loss:     0.000297 \n",
      "\n",
      "Epoch [420/5000] | Train Loss: 0.316119\n",
      "Validation AVG Loss:     0.000297 \n",
      "\n",
      "Epoch [421/5000] | Train Loss: 0.316018\n",
      "Validation AVG Loss:     0.000297 \n",
      "\n",
      "Epoch [422/5000] | Train Loss: 0.315918\n",
      "Validation AVG Loss:     0.000297 \n",
      "\n",
      "Epoch [423/5000] | Train Loss: 0.315818\n",
      "Validation AVG Loss:     0.000297 \n",
      "\n",
      "Epoch [424/5000] | Train Loss: 0.315717\n",
      "Validation AVG Loss:     0.000297 \n",
      "\n",
      "Epoch [425/5000] | Train Loss: 0.315617\n",
      "Validation AVG Loss:     0.000297 \n",
      "\n",
      "Epoch [426/5000] | Train Loss: 0.315517\n",
      "Validation AVG Loss:     0.000297 \n",
      "\n",
      "Epoch [427/5000] | Train Loss: 0.315417\n",
      "Validation AVG Loss:     0.000297 \n",
      "\n",
      "Epoch [428/5000] | Train Loss: 0.315317\n",
      "Validation AVG Loss:     0.000297 \n",
      "\n",
      "Epoch [429/5000] | Train Loss: 0.315216\n",
      "Validation AVG Loss:     0.000297 \n",
      "\n",
      "Epoch [430/5000] | Train Loss: 0.315116\n",
      "Validation AVG Loss:     0.000296 \n",
      "\n",
      "Epoch [431/5000] | Train Loss: 0.315016\n",
      "Validation AVG Loss:     0.000296 \n",
      "\n",
      "Epoch [432/5000] | Train Loss: 0.314916\n",
      "Validation AVG Loss:     0.000296 \n",
      "\n",
      "Epoch [433/5000] | Train Loss: 0.314816\n",
      "Validation AVG Loss:     0.000296 \n",
      "\n",
      "Epoch [434/5000] | Train Loss: 0.314717\n",
      "Validation AVG Loss:     0.000296 \n",
      "\n",
      "Epoch [435/5000] | Train Loss: 0.314617\n",
      "Validation AVG Loss:     0.000296 \n",
      "\n",
      "Epoch [436/5000] | Train Loss: 0.314517\n",
      "Validation AVG Loss:     0.000296 \n",
      "\n",
      "Epoch [437/5000] | Train Loss: 0.314417\n",
      "Validation AVG Loss:     0.000296 \n",
      "\n",
      "Epoch [438/5000] | Train Loss: 0.314317\n",
      "Validation AVG Loss:     0.000296 \n",
      "\n",
      "Epoch [439/5000] | Train Loss: 0.314217\n",
      "Validation AVG Loss:     0.000296 \n",
      "\n",
      "Epoch [440/5000] | Train Loss: 0.314118\n",
      "Validation AVG Loss:     0.000296 \n",
      "\n",
      "Epoch [441/5000] | Train Loss: 0.314018\n",
      "Validation AVG Loss:     0.000295 \n",
      "\n",
      "Epoch [442/5000] | Train Loss: 0.313918\n",
      "Validation AVG Loss:     0.000295 \n",
      "\n",
      "Epoch [443/5000] | Train Loss: 0.313819\n",
      "Validation AVG Loss:     0.000295 \n",
      "\n",
      "Epoch [444/5000] | Train Loss: 0.313719\n",
      "Validation AVG Loss:     0.000295 \n",
      "\n",
      "Epoch [445/5000] | Train Loss: 0.313620\n",
      "Validation AVG Loss:     0.000295 \n",
      "\n",
      "Epoch [446/5000] | Train Loss: 0.313520\n",
      "Validation AVG Loss:     0.000295 \n",
      "\n",
      "Epoch [447/5000] | Train Loss: 0.313421\n",
      "Validation AVG Loss:     0.000295 \n",
      "\n",
      "Epoch [448/5000] | Train Loss: 0.313322\n",
      "Validation AVG Loss:     0.000295 \n",
      "\n",
      "Epoch [449/5000] | Train Loss: 0.313222\n",
      "Validation AVG Loss:     0.000295 \n",
      "\n",
      "Epoch [450/5000] | Train Loss: 0.313123\n",
      "Validation AVG Loss:     0.000295 \n",
      "\n",
      "Epoch [451/5000] | Train Loss: 0.313024\n",
      "Validation AVG Loss:     0.000295 \n",
      "\n",
      "Epoch [452/5000] | Train Loss: 0.312925\n",
      "Validation AVG Loss:     0.000294 \n",
      "\n",
      "Epoch [453/5000] | Train Loss: 0.312826\n",
      "Validation AVG Loss:     0.000294 \n",
      "\n",
      "Epoch [454/5000] | Train Loss: 0.312727\n",
      "Validation AVG Loss:     0.000294 \n",
      "\n",
      "Epoch [455/5000] | Train Loss: 0.312628\n",
      "Validation AVG Loss:     0.000294 \n",
      "\n",
      "Epoch [456/5000] | Train Loss: 0.312529\n",
      "Validation AVG Loss:     0.000294 \n",
      "\n",
      "Epoch [457/5000] | Train Loss: 0.312430\n",
      "Validation AVG Loss:     0.000294 \n",
      "\n",
      "Epoch [458/5000] | Train Loss: 0.312331\n",
      "Validation AVG Loss:     0.000294 \n",
      "\n",
      "Epoch [459/5000] | Train Loss: 0.312232\n",
      "Validation AVG Loss:     0.000294 \n",
      "\n",
      "Epoch [460/5000] | Train Loss: 0.312134\n",
      "Validation AVG Loss:     0.000294 \n",
      "\n",
      "Epoch [461/5000] | Train Loss: 0.312035\n",
      "Validation AVG Loss:     0.000294 \n",
      "\n",
      "Epoch [462/5000] | Train Loss: 0.311936\n",
      "Validation AVG Loss:     0.000294 \n",
      "\n",
      "Epoch [463/5000] | Train Loss: 0.311838\n",
      "Validation AVG Loss:     0.000293 \n",
      "\n",
      "Epoch [464/5000] | Train Loss: 0.311739\n",
      "Validation AVG Loss:     0.000293 \n",
      "\n",
      "Epoch [465/5000] | Train Loss: 0.311640\n",
      "Validation AVG Loss:     0.000293 \n",
      "\n",
      "Epoch [466/5000] | Train Loss: 0.311542\n",
      "Validation AVG Loss:     0.000293 \n",
      "\n",
      "Epoch [467/5000] | Train Loss: 0.311444\n",
      "Validation AVG Loss:     0.000293 \n",
      "\n",
      "Epoch [468/5000] | Train Loss: 0.311345\n",
      "Validation AVG Loss:     0.000293 \n",
      "\n",
      "Epoch [469/5000] | Train Loss: 0.311247\n",
      "Validation AVG Loss:     0.000293 \n",
      "\n",
      "Epoch [470/5000] | Train Loss: 0.311148\n",
      "Validation AVG Loss:     0.000293 \n",
      "\n",
      "Epoch [471/5000] | Train Loss: 0.311050\n",
      "Validation AVG Loss:     0.000293 \n",
      "\n",
      "Epoch [472/5000] | Train Loss: 0.310952\n",
      "Validation AVG Loss:     0.000293 \n",
      "\n",
      "Epoch [473/5000] | Train Loss: 0.310853\n",
      "Validation AVG Loss:     0.000293 \n",
      "\n",
      "Epoch [474/5000] | Train Loss: 0.310755\n",
      "Validation AVG Loss:     0.000292 \n",
      "\n",
      "Epoch [475/5000] | Train Loss: 0.310657\n",
      "Validation AVG Loss:     0.000292 \n",
      "\n",
      "Epoch [476/5000] | Train Loss: 0.310558\n",
      "Validation AVG Loss:     0.000292 \n",
      "\n",
      "Epoch [477/5000] | Train Loss: 0.310460\n",
      "Validation AVG Loss:     0.000292 \n",
      "\n",
      "Epoch [478/5000] | Train Loss: 0.310362\n",
      "Validation AVG Loss:     0.000292 \n",
      "\n",
      "Epoch [479/5000] | Train Loss: 0.310264\n",
      "Validation AVG Loss:     0.000292 \n",
      "\n",
      "Epoch [480/5000] | Train Loss: 0.310166\n",
      "Validation AVG Loss:     0.000292 \n",
      "\n",
      "Epoch [481/5000] | Train Loss: 0.310068\n",
      "Validation AVG Loss:     0.000292 \n",
      "\n",
      "Epoch [482/5000] | Train Loss: 0.309970\n",
      "Validation AVG Loss:     0.000292 \n",
      "\n",
      "Epoch [483/5000] | Train Loss: 0.309872\n",
      "Validation AVG Loss:     0.000292 \n",
      "\n",
      "Epoch [484/5000] | Train Loss: 0.309774\n",
      "Validation AVG Loss:     0.000292 \n",
      "\n",
      "Epoch [485/5000] | Train Loss: 0.309676\n",
      "Validation AVG Loss:     0.000291 \n",
      "\n",
      "Epoch [486/5000] | Train Loss: 0.309578\n",
      "Validation AVG Loss:     0.000291 \n",
      "\n",
      "Epoch [487/5000] | Train Loss: 0.309480\n",
      "Validation AVG Loss:     0.000291 \n",
      "\n",
      "Epoch [488/5000] | Train Loss: 0.309382\n",
      "Validation AVG Loss:     0.000291 \n",
      "\n",
      "Epoch [489/5000] | Train Loss: 0.309284\n",
      "Validation AVG Loss:     0.000291 \n",
      "\n",
      "Epoch [490/5000] | Train Loss: 0.309186\n",
      "Validation AVG Loss:     0.000291 \n",
      "\n",
      "Epoch [491/5000] | Train Loss: 0.309089\n",
      "Validation AVG Loss:     0.000291 \n",
      "\n",
      "Epoch [492/5000] | Train Loss: 0.308991\n",
      "Validation AVG Loss:     0.000291 \n",
      "\n",
      "Epoch [493/5000] | Train Loss: 0.308893\n",
      "Validation AVG Loss:     0.000291 \n",
      "\n",
      "Epoch [494/5000] | Train Loss: 0.308795\n",
      "Validation AVG Loss:     0.000291 \n",
      "\n",
      "Epoch [495/5000] | Train Loss: 0.308698\n",
      "Validation AVG Loss:     0.000290 \n",
      "\n",
      "Epoch [496/5000] | Train Loss: 0.308600\n",
      "Validation AVG Loss:     0.000290 \n",
      "\n",
      "Epoch [497/5000] | Train Loss: 0.308502\n",
      "Validation AVG Loss:     0.000290 \n",
      "\n",
      "Epoch [498/5000] | Train Loss: 0.308405\n",
      "Validation AVG Loss:     0.000290 \n",
      "\n",
      "Epoch [499/5000] | Train Loss: 0.308307\n",
      "Validation AVG Loss:     0.000290 \n",
      "\n",
      "Epoch [500/5000] | Train Loss: 0.308210\n",
      "Validation AVG Loss:     0.000290 \n",
      "\n",
      "Epoch [501/5000] | Train Loss: 0.308112\n",
      "Validation AVG Loss:     0.000290 \n",
      "\n",
      "Epoch [502/5000] | Train Loss: 0.308015\n",
      "Validation AVG Loss:     0.000290 \n",
      "\n",
      "Epoch [503/5000] | Train Loss: 0.307917\n",
      "Validation AVG Loss:     0.000290 \n",
      "\n",
      "Epoch [504/5000] | Train Loss: 0.307820\n",
      "Validation AVG Loss:     0.000290 \n",
      "\n",
      "Epoch [505/5000] | Train Loss: 0.307723\n",
      "Validation AVG Loss:     0.000290 \n",
      "\n",
      "Epoch [506/5000] | Train Loss: 0.307625\n",
      "Validation AVG Loss:     0.000289 \n",
      "\n",
      "Epoch [507/5000] | Train Loss: 0.307528\n",
      "Validation AVG Loss:     0.000289 \n",
      "\n",
      "Epoch [508/5000] | Train Loss: 0.307431\n",
      "Validation AVG Loss:     0.000289 \n",
      "\n",
      "Epoch [509/5000] | Train Loss: 0.307333\n",
      "Validation AVG Loss:     0.000289 \n",
      "\n",
      "Epoch [510/5000] | Train Loss: 0.307236\n",
      "Validation AVG Loss:     0.000289 \n",
      "\n",
      "Epoch [511/5000] | Train Loss: 0.307139\n",
      "Validation AVG Loss:     0.000289 \n",
      "\n",
      "Epoch [512/5000] | Train Loss: 0.307042\n",
      "Validation AVG Loss:     0.000289 \n",
      "\n",
      "Epoch [513/5000] | Train Loss: 0.306945\n",
      "Validation AVG Loss:     0.000289 \n",
      "\n",
      "Epoch [514/5000] | Train Loss: 0.306848\n",
      "Validation AVG Loss:     0.000289 \n",
      "\n",
      "Epoch [515/5000] | Train Loss: 0.306751\n",
      "Validation AVG Loss:     0.000289 \n",
      "\n",
      "Epoch [516/5000] | Train Loss: 0.306653\n",
      "Validation AVG Loss:     0.000289 \n",
      "\n",
      "Epoch [517/5000] | Train Loss: 0.306556\n",
      "Validation AVG Loss:     0.000289 \n",
      "\n",
      "Epoch [518/5000] | Train Loss: 0.306459\n",
      "Validation AVG Loss:     0.000288 \n",
      "\n",
      "Epoch [519/5000] | Train Loss: 0.306363\n",
      "Validation AVG Loss:     0.000288 \n",
      "\n",
      "Epoch [520/5000] | Train Loss: 0.306266\n",
      "Validation AVG Loss:     0.000288 \n",
      "\n",
      "Epoch [521/5000] | Train Loss: 0.306169\n",
      "Validation AVG Loss:     0.000288 \n",
      "\n",
      "Epoch [522/5000] | Train Loss: 0.306072\n",
      "Validation AVG Loss:     0.000288 \n",
      "\n",
      "Epoch [523/5000] | Train Loss: 0.305975\n",
      "Validation AVG Loss:     0.000288 \n",
      "\n",
      "Epoch [524/5000] | Train Loss: 0.305878\n",
      "Validation AVG Loss:     0.000288 \n",
      "\n",
      "Epoch [525/5000] | Train Loss: 0.305782\n",
      "Validation AVG Loss:     0.000288 \n",
      "\n",
      "Epoch [526/5000] | Train Loss: 0.305685\n",
      "Validation AVG Loss:     0.000288 \n",
      "\n",
      "Epoch [527/5000] | Train Loss: 0.305588\n",
      "Validation AVG Loss:     0.000288 \n",
      "\n",
      "Epoch [528/5000] | Train Loss: 0.305491\n",
      "Validation AVG Loss:     0.000288 \n",
      "\n",
      "Epoch [529/5000] | Train Loss: 0.305395\n",
      "Validation AVG Loss:     0.000287 \n",
      "\n",
      "Epoch [530/5000] | Train Loss: 0.305298\n",
      "Validation AVG Loss:     0.000287 \n",
      "\n",
      "Epoch [531/5000] | Train Loss: 0.305202\n",
      "Validation AVG Loss:     0.000287 \n",
      "\n",
      "Epoch [532/5000] | Train Loss: 0.305105\n",
      "Validation AVG Loss:     0.000287 \n",
      "\n",
      "Epoch [533/5000] | Train Loss: 0.305008\n",
      "Validation AVG Loss:     0.000287 \n",
      "\n",
      "Epoch [534/5000] | Train Loss: 0.304912\n",
      "Validation AVG Loss:     0.000287 \n",
      "\n",
      "Epoch [535/5000] | Train Loss: 0.304815\n",
      "Validation AVG Loss:     0.000287 \n",
      "\n",
      "Epoch [536/5000] | Train Loss: 0.304719\n",
      "Validation AVG Loss:     0.000287 \n",
      "\n",
      "Epoch [537/5000] | Train Loss: 0.304622\n",
      "Validation AVG Loss:     0.000287 \n",
      "\n",
      "Epoch [538/5000] | Train Loss: 0.304526\n",
      "Validation AVG Loss:     0.000287 \n",
      "\n",
      "Epoch [539/5000] | Train Loss: 0.304429\n",
      "Validation AVG Loss:     0.000287 \n",
      "\n",
      "Epoch [540/5000] | Train Loss: 0.304333\n",
      "Validation AVG Loss:     0.000286 \n",
      "\n",
      "Epoch [541/5000] | Train Loss: 0.304236\n",
      "Validation AVG Loss:     0.000286 \n",
      "\n",
      "Epoch [542/5000] | Train Loss: 0.304140\n",
      "Validation AVG Loss:     0.000286 \n",
      "\n",
      "Epoch [543/5000] | Train Loss: 0.304043\n",
      "Validation AVG Loss:     0.000286 \n",
      "\n",
      "Epoch [544/5000] | Train Loss: 0.303947\n",
      "Validation AVG Loss:     0.000286 \n",
      "\n",
      "Epoch [545/5000] | Train Loss: 0.303850\n",
      "Validation AVG Loss:     0.000286 \n",
      "\n",
      "Epoch [546/5000] | Train Loss: 0.303754\n",
      "Validation AVG Loss:     0.000286 \n",
      "\n",
      "Epoch [547/5000] | Train Loss: 0.303658\n",
      "Validation AVG Loss:     0.000286 \n",
      "\n",
      "Epoch [548/5000] | Train Loss: 0.303561\n",
      "Validation AVG Loss:     0.000286 \n",
      "\n",
      "Epoch [549/5000] | Train Loss: 0.303465\n",
      "Validation AVG Loss:     0.000286 \n",
      "\n",
      "Epoch [550/5000] | Train Loss: 0.303369\n",
      "Validation AVG Loss:     0.000286 \n",
      "\n",
      "Epoch [551/5000] | Train Loss: 0.303273\n",
      "Validation AVG Loss:     0.000285 \n",
      "\n",
      "Epoch [552/5000] | Train Loss: 0.303176\n",
      "Validation AVG Loss:     0.000285 \n",
      "\n",
      "Epoch [553/5000] | Train Loss: 0.303080\n",
      "Validation AVG Loss:     0.000285 \n",
      "\n",
      "Epoch [554/5000] | Train Loss: 0.302984\n",
      "Validation AVG Loss:     0.000285 \n",
      "\n",
      "Epoch [555/5000] | Train Loss: 0.302888\n",
      "Validation AVG Loss:     0.000285 \n",
      "\n",
      "Epoch [556/5000] | Train Loss: 0.302792\n",
      "Validation AVG Loss:     0.000285 \n",
      "\n",
      "Epoch [557/5000] | Train Loss: 0.302696\n",
      "Validation AVG Loss:     0.000285 \n",
      "\n",
      "Epoch [558/5000] | Train Loss: 0.302600\n",
      "Validation AVG Loss:     0.000285 \n",
      "\n",
      "Epoch [559/5000] | Train Loss: 0.302503\n",
      "Validation AVG Loss:     0.000285 \n",
      "\n",
      "Epoch [560/5000] | Train Loss: 0.302407\n",
      "Validation AVG Loss:     0.000285 \n",
      "\n",
      "Epoch [561/5000] | Train Loss: 0.302311\n",
      "Validation AVG Loss:     0.000285 \n",
      "\n",
      "Epoch [562/5000] | Train Loss: 0.302215\n",
      "Validation AVG Loss:     0.000284 \n",
      "\n",
      "Epoch [563/5000] | Train Loss: 0.302119\n",
      "Validation AVG Loss:     0.000284 \n",
      "\n",
      "Epoch [564/5000] | Train Loss: 0.302023\n",
      "Validation AVG Loss:     0.000284 \n",
      "\n",
      "Epoch [565/5000] | Train Loss: 0.301927\n",
      "Validation AVG Loss:     0.000284 \n",
      "\n",
      "Epoch [566/5000] | Train Loss: 0.301831\n",
      "Validation AVG Loss:     0.000284 \n",
      "\n",
      "Epoch [567/5000] | Train Loss: 0.301735\n",
      "Validation AVG Loss:     0.000284 \n",
      "\n",
      "Epoch [568/5000] | Train Loss: 0.301639\n",
      "Validation AVG Loss:     0.000284 \n",
      "\n",
      "Epoch [569/5000] | Train Loss: 0.301543\n",
      "Validation AVG Loss:     0.000284 \n",
      "\n",
      "Epoch [570/5000] | Train Loss: 0.301448\n",
      "Validation AVG Loss:     0.000284 \n",
      "\n",
      "Epoch [571/5000] | Train Loss: 0.301352\n",
      "Validation AVG Loss:     0.000284 \n",
      "\n",
      "Epoch [572/5000] | Train Loss: 0.301256\n",
      "Validation AVG Loss:     0.000284 \n",
      "\n",
      "Epoch [573/5000] | Train Loss: 0.301160\n",
      "Validation AVG Loss:     0.000283 \n",
      "\n",
      "Epoch [574/5000] | Train Loss: 0.301065\n",
      "Validation AVG Loss:     0.000283 \n",
      "\n",
      "Epoch [575/5000] | Train Loss: 0.300969\n",
      "Validation AVG Loss:     0.000283 \n",
      "\n",
      "Epoch [576/5000] | Train Loss: 0.300873\n",
      "Validation AVG Loss:     0.000283 \n",
      "\n",
      "Epoch [577/5000] | Train Loss: 0.300778\n",
      "Validation AVG Loss:     0.000283 \n",
      "\n",
      "Epoch [578/5000] | Train Loss: 0.300682\n",
      "Validation AVG Loss:     0.000283 \n",
      "\n",
      "Epoch [579/5000] | Train Loss: 0.300587\n",
      "Validation AVG Loss:     0.000283 \n",
      "\n",
      "Epoch [580/5000] | Train Loss: 0.300491\n",
      "Validation AVG Loss:     0.000283 \n",
      "\n",
      "Epoch [581/5000] | Train Loss: 0.300395\n",
      "Validation AVG Loss:     0.000283 \n",
      "\n",
      "Epoch [582/5000] | Train Loss: 0.300300\n",
      "Validation AVG Loss:     0.000283 \n",
      "\n",
      "Epoch [583/5000] | Train Loss: 0.300205\n",
      "Validation AVG Loss:     0.000283 \n",
      "\n",
      "Epoch [584/5000] | Train Loss: 0.300109\n",
      "Validation AVG Loss:     0.000282 \n",
      "\n",
      "Epoch [585/5000] | Train Loss: 0.300014\n",
      "Validation AVG Loss:     0.000282 \n",
      "\n",
      "Epoch [586/5000] | Train Loss: 0.299918\n",
      "Validation AVG Loss:     0.000282 \n",
      "\n",
      "Epoch [587/5000] | Train Loss: 0.299823\n",
      "Validation AVG Loss:     0.000282 \n",
      "\n",
      "Epoch [588/5000] | Train Loss: 0.299728\n",
      "Validation AVG Loss:     0.000282 \n",
      "\n",
      "Epoch [589/5000] | Train Loss: 0.299632\n",
      "Validation AVG Loss:     0.000282 \n",
      "\n",
      "Epoch [590/5000] | Train Loss: 0.299537\n",
      "Validation AVG Loss:     0.000282 \n",
      "\n",
      "Epoch [591/5000] | Train Loss: 0.299442\n",
      "Validation AVG Loss:     0.000282 \n",
      "\n",
      "Epoch [592/5000] | Train Loss: 0.299346\n",
      "Validation AVG Loss:     0.000282 \n",
      "\n",
      "Epoch [593/5000] | Train Loss: 0.299251\n",
      "Validation AVG Loss:     0.000282 \n",
      "\n",
      "Epoch [594/5000] | Train Loss: 0.299156\n",
      "Validation AVG Loss:     0.000282 \n",
      "\n",
      "Epoch [595/5000] | Train Loss: 0.299060\n",
      "Validation AVG Loss:     0.000281 \n",
      "\n",
      "Epoch [596/5000] | Train Loss: 0.298965\n",
      "Validation AVG Loss:     0.000281 \n",
      "\n",
      "Epoch [597/5000] | Train Loss: 0.298870\n",
      "Validation AVG Loss:     0.000281 \n",
      "\n",
      "Epoch [598/5000] | Train Loss: 0.298775\n",
      "Validation AVG Loss:     0.000281 \n",
      "\n",
      "Epoch [599/5000] | Train Loss: 0.298680\n",
      "Validation AVG Loss:     0.000281 \n",
      "\n",
      "Epoch [600/5000] | Train Loss: 0.298585\n",
      "Validation AVG Loss:     0.000281 \n",
      "\n",
      "Epoch [601/5000] | Train Loss: 0.298490\n",
      "Validation AVG Loss:     0.000281 \n",
      "\n",
      "Epoch [602/5000] | Train Loss: 0.298394\n",
      "Validation AVG Loss:     0.000281 \n",
      "\n",
      "Epoch [603/5000] | Train Loss: 0.298299\n",
      "Validation AVG Loss:     0.000281 \n",
      "\n",
      "Epoch [604/5000] | Train Loss: 0.298204\n",
      "Validation AVG Loss:     0.000281 \n",
      "\n",
      "Epoch [605/5000] | Train Loss: 0.298109\n",
      "Validation AVG Loss:     0.000281 \n",
      "\n",
      "Epoch [606/5000] | Train Loss: 0.298014\n",
      "Validation AVG Loss:     0.000280 \n",
      "\n",
      "Epoch [607/5000] | Train Loss: 0.297919\n",
      "Validation AVG Loss:     0.000280 \n",
      "\n",
      "Epoch [608/5000] | Train Loss: 0.297824\n",
      "Validation AVG Loss:     0.000280 \n",
      "\n",
      "Epoch [609/5000] | Train Loss: 0.297729\n",
      "Validation AVG Loss:     0.000280 \n",
      "\n",
      "Epoch [610/5000] | Train Loss: 0.297635\n",
      "Validation AVG Loss:     0.000280 \n",
      "\n",
      "Epoch [611/5000] | Train Loss: 0.297540\n",
      "Validation AVG Loss:     0.000280 \n",
      "\n",
      "Epoch [612/5000] | Train Loss: 0.297445\n",
      "Validation AVG Loss:     0.000280 \n",
      "\n",
      "Epoch [613/5000] | Train Loss: 0.297350\n",
      "Validation AVG Loss:     0.000280 \n",
      "\n",
      "Epoch [614/5000] | Train Loss: 0.297255\n",
      "Validation AVG Loss:     0.000280 \n",
      "\n",
      "Epoch [615/5000] | Train Loss: 0.297161\n",
      "Validation AVG Loss:     0.000280 \n",
      "\n",
      "Epoch [616/5000] | Train Loss: 0.297066\n",
      "Validation AVG Loss:     0.000280 \n",
      "\n",
      "Epoch [617/5000] | Train Loss: 0.296971\n",
      "Validation AVG Loss:     0.000280 \n",
      "\n",
      "Epoch [618/5000] | Train Loss: 0.296876\n",
      "Validation AVG Loss:     0.000279 \n",
      "\n",
      "Epoch [619/5000] | Train Loss: 0.296782\n",
      "Validation AVG Loss:     0.000279 \n",
      "\n",
      "Epoch [620/5000] | Train Loss: 0.296687\n",
      "Validation AVG Loss:     0.000279 \n",
      "\n",
      "Epoch [621/5000] | Train Loss: 0.296593\n",
      "Validation AVG Loss:     0.000279 \n",
      "\n",
      "Epoch [622/5000] | Train Loss: 0.296498\n",
      "Validation AVG Loss:     0.000279 \n",
      "\n",
      "Epoch [623/5000] | Train Loss: 0.296403\n",
      "Validation AVG Loss:     0.000279 \n",
      "\n",
      "Epoch [624/5000] | Train Loss: 0.296309\n",
      "Validation AVG Loss:     0.000279 \n",
      "\n",
      "Epoch [625/5000] | Train Loss: 0.296214\n",
      "Validation AVG Loss:     0.000279 \n",
      "\n",
      "Epoch [626/5000] | Train Loss: 0.296120\n",
      "Validation AVG Loss:     0.000279 \n",
      "\n",
      "Epoch [627/5000] | Train Loss: 0.296025\n",
      "Validation AVG Loss:     0.000279 \n",
      "\n",
      "Epoch [628/5000] | Train Loss: 0.295931\n",
      "Validation AVG Loss:     0.000279 \n",
      "\n",
      "Epoch [629/5000] | Train Loss: 0.295836\n",
      "Validation AVG Loss:     0.000278 \n",
      "\n",
      "Epoch [630/5000] | Train Loss: 0.295742\n",
      "Validation AVG Loss:     0.000278 \n",
      "\n",
      "Epoch [631/5000] | Train Loss: 0.295648\n",
      "Validation AVG Loss:     0.000278 \n",
      "\n",
      "Epoch [632/5000] | Train Loss: 0.295553\n",
      "Validation AVG Loss:     0.000278 \n",
      "\n",
      "Epoch [633/5000] | Train Loss: 0.295459\n",
      "Validation AVG Loss:     0.000278 \n",
      "\n",
      "Epoch [634/5000] | Train Loss: 0.295365\n",
      "Validation AVG Loss:     0.000278 \n",
      "\n",
      "Epoch [635/5000] | Train Loss: 0.295270\n",
      "Validation AVG Loss:     0.000278 \n",
      "\n",
      "Epoch [636/5000] | Train Loss: 0.295176\n",
      "Validation AVG Loss:     0.000278 \n",
      "\n",
      "Epoch [637/5000] | Train Loss: 0.295082\n",
      "Validation AVG Loss:     0.000278 \n",
      "\n",
      "Epoch [638/5000] | Train Loss: 0.294987\n",
      "Validation AVG Loss:     0.000278 \n",
      "\n",
      "Epoch [639/5000] | Train Loss: 0.294893\n",
      "Validation AVG Loss:     0.000278 \n",
      "\n",
      "Epoch [640/5000] | Train Loss: 0.294799\n",
      "Validation AVG Loss:     0.000277 \n",
      "\n",
      "Epoch [641/5000] | Train Loss: 0.294705\n",
      "Validation AVG Loss:     0.000277 \n",
      "\n",
      "Epoch [642/5000] | Train Loss: 0.294611\n",
      "Validation AVG Loss:     0.000277 \n",
      "\n",
      "Epoch [643/5000] | Train Loss: 0.294517\n",
      "Validation AVG Loss:     0.000277 \n",
      "\n",
      "Epoch [644/5000] | Train Loss: 0.294422\n",
      "Validation AVG Loss:     0.000277 \n",
      "\n",
      "Epoch [645/5000] | Train Loss: 0.294328\n",
      "Validation AVG Loss:     0.000277 \n",
      "\n",
      "Epoch [646/5000] | Train Loss: 0.294234\n",
      "Validation AVG Loss:     0.000277 \n",
      "\n",
      "Epoch [647/5000] | Train Loss: 0.294140\n",
      "Validation AVG Loss:     0.000277 \n",
      "\n",
      "Epoch [648/5000] | Train Loss: 0.294046\n",
      "Validation AVG Loss:     0.000277 \n",
      "\n",
      "Epoch [649/5000] | Train Loss: 0.293952\n",
      "Validation AVG Loss:     0.000277 \n",
      "\n",
      "Epoch [650/5000] | Train Loss: 0.293858\n",
      "Validation AVG Loss:     0.000277 \n",
      "\n",
      "Epoch [651/5000] | Train Loss: 0.293764\n",
      "Validation AVG Loss:     0.000276 \n",
      "\n",
      "Epoch [652/5000] | Train Loss: 0.293670\n",
      "Validation AVG Loss:     0.000276 \n",
      "\n",
      "Epoch [653/5000] | Train Loss: 0.293576\n",
      "Validation AVG Loss:     0.000276 \n",
      "\n",
      "Epoch [654/5000] | Train Loss: 0.293482\n",
      "Validation AVG Loss:     0.000276 \n",
      "\n",
      "Epoch [655/5000] | Train Loss: 0.293388\n",
      "Validation AVG Loss:     0.000276 \n",
      "\n",
      "Epoch [656/5000] | Train Loss: 0.293294\n",
      "Validation AVG Loss:     0.000276 \n",
      "\n",
      "Epoch [657/5000] | Train Loss: 0.293200\n",
      "Validation AVG Loss:     0.000276 \n",
      "\n",
      "Epoch [658/5000] | Train Loss: 0.293107\n",
      "Validation AVG Loss:     0.000276 \n",
      "\n",
      "Epoch [659/5000] | Train Loss: 0.293013\n",
      "Validation AVG Loss:     0.000276 \n",
      "\n",
      "Epoch [660/5000] | Train Loss: 0.292919\n",
      "Validation AVG Loss:     0.000276 \n",
      "\n",
      "Epoch [661/5000] | Train Loss: 0.292825\n",
      "Validation AVG Loss:     0.000276 \n",
      "\n",
      "Epoch [662/5000] | Train Loss: 0.292732\n",
      "Validation AVG Loss:     0.000276 \n",
      "\n",
      "Epoch [663/5000] | Train Loss: 0.292638\n",
      "Validation AVG Loss:     0.000275 \n",
      "\n",
      "Epoch [664/5000] | Train Loss: 0.292544\n",
      "Validation AVG Loss:     0.000275 \n",
      "\n",
      "Epoch [665/5000] | Train Loss: 0.292451\n",
      "Validation AVG Loss:     0.000275 \n",
      "\n",
      "Epoch [666/5000] | Train Loss: 0.292357\n",
      "Validation AVG Loss:     0.000275 \n",
      "\n",
      "Epoch [667/5000] | Train Loss: 0.292264\n",
      "Validation AVG Loss:     0.000275 \n",
      "\n",
      "Epoch [668/5000] | Train Loss: 0.292170\n",
      "Validation AVG Loss:     0.000275 \n",
      "\n",
      "Epoch [669/5000] | Train Loss: 0.292077\n",
      "Validation AVG Loss:     0.000275 \n",
      "\n",
      "Epoch [670/5000] | Train Loss: 0.291983\n",
      "Validation AVG Loss:     0.000275 \n",
      "\n",
      "Epoch [671/5000] | Train Loss: 0.291890\n",
      "Validation AVG Loss:     0.000275 \n",
      "\n",
      "Epoch [672/5000] | Train Loss: 0.291796\n",
      "Validation AVG Loss:     0.000275 \n",
      "\n",
      "Epoch [673/5000] | Train Loss: 0.291703\n",
      "Validation AVG Loss:     0.000275 \n",
      "\n",
      "Epoch [674/5000] | Train Loss: 0.291609\n",
      "Validation AVG Loss:     0.000274 \n",
      "\n",
      "Epoch [675/5000] | Train Loss: 0.291516\n",
      "Validation AVG Loss:     0.000274 \n",
      "\n",
      "Epoch [676/5000] | Train Loss: 0.291422\n",
      "Validation AVG Loss:     0.000274 \n",
      "\n",
      "Epoch [677/5000] | Train Loss: 0.291329\n",
      "Validation AVG Loss:     0.000274 \n",
      "\n",
      "Epoch [678/5000] | Train Loss: 0.291236\n",
      "Validation AVG Loss:     0.000274 \n",
      "\n",
      "Epoch [679/5000] | Train Loss: 0.291142\n",
      "Validation AVG Loss:     0.000274 \n",
      "\n",
      "Epoch [680/5000] | Train Loss: 0.291049\n",
      "Validation AVG Loss:     0.000274 \n",
      "\n",
      "Epoch [681/5000] | Train Loss: 0.290956\n",
      "Validation AVG Loss:     0.000274 \n",
      "\n",
      "Epoch [682/5000] | Train Loss: 0.290862\n",
      "Validation AVG Loss:     0.000274 \n",
      "\n",
      "Epoch [683/5000] | Train Loss: 0.290769\n",
      "Validation AVG Loss:     0.000274 \n",
      "\n",
      "Epoch [684/5000] | Train Loss: 0.290675\n",
      "Validation AVG Loss:     0.000274 \n",
      "\n",
      "Epoch [685/5000] | Train Loss: 0.290582\n",
      "Validation AVG Loss:     0.000273 \n",
      "\n",
      "Epoch [686/5000] | Train Loss: 0.290489\n",
      "Validation AVG Loss:     0.000273 \n",
      "\n",
      "Epoch [687/5000] | Train Loss: 0.290396\n",
      "Validation AVG Loss:     0.000273 \n",
      "\n",
      "Epoch [688/5000] | Train Loss: 0.290302\n",
      "Validation AVG Loss:     0.000273 \n",
      "\n",
      "Epoch [689/5000] | Train Loss: 0.290209\n",
      "Validation AVG Loss:     0.000273 \n",
      "\n",
      "Epoch [690/5000] | Train Loss: 0.290116\n",
      "Validation AVG Loss:     0.000273 \n",
      "\n",
      "Epoch [691/5000] | Train Loss: 0.290023\n",
      "Validation AVG Loss:     0.000273 \n",
      "\n",
      "Epoch [692/5000] | Train Loss: 0.289930\n",
      "Validation AVG Loss:     0.000273 \n",
      "\n",
      "Epoch [693/5000] | Train Loss: 0.289836\n",
      "Validation AVG Loss:     0.000273 \n",
      "\n",
      "Epoch [694/5000] | Train Loss: 0.289743\n",
      "Validation AVG Loss:     0.000273 \n",
      "\n",
      "Epoch [695/5000] | Train Loss: 0.289650\n",
      "Validation AVG Loss:     0.000273 \n",
      "\n",
      "Epoch [696/5000] | Train Loss: 0.289557\n",
      "Validation AVG Loss:     0.000273 \n",
      "\n",
      "Epoch [697/5000] | Train Loss: 0.289464\n",
      "Validation AVG Loss:     0.000272 \n",
      "\n",
      "Epoch [698/5000] | Train Loss: 0.289371\n",
      "Validation AVG Loss:     0.000272 \n",
      "\n",
      "Epoch [699/5000] | Train Loss: 0.289278\n",
      "Validation AVG Loss:     0.000272 \n",
      "\n",
      "Epoch [700/5000] | Train Loss: 0.289185\n",
      "Validation AVG Loss:     0.000272 \n",
      "\n",
      "Epoch [701/5000] | Train Loss: 0.289092\n",
      "Validation AVG Loss:     0.000272 \n",
      "\n",
      "Epoch [702/5000] | Train Loss: 0.288999\n",
      "Validation AVG Loss:     0.000272 \n",
      "\n",
      "Epoch [703/5000] | Train Loss: 0.288906\n",
      "Validation AVG Loss:     0.000272 \n",
      "\n",
      "Epoch [704/5000] | Train Loss: 0.288813\n",
      "Validation AVG Loss:     0.000272 \n",
      "\n",
      "Epoch [705/5000] | Train Loss: 0.288720\n",
      "Validation AVG Loss:     0.000272 \n",
      "\n",
      "Epoch [706/5000] | Train Loss: 0.288627\n",
      "Validation AVG Loss:     0.000272 \n",
      "\n",
      "Epoch [707/5000] | Train Loss: 0.288534\n",
      "Validation AVG Loss:     0.000272 \n",
      "\n",
      "Epoch [708/5000] | Train Loss: 0.288441\n",
      "Validation AVG Loss:     0.000271 \n",
      "\n",
      "Epoch [709/5000] | Train Loss: 0.288348\n",
      "Validation AVG Loss:     0.000271 \n",
      "\n",
      "Epoch [710/5000] | Train Loss: 0.288255\n",
      "Validation AVG Loss:     0.000271 \n",
      "\n",
      "Epoch [711/5000] | Train Loss: 0.288163\n",
      "Validation AVG Loss:     0.000271 \n",
      "\n",
      "Epoch [712/5000] | Train Loss: 0.288070\n",
      "Validation AVG Loss:     0.000271 \n",
      "\n",
      "Epoch [713/5000] | Train Loss: 0.287977\n",
      "Validation AVG Loss:     0.000271 \n",
      "\n",
      "Epoch [714/5000] | Train Loss: 0.287884\n",
      "Validation AVG Loss:     0.000271 \n",
      "\n",
      "Epoch [715/5000] | Train Loss: 0.287791\n",
      "Validation AVG Loss:     0.000271 \n",
      "\n",
      "Epoch [716/5000] | Train Loss: 0.287699\n",
      "Validation AVG Loss:     0.000271 \n",
      "\n",
      "Epoch [717/5000] | Train Loss: 0.287606\n",
      "Validation AVG Loss:     0.000271 \n",
      "\n",
      "Epoch [718/5000] | Train Loss: 0.287513\n",
      "Validation AVG Loss:     0.000271 \n",
      "\n",
      "Epoch [719/5000] | Train Loss: 0.287420\n",
      "Validation AVG Loss:     0.000270 \n",
      "\n",
      "Epoch [720/5000] | Train Loss: 0.287328\n",
      "Validation AVG Loss:     0.000270 \n",
      "\n",
      "Epoch [721/5000] | Train Loss: 0.287235\n",
      "Validation AVG Loss:     0.000270 \n",
      "\n",
      "Epoch [722/5000] | Train Loss: 0.287142\n",
      "Validation AVG Loss:     0.000270 \n",
      "\n",
      "Epoch [723/5000] | Train Loss: 0.287050\n",
      "Validation AVG Loss:     0.000270 \n",
      "\n",
      "Epoch [724/5000] | Train Loss: 0.286957\n",
      "Validation AVG Loss:     0.000270 \n",
      "\n",
      "Epoch [725/5000] | Train Loss: 0.286864\n",
      "Validation AVG Loss:     0.000270 \n",
      "\n",
      "Epoch [726/5000] | Train Loss: 0.286772\n",
      "Validation AVG Loss:     0.000270 \n",
      "\n",
      "Epoch [727/5000] | Train Loss: 0.286679\n",
      "Validation AVG Loss:     0.000270 \n",
      "\n",
      "Epoch [728/5000] | Train Loss: 0.286586\n",
      "Validation AVG Loss:     0.000270 \n",
      "\n",
      "Epoch [729/5000] | Train Loss: 0.286494\n",
      "Validation AVG Loss:     0.000270 \n",
      "\n",
      "Epoch [730/5000] | Train Loss: 0.286401\n",
      "Validation AVG Loss:     0.000270 \n",
      "\n",
      "Epoch [731/5000] | Train Loss: 0.286309\n",
      "Validation AVG Loss:     0.000269 \n",
      "\n",
      "Epoch [732/5000] | Train Loss: 0.286216\n",
      "Validation AVG Loss:     0.000269 \n",
      "\n",
      "Epoch [733/5000] | Train Loss: 0.286123\n",
      "Validation AVG Loss:     0.000269 \n",
      "\n",
      "Epoch [734/5000] | Train Loss: 0.286031\n",
      "Validation AVG Loss:     0.000269 \n",
      "\n",
      "Epoch [735/5000] | Train Loss: 0.285938\n",
      "Validation AVG Loss:     0.000269 \n",
      "\n",
      "Epoch [736/5000] | Train Loss: 0.285846\n",
      "Validation AVG Loss:     0.000269 \n",
      "\n",
      "Epoch [737/5000] | Train Loss: 0.285753\n",
      "Validation AVG Loss:     0.000269 \n",
      "\n",
      "Epoch [738/5000] | Train Loss: 0.285661\n",
      "Validation AVG Loss:     0.000269 \n",
      "\n",
      "Epoch [739/5000] | Train Loss: 0.285568\n",
      "Validation AVG Loss:     0.000269 \n",
      "\n",
      "Epoch [740/5000] | Train Loss: 0.285476\n",
      "Validation AVG Loss:     0.000269 \n",
      "\n",
      "Epoch [741/5000] | Train Loss: 0.285383\n",
      "Validation AVG Loss:     0.000269 \n",
      "\n",
      "Epoch [742/5000] | Train Loss: 0.285291\n",
      "Validation AVG Loss:     0.000268 \n",
      "\n",
      "Epoch [743/5000] | Train Loss: 0.285198\n",
      "Validation AVG Loss:     0.000268 \n",
      "\n",
      "Epoch [744/5000] | Train Loss: 0.285106\n",
      "Validation AVG Loss:     0.000268 \n",
      "\n",
      "Epoch [745/5000] | Train Loss: 0.285013\n",
      "Validation AVG Loss:     0.000268 \n",
      "\n",
      "Epoch [746/5000] | Train Loss: 0.284921\n",
      "Validation AVG Loss:     0.000268 \n",
      "\n",
      "Epoch [747/5000] | Train Loss: 0.284828\n",
      "Validation AVG Loss:     0.000268 \n",
      "\n",
      "Epoch [748/5000] | Train Loss: 0.284736\n",
      "Validation AVG Loss:     0.000268 \n",
      "\n",
      "Epoch [749/5000] | Train Loss: 0.284643\n",
      "Validation AVG Loss:     0.000268 \n",
      "\n",
      "Epoch [750/5000] | Train Loss: 0.284551\n",
      "Validation AVG Loss:     0.000268 \n",
      "\n",
      "Epoch [751/5000] | Train Loss: 0.284459\n",
      "Validation AVG Loss:     0.000268 \n",
      "\n",
      "Epoch [752/5000] | Train Loss: 0.284366\n",
      "Validation AVG Loss:     0.000268 \n",
      "\n",
      "Epoch [753/5000] | Train Loss: 0.284274\n",
      "Validation AVG Loss:     0.000268 \n",
      "\n",
      "Epoch [754/5000] | Train Loss: 0.284182\n",
      "Validation AVG Loss:     0.000267 \n",
      "\n",
      "Epoch [755/5000] | Train Loss: 0.284089\n",
      "Validation AVG Loss:     0.000267 \n",
      "\n",
      "Epoch [756/5000] | Train Loss: 0.283997\n",
      "Validation AVG Loss:     0.000267 \n",
      "\n",
      "Epoch [757/5000] | Train Loss: 0.283904\n",
      "Validation AVG Loss:     0.000267 \n",
      "\n",
      "Epoch [758/5000] | Train Loss: 0.283812\n",
      "Validation AVG Loss:     0.000267 \n",
      "\n",
      "Epoch [759/5000] | Train Loss: 0.283720\n",
      "Validation AVG Loss:     0.000267 \n",
      "\n",
      "Epoch [760/5000] | Train Loss: 0.283627\n",
      "Validation AVG Loss:     0.000267 \n",
      "\n",
      "Epoch [761/5000] | Train Loss: 0.283535\n",
      "Validation AVG Loss:     0.000267 \n",
      "\n",
      "Epoch [762/5000] | Train Loss: 0.283443\n",
      "Validation AVG Loss:     0.000267 \n",
      "\n",
      "Epoch [763/5000] | Train Loss: 0.283350\n",
      "Validation AVG Loss:     0.000267 \n",
      "\n",
      "Epoch [764/5000] | Train Loss: 0.283258\n",
      "Validation AVG Loss:     0.000267 \n",
      "\n",
      "Epoch [765/5000] | Train Loss: 0.283166\n",
      "Validation AVG Loss:     0.000266 \n",
      "\n",
      "Epoch [766/5000] | Train Loss: 0.283074\n",
      "Validation AVG Loss:     0.000266 \n",
      "\n",
      "Epoch [767/5000] | Train Loss: 0.282981\n",
      "Validation AVG Loss:     0.000266 \n",
      "\n",
      "Epoch [768/5000] | Train Loss: 0.282889\n",
      "Validation AVG Loss:     0.000266 \n",
      "\n",
      "Epoch [769/5000] | Train Loss: 0.282797\n",
      "Validation AVG Loss:     0.000266 \n",
      "\n",
      "Epoch [770/5000] | Train Loss: 0.282704\n",
      "Validation AVG Loss:     0.000266 \n",
      "\n",
      "Epoch [771/5000] | Train Loss: 0.282612\n",
      "Validation AVG Loss:     0.000266 \n",
      "\n",
      "Epoch [772/5000] | Train Loss: 0.282520\n",
      "Validation AVG Loss:     0.000266 \n",
      "\n",
      "Epoch [773/5000] | Train Loss: 0.282428\n",
      "Validation AVG Loss:     0.000266 \n",
      "\n",
      "Epoch [774/5000] | Train Loss: 0.282336\n",
      "Validation AVG Loss:     0.000266 \n",
      "\n",
      "Epoch [775/5000] | Train Loss: 0.282243\n",
      "Validation AVG Loss:     0.000266 \n",
      "\n",
      "Epoch [776/5000] | Train Loss: 0.282151\n",
      "Validation AVG Loss:     0.000265 \n",
      "\n",
      "Epoch [777/5000] | Train Loss: 0.282059\n",
      "Validation AVG Loss:     0.000265 \n",
      "\n",
      "Epoch [778/5000] | Train Loss: 0.281967\n",
      "Validation AVG Loss:     0.000265 \n",
      "\n",
      "Epoch [779/5000] | Train Loss: 0.281874\n",
      "Validation AVG Loss:     0.000265 \n",
      "\n",
      "Epoch [780/5000] | Train Loss: 0.281782\n",
      "Validation AVG Loss:     0.000265 \n",
      "\n",
      "Epoch [781/5000] | Train Loss: 0.281690\n",
      "Validation AVG Loss:     0.000265 \n",
      "\n",
      "Epoch [782/5000] | Train Loss: 0.281598\n",
      "Validation AVG Loss:     0.000265 \n",
      "\n",
      "Epoch [783/5000] | Train Loss: 0.281506\n",
      "Validation AVG Loss:     0.000265 \n",
      "\n",
      "Epoch [784/5000] | Train Loss: 0.281413\n",
      "Validation AVG Loss:     0.000265 \n",
      "\n",
      "Epoch [785/5000] | Train Loss: 0.281321\n",
      "Validation AVG Loss:     0.000265 \n",
      "\n",
      "Epoch [786/5000] | Train Loss: 0.281229\n",
      "Validation AVG Loss:     0.000265 \n",
      "\n",
      "Epoch [787/5000] | Train Loss: 0.281137\n",
      "Validation AVG Loss:     0.000265 \n",
      "\n",
      "Epoch [788/5000] | Train Loss: 0.281045\n",
      "Validation AVG Loss:     0.000264 \n",
      "\n",
      "Epoch [789/5000] | Train Loss: 0.280953\n",
      "Validation AVG Loss:     0.000264 \n",
      "\n",
      "Epoch [790/5000] | Train Loss: 0.280860\n",
      "Validation AVG Loss:     0.000264 \n",
      "\n",
      "Epoch [791/5000] | Train Loss: 0.280768\n",
      "Validation AVG Loss:     0.000264 \n",
      "\n",
      "Epoch [792/5000] | Train Loss: 0.280676\n",
      "Validation AVG Loss:     0.000264 \n",
      "\n",
      "Epoch [793/5000] | Train Loss: 0.280584\n",
      "Validation AVG Loss:     0.000264 \n",
      "\n",
      "Epoch [794/5000] | Train Loss: 0.280492\n",
      "Validation AVG Loss:     0.000264 \n",
      "\n",
      "Epoch [795/5000] | Train Loss: 0.280399\n",
      "Validation AVG Loss:     0.000264 \n",
      "\n",
      "Epoch [796/5000] | Train Loss: 0.280307\n",
      "Validation AVG Loss:     0.000264 \n",
      "\n",
      "Epoch [797/5000] | Train Loss: 0.280215\n",
      "Validation AVG Loss:     0.000264 \n",
      "\n",
      "Epoch [798/5000] | Train Loss: 0.280123\n",
      "Validation AVG Loss:     0.000264 \n",
      "\n",
      "Epoch [799/5000] | Train Loss: 0.280031\n",
      "Validation AVG Loss:     0.000263 \n",
      "\n",
      "Epoch [800/5000] | Train Loss: 0.279939\n",
      "Validation AVG Loss:     0.000263 \n",
      "\n",
      "Epoch [801/5000] | Train Loss: 0.279847\n",
      "Validation AVG Loss:     0.000263 \n",
      "\n",
      "Epoch [802/5000] | Train Loss: 0.279754\n",
      "Validation AVG Loss:     0.000263 \n",
      "\n",
      "Epoch [803/5000] | Train Loss: 0.279662\n",
      "Validation AVG Loss:     0.000263 \n",
      "\n",
      "Epoch [804/5000] | Train Loss: 0.279570\n",
      "Validation AVG Loss:     0.000263 \n",
      "\n",
      "Epoch [805/5000] | Train Loss: 0.279478\n",
      "Validation AVG Loss:     0.000263 \n",
      "\n",
      "Epoch [806/5000] | Train Loss: 0.279386\n",
      "Validation AVG Loss:     0.000263 \n",
      "\n",
      "Epoch [807/5000] | Train Loss: 0.279294\n",
      "Validation AVG Loss:     0.000263 \n",
      "\n",
      "Epoch [808/5000] | Train Loss: 0.279202\n",
      "Validation AVG Loss:     0.000263 \n",
      "\n",
      "Epoch [809/5000] | Train Loss: 0.279110\n",
      "Validation AVG Loss:     0.000263 \n",
      "\n",
      "Epoch [810/5000] | Train Loss: 0.279017\n",
      "Validation AVG Loss:     0.000263 \n",
      "\n",
      "Epoch [811/5000] | Train Loss: 0.278925\n",
      "Validation AVG Loss:     0.000262 \n",
      "\n",
      "Epoch [812/5000] | Train Loss: 0.278833\n",
      "Validation AVG Loss:     0.000262 \n",
      "\n",
      "Epoch [813/5000] | Train Loss: 0.278741\n",
      "Validation AVG Loss:     0.000262 \n",
      "\n",
      "Epoch [814/5000] | Train Loss: 0.278649\n",
      "Validation AVG Loss:     0.000262 \n",
      "\n",
      "Epoch [815/5000] | Train Loss: 0.278557\n",
      "Validation AVG Loss:     0.000262 \n",
      "\n",
      "Epoch [816/5000] | Train Loss: 0.278465\n",
      "Validation AVG Loss:     0.000262 \n",
      "\n",
      "Epoch [817/5000] | Train Loss: 0.278373\n",
      "Validation AVG Loss:     0.000262 \n",
      "\n",
      "Epoch [818/5000] | Train Loss: 0.278281\n",
      "Validation AVG Loss:     0.000262 \n",
      "\n",
      "Epoch [819/5000] | Train Loss: 0.278189\n",
      "Validation AVG Loss:     0.000262 \n",
      "\n",
      "Epoch [820/5000] | Train Loss: 0.278097\n",
      "Validation AVG Loss:     0.000262 \n",
      "\n",
      "Epoch [821/5000] | Train Loss: 0.278005\n",
      "Validation AVG Loss:     0.000262 \n",
      "\n",
      "Epoch [822/5000] | Train Loss: 0.277913\n",
      "Validation AVG Loss:     0.000261 \n",
      "\n",
      "Epoch [823/5000] | Train Loss: 0.277821\n",
      "Validation AVG Loss:     0.000261 \n",
      "\n",
      "Epoch [824/5000] | Train Loss: 0.277729\n",
      "Validation AVG Loss:     0.000261 \n",
      "\n",
      "Epoch [825/5000] | Train Loss: 0.277637\n",
      "Validation AVG Loss:     0.000261 \n",
      "\n",
      "Epoch [826/5000] | Train Loss: 0.277545\n",
      "Validation AVG Loss:     0.000261 \n",
      "\n",
      "Epoch [827/5000] | Train Loss: 0.277453\n",
      "Validation AVG Loss:     0.000261 \n",
      "\n",
      "Epoch [828/5000] | Train Loss: 0.277361\n",
      "Validation AVG Loss:     0.000261 \n",
      "\n",
      "Epoch [829/5000] | Train Loss: 0.277269\n",
      "Validation AVG Loss:     0.000261 \n",
      "\n",
      "Epoch [830/5000] | Train Loss: 0.277177\n",
      "Validation AVG Loss:     0.000261 \n",
      "\n",
      "Epoch [831/5000] | Train Loss: 0.277085\n",
      "Validation AVG Loss:     0.000261 \n",
      "\n",
      "Epoch [832/5000] | Train Loss: 0.276992\n",
      "Validation AVG Loss:     0.000261 \n",
      "\n",
      "Epoch [833/5000] | Train Loss: 0.276900\n",
      "Validation AVG Loss:     0.000261 \n",
      "\n",
      "Epoch [834/5000] | Train Loss: 0.276808\n",
      "Validation AVG Loss:     0.000260 \n",
      "\n",
      "Epoch [835/5000] | Train Loss: 0.276716\n",
      "Validation AVG Loss:     0.000260 \n",
      "\n",
      "Epoch [836/5000] | Train Loss: 0.276624\n",
      "Validation AVG Loss:     0.000260 \n",
      "\n",
      "Epoch [837/5000] | Train Loss: 0.276532\n",
      "Validation AVG Loss:     0.000260 \n",
      "\n",
      "Epoch [838/5000] | Train Loss: 0.276440\n",
      "Validation AVG Loss:     0.000260 \n",
      "\n",
      "Epoch [839/5000] | Train Loss: 0.276348\n",
      "Validation AVG Loss:     0.000260 \n",
      "\n",
      "Epoch [840/5000] | Train Loss: 0.276256\n",
      "Validation AVG Loss:     0.000260 \n",
      "\n",
      "Epoch [841/5000] | Train Loss: 0.276164\n",
      "Validation AVG Loss:     0.000260 \n",
      "\n",
      "Epoch [842/5000] | Train Loss: 0.276072\n",
      "Validation AVG Loss:     0.000260 \n",
      "\n",
      "Epoch [843/5000] | Train Loss: 0.275980\n",
      "Validation AVG Loss:     0.000260 \n",
      "\n",
      "Epoch [844/5000] | Train Loss: 0.275888\n",
      "Validation AVG Loss:     0.000260 \n",
      "\n",
      "Epoch [845/5000] | Train Loss: 0.275796\n",
      "Validation AVG Loss:     0.000259 \n",
      "\n",
      "Epoch [846/5000] | Train Loss: 0.275704\n",
      "Validation AVG Loss:     0.000259 \n",
      "\n",
      "Epoch [847/5000] | Train Loss: 0.275612\n",
      "Validation AVG Loss:     0.000259 \n",
      "\n",
      "Epoch [848/5000] | Train Loss: 0.275520\n",
      "Validation AVG Loss:     0.000259 \n",
      "\n",
      "Epoch [849/5000] | Train Loss: 0.275428\n",
      "Validation AVG Loss:     0.000259 \n",
      "\n",
      "Epoch [850/5000] | Train Loss: 0.275336\n",
      "Validation AVG Loss:     0.000259 \n",
      "\n",
      "Epoch [851/5000] | Train Loss: 0.275244\n",
      "Validation AVG Loss:     0.000259 \n",
      "\n",
      "Epoch [852/5000] | Train Loss: 0.275152\n",
      "Validation AVG Loss:     0.000259 \n",
      "\n",
      "Epoch [853/5000] | Train Loss: 0.275060\n",
      "Validation AVG Loss:     0.000259 \n",
      "\n",
      "Epoch [854/5000] | Train Loss: 0.274968\n",
      "Validation AVG Loss:     0.000259 \n",
      "\n",
      "Epoch [855/5000] | Train Loss: 0.274876\n",
      "Validation AVG Loss:     0.000259 \n",
      "\n",
      "Epoch [856/5000] | Train Loss: 0.274784\n",
      "Validation AVG Loss:     0.000258 \n",
      "\n",
      "Epoch [857/5000] | Train Loss: 0.274692\n",
      "Validation AVG Loss:     0.000258 \n",
      "\n",
      "Epoch [858/5000] | Train Loss: 0.274600\n",
      "Validation AVG Loss:     0.000258 \n",
      "\n",
      "Epoch [859/5000] | Train Loss: 0.274508\n",
      "Validation AVG Loss:     0.000258 \n",
      "\n",
      "Epoch [860/5000] | Train Loss: 0.274416\n",
      "Validation AVG Loss:     0.000258 \n",
      "\n",
      "Epoch [861/5000] | Train Loss: 0.274323\n",
      "Validation AVG Loss:     0.000258 \n",
      "\n",
      "Epoch [862/5000] | Train Loss: 0.274231\n",
      "Validation AVG Loss:     0.000258 \n",
      "\n",
      "Epoch [863/5000] | Train Loss: 0.274139\n",
      "Validation AVG Loss:     0.000258 \n",
      "\n",
      "Epoch [864/5000] | Train Loss: 0.274047\n",
      "Validation AVG Loss:     0.000258 \n",
      "\n",
      "Epoch [865/5000] | Train Loss: 0.273955\n",
      "Validation AVG Loss:     0.000258 \n",
      "\n",
      "Epoch [866/5000] | Train Loss: 0.273863\n",
      "Validation AVG Loss:     0.000258 \n",
      "\n",
      "Epoch [867/5000] | Train Loss: 0.273771\n",
      "Validation AVG Loss:     0.000258 \n",
      "\n",
      "Epoch [868/5000] | Train Loss: 0.273679\n",
      "Validation AVG Loss:     0.000257 \n",
      "\n",
      "Epoch [869/5000] | Train Loss: 0.273587\n",
      "Validation AVG Loss:     0.000257 \n",
      "\n",
      "Epoch [870/5000] | Train Loss: 0.273495\n",
      "Validation AVG Loss:     0.000257 \n",
      "\n",
      "Epoch [871/5000] | Train Loss: 0.273403\n",
      "Validation AVG Loss:     0.000257 \n",
      "\n",
      "Epoch [872/5000] | Train Loss: 0.273311\n",
      "Validation AVG Loss:     0.000257 \n",
      "\n",
      "Epoch [873/5000] | Train Loss: 0.273219\n",
      "Validation AVG Loss:     0.000257 \n",
      "\n",
      "Epoch [874/5000] | Train Loss: 0.273127\n",
      "Validation AVG Loss:     0.000257 \n",
      "\n",
      "Epoch [875/5000] | Train Loss: 0.273035\n",
      "Validation AVG Loss:     0.000257 \n",
      "\n",
      "Epoch [876/5000] | Train Loss: 0.272943\n",
      "Validation AVG Loss:     0.000257 \n",
      "\n",
      "Epoch [877/5000] | Train Loss: 0.272851\n",
      "Validation AVG Loss:     0.000257 \n",
      "\n",
      "Epoch [878/5000] | Train Loss: 0.272758\n",
      "Validation AVG Loss:     0.000257 \n",
      "\n",
      "Epoch [879/5000] | Train Loss: 0.272666\n",
      "Validation AVG Loss:     0.000256 \n",
      "\n",
      "Epoch [880/5000] | Train Loss: 0.272574\n",
      "Validation AVG Loss:     0.000256 \n",
      "\n",
      "Epoch [881/5000] | Train Loss: 0.272482\n",
      "Validation AVG Loss:     0.000256 \n",
      "\n",
      "Epoch [882/5000] | Train Loss: 0.272390\n",
      "Validation AVG Loss:     0.000256 \n",
      "\n",
      "Epoch [883/5000] | Train Loss: 0.272298\n",
      "Validation AVG Loss:     0.000256 \n",
      "\n",
      "Epoch [884/5000] | Train Loss: 0.272206\n",
      "Validation AVG Loss:     0.000256 \n",
      "\n",
      "Epoch [885/5000] | Train Loss: 0.272114\n",
      "Validation AVG Loss:     0.000256 \n",
      "\n",
      "Epoch [886/5000] | Train Loss: 0.272022\n",
      "Validation AVG Loss:     0.000256 \n",
      "\n",
      "Epoch [887/5000] | Train Loss: 0.271930\n",
      "Validation AVG Loss:     0.000256 \n",
      "\n",
      "Epoch [888/5000] | Train Loss: 0.271838\n",
      "Validation AVG Loss:     0.000256 \n",
      "\n",
      "Epoch [889/5000] | Train Loss: 0.271746\n",
      "Validation AVG Loss:     0.000256 \n",
      "\n",
      "Epoch [890/5000] | Train Loss: 0.271654\n",
      "Validation AVG Loss:     0.000256 \n",
      "\n",
      "Epoch [891/5000] | Train Loss: 0.271562\n",
      "Validation AVG Loss:     0.000255 \n",
      "\n",
      "Epoch [892/5000] | Train Loss: 0.271470\n",
      "Validation AVG Loss:     0.000255 \n",
      "\n",
      "Epoch [893/5000] | Train Loss: 0.271378\n",
      "Validation AVG Loss:     0.000255 \n",
      "\n",
      "Epoch [894/5000] | Train Loss: 0.271286\n",
      "Validation AVG Loss:     0.000255 \n",
      "\n",
      "Epoch [895/5000] | Train Loss: 0.271194\n",
      "Validation AVG Loss:     0.000255 \n",
      "\n",
      "Epoch [896/5000] | Train Loss: 0.271102\n",
      "Validation AVG Loss:     0.000255 \n",
      "\n",
      "Epoch [897/5000] | Train Loss: 0.271010\n",
      "Validation AVG Loss:     0.000255 \n",
      "\n",
      "Epoch [898/5000] | Train Loss: 0.270918\n",
      "Validation AVG Loss:     0.000255 \n",
      "\n",
      "Epoch [899/5000] | Train Loss: 0.270826\n",
      "Validation AVG Loss:     0.000255 \n",
      "\n",
      "Epoch [900/5000] | Train Loss: 0.270733\n",
      "Validation AVG Loss:     0.000255 \n",
      "\n",
      "Epoch [901/5000] | Train Loss: 0.270641\n",
      "Validation AVG Loss:     0.000255 \n",
      "\n",
      "Epoch [902/5000] | Train Loss: 0.270549\n",
      "Validation AVG Loss:     0.000254 \n",
      "\n",
      "Epoch [903/5000] | Train Loss: 0.270457\n",
      "Validation AVG Loss:     0.000254 \n",
      "\n",
      "Epoch [904/5000] | Train Loss: 0.270365\n",
      "Validation AVG Loss:     0.000254 \n",
      "\n",
      "Epoch [905/5000] | Train Loss: 0.270273\n",
      "Validation AVG Loss:     0.000254 \n",
      "\n",
      "Epoch [906/5000] | Train Loss: 0.270181\n",
      "Validation AVG Loss:     0.000254 \n",
      "\n",
      "Epoch [907/5000] | Train Loss: 0.270089\n",
      "Validation AVG Loss:     0.000254 \n",
      "\n",
      "Epoch [908/5000] | Train Loss: 0.269997\n",
      "Validation AVG Loss:     0.000254 \n",
      "\n",
      "Epoch [909/5000] | Train Loss: 0.269905\n",
      "Validation AVG Loss:     0.000254 \n",
      "\n",
      "Epoch [910/5000] | Train Loss: 0.269812\n",
      "Validation AVG Loss:     0.000254 \n",
      "\n",
      "Epoch [911/5000] | Train Loss: 0.269720\n",
      "Validation AVG Loss:     0.000254 \n",
      "\n",
      "Epoch [912/5000] | Train Loss: 0.269628\n",
      "Validation AVG Loss:     0.000254 \n",
      "\n",
      "Epoch [913/5000] | Train Loss: 0.269536\n",
      "Validation AVG Loss:     0.000253 \n",
      "\n",
      "Epoch [914/5000] | Train Loss: 0.269444\n",
      "Validation AVG Loss:     0.000253 \n",
      "\n",
      "Epoch [915/5000] | Train Loss: 0.269352\n",
      "Validation AVG Loss:     0.000253 \n",
      "\n",
      "Epoch [916/5000] | Train Loss: 0.269260\n",
      "Validation AVG Loss:     0.000253 \n",
      "\n",
      "Epoch [917/5000] | Train Loss: 0.269167\n",
      "Validation AVG Loss:     0.000253 \n",
      "\n",
      "Epoch [918/5000] | Train Loss: 0.269075\n",
      "Validation AVG Loss:     0.000253 \n",
      "\n",
      "Epoch [919/5000] | Train Loss: 0.268983\n",
      "Validation AVG Loss:     0.000253 \n",
      "\n",
      "Epoch [920/5000] | Train Loss: 0.268891\n",
      "Validation AVG Loss:     0.000253 \n",
      "\n",
      "Epoch [921/5000] | Train Loss: 0.268799\n",
      "Validation AVG Loss:     0.000253 \n",
      "\n",
      "Epoch [922/5000] | Train Loss: 0.268707\n",
      "Validation AVG Loss:     0.000253 \n",
      "\n",
      "Epoch [923/5000] | Train Loss: 0.268614\n",
      "Validation AVG Loss:     0.000253 \n",
      "\n",
      "Epoch [924/5000] | Train Loss: 0.268522\n",
      "Validation AVG Loss:     0.000253 \n",
      "\n",
      "Epoch [925/5000] | Train Loss: 0.268430\n",
      "Validation AVG Loss:     0.000252 \n",
      "\n",
      "Epoch [926/5000] | Train Loss: 0.268338\n",
      "Validation AVG Loss:     0.000252 \n",
      "\n",
      "Epoch [927/5000] | Train Loss: 0.268246\n",
      "Validation AVG Loss:     0.000252 \n",
      "\n",
      "Epoch [928/5000] | Train Loss: 0.268153\n",
      "Validation AVG Loss:     0.000252 \n",
      "\n",
      "Epoch [929/5000] | Train Loss: 0.268061\n",
      "Validation AVG Loss:     0.000252 \n",
      "\n",
      "Epoch [930/5000] | Train Loss: 0.267969\n",
      "Validation AVG Loss:     0.000252 \n",
      "\n",
      "Epoch [931/5000] | Train Loss: 0.267877\n",
      "Validation AVG Loss:     0.000252 \n",
      "\n",
      "Epoch [932/5000] | Train Loss: 0.267785\n",
      "Validation AVG Loss:     0.000252 \n",
      "\n",
      "Epoch [933/5000] | Train Loss: 0.267692\n",
      "Validation AVG Loss:     0.000252 \n",
      "\n",
      "Epoch [934/5000] | Train Loss: 0.267600\n",
      "Validation AVG Loss:     0.000252 \n",
      "\n",
      "Epoch [935/5000] | Train Loss: 0.267508\n",
      "Validation AVG Loss:     0.000252 \n",
      "\n",
      "Epoch [936/5000] | Train Loss: 0.267416\n",
      "Validation AVG Loss:     0.000251 \n",
      "\n",
      "Epoch [937/5000] | Train Loss: 0.267324\n",
      "Validation AVG Loss:     0.000251 \n",
      "\n",
      "Epoch [938/5000] | Train Loss: 0.267231\n",
      "Validation AVG Loss:     0.000251 \n",
      "\n",
      "Epoch [939/5000] | Train Loss: 0.267139\n",
      "Validation AVG Loss:     0.000251 \n",
      "\n",
      "Epoch [940/5000] | Train Loss: 0.267047\n",
      "Validation AVG Loss:     0.000251 \n",
      "\n",
      "Epoch [941/5000] | Train Loss: 0.266954\n",
      "Validation AVG Loss:     0.000251 \n",
      "\n",
      "Epoch [942/5000] | Train Loss: 0.266862\n",
      "Validation AVG Loss:     0.000251 \n",
      "\n",
      "Epoch [943/5000] | Train Loss: 0.266770\n",
      "Validation AVG Loss:     0.000251 \n",
      "\n",
      "Epoch [944/5000] | Train Loss: 0.266678\n",
      "Validation AVG Loss:     0.000251 \n",
      "\n",
      "Epoch [945/5000] | Train Loss: 0.266585\n",
      "Validation AVG Loss:     0.000251 \n",
      "\n",
      "Epoch [946/5000] | Train Loss: 0.266493\n",
      "Validation AVG Loss:     0.000251 \n",
      "\n",
      "Epoch [947/5000] | Train Loss: 0.266401\n",
      "Validation AVG Loss:     0.000251 \n",
      "\n",
      "Epoch [948/5000] | Train Loss: 0.266308\n",
      "Validation AVG Loss:     0.000250 \n",
      "\n",
      "Epoch [949/5000] | Train Loss: 0.266216\n",
      "Validation AVG Loss:     0.000250 \n",
      "\n",
      "Epoch [950/5000] | Train Loss: 0.266124\n",
      "Validation AVG Loss:     0.000250 \n",
      "\n",
      "Epoch [951/5000] | Train Loss: 0.266032\n",
      "Validation AVG Loss:     0.000250 \n",
      "\n",
      "Epoch [952/5000] | Train Loss: 0.265939\n",
      "Validation AVG Loss:     0.000250 \n",
      "\n",
      "Epoch [953/5000] | Train Loss: 0.265847\n",
      "Validation AVG Loss:     0.000250 \n",
      "\n",
      "Epoch [954/5000] | Train Loss: 0.265755\n",
      "Validation AVG Loss:     0.000250 \n",
      "\n",
      "Epoch [955/5000] | Train Loss: 0.265663\n",
      "Validation AVG Loss:     0.000250 \n",
      "\n",
      "Epoch [956/5000] | Train Loss: 0.265570\n",
      "Validation AVG Loss:     0.000250 \n",
      "\n",
      "Epoch [957/5000] | Train Loss: 0.265478\n",
      "Validation AVG Loss:     0.000250 \n",
      "\n",
      "Epoch [958/5000] | Train Loss: 0.265386\n",
      "Validation AVG Loss:     0.000250 \n",
      "\n",
      "Epoch [959/5000] | Train Loss: 0.265293\n",
      "Validation AVG Loss:     0.000249 \n",
      "\n",
      "Epoch [960/5000] | Train Loss: 0.265201\n",
      "Validation AVG Loss:     0.000249 \n",
      "\n",
      "Epoch [961/5000] | Train Loss: 0.265109\n",
      "Validation AVG Loss:     0.000249 \n",
      "\n",
      "Epoch [962/5000] | Train Loss: 0.265017\n",
      "Validation AVG Loss:     0.000249 \n",
      "\n",
      "Epoch [963/5000] | Train Loss: 0.264924\n",
      "Validation AVG Loss:     0.000249 \n",
      "\n",
      "Epoch [964/5000] | Train Loss: 0.264832\n",
      "Validation AVG Loss:     0.000249 \n",
      "\n",
      "Epoch [965/5000] | Train Loss: 0.264740\n",
      "Validation AVG Loss:     0.000249 \n",
      "\n",
      "Epoch [966/5000] | Train Loss: 0.264647\n",
      "Validation AVG Loss:     0.000249 \n",
      "\n",
      "Epoch [967/5000] | Train Loss: 0.264555\n",
      "Validation AVG Loss:     0.000249 \n",
      "\n",
      "Epoch [968/5000] | Train Loss: 0.264463\n",
      "Validation AVG Loss:     0.000249 \n",
      "\n",
      "Epoch [969/5000] | Train Loss: 0.264370\n",
      "Validation AVG Loss:     0.000249 \n",
      "\n",
      "Epoch [970/5000] | Train Loss: 0.264278\n",
      "Validation AVG Loss:     0.000248 \n",
      "\n",
      "Epoch [971/5000] | Train Loss: 0.264186\n",
      "Validation AVG Loss:     0.000248 \n",
      "\n",
      "Epoch [972/5000] | Train Loss: 0.264093\n",
      "Validation AVG Loss:     0.000248 \n",
      "\n",
      "Epoch [973/5000] | Train Loss: 0.264001\n",
      "Validation AVG Loss:     0.000248 \n",
      "\n",
      "Epoch [974/5000] | Train Loss: 0.263909\n",
      "Validation AVG Loss:     0.000248 \n",
      "\n",
      "Epoch [975/5000] | Train Loss: 0.263816\n",
      "Validation AVG Loss:     0.000248 \n",
      "\n",
      "Epoch [976/5000] | Train Loss: 0.263724\n",
      "Validation AVG Loss:     0.000248 \n",
      "\n",
      "Epoch [977/5000] | Train Loss: 0.263632\n",
      "Validation AVG Loss:     0.000248 \n",
      "\n",
      "Epoch [978/5000] | Train Loss: 0.263539\n",
      "Validation AVG Loss:     0.000248 \n",
      "\n",
      "Epoch [979/5000] | Train Loss: 0.263447\n",
      "Validation AVG Loss:     0.000248 \n",
      "\n",
      "Epoch [980/5000] | Train Loss: 0.263355\n",
      "Validation AVG Loss:     0.000248 \n",
      "\n",
      "Epoch [981/5000] | Train Loss: 0.263262\n",
      "Validation AVG Loss:     0.000248 \n",
      "\n",
      "Epoch [982/5000] | Train Loss: 0.263170\n",
      "Validation AVG Loss:     0.000247 \n",
      "\n",
      "Epoch [983/5000] | Train Loss: 0.263078\n",
      "Validation AVG Loss:     0.000247 \n",
      "\n",
      "Epoch [984/5000] | Train Loss: 0.262985\n",
      "Validation AVG Loss:     0.000247 \n",
      "\n",
      "Epoch [985/5000] | Train Loss: 0.262893\n",
      "Validation AVG Loss:     0.000247 \n",
      "\n",
      "Epoch [986/5000] | Train Loss: 0.262800\n",
      "Validation AVG Loss:     0.000247 \n",
      "\n",
      "Epoch [987/5000] | Train Loss: 0.262708\n",
      "Validation AVG Loss:     0.000247 \n",
      "\n",
      "Epoch [988/5000] | Train Loss: 0.262616\n",
      "Validation AVG Loss:     0.000247 \n",
      "\n",
      "Epoch [989/5000] | Train Loss: 0.262523\n",
      "Validation AVG Loss:     0.000247 \n",
      "\n",
      "Epoch [990/5000] | Train Loss: 0.262431\n",
      "Validation AVG Loss:     0.000247 \n",
      "\n",
      "Epoch [991/5000] | Train Loss: 0.262339\n",
      "Validation AVG Loss:     0.000247 \n",
      "\n",
      "Epoch [992/5000] | Train Loss: 0.262246\n",
      "Validation AVG Loss:     0.000247 \n",
      "\n",
      "Epoch [993/5000] | Train Loss: 0.262154\n",
      "Validation AVG Loss:     0.000246 \n",
      "\n",
      "Epoch [994/5000] | Train Loss: 0.262061\n",
      "Validation AVG Loss:     0.000246 \n",
      "\n",
      "Epoch [995/5000] | Train Loss: 0.261969\n",
      "Validation AVG Loss:     0.000246 \n",
      "\n",
      "Epoch [996/5000] | Train Loss: 0.261877\n",
      "Validation AVG Loss:     0.000246 \n",
      "\n",
      "Epoch [997/5000] | Train Loss: 0.261784\n",
      "Validation AVG Loss:     0.000246 \n",
      "\n",
      "Epoch [998/5000] | Train Loss: 0.261692\n",
      "Validation AVG Loss:     0.000246 \n",
      "\n",
      "Epoch [999/5000] | Train Loss: 0.261599\n",
      "Validation AVG Loss:     0.000246 \n",
      "\n",
      "Epoch [1000/5000] | Train Loss: 0.261507\n",
      "Validation AVG Loss:     0.000246 \n",
      "\n",
      "Epoch [1001/5000] | Train Loss: 0.261415\n",
      "Validation AVG Loss:     0.000246 \n",
      "\n",
      "Epoch [1002/5000] | Train Loss: 0.261322\n",
      "Validation AVG Loss:     0.000246 \n",
      "\n",
      "Epoch [1003/5000] | Train Loss: 0.261230\n",
      "Validation AVG Loss:     0.000246 \n",
      "\n",
      "Epoch [1004/5000] | Train Loss: 0.261137\n",
      "Validation AVG Loss:     0.000245 \n",
      "\n",
      "Epoch [1005/5000] | Train Loss: 0.261045\n",
      "Validation AVG Loss:     0.000245 \n",
      "\n",
      "Epoch [1006/5000] | Train Loss: 0.260952\n",
      "Validation AVG Loss:     0.000245 \n",
      "\n",
      "Epoch [1007/5000] | Train Loss: 0.260860\n",
      "Validation AVG Loss:     0.000245 \n",
      "\n",
      "Epoch [1008/5000] | Train Loss: 0.260768\n",
      "Validation AVG Loss:     0.000245 \n",
      "\n",
      "Epoch [1009/5000] | Train Loss: 0.260675\n",
      "Validation AVG Loss:     0.000245 \n",
      "\n",
      "Epoch [1010/5000] | Train Loss: 0.260583\n",
      "Validation AVG Loss:     0.000245 \n",
      "\n",
      "Epoch [1011/5000] | Train Loss: 0.260490\n",
      "Validation AVG Loss:     0.000245 \n",
      "\n",
      "Epoch [1012/5000] | Train Loss: 0.260398\n",
      "Validation AVG Loss:     0.000245 \n",
      "\n",
      "Epoch [1013/5000] | Train Loss: 0.260306\n",
      "Validation AVG Loss:     0.000245 \n",
      "\n",
      "Epoch [1014/5000] | Train Loss: 0.260213\n",
      "Validation AVG Loss:     0.000245 \n",
      "\n",
      "Epoch [1015/5000] | Train Loss: 0.260121\n",
      "Validation AVG Loss:     0.000245 \n",
      "\n",
      "Epoch [1016/5000] | Train Loss: 0.260028\n",
      "Validation AVG Loss:     0.000244 \n",
      "\n",
      "Epoch [1017/5000] | Train Loss: 0.259936\n",
      "Validation AVG Loss:     0.000244 \n",
      "\n",
      "Epoch [1018/5000] | Train Loss: 0.259843\n",
      "Validation AVG Loss:     0.000244 \n",
      "\n",
      "Epoch [1019/5000] | Train Loss: 0.259751\n",
      "Validation AVG Loss:     0.000244 \n",
      "\n",
      "Epoch [1020/5000] | Train Loss: 0.259658\n",
      "Validation AVG Loss:     0.000244 \n",
      "\n",
      "Epoch [1021/5000] | Train Loss: 0.259566\n",
      "Validation AVG Loss:     0.000244 \n",
      "\n",
      "Epoch [1022/5000] | Train Loss: 0.259473\n",
      "Validation AVG Loss:     0.000244 \n",
      "\n",
      "Epoch [1023/5000] | Train Loss: 0.259381\n",
      "Validation AVG Loss:     0.000244 \n",
      "\n",
      "Epoch [1024/5000] | Train Loss: 0.259288\n",
      "Validation AVG Loss:     0.000244 \n",
      "\n",
      "Epoch [1025/5000] | Train Loss: 0.259196\n",
      "Validation AVG Loss:     0.000244 \n",
      "\n",
      "Epoch [1026/5000] | Train Loss: 0.259103\n",
      "Validation AVG Loss:     0.000244 \n",
      "\n",
      "Epoch [1027/5000] | Train Loss: 0.259011\n",
      "Validation AVG Loss:     0.000243 \n",
      "\n",
      "Epoch [1028/5000] | Train Loss: 0.258918\n",
      "Validation AVG Loss:     0.000243 \n",
      "\n",
      "Epoch [1029/5000] | Train Loss: 0.258825\n",
      "Validation AVG Loss:     0.000243 \n",
      "\n",
      "Epoch [1030/5000] | Train Loss: 0.258733\n",
      "Validation AVG Loss:     0.000243 \n",
      "\n",
      "Epoch [1031/5000] | Train Loss: 0.258640\n",
      "Validation AVG Loss:     0.000243 \n",
      "\n",
      "Epoch [1032/5000] | Train Loss: 0.258548\n",
      "Validation AVG Loss:     0.000243 \n",
      "\n",
      "Epoch [1033/5000] | Train Loss: 0.258455\n",
      "Validation AVG Loss:     0.000243 \n",
      "\n",
      "Epoch [1034/5000] | Train Loss: 0.258363\n",
      "Validation AVG Loss:     0.000243 \n",
      "\n",
      "Epoch [1035/5000] | Train Loss: 0.258270\n",
      "Validation AVG Loss:     0.000243 \n",
      "\n",
      "Epoch [1036/5000] | Train Loss: 0.258177\n",
      "Validation AVG Loss:     0.000243 \n",
      "\n",
      "Epoch [1037/5000] | Train Loss: 0.258085\n",
      "Validation AVG Loss:     0.000243 \n",
      "\n",
      "Epoch [1038/5000] | Train Loss: 0.257992\n",
      "Validation AVG Loss:     0.000242 \n",
      "\n",
      "Epoch [1039/5000] | Train Loss: 0.257900\n",
      "Validation AVG Loss:     0.000242 \n",
      "\n",
      "Epoch [1040/5000] | Train Loss: 0.257807\n",
      "Validation AVG Loss:     0.000242 \n",
      "\n",
      "Epoch [1041/5000] | Train Loss: 0.257715\n",
      "Validation AVG Loss:     0.000242 \n",
      "\n",
      "Epoch [1042/5000] | Train Loss: 0.257622\n",
      "Validation AVG Loss:     0.000242 \n",
      "\n",
      "Epoch [1043/5000] | Train Loss: 0.257529\n",
      "Validation AVG Loss:     0.000242 \n",
      "\n",
      "Epoch [1044/5000] | Train Loss: 0.257437\n",
      "Validation AVG Loss:     0.000242 \n",
      "\n",
      "Epoch [1045/5000] | Train Loss: 0.257344\n",
      "Validation AVG Loss:     0.000242 \n",
      "\n",
      "Epoch [1046/5000] | Train Loss: 0.257252\n",
      "Validation AVG Loss:     0.000242 \n",
      "\n",
      "Epoch [1047/5000] | Train Loss: 0.257159\n",
      "Validation AVG Loss:     0.000242 \n",
      "\n",
      "Epoch [1048/5000] | Train Loss: 0.257066\n",
      "Validation AVG Loss:     0.000242 \n",
      "\n",
      "Epoch [1049/5000] | Train Loss: 0.256974\n",
      "Validation AVG Loss:     0.000242 \n",
      "\n",
      "Epoch [1050/5000] | Train Loss: 0.256881\n",
      "Validation AVG Loss:     0.000241 \n",
      "\n",
      "Epoch [1051/5000] | Train Loss: 0.256788\n",
      "Validation AVG Loss:     0.000241 \n",
      "\n",
      "Epoch [1052/5000] | Train Loss: 0.256696\n",
      "Validation AVG Loss:     0.000241 \n",
      "\n",
      "Epoch [1053/5000] | Train Loss: 0.256603\n",
      "Validation AVG Loss:     0.000241 \n",
      "\n",
      "Epoch [1054/5000] | Train Loss: 0.256511\n",
      "Validation AVG Loss:     0.000241 \n",
      "\n",
      "Epoch [1055/5000] | Train Loss: 0.256418\n",
      "Validation AVG Loss:     0.000241 \n",
      "\n",
      "Epoch [1056/5000] | Train Loss: 0.256325\n",
      "Validation AVG Loss:     0.000241 \n",
      "\n",
      "Epoch [1057/5000] | Train Loss: 0.256233\n",
      "Validation AVG Loss:     0.000241 \n",
      "\n",
      "Epoch [1058/5000] | Train Loss: 0.256140\n",
      "Validation AVG Loss:     0.000241 \n",
      "\n",
      "Epoch [1059/5000] | Train Loss: 0.256048\n",
      "Validation AVG Loss:     0.000241 \n",
      "\n",
      "Epoch [1060/5000] | Train Loss: 0.255955\n",
      "Validation AVG Loss:     0.000241 \n",
      "\n",
      "Epoch [1061/5000] | Train Loss: 0.255862\n",
      "Validation AVG Loss:     0.000240 \n",
      "\n",
      "Epoch [1062/5000] | Train Loss: 0.255770\n",
      "Validation AVG Loss:     0.000240 \n",
      "\n",
      "Epoch [1063/5000] | Train Loss: 0.255677\n",
      "Validation AVG Loss:     0.000240 \n",
      "\n",
      "Epoch [1064/5000] | Train Loss: 0.255584\n",
      "Validation AVG Loss:     0.000240 \n",
      "\n",
      "Epoch [1065/5000] | Train Loss: 0.255492\n",
      "Validation AVG Loss:     0.000240 \n",
      "\n",
      "Epoch [1066/5000] | Train Loss: 0.255399\n",
      "Validation AVG Loss:     0.000240 \n",
      "\n",
      "Epoch [1067/5000] | Train Loss: 0.255306\n",
      "Validation AVG Loss:     0.000240 \n",
      "\n",
      "Epoch [1068/5000] | Train Loss: 0.255214\n",
      "Validation AVG Loss:     0.000240 \n",
      "\n",
      "Epoch [1069/5000] | Train Loss: 0.255121\n",
      "Validation AVG Loss:     0.000240 \n",
      "\n",
      "Epoch [1070/5000] | Train Loss: 0.255028\n",
      "Validation AVG Loss:     0.000240 \n",
      "\n",
      "Epoch [1071/5000] | Train Loss: 0.254936\n",
      "Validation AVG Loss:     0.000240 \n",
      "\n",
      "Epoch [1072/5000] | Train Loss: 0.254843\n",
      "Validation AVG Loss:     0.000239 \n",
      "\n",
      "Epoch [1073/5000] | Train Loss: 0.254750\n",
      "Validation AVG Loss:     0.000239 \n",
      "\n",
      "Epoch [1074/5000] | Train Loss: 0.254657\n",
      "Validation AVG Loss:     0.000239 \n",
      "\n",
      "Epoch [1075/5000] | Train Loss: 0.254565\n",
      "Validation AVG Loss:     0.000239 \n",
      "\n",
      "Epoch [1076/5000] | Train Loss: 0.254472\n",
      "Validation AVG Loss:     0.000239 \n",
      "\n",
      "Epoch [1077/5000] | Train Loss: 0.254379\n",
      "Validation AVG Loss:     0.000239 \n",
      "\n",
      "Epoch [1078/5000] | Train Loss: 0.254287\n",
      "Validation AVG Loss:     0.000239 \n",
      "\n",
      "Epoch [1079/5000] | Train Loss: 0.254194\n",
      "Validation AVG Loss:     0.000239 \n",
      "\n",
      "Epoch [1080/5000] | Train Loss: 0.254101\n",
      "Validation AVG Loss:     0.000239 \n",
      "\n",
      "Epoch [1081/5000] | Train Loss: 0.254008\n",
      "Validation AVG Loss:     0.000239 \n",
      "\n",
      "Epoch [1082/5000] | Train Loss: 0.253916\n",
      "Validation AVG Loss:     0.000239 \n",
      "\n",
      "Epoch [1083/5000] | Train Loss: 0.253823\n",
      "Validation AVG Loss:     0.000238 \n",
      "\n",
      "Epoch [1084/5000] | Train Loss: 0.253730\n",
      "Validation AVG Loss:     0.000238 \n",
      "\n",
      "Epoch [1085/5000] | Train Loss: 0.253638\n",
      "Validation AVG Loss:     0.000238 \n",
      "\n",
      "Epoch [1086/5000] | Train Loss: 0.253545\n",
      "Validation AVG Loss:     0.000238 \n",
      "\n",
      "Epoch [1087/5000] | Train Loss: 0.253452\n",
      "Validation AVG Loss:     0.000238 \n",
      "\n",
      "Epoch [1088/5000] | Train Loss: 0.253359\n",
      "Validation AVG Loss:     0.000238 \n",
      "\n",
      "Epoch [1089/5000] | Train Loss: 0.253267\n",
      "Validation AVG Loss:     0.000238 \n",
      "\n",
      "Epoch [1090/5000] | Train Loss: 0.253174\n",
      "Validation AVG Loss:     0.000238 \n",
      "\n",
      "Epoch [1091/5000] | Train Loss: 0.253081\n",
      "Validation AVG Loss:     0.000238 \n",
      "\n",
      "Epoch [1092/5000] | Train Loss: 0.252988\n",
      "Validation AVG Loss:     0.000238 \n",
      "\n",
      "Epoch [1093/5000] | Train Loss: 0.252895\n",
      "Validation AVG Loss:     0.000238 \n",
      "\n",
      "Epoch [1094/5000] | Train Loss: 0.252803\n",
      "Validation AVG Loss:     0.000238 \n",
      "\n",
      "Epoch [1095/5000] | Train Loss: 0.252710\n",
      "Validation AVG Loss:     0.000237 \n",
      "\n",
      "Epoch [1096/5000] | Train Loss: 0.252617\n",
      "Validation AVG Loss:     0.000237 \n",
      "\n",
      "Epoch [1097/5000] | Train Loss: 0.252524\n",
      "Validation AVG Loss:     0.000237 \n",
      "\n",
      "Epoch [1098/5000] | Train Loss: 0.252431\n",
      "Validation AVG Loss:     0.000237 \n",
      "\n",
      "Epoch [1099/5000] | Train Loss: 0.252338\n",
      "Validation AVG Loss:     0.000237 \n",
      "\n",
      "Epoch [1100/5000] | Train Loss: 0.252246\n",
      "Validation AVG Loss:     0.000237 \n",
      "\n",
      "Epoch [1101/5000] | Train Loss: 0.252153\n",
      "Validation AVG Loss:     0.000237 \n",
      "\n",
      "Epoch [1102/5000] | Train Loss: 0.252060\n",
      "Validation AVG Loss:     0.000237 \n",
      "\n",
      "Epoch [1103/5000] | Train Loss: 0.251967\n",
      "Validation AVG Loss:     0.000237 \n",
      "\n",
      "Epoch [1104/5000] | Train Loss: 0.251874\n",
      "Validation AVG Loss:     0.000237 \n",
      "\n",
      "Epoch [1105/5000] | Train Loss: 0.251781\n",
      "Validation AVG Loss:     0.000237 \n",
      "\n",
      "Epoch [1106/5000] | Train Loss: 0.251689\n",
      "Validation AVG Loss:     0.000236 \n",
      "\n",
      "Epoch [1107/5000] | Train Loss: 0.251596\n",
      "Validation AVG Loss:     0.000236 \n",
      "\n",
      "Epoch [1108/5000] | Train Loss: 0.251503\n",
      "Validation AVG Loss:     0.000236 \n",
      "\n",
      "Epoch [1109/5000] | Train Loss: 0.251410\n",
      "Validation AVG Loss:     0.000236 \n",
      "\n",
      "Epoch [1110/5000] | Train Loss: 0.251317\n",
      "Validation AVG Loss:     0.000236 \n",
      "\n",
      "Epoch [1111/5000] | Train Loss: 0.251224\n",
      "Validation AVG Loss:     0.000236 \n",
      "\n",
      "Epoch [1112/5000] | Train Loss: 0.251131\n",
      "Validation AVG Loss:     0.000236 \n",
      "\n",
      "Epoch [1113/5000] | Train Loss: 0.251039\n",
      "Validation AVG Loss:     0.000236 \n",
      "\n",
      "Epoch [1114/5000] | Train Loss: 0.250946\n",
      "Validation AVG Loss:     0.000236 \n",
      "\n",
      "Epoch [1115/5000] | Train Loss: 0.250853\n",
      "Validation AVG Loss:     0.000236 \n",
      "\n",
      "Epoch [1116/5000] | Train Loss: 0.250760\n",
      "Validation AVG Loss:     0.000236 \n",
      "\n",
      "Epoch [1117/5000] | Train Loss: 0.250667\n",
      "Validation AVG Loss:     0.000235 \n",
      "\n",
      "Epoch [1118/5000] | Train Loss: 0.250574\n",
      "Validation AVG Loss:     0.000235 \n",
      "\n",
      "Epoch [1119/5000] | Train Loss: 0.250481\n",
      "Validation AVG Loss:     0.000235 \n",
      "\n",
      "Epoch [1120/5000] | Train Loss: 0.250388\n",
      "Validation AVG Loss:     0.000235 \n",
      "\n",
      "Epoch [1121/5000] | Train Loss: 0.250295\n",
      "Validation AVG Loss:     0.000235 \n",
      "\n",
      "Epoch [1122/5000] | Train Loss: 0.250202\n",
      "Validation AVG Loss:     0.000235 \n",
      "\n",
      "Epoch [1123/5000] | Train Loss: 0.250110\n",
      "Validation AVG Loss:     0.000235 \n",
      "\n",
      "Epoch [1124/5000] | Train Loss: 0.250017\n",
      "Validation AVG Loss:     0.000235 \n",
      "\n",
      "Epoch [1125/5000] | Train Loss: 0.249924\n",
      "Validation AVG Loss:     0.000235 \n",
      "\n",
      "Epoch [1126/5000] | Train Loss: 0.249831\n",
      "Validation AVG Loss:     0.000235 \n",
      "\n",
      "Epoch [1127/5000] | Train Loss: 0.249738\n",
      "Validation AVG Loss:     0.000235 \n",
      "\n",
      "Epoch [1128/5000] | Train Loss: 0.249645\n",
      "Validation AVG Loss:     0.000234 \n",
      "\n",
      "Epoch [1129/5000] | Train Loss: 0.249552\n",
      "Validation AVG Loss:     0.000234 \n",
      "\n",
      "Epoch [1130/5000] | Train Loss: 0.249459\n",
      "Validation AVG Loss:     0.000234 \n",
      "\n",
      "Epoch [1131/5000] | Train Loss: 0.249366\n",
      "Validation AVG Loss:     0.000234 \n",
      "\n",
      "Epoch [1132/5000] | Train Loss: 0.249273\n",
      "Validation AVG Loss:     0.000234 \n",
      "\n",
      "Epoch [1133/5000] | Train Loss: 0.249180\n",
      "Validation AVG Loss:     0.000234 \n",
      "\n",
      "Epoch [1134/5000] | Train Loss: 0.249087\n",
      "Validation AVG Loss:     0.000234 \n",
      "\n",
      "Epoch [1135/5000] | Train Loss: 0.248994\n",
      "Validation AVG Loss:     0.000234 \n",
      "\n",
      "Epoch [1136/5000] | Train Loss: 0.248901\n",
      "Validation AVG Loss:     0.000234 \n",
      "\n",
      "Epoch [1137/5000] | Train Loss: 0.248808\n",
      "Validation AVG Loss:     0.000234 \n",
      "\n",
      "Epoch [1138/5000] | Train Loss: 0.248715\n",
      "Validation AVG Loss:     0.000234 \n",
      "\n",
      "Epoch [1139/5000] | Train Loss: 0.248622\n",
      "Validation AVG Loss:     0.000234 \n",
      "\n",
      "Epoch [1140/5000] | Train Loss: 0.248529\n",
      "Validation AVG Loss:     0.000233 \n",
      "\n",
      "Epoch [1141/5000] | Train Loss: 0.248436\n",
      "Validation AVG Loss:     0.000233 \n",
      "\n",
      "Epoch [1142/5000] | Train Loss: 0.248343\n",
      "Validation AVG Loss:     0.000233 \n",
      "\n",
      "Epoch [1143/5000] | Train Loss: 0.248250\n",
      "Validation AVG Loss:     0.000233 \n",
      "\n",
      "Epoch [1144/5000] | Train Loss: 0.248157\n",
      "Validation AVG Loss:     0.000233 \n",
      "\n",
      "Epoch [1145/5000] | Train Loss: 0.248064\n",
      "Validation AVG Loss:     0.000233 \n",
      "\n",
      "Epoch [1146/5000] | Train Loss: 0.247971\n",
      "Validation AVG Loss:     0.000233 \n",
      "\n",
      "Epoch [1147/5000] | Train Loss: 0.247878\n",
      "Validation AVG Loss:     0.000233 \n",
      "\n",
      "Epoch [1148/5000] | Train Loss: 0.247785\n",
      "Validation AVG Loss:     0.000233 \n",
      "\n",
      "Epoch [1149/5000] | Train Loss: 0.247692\n",
      "Validation AVG Loss:     0.000233 \n",
      "\n",
      "Epoch [1150/5000] | Train Loss: 0.247599\n",
      "Validation AVG Loss:     0.000233 \n",
      "\n",
      "Epoch [1151/5000] | Train Loss: 0.247506\n",
      "Validation AVG Loss:     0.000232 \n",
      "\n",
      "Epoch [1152/5000] | Train Loss: 0.247413\n",
      "Validation AVG Loss:     0.000232 \n",
      "\n",
      "Epoch [1153/5000] | Train Loss: 0.247320\n",
      "Validation AVG Loss:     0.000232 \n",
      "\n",
      "Epoch [1154/5000] | Train Loss: 0.247227\n",
      "Validation AVG Loss:     0.000232 \n",
      "\n",
      "Epoch [1155/5000] | Train Loss: 0.247134\n",
      "Validation AVG Loss:     0.000232 \n",
      "\n",
      "Epoch [1156/5000] | Train Loss: 0.247041\n",
      "Validation AVG Loss:     0.000232 \n",
      "\n",
      "Epoch [1157/5000] | Train Loss: 0.246948\n",
      "Validation AVG Loss:     0.000232 \n",
      "\n",
      "Epoch [1158/5000] | Train Loss: 0.246855\n",
      "Validation AVG Loss:     0.000232 \n",
      "\n",
      "Epoch [1159/5000] | Train Loss: 0.246762\n",
      "Validation AVG Loss:     0.000232 \n",
      "\n",
      "Epoch [1160/5000] | Train Loss: 0.246669\n",
      "Validation AVG Loss:     0.000232 \n",
      "\n",
      "Epoch [1161/5000] | Train Loss: 0.246576\n",
      "Validation AVG Loss:     0.000232 \n",
      "\n",
      "Epoch [1162/5000] | Train Loss: 0.246483\n",
      "Validation AVG Loss:     0.000231 \n",
      "\n",
      "Epoch [1163/5000] | Train Loss: 0.246389\n",
      "Validation AVG Loss:     0.000231 \n",
      "\n",
      "Epoch [1164/5000] | Train Loss: 0.246296\n",
      "Validation AVG Loss:     0.000231 \n",
      "\n",
      "Epoch [1165/5000] | Train Loss: 0.246203\n",
      "Validation AVG Loss:     0.000231 \n",
      "\n",
      "Epoch [1166/5000] | Train Loss: 0.246110\n",
      "Validation AVG Loss:     0.000231 \n",
      "\n",
      "Epoch [1167/5000] | Train Loss: 0.246017\n",
      "Validation AVG Loss:     0.000231 \n",
      "\n",
      "Epoch [1168/5000] | Train Loss: 0.245924\n",
      "Validation AVG Loss:     0.000231 \n",
      "\n",
      "Epoch [1169/5000] | Train Loss: 0.245831\n",
      "Validation AVG Loss:     0.000231 \n",
      "\n",
      "Epoch [1170/5000] | Train Loss: 0.245738\n",
      "Validation AVG Loss:     0.000231 \n",
      "\n",
      "Epoch [1171/5000] | Train Loss: 0.245645\n",
      "Validation AVG Loss:     0.000231 \n",
      "\n",
      "Epoch [1172/5000] | Train Loss: 0.245551\n",
      "Validation AVG Loss:     0.000231 \n",
      "\n",
      "Epoch [1173/5000] | Train Loss: 0.245458\n",
      "Validation AVG Loss:     0.000230 \n",
      "\n",
      "Epoch [1174/5000] | Train Loss: 0.245365\n",
      "Validation AVG Loss:     0.000230 \n",
      "\n",
      "Epoch [1175/5000] | Train Loss: 0.245272\n",
      "Validation AVG Loss:     0.000230 \n",
      "\n",
      "Epoch [1176/5000] | Train Loss: 0.245179\n",
      "Validation AVG Loss:     0.000230 \n",
      "\n",
      "Epoch [1177/5000] | Train Loss: 0.245086\n",
      "Validation AVG Loss:     0.000230 \n",
      "\n",
      "Epoch [1178/5000] | Train Loss: 0.244993\n",
      "Validation AVG Loss:     0.000230 \n",
      "\n",
      "Epoch [1179/5000] | Train Loss: 0.244900\n",
      "Validation AVG Loss:     0.000230 \n",
      "\n",
      "Epoch [1180/5000] | Train Loss: 0.244806\n",
      "Validation AVG Loss:     0.000230 \n",
      "\n",
      "Epoch [1181/5000] | Train Loss: 0.244713\n",
      "Validation AVG Loss:     0.000230 \n",
      "\n",
      "Epoch [1182/5000] | Train Loss: 0.244620\n",
      "Validation AVG Loss:     0.000230 \n",
      "\n",
      "Epoch [1183/5000] | Train Loss: 0.244527\n",
      "Validation AVG Loss:     0.000230 \n",
      "\n",
      "Epoch [1184/5000] | Train Loss: 0.244434\n",
      "Validation AVG Loss:     0.000229 \n",
      "\n",
      "Epoch [1185/5000] | Train Loss: 0.244341\n",
      "Validation AVG Loss:     0.000229 \n",
      "\n",
      "Epoch [1186/5000] | Train Loss: 0.244247\n",
      "Validation AVG Loss:     0.000229 \n",
      "\n",
      "Epoch [1187/5000] | Train Loss: 0.244154\n",
      "Validation AVG Loss:     0.000229 \n",
      "\n",
      "Epoch [1188/5000] | Train Loss: 0.244061\n",
      "Validation AVG Loss:     0.000229 \n",
      "\n",
      "Epoch [1189/5000] | Train Loss: 0.243968\n",
      "Validation AVG Loss:     0.000229 \n",
      "\n",
      "Epoch [1190/5000] | Train Loss: 0.243875\n",
      "Validation AVG Loss:     0.000229 \n",
      "\n",
      "Epoch [1191/5000] | Train Loss: 0.243781\n",
      "Validation AVG Loss:     0.000229 \n",
      "\n",
      "Epoch [1192/5000] | Train Loss: 0.243688\n",
      "Validation AVG Loss:     0.000229 \n",
      "\n",
      "Epoch [1193/5000] | Train Loss: 0.243595\n",
      "Validation AVG Loss:     0.000229 \n",
      "\n",
      "Epoch [1194/5000] | Train Loss: 0.243502\n",
      "Validation AVG Loss:     0.000229 \n",
      "\n",
      "Epoch [1195/5000] | Train Loss: 0.243409\n",
      "Validation AVG Loss:     0.000229 \n",
      "\n",
      "Epoch [1196/5000] | Train Loss: 0.243315\n",
      "Validation AVG Loss:     0.000228 \n",
      "\n",
      "Epoch [1197/5000] | Train Loss: 0.243222\n",
      "Validation AVG Loss:     0.000228 \n",
      "\n",
      "Epoch [1198/5000] | Train Loss: 0.243129\n",
      "Validation AVG Loss:     0.000228 \n",
      "\n",
      "Epoch [1199/5000] | Train Loss: 0.243036\n",
      "Validation AVG Loss:     0.000228 \n",
      "\n",
      "Epoch [1200/5000] | Train Loss: 0.242942\n",
      "Validation AVG Loss:     0.000228 \n",
      "\n",
      "Epoch [1201/5000] | Train Loss: 0.242849\n",
      "Validation AVG Loss:     0.000228 \n",
      "\n",
      "Epoch [1202/5000] | Train Loss: 0.242756\n",
      "Validation AVG Loss:     0.000228 \n",
      "\n",
      "Epoch [1203/5000] | Train Loss: 0.242663\n",
      "Validation AVG Loss:     0.000228 \n",
      "\n",
      "Epoch [1204/5000] | Train Loss: 0.242569\n",
      "Validation AVG Loss:     0.000228 \n",
      "\n",
      "Epoch [1205/5000] | Train Loss: 0.242476\n",
      "Validation AVG Loss:     0.000228 \n",
      "\n",
      "Epoch [1206/5000] | Train Loss: 0.242383\n",
      "Validation AVG Loss:     0.000228 \n",
      "\n",
      "Epoch [1207/5000] | Train Loss: 0.242289\n",
      "Validation AVG Loss:     0.000227 \n",
      "\n",
      "Epoch [1208/5000] | Train Loss: 0.242196\n",
      "Validation AVG Loss:     0.000227 \n",
      "\n",
      "Epoch [1209/5000] | Train Loss: 0.242103\n",
      "Validation AVG Loss:     0.000227 \n",
      "\n",
      "Epoch [1210/5000] | Train Loss: 0.242009\n",
      "Validation AVG Loss:     0.000227 \n",
      "\n",
      "Epoch [1211/5000] | Train Loss: 0.241916\n",
      "Validation AVG Loss:     0.000227 \n",
      "\n",
      "Epoch [1212/5000] | Train Loss: 0.241822\n",
      "Validation AVG Loss:     0.000227 \n",
      "\n",
      "Epoch [1213/5000] | Train Loss: 0.241729\n",
      "Validation AVG Loss:     0.000227 \n",
      "\n",
      "Epoch [1214/5000] | Train Loss: 0.241636\n",
      "Validation AVG Loss:     0.000227 \n",
      "\n",
      "Epoch [1215/5000] | Train Loss: 0.241542\n",
      "Validation AVG Loss:     0.000227 \n",
      "\n",
      "Epoch [1216/5000] | Train Loss: 0.241449\n",
      "Validation AVG Loss:     0.000227 \n",
      "\n",
      "Epoch [1217/5000] | Train Loss: 0.241356\n",
      "Validation AVG Loss:     0.000227 \n",
      "\n",
      "Epoch [1218/5000] | Train Loss: 0.241262\n",
      "Validation AVG Loss:     0.000226 \n",
      "\n",
      "Epoch [1219/5000] | Train Loss: 0.241169\n",
      "Validation AVG Loss:     0.000226 \n",
      "\n",
      "Epoch [1220/5000] | Train Loss: 0.241075\n",
      "Validation AVG Loss:     0.000226 \n",
      "\n",
      "Epoch [1221/5000] | Train Loss: 0.240982\n",
      "Validation AVG Loss:     0.000226 \n",
      "\n",
      "Epoch [1222/5000] | Train Loss: 0.240888\n",
      "Validation AVG Loss:     0.000226 \n",
      "\n",
      "Epoch [1223/5000] | Train Loss: 0.240795\n",
      "Validation AVG Loss:     0.000226 \n",
      "\n",
      "Epoch [1224/5000] | Train Loss: 0.240701\n",
      "Validation AVG Loss:     0.000226 \n",
      "\n",
      "Epoch [1225/5000] | Train Loss: 0.240608\n",
      "Validation AVG Loss:     0.000226 \n",
      "\n",
      "Epoch [1226/5000] | Train Loss: 0.240514\n",
      "Validation AVG Loss:     0.000226 \n",
      "\n",
      "Epoch [1227/5000] | Train Loss: 0.240421\n",
      "Validation AVG Loss:     0.000226 \n",
      "\n",
      "Epoch [1228/5000] | Train Loss: 0.240327\n",
      "Validation AVG Loss:     0.000226 \n",
      "\n",
      "Epoch [1229/5000] | Train Loss: 0.240234\n",
      "Validation AVG Loss:     0.000225 \n",
      "\n",
      "Epoch [1230/5000] | Train Loss: 0.240141\n",
      "Validation AVG Loss:     0.000225 \n",
      "\n",
      "Epoch [1231/5000] | Train Loss: 0.240047\n",
      "Validation AVG Loss:     0.000225 \n",
      "\n",
      "Epoch [1232/5000] | Train Loss: 0.239954\n",
      "Validation AVG Loss:     0.000225 \n",
      "\n",
      "Epoch [1233/5000] | Train Loss: 0.239860\n",
      "Validation AVG Loss:     0.000225 \n",
      "\n",
      "Epoch [1234/5000] | Train Loss: 0.239767\n",
      "Validation AVG Loss:     0.000225 \n",
      "\n",
      "Epoch [1235/5000] | Train Loss: 0.239673\n",
      "Validation AVG Loss:     0.000225 \n",
      "\n",
      "Epoch [1236/5000] | Train Loss: 0.239580\n",
      "Validation AVG Loss:     0.000225 \n",
      "\n",
      "Epoch [1237/5000] | Train Loss: 0.239486\n",
      "Validation AVG Loss:     0.000225 \n",
      "\n",
      "Epoch [1238/5000] | Train Loss: 0.239393\n",
      "Validation AVG Loss:     0.000225 \n",
      "\n",
      "Epoch [1239/5000] | Train Loss: 0.239299\n",
      "Validation AVG Loss:     0.000225 \n",
      "\n",
      "Epoch [1240/5000] | Train Loss: 0.239206\n",
      "Validation AVG Loss:     0.000224 \n",
      "\n",
      "Epoch [1241/5000] | Train Loss: 0.239112\n",
      "Validation AVG Loss:     0.000224 \n",
      "\n",
      "Epoch [1242/5000] | Train Loss: 0.239019\n",
      "Validation AVG Loss:     0.000224 \n",
      "\n",
      "Epoch [1243/5000] | Train Loss: 0.238925\n",
      "Validation AVG Loss:     0.000224 \n",
      "\n",
      "Epoch [1244/5000] | Train Loss: 0.238832\n",
      "Validation AVG Loss:     0.000224 \n",
      "\n",
      "Epoch [1245/5000] | Train Loss: 0.238738\n",
      "Validation AVG Loss:     0.000224 \n",
      "\n",
      "Epoch [1246/5000] | Train Loss: 0.238645\n",
      "Validation AVG Loss:     0.000224 \n",
      "\n",
      "Epoch [1247/5000] | Train Loss: 0.238551\n",
      "Validation AVG Loss:     0.000224 \n",
      "\n",
      "Epoch [1248/5000] | Train Loss: 0.238457\n",
      "Validation AVG Loss:     0.000224 \n",
      "\n",
      "Epoch [1249/5000] | Train Loss: 0.238364\n",
      "Validation AVG Loss:     0.000224 \n",
      "\n",
      "Epoch [1250/5000] | Train Loss: 0.238270\n",
      "Validation AVG Loss:     0.000224 \n",
      "\n",
      "Epoch [1251/5000] | Train Loss: 0.238177\n",
      "Validation AVG Loss:     0.000223 \n",
      "\n",
      "Epoch [1252/5000] | Train Loss: 0.238083\n",
      "Validation AVG Loss:     0.000223 \n",
      "\n",
      "Epoch [1253/5000] | Train Loss: 0.237990\n",
      "Validation AVG Loss:     0.000223 \n",
      "\n",
      "Epoch [1254/5000] | Train Loss: 0.237896\n",
      "Validation AVG Loss:     0.000223 \n",
      "\n",
      "Epoch [1255/5000] | Train Loss: 0.237803\n",
      "Validation AVG Loss:     0.000223 \n",
      "\n",
      "Epoch [1256/5000] | Train Loss: 0.237709\n",
      "Validation AVG Loss:     0.000223 \n",
      "\n",
      "Epoch [1257/5000] | Train Loss: 0.237615\n",
      "Validation AVG Loss:     0.000223 \n",
      "\n",
      "Epoch [1258/5000] | Train Loss: 0.237522\n",
      "Validation AVG Loss:     0.000223 \n",
      "\n",
      "Epoch [1259/5000] | Train Loss: 0.237428\n",
      "Validation AVG Loss:     0.000223 \n",
      "\n",
      "Epoch [1260/5000] | Train Loss: 0.237335\n",
      "Validation AVG Loss:     0.000223 \n",
      "\n",
      "Epoch [1261/5000] | Train Loss: 0.237241\n",
      "Validation AVG Loss:     0.000223 \n",
      "\n",
      "Epoch [1262/5000] | Train Loss: 0.237147\n",
      "Validation AVG Loss:     0.000223 \n",
      "\n",
      "Epoch [1263/5000] | Train Loss: 0.237054\n",
      "Validation AVG Loss:     0.000222 \n",
      "\n",
      "Epoch [1264/5000] | Train Loss: 0.236960\n",
      "Validation AVG Loss:     0.000222 \n",
      "\n",
      "Epoch [1265/5000] | Train Loss: 0.236866\n",
      "Validation AVG Loss:     0.000222 \n",
      "\n",
      "Epoch [1266/5000] | Train Loss: 0.236773\n",
      "Validation AVG Loss:     0.000222 \n",
      "\n",
      "Epoch [1267/5000] | Train Loss: 0.236679\n",
      "Validation AVG Loss:     0.000222 \n",
      "\n",
      "Epoch [1268/5000] | Train Loss: 0.236585\n",
      "Validation AVG Loss:     0.000222 \n",
      "\n",
      "Epoch [1269/5000] | Train Loss: 0.236492\n",
      "Validation AVG Loss:     0.000222 \n",
      "\n",
      "Epoch [1270/5000] | Train Loss: 0.236398\n",
      "Validation AVG Loss:     0.000222 \n",
      "\n",
      "Epoch [1271/5000] | Train Loss: 0.236304\n",
      "Validation AVG Loss:     0.000222 \n",
      "\n",
      "Epoch [1272/5000] | Train Loss: 0.236211\n",
      "Validation AVG Loss:     0.000222 \n",
      "\n",
      "Epoch [1273/5000] | Train Loss: 0.236117\n",
      "Validation AVG Loss:     0.000222 \n",
      "\n",
      "Epoch [1274/5000] | Train Loss: 0.236023\n",
      "Validation AVG Loss:     0.000221 \n",
      "\n",
      "Epoch [1275/5000] | Train Loss: 0.235929\n",
      "Validation AVG Loss:     0.000221 \n",
      "\n",
      "Epoch [1276/5000] | Train Loss: 0.235836\n",
      "Validation AVG Loss:     0.000221 \n",
      "\n",
      "Epoch [1277/5000] | Train Loss: 0.235742\n",
      "Validation AVG Loss:     0.000221 \n",
      "\n",
      "Epoch [1278/5000] | Train Loss: 0.235648\n",
      "Validation AVG Loss:     0.000221 \n",
      "\n",
      "Epoch [1279/5000] | Train Loss: 0.235555\n",
      "Validation AVG Loss:     0.000221 \n",
      "\n",
      "Epoch [1280/5000] | Train Loss: 0.235461\n",
      "Validation AVG Loss:     0.000221 \n",
      "\n",
      "Epoch [1281/5000] | Train Loss: 0.235367\n",
      "Validation AVG Loss:     0.000221 \n",
      "\n",
      "Epoch [1282/5000] | Train Loss: 0.235273\n",
      "Validation AVG Loss:     0.000221 \n",
      "\n",
      "Epoch [1283/5000] | Train Loss: 0.235179\n",
      "Validation AVG Loss:     0.000221 \n",
      "\n",
      "Epoch [1284/5000] | Train Loss: 0.235086\n",
      "Validation AVG Loss:     0.000221 \n",
      "\n",
      "Epoch [1285/5000] | Train Loss: 0.234992\n",
      "Validation AVG Loss:     0.000220 \n",
      "\n",
      "Epoch [1286/5000] | Train Loss: 0.234898\n",
      "Validation AVG Loss:     0.000220 \n",
      "\n",
      "Epoch [1287/5000] | Train Loss: 0.234804\n",
      "Validation AVG Loss:     0.000220 \n",
      "\n",
      "Epoch [1288/5000] | Train Loss: 0.234711\n",
      "Validation AVG Loss:     0.000220 \n",
      "\n",
      "Epoch [1289/5000] | Train Loss: 0.234617\n",
      "Validation AVG Loss:     0.000220 \n",
      "\n",
      "Epoch [1290/5000] | Train Loss: 0.234523\n",
      "Validation AVG Loss:     0.000220 \n",
      "\n",
      "Epoch [1291/5000] | Train Loss: 0.234429\n",
      "Validation AVG Loss:     0.000220 \n",
      "\n",
      "Epoch [1292/5000] | Train Loss: 0.234335\n",
      "Validation AVG Loss:     0.000220 \n",
      "\n",
      "Epoch [1293/5000] | Train Loss: 0.234241\n",
      "Validation AVG Loss:     0.000220 \n",
      "\n",
      "Epoch [1294/5000] | Train Loss: 0.234148\n",
      "Validation AVG Loss:     0.000220 \n",
      "\n",
      "Epoch [1295/5000] | Train Loss: 0.234054\n",
      "Validation AVG Loss:     0.000220 \n",
      "\n",
      "Epoch [1296/5000] | Train Loss: 0.233960\n",
      "Validation AVG Loss:     0.000219 \n",
      "\n",
      "Epoch [1297/5000] | Train Loss: 0.233866\n",
      "Validation AVG Loss:     0.000219 \n",
      "\n",
      "Epoch [1298/5000] | Train Loss: 0.233772\n",
      "Validation AVG Loss:     0.000219 \n",
      "\n",
      "Epoch [1299/5000] | Train Loss: 0.233678\n",
      "Validation AVG Loss:     0.000219 \n",
      "\n",
      "Epoch [1300/5000] | Train Loss: 0.233585\n",
      "Validation AVG Loss:     0.000219 \n",
      "\n",
      "Epoch [1301/5000] | Train Loss: 0.233491\n",
      "Validation AVG Loss:     0.000219 \n",
      "\n",
      "Epoch [1302/5000] | Train Loss: 0.233397\n",
      "Validation AVG Loss:     0.000219 \n",
      "\n",
      "Epoch [1303/5000] | Train Loss: 0.233303\n",
      "Validation AVG Loss:     0.000219 \n",
      "\n",
      "Epoch [1304/5000] | Train Loss: 0.233209\n",
      "Validation AVG Loss:     0.000219 \n",
      "\n",
      "Epoch [1305/5000] | Train Loss: 0.233115\n",
      "Validation AVG Loss:     0.000219 \n",
      "\n",
      "Epoch [1306/5000] | Train Loss: 0.233021\n",
      "Validation AVG Loss:     0.000219 \n",
      "\n",
      "Epoch [1307/5000] | Train Loss: 0.232927\n",
      "Validation AVG Loss:     0.000218 \n",
      "\n",
      "Epoch [1308/5000] | Train Loss: 0.232833\n",
      "Validation AVG Loss:     0.000218 \n",
      "\n",
      "Epoch [1309/5000] | Train Loss: 0.232740\n",
      "Validation AVG Loss:     0.000218 \n",
      "\n",
      "Epoch [1310/5000] | Train Loss: 0.232646\n",
      "Validation AVG Loss:     0.000218 \n",
      "\n",
      "Epoch [1311/5000] | Train Loss: 0.232552\n",
      "Validation AVG Loss:     0.000218 \n",
      "\n",
      "Epoch [1312/5000] | Train Loss: 0.232458\n",
      "Validation AVG Loss:     0.000218 \n",
      "\n",
      "Epoch [1313/5000] | Train Loss: 0.232364\n",
      "Validation AVG Loss:     0.000218 \n",
      "\n",
      "Epoch [1314/5000] | Train Loss: 0.232270\n",
      "Validation AVG Loss:     0.000218 \n",
      "\n",
      "Epoch [1315/5000] | Train Loss: 0.232176\n",
      "Validation AVG Loss:     0.000218 \n",
      "\n",
      "Epoch [1316/5000] | Train Loss: 0.232082\n",
      "Validation AVG Loss:     0.000218 \n",
      "\n",
      "Epoch [1317/5000] | Train Loss: 0.231988\n",
      "Validation AVG Loss:     0.000218 \n",
      "\n",
      "Epoch [1318/5000] | Train Loss: 0.231894\n",
      "Validation AVG Loss:     0.000217 \n",
      "\n",
      "Epoch [1319/5000] | Train Loss: 0.231800\n",
      "Validation AVG Loss:     0.000217 \n",
      "\n",
      "Epoch [1320/5000] | Train Loss: 0.231706\n",
      "Validation AVG Loss:     0.000217 \n",
      "\n",
      "Epoch [1321/5000] | Train Loss: 0.231612\n",
      "Validation AVG Loss:     0.000217 \n",
      "\n",
      "Epoch [1322/5000] | Train Loss: 0.231518\n",
      "Validation AVG Loss:     0.000217 \n",
      "\n",
      "Epoch [1323/5000] | Train Loss: 0.231424\n",
      "Validation AVG Loss:     0.000217 \n",
      "\n",
      "Epoch [1324/5000] | Train Loss: 0.231330\n",
      "Validation AVG Loss:     0.000217 \n",
      "\n",
      "Epoch [1325/5000] | Train Loss: 0.231236\n",
      "Validation AVG Loss:     0.000217 \n",
      "\n",
      "Epoch [1326/5000] | Train Loss: 0.231141\n",
      "Validation AVG Loss:     0.000217 \n",
      "\n",
      "Epoch [1327/5000] | Train Loss: 0.231047\n",
      "Validation AVG Loss:     0.000217 \n",
      "\n",
      "Epoch [1328/5000] | Train Loss: 0.230953\n",
      "Validation AVG Loss:     0.000217 \n",
      "\n",
      "Epoch [1329/5000] | Train Loss: 0.230859\n",
      "Validation AVG Loss:     0.000216 \n",
      "\n",
      "Epoch [1330/5000] | Train Loss: 0.230765\n",
      "Validation AVG Loss:     0.000216 \n",
      "\n",
      "Epoch [1331/5000] | Train Loss: 0.230671\n",
      "Validation AVG Loss:     0.000216 \n",
      "\n",
      "Epoch [1332/5000] | Train Loss: 0.230577\n",
      "Validation AVG Loss:     0.000216 \n",
      "\n",
      "Epoch [1333/5000] | Train Loss: 0.230483\n",
      "Validation AVG Loss:     0.000216 \n",
      "\n",
      "Epoch [1334/5000] | Train Loss: 0.230389\n",
      "Validation AVG Loss:     0.000216 \n",
      "\n",
      "Epoch [1335/5000] | Train Loss: 0.230295\n",
      "Validation AVG Loss:     0.000216 \n",
      "\n",
      "Epoch [1336/5000] | Train Loss: 0.230200\n",
      "Validation AVG Loss:     0.000216 \n",
      "\n",
      "Epoch [1337/5000] | Train Loss: 0.230106\n",
      "Validation AVG Loss:     0.000216 \n",
      "\n",
      "Epoch [1338/5000] | Train Loss: 0.230012\n",
      "Validation AVG Loss:     0.000216 \n",
      "\n",
      "Epoch [1339/5000] | Train Loss: 0.229918\n",
      "Validation AVG Loss:     0.000216 \n",
      "\n",
      "Epoch [1340/5000] | Train Loss: 0.229824\n",
      "Validation AVG Loss:     0.000215 \n",
      "\n",
      "Epoch [1341/5000] | Train Loss: 0.229730\n",
      "Validation AVG Loss:     0.000215 \n",
      "\n",
      "Epoch [1342/5000] | Train Loss: 0.229636\n",
      "Validation AVG Loss:     0.000215 \n",
      "\n",
      "Epoch [1343/5000] | Train Loss: 0.229541\n",
      "Validation AVG Loss:     0.000215 \n",
      "\n",
      "Epoch [1344/5000] | Train Loss: 0.229447\n",
      "Validation AVG Loss:     0.000215 \n",
      "\n",
      "Epoch [1345/5000] | Train Loss: 0.229353\n",
      "Validation AVG Loss:     0.000215 \n",
      "\n",
      "Epoch [1346/5000] | Train Loss: 0.229259\n",
      "Validation AVG Loss:     0.000215 \n",
      "\n",
      "Epoch [1347/5000] | Train Loss: 0.229165\n",
      "Validation AVG Loss:     0.000215 \n",
      "\n",
      "Epoch [1348/5000] | Train Loss: 0.229071\n",
      "Validation AVG Loss:     0.000215 \n",
      "\n",
      "Epoch [1349/5000] | Train Loss: 0.228976\n",
      "Validation AVG Loss:     0.000215 \n",
      "\n",
      "Epoch [1350/5000] | Train Loss: 0.228882\n",
      "Validation AVG Loss:     0.000215 \n",
      "\n",
      "Epoch [1351/5000] | Train Loss: 0.228788\n",
      "Validation AVG Loss:     0.000214 \n",
      "\n",
      "Epoch [1352/5000] | Train Loss: 0.228694\n",
      "Validation AVG Loss:     0.000214 \n",
      "\n",
      "Epoch [1353/5000] | Train Loss: 0.228600\n",
      "Validation AVG Loss:     0.000214 \n",
      "\n",
      "Epoch [1354/5000] | Train Loss: 0.228506\n",
      "Validation AVG Loss:     0.000214 \n",
      "\n",
      "Epoch [1355/5000] | Train Loss: 0.228411\n",
      "Validation AVG Loss:     0.000214 \n",
      "\n",
      "Epoch [1356/5000] | Train Loss: 0.228317\n",
      "Validation AVG Loss:     0.000214 \n",
      "\n",
      "Epoch [1357/5000] | Train Loss: 0.228223\n",
      "Validation AVG Loss:     0.000214 \n",
      "\n",
      "Epoch [1358/5000] | Train Loss: 0.228129\n",
      "Validation AVG Loss:     0.000214 \n",
      "\n",
      "Epoch [1359/5000] | Train Loss: 0.228035\n",
      "Validation AVG Loss:     0.000214 \n",
      "\n",
      "Epoch [1360/5000] | Train Loss: 0.227940\n",
      "Validation AVG Loss:     0.000214 \n",
      "\n",
      "Epoch [1361/5000] | Train Loss: 0.227846\n",
      "Validation AVG Loss:     0.000214 \n",
      "\n",
      "Epoch [1362/5000] | Train Loss: 0.227752\n",
      "Validation AVG Loss:     0.000213 \n",
      "\n",
      "Epoch [1363/5000] | Train Loss: 0.227658\n",
      "Validation AVG Loss:     0.000213 \n",
      "\n",
      "Epoch [1364/5000] | Train Loss: 0.227563\n",
      "Validation AVG Loss:     0.000213 \n",
      "\n",
      "Epoch [1365/5000] | Train Loss: 0.227469\n",
      "Validation AVG Loss:     0.000213 \n",
      "\n",
      "Epoch [1366/5000] | Train Loss: 0.227375\n",
      "Validation AVG Loss:     0.000213 \n",
      "\n",
      "Epoch [1367/5000] | Train Loss: 0.227281\n",
      "Validation AVG Loss:     0.000213 \n",
      "\n",
      "Epoch [1368/5000] | Train Loss: 0.227186\n",
      "Validation AVG Loss:     0.000213 \n",
      "\n",
      "Epoch [1369/5000] | Train Loss: 0.227092\n",
      "Validation AVG Loss:     0.000213 \n",
      "\n",
      "Epoch [1370/5000] | Train Loss: 0.226998\n",
      "Validation AVG Loss:     0.000213 \n",
      "\n",
      "Epoch [1371/5000] | Train Loss: 0.226904\n",
      "Validation AVG Loss:     0.000213 \n",
      "\n",
      "Epoch [1372/5000] | Train Loss: 0.226809\n",
      "Validation AVG Loss:     0.000213 \n",
      "\n",
      "Epoch [1373/5000] | Train Loss: 0.226715\n",
      "Validation AVG Loss:     0.000212 \n",
      "\n",
      "Epoch [1374/5000] | Train Loss: 0.226621\n",
      "Validation AVG Loss:     0.000212 \n",
      "\n",
      "Epoch [1375/5000] | Train Loss: 0.226526\n",
      "Validation AVG Loss:     0.000212 \n",
      "\n",
      "Epoch [1376/5000] | Train Loss: 0.226432\n",
      "Validation AVG Loss:     0.000212 \n",
      "\n",
      "Epoch [1377/5000] | Train Loss: 0.226338\n",
      "Validation AVG Loss:     0.000212 \n",
      "\n",
      "Epoch [1378/5000] | Train Loss: 0.226244\n",
      "Validation AVG Loss:     0.000212 \n",
      "\n",
      "Epoch [1379/5000] | Train Loss: 0.226149\n",
      "Validation AVG Loss:     0.000212 \n",
      "\n",
      "Epoch [1380/5000] | Train Loss: 0.226055\n",
      "Validation AVG Loss:     0.000212 \n",
      "\n",
      "Epoch [1381/5000] | Train Loss: 0.225961\n",
      "Validation AVG Loss:     0.000212 \n",
      "\n",
      "Epoch [1382/5000] | Train Loss: 0.225866\n",
      "Validation AVG Loss:     0.000212 \n",
      "\n",
      "Epoch [1383/5000] | Train Loss: 0.225772\n",
      "Validation AVG Loss:     0.000212 \n",
      "\n",
      "Epoch [1384/5000] | Train Loss: 0.225678\n",
      "Validation AVG Loss:     0.000211 \n",
      "\n",
      "Epoch [1385/5000] | Train Loss: 0.225583\n",
      "Validation AVG Loss:     0.000211 \n",
      "\n",
      "Epoch [1386/5000] | Train Loss: 0.225489\n",
      "Validation AVG Loss:     0.000211 \n",
      "\n",
      "Epoch [1387/5000] | Train Loss: 0.225395\n",
      "Validation AVG Loss:     0.000211 \n",
      "\n",
      "Epoch [1388/5000] | Train Loss: 0.225301\n",
      "Validation AVG Loss:     0.000211 \n",
      "\n",
      "Epoch [1389/5000] | Train Loss: 0.225206\n",
      "Validation AVG Loss:     0.000211 \n",
      "\n",
      "Epoch [1390/5000] | Train Loss: 0.225112\n",
      "Validation AVG Loss:     0.000211 \n",
      "\n",
      "Epoch [1391/5000] | Train Loss: 0.225018\n",
      "Validation AVG Loss:     0.000211 \n",
      "\n",
      "Epoch [1392/5000] | Train Loss: 0.224923\n",
      "Validation AVG Loss:     0.000211 \n",
      "\n",
      "Epoch [1393/5000] | Train Loss: 0.224829\n",
      "Validation AVG Loss:     0.000211 \n",
      "\n",
      "Epoch [1394/5000] | Train Loss: 0.224735\n",
      "Validation AVG Loss:     0.000211 \n",
      "\n",
      "Epoch [1395/5000] | Train Loss: 0.224640\n",
      "Validation AVG Loss:     0.000210 \n",
      "\n",
      "Epoch [1396/5000] | Train Loss: 0.224546\n",
      "Validation AVG Loss:     0.000210 \n",
      "\n",
      "Epoch [1397/5000] | Train Loss: 0.224451\n",
      "Validation AVG Loss:     0.000210 \n",
      "\n",
      "Epoch [1398/5000] | Train Loss: 0.224357\n",
      "Validation AVG Loss:     0.000210 \n",
      "\n",
      "Epoch [1399/5000] | Train Loss: 0.224263\n",
      "Validation AVG Loss:     0.000210 \n",
      "\n",
      "Epoch [1400/5000] | Train Loss: 0.224168\n",
      "Validation AVG Loss:     0.000210 \n",
      "\n",
      "Epoch [1401/5000] | Train Loss: 0.224074\n",
      "Validation AVG Loss:     0.000210 \n",
      "\n",
      "Epoch [1402/5000] | Train Loss: 0.223980\n",
      "Validation AVG Loss:     0.000210 \n",
      "\n",
      "Epoch [1403/5000] | Train Loss: 0.223885\n",
      "Validation AVG Loss:     0.000210 \n",
      "\n",
      "Epoch [1404/5000] | Train Loss: 0.223791\n",
      "Validation AVG Loss:     0.000210 \n",
      "\n",
      "Epoch [1405/5000] | Train Loss: 0.223697\n",
      "Validation AVG Loss:     0.000210 \n",
      "\n",
      "Epoch [1406/5000] | Train Loss: 0.223602\n",
      "Validation AVG Loss:     0.000210 \n",
      "\n",
      "Epoch [1407/5000] | Train Loss: 0.223508\n",
      "Validation AVG Loss:     0.000209 \n",
      "\n",
      "Epoch [1408/5000] | Train Loss: 0.223413\n",
      "Validation AVG Loss:     0.000209 \n",
      "\n",
      "Epoch [1409/5000] | Train Loss: 0.223319\n",
      "Validation AVG Loss:     0.000209 \n",
      "\n",
      "Epoch [1410/5000] | Train Loss: 0.223225\n",
      "Validation AVG Loss:     0.000209 \n",
      "\n",
      "Epoch [1411/5000] | Train Loss: 0.223130\n",
      "Validation AVG Loss:     0.000209 \n",
      "\n",
      "Epoch [1412/5000] | Train Loss: 0.223036\n",
      "Validation AVG Loss:     0.000209 \n",
      "\n",
      "Epoch [1413/5000] | Train Loss: 0.222941\n",
      "Validation AVG Loss:     0.000209 \n",
      "\n",
      "Epoch [1414/5000] | Train Loss: 0.222847\n",
      "Validation AVG Loss:     0.000209 \n",
      "\n",
      "Epoch [1415/5000] | Train Loss: 0.222753\n",
      "Validation AVG Loss:     0.000209 \n",
      "\n",
      "Epoch [1416/5000] | Train Loss: 0.222658\n",
      "Validation AVG Loss:     0.000209 \n",
      "\n",
      "Epoch [1417/5000] | Train Loss: 0.222564\n",
      "Validation AVG Loss:     0.000209 \n",
      "\n",
      "Epoch [1418/5000] | Train Loss: 0.222469\n",
      "Validation AVG Loss:     0.000208 \n",
      "\n",
      "Epoch [1419/5000] | Train Loss: 0.222375\n",
      "Validation AVG Loss:     0.000208 \n",
      "\n",
      "Epoch [1420/5000] | Train Loss: 0.222280\n",
      "Validation AVG Loss:     0.000208 \n",
      "\n",
      "Epoch [1421/5000] | Train Loss: 0.222186\n",
      "Validation AVG Loss:     0.000208 \n",
      "\n",
      "Epoch [1422/5000] | Train Loss: 0.222092\n",
      "Validation AVG Loss:     0.000208 \n",
      "\n",
      "Epoch [1423/5000] | Train Loss: 0.221997\n",
      "Validation AVG Loss:     0.000208 \n",
      "\n",
      "Epoch [1424/5000] | Train Loss: 0.221903\n",
      "Validation AVG Loss:     0.000208 \n",
      "\n",
      "Epoch [1425/5000] | Train Loss: 0.221808\n",
      "Validation AVG Loss:     0.000208 \n",
      "\n",
      "Epoch [1426/5000] | Train Loss: 0.221714\n",
      "Validation AVG Loss:     0.000208 \n",
      "\n",
      "Epoch [1427/5000] | Train Loss: 0.221619\n",
      "Validation AVG Loss:     0.000208 \n",
      "\n",
      "Epoch [1428/5000] | Train Loss: 0.221525\n",
      "Validation AVG Loss:     0.000208 \n",
      "\n",
      "Epoch [1429/5000] | Train Loss: 0.221430\n",
      "Validation AVG Loss:     0.000207 \n",
      "\n",
      "Epoch [1430/5000] | Train Loss: 0.221336\n",
      "Validation AVG Loss:     0.000207 \n",
      "\n",
      "Epoch [1431/5000] | Train Loss: 0.221241\n",
      "Validation AVG Loss:     0.000207 \n",
      "\n",
      "Epoch [1432/5000] | Train Loss: 0.221147\n",
      "Validation AVG Loss:     0.000207 \n",
      "\n",
      "Epoch [1433/5000] | Train Loss: 0.221052\n",
      "Validation AVG Loss:     0.000207 \n",
      "\n",
      "Epoch [1434/5000] | Train Loss: 0.220958\n",
      "Validation AVG Loss:     0.000207 \n",
      "\n",
      "Epoch [1435/5000] | Train Loss: 0.220863\n",
      "Validation AVG Loss:     0.000207 \n",
      "\n",
      "Epoch [1436/5000] | Train Loss: 0.220769\n",
      "Validation AVG Loss:     0.000207 \n",
      "\n",
      "Epoch [1437/5000] | Train Loss: 0.220674\n",
      "Validation AVG Loss:     0.000207 \n",
      "\n",
      "Epoch [1438/5000] | Train Loss: 0.220580\n",
      "Validation AVG Loss:     0.000207 \n",
      "\n",
      "Epoch [1439/5000] | Train Loss: 0.220485\n",
      "Validation AVG Loss:     0.000207 \n",
      "\n",
      "Epoch [1440/5000] | Train Loss: 0.220391\n",
      "Validation AVG Loss:     0.000206 \n",
      "\n",
      "Epoch [1441/5000] | Train Loss: 0.220296\n",
      "Validation AVG Loss:     0.000206 \n",
      "\n",
      "Epoch [1442/5000] | Train Loss: 0.220201\n",
      "Validation AVG Loss:     0.000206 \n",
      "\n",
      "Epoch [1443/5000] | Train Loss: 0.220107\n",
      "Validation AVG Loss:     0.000206 \n",
      "\n",
      "Epoch [1444/5000] | Train Loss: 0.220012\n",
      "Validation AVG Loss:     0.000206 \n",
      "\n",
      "Epoch [1445/5000] | Train Loss: 0.219918\n",
      "Validation AVG Loss:     0.000206 \n",
      "\n",
      "Epoch [1446/5000] | Train Loss: 0.219823\n",
      "Validation AVG Loss:     0.000206 \n",
      "\n",
      "Epoch [1447/5000] | Train Loss: 0.219729\n",
      "Validation AVG Loss:     0.000206 \n",
      "\n",
      "Epoch [1448/5000] | Train Loss: 0.219634\n",
      "Validation AVG Loss:     0.000206 \n",
      "\n",
      "Epoch [1449/5000] | Train Loss: 0.219539\n",
      "Validation AVG Loss:     0.000206 \n",
      "\n",
      "Epoch [1450/5000] | Train Loss: 0.219445\n",
      "Validation AVG Loss:     0.000206 \n",
      "\n",
      "Epoch [1451/5000] | Train Loss: 0.219350\n",
      "Validation AVG Loss:     0.000205 \n",
      "\n",
      "Epoch [1452/5000] | Train Loss: 0.219255\n",
      "Validation AVG Loss:     0.000205 \n",
      "\n",
      "Epoch [1453/5000] | Train Loss: 0.219161\n",
      "Validation AVG Loss:     0.000205 \n",
      "\n",
      "Epoch [1454/5000] | Train Loss: 0.219066\n",
      "Validation AVG Loss:     0.000205 \n",
      "\n",
      "Epoch [1455/5000] | Train Loss: 0.218971\n",
      "Validation AVG Loss:     0.000205 \n",
      "\n",
      "Epoch [1456/5000] | Train Loss: 0.218877\n",
      "Validation AVG Loss:     0.000205 \n",
      "\n",
      "Epoch [1457/5000] | Train Loss: 0.218782\n",
      "Validation AVG Loss:     0.000205 \n",
      "\n",
      "Epoch [1458/5000] | Train Loss: 0.218687\n",
      "Validation AVG Loss:     0.000205 \n",
      "\n",
      "Epoch [1459/5000] | Train Loss: 0.218593\n",
      "Validation AVG Loss:     0.000205 \n",
      "\n",
      "Epoch [1460/5000] | Train Loss: 0.218498\n",
      "Validation AVG Loss:     0.000205 \n",
      "\n",
      "Epoch [1461/5000] | Train Loss: 0.218403\n",
      "Validation AVG Loss:     0.000205 \n",
      "\n",
      "Epoch [1462/5000] | Train Loss: 0.218309\n",
      "Validation AVG Loss:     0.000204 \n",
      "\n",
      "Epoch [1463/5000] | Train Loss: 0.218214\n",
      "Validation AVG Loss:     0.000204 \n",
      "\n",
      "Epoch [1464/5000] | Train Loss: 0.218119\n",
      "Validation AVG Loss:     0.000204 \n",
      "\n",
      "Epoch [1465/5000] | Train Loss: 0.218025\n",
      "Validation AVG Loss:     0.000204 \n",
      "\n",
      "Epoch [1466/5000] | Train Loss: 0.217930\n",
      "Validation AVG Loss:     0.000204 \n",
      "\n",
      "Epoch [1467/5000] | Train Loss: 0.217835\n",
      "Validation AVG Loss:     0.000204 \n",
      "\n",
      "Epoch [1468/5000] | Train Loss: 0.217740\n",
      "Validation AVG Loss:     0.000204 \n",
      "\n",
      "Epoch [1469/5000] | Train Loss: 0.217646\n",
      "Validation AVG Loss:     0.000204 \n",
      "\n",
      "Epoch [1470/5000] | Train Loss: 0.217551\n",
      "Validation AVG Loss:     0.000204 \n",
      "\n",
      "Epoch [1471/5000] | Train Loss: 0.217456\n",
      "Validation AVG Loss:     0.000204 \n",
      "\n",
      "Epoch [1472/5000] | Train Loss: 0.217361\n",
      "Validation AVG Loss:     0.000204 \n",
      "\n",
      "Epoch [1473/5000] | Train Loss: 0.217267\n",
      "Validation AVG Loss:     0.000203 \n",
      "\n",
      "Epoch [1474/5000] | Train Loss: 0.217172\n",
      "Validation AVG Loss:     0.000203 \n",
      "\n",
      "Epoch [1475/5000] | Train Loss: 0.217077\n",
      "Validation AVG Loss:     0.000203 \n",
      "\n",
      "Epoch [1476/5000] | Train Loss: 0.216982\n",
      "Validation AVG Loss:     0.000203 \n",
      "\n",
      "Epoch [1477/5000] | Train Loss: 0.216888\n",
      "Validation AVG Loss:     0.000203 \n",
      "\n",
      "Epoch [1478/5000] | Train Loss: 0.216793\n",
      "Validation AVG Loss:     0.000203 \n",
      "\n",
      "Epoch [1479/5000] | Train Loss: 0.216698\n",
      "Validation AVG Loss:     0.000203 \n",
      "\n",
      "Epoch [1480/5000] | Train Loss: 0.216603\n",
      "Validation AVG Loss:     0.000203 \n",
      "\n",
      "Epoch [1481/5000] | Train Loss: 0.216508\n",
      "Validation AVG Loss:     0.000203 \n",
      "\n",
      "Epoch [1482/5000] | Train Loss: 0.216414\n",
      "Validation AVG Loss:     0.000203 \n",
      "\n",
      "Epoch [1483/5000] | Train Loss: 0.216319\n",
      "Validation AVG Loss:     0.000203 \n",
      "\n",
      "Epoch [1484/5000] | Train Loss: 0.216224\n",
      "Validation AVG Loss:     0.000202 \n",
      "\n",
      "Epoch [1485/5000] | Train Loss: 0.216129\n",
      "Validation AVG Loss:     0.000202 \n",
      "\n",
      "Epoch [1486/5000] | Train Loss: 0.216034\n",
      "Validation AVG Loss:     0.000202 \n",
      "\n",
      "Epoch [1487/5000] | Train Loss: 0.215939\n",
      "Validation AVG Loss:     0.000202 \n",
      "\n",
      "Epoch [1488/5000] | Train Loss: 0.215844\n",
      "Validation AVG Loss:     0.000202 \n",
      "\n",
      "Epoch [1489/5000] | Train Loss: 0.215750\n",
      "Validation AVG Loss:     0.000202 \n",
      "\n",
      "Epoch [1490/5000] | Train Loss: 0.215655\n",
      "Validation AVG Loss:     0.000202 \n",
      "\n",
      "Epoch [1491/5000] | Train Loss: 0.215560\n",
      "Validation AVG Loss:     0.000202 \n",
      "\n",
      "Epoch [1492/5000] | Train Loss: 0.215465\n",
      "Validation AVG Loss:     0.000202 \n",
      "\n",
      "Epoch [1493/5000] | Train Loss: 0.215370\n",
      "Validation AVG Loss:     0.000202 \n",
      "\n",
      "Epoch [1494/5000] | Train Loss: 0.215275\n",
      "Validation AVG Loss:     0.000201 \n",
      "\n",
      "Epoch [1495/5000] | Train Loss: 0.215180\n",
      "Validation AVG Loss:     0.000201 \n",
      "\n",
      "Epoch [1496/5000] | Train Loss: 0.215085\n",
      "Validation AVG Loss:     0.000201 \n",
      "\n",
      "Epoch [1497/5000] | Train Loss: 0.214991\n",
      "Validation AVG Loss:     0.000201 \n",
      "\n",
      "Epoch [1498/5000] | Train Loss: 0.214896\n",
      "Validation AVG Loss:     0.000201 \n",
      "\n",
      "Epoch [1499/5000] | Train Loss: 0.214801\n",
      "Validation AVG Loss:     0.000201 \n",
      "\n",
      "Epoch [1500/5000] | Train Loss: 0.214706\n",
      "Validation AVG Loss:     0.000201 \n",
      "\n",
      "Epoch [1501/5000] | Train Loss: 0.214611\n",
      "Validation AVG Loss:     0.000201 \n",
      "\n",
      "Epoch [1502/5000] | Train Loss: 0.214516\n",
      "Validation AVG Loss:     0.000201 \n",
      "\n",
      "Epoch [1503/5000] | Train Loss: 0.214421\n",
      "Validation AVG Loss:     0.000201 \n",
      "\n",
      "Epoch [1504/5000] | Train Loss: 0.214326\n",
      "Validation AVG Loss:     0.000201 \n",
      "\n",
      "Epoch [1505/5000] | Train Loss: 0.214231\n",
      "Validation AVG Loss:     0.000200 \n",
      "\n",
      "Epoch [1506/5000] | Train Loss: 0.214136\n",
      "Validation AVG Loss:     0.000200 \n",
      "\n",
      "Epoch [1507/5000] | Train Loss: 0.214041\n",
      "Validation AVG Loss:     0.000200 \n",
      "\n",
      "Epoch [1508/5000] | Train Loss: 0.213946\n",
      "Validation AVG Loss:     0.000200 \n",
      "\n",
      "Epoch [1509/5000] | Train Loss: 0.213851\n",
      "Validation AVG Loss:     0.000200 \n",
      "\n",
      "Epoch [1510/5000] | Train Loss: 0.213756\n",
      "Validation AVG Loss:     0.000200 \n",
      "\n",
      "Epoch [1511/5000] | Train Loss: 0.213661\n",
      "Validation AVG Loss:     0.000200 \n",
      "\n",
      "Epoch [1512/5000] | Train Loss: 0.213566\n",
      "Validation AVG Loss:     0.000200 \n",
      "\n",
      "Epoch [1513/5000] | Train Loss: 0.213471\n",
      "Validation AVG Loss:     0.000200 \n",
      "\n",
      "Epoch [1514/5000] | Train Loss: 0.213376\n",
      "Validation AVG Loss:     0.000200 \n",
      "\n",
      "Epoch [1515/5000] | Train Loss: 0.213281\n",
      "Validation AVG Loss:     0.000200 \n",
      "\n",
      "Epoch [1516/5000] | Train Loss: 0.213186\n",
      "Validation AVG Loss:     0.000199 \n",
      "\n",
      "Epoch [1517/5000] | Train Loss: 0.213091\n",
      "Validation AVG Loss:     0.000199 \n",
      "\n",
      "Epoch [1518/5000] | Train Loss: 0.212996\n",
      "Validation AVG Loss:     0.000199 \n",
      "\n",
      "Epoch [1519/5000] | Train Loss: 0.212901\n",
      "Validation AVG Loss:     0.000199 \n",
      "\n",
      "Epoch [1520/5000] | Train Loss: 0.212806\n",
      "Validation AVG Loss:     0.000199 \n",
      "\n",
      "Epoch [1521/5000] | Train Loss: 0.212711\n",
      "Validation AVG Loss:     0.000199 \n",
      "\n",
      "Epoch [1522/5000] | Train Loss: 0.212616\n",
      "Validation AVG Loss:     0.000199 \n",
      "\n",
      "Epoch [1523/5000] | Train Loss: 0.212520\n",
      "Validation AVG Loss:     0.000199 \n",
      "\n",
      "Epoch [1524/5000] | Train Loss: 0.212425\n",
      "Validation AVG Loss:     0.000199 \n",
      "\n",
      "Epoch [1525/5000] | Train Loss: 0.212330\n",
      "Validation AVG Loss:     0.000199 \n",
      "\n",
      "Epoch [1526/5000] | Train Loss: 0.212235\n",
      "Validation AVG Loss:     0.000199 \n",
      "\n",
      "Epoch [1527/5000] | Train Loss: 0.212140\n",
      "Validation AVG Loss:     0.000198 \n",
      "\n",
      "Epoch [1528/5000] | Train Loss: 0.212045\n",
      "Validation AVG Loss:     0.000198 \n",
      "\n",
      "Epoch [1529/5000] | Train Loss: 0.211950\n",
      "Validation AVG Loss:     0.000198 \n",
      "\n",
      "Epoch [1530/5000] | Train Loss: 0.211855\n",
      "Validation AVG Loss:     0.000198 \n",
      "\n",
      "Epoch [1531/5000] | Train Loss: 0.211760\n",
      "Validation AVG Loss:     0.000198 \n",
      "\n",
      "Epoch [1532/5000] | Train Loss: 0.211665\n",
      "Validation AVG Loss:     0.000198 \n",
      "\n",
      "Epoch [1533/5000] | Train Loss: 0.211569\n",
      "Validation AVG Loss:     0.000198 \n",
      "\n",
      "Epoch [1534/5000] | Train Loss: 0.211474\n",
      "Validation AVG Loss:     0.000198 \n",
      "\n",
      "Epoch [1535/5000] | Train Loss: 0.211379\n",
      "Validation AVG Loss:     0.000198 \n",
      "\n",
      "Epoch [1536/5000] | Train Loss: 0.211284\n",
      "Validation AVG Loss:     0.000198 \n",
      "\n",
      "Epoch [1537/5000] | Train Loss: 0.211189\n",
      "Validation AVG Loss:     0.000198 \n",
      "\n",
      "Epoch [1538/5000] | Train Loss: 0.211094\n",
      "Validation AVG Loss:     0.000197 \n",
      "\n",
      "Epoch [1539/5000] | Train Loss: 0.210998\n",
      "Validation AVG Loss:     0.000197 \n",
      "\n",
      "Epoch [1540/5000] | Train Loss: 0.210903\n",
      "Validation AVG Loss:     0.000197 \n",
      "\n",
      "Epoch [1541/5000] | Train Loss: 0.210808\n",
      "Validation AVG Loss:     0.000197 \n",
      "\n",
      "Epoch [1542/5000] | Train Loss: 0.210713\n",
      "Validation AVG Loss:     0.000197 \n",
      "\n",
      "Epoch [1543/5000] | Train Loss: 0.210618\n",
      "Validation AVG Loss:     0.000197 \n",
      "\n",
      "Epoch [1544/5000] | Train Loss: 0.210523\n",
      "Validation AVG Loss:     0.000197 \n",
      "\n",
      "Epoch [1545/5000] | Train Loss: 0.210427\n",
      "Validation AVG Loss:     0.000197 \n",
      "\n",
      "Epoch [1546/5000] | Train Loss: 0.210332\n",
      "Validation AVG Loss:     0.000197 \n",
      "\n",
      "Epoch [1547/5000] | Train Loss: 0.210237\n",
      "Validation AVG Loss:     0.000197 \n",
      "\n",
      "Epoch [1548/5000] | Train Loss: 0.210142\n",
      "Validation AVG Loss:     0.000197 \n",
      "\n",
      "Epoch [1549/5000] | Train Loss: 0.210046\n",
      "Validation AVG Loss:     0.000196 \n",
      "\n",
      "Epoch [1550/5000] | Train Loss: 0.209951\n",
      "Validation AVG Loss:     0.000196 \n",
      "\n",
      "Epoch [1551/5000] | Train Loss: 0.209856\n",
      "Validation AVG Loss:     0.000196 \n",
      "\n",
      "Epoch [1552/5000] | Train Loss: 0.209761\n",
      "Validation AVG Loss:     0.000196 \n",
      "\n",
      "Epoch [1553/5000] | Train Loss: 0.209666\n",
      "Validation AVG Loss:     0.000196 \n",
      "\n",
      "Epoch [1554/5000] | Train Loss: 0.209570\n",
      "Validation AVG Loss:     0.000196 \n",
      "\n",
      "Epoch [1555/5000] | Train Loss: 0.209475\n",
      "Validation AVG Loss:     0.000196 \n",
      "\n",
      "Epoch [1556/5000] | Train Loss: 0.209380\n",
      "Validation AVG Loss:     0.000196 \n",
      "\n",
      "Epoch [1557/5000] | Train Loss: 0.209285\n",
      "Validation AVG Loss:     0.000196 \n",
      "\n",
      "Epoch [1558/5000] | Train Loss: 0.209189\n",
      "Validation AVG Loss:     0.000196 \n",
      "\n",
      "Epoch [1559/5000] | Train Loss: 0.209094\n",
      "Validation AVG Loss:     0.000196 \n",
      "\n",
      "Epoch [1560/5000] | Train Loss: 0.208999\n",
      "Validation AVG Loss:     0.000195 \n",
      "\n",
      "Epoch [1561/5000] | Train Loss: 0.208904\n",
      "Validation AVG Loss:     0.000195 \n",
      "\n",
      "Epoch [1562/5000] | Train Loss: 0.208808\n",
      "Validation AVG Loss:     0.000195 \n",
      "\n",
      "Epoch [1563/5000] | Train Loss: 0.208713\n",
      "Validation AVG Loss:     0.000195 \n",
      "\n",
      "Epoch [1564/5000] | Train Loss: 0.208618\n",
      "Validation AVG Loss:     0.000195 \n",
      "\n",
      "Epoch [1565/5000] | Train Loss: 0.208522\n",
      "Validation AVG Loss:     0.000195 \n",
      "\n",
      "Epoch [1566/5000] | Train Loss: 0.208427\n",
      "Validation AVG Loss:     0.000195 \n",
      "\n",
      "Epoch [1567/5000] | Train Loss: 0.208332\n",
      "Validation AVG Loss:     0.000195 \n",
      "\n",
      "Epoch [1568/5000] | Train Loss: 0.208236\n",
      "Validation AVG Loss:     0.000195 \n",
      "\n",
      "Epoch [1569/5000] | Train Loss: 0.208141\n",
      "Validation AVG Loss:     0.000195 \n",
      "\n",
      "Epoch [1570/5000] | Train Loss: 0.208046\n",
      "Validation AVG Loss:     0.000195 \n",
      "\n",
      "Epoch [1571/5000] | Train Loss: 0.207950\n",
      "Validation AVG Loss:     0.000194 \n",
      "\n",
      "Epoch [1572/5000] | Train Loss: 0.207855\n",
      "Validation AVG Loss:     0.000194 \n",
      "\n",
      "Epoch [1573/5000] | Train Loss: 0.207760\n",
      "Validation AVG Loss:     0.000194 \n",
      "\n",
      "Epoch [1574/5000] | Train Loss: 0.207664\n",
      "Validation AVG Loss:     0.000194 \n",
      "\n",
      "Epoch [1575/5000] | Train Loss: 0.207569\n",
      "Validation AVG Loss:     0.000194 \n",
      "\n",
      "Epoch [1576/5000] | Train Loss: 0.207474\n",
      "Validation AVG Loss:     0.000194 \n",
      "\n",
      "Epoch [1577/5000] | Train Loss: 0.207378\n",
      "Validation AVG Loss:     0.000194 \n",
      "\n",
      "Epoch [1578/5000] | Train Loss: 0.207283\n",
      "Validation AVG Loss:     0.000194 \n",
      "\n",
      "Epoch [1579/5000] | Train Loss: 0.207188\n",
      "Validation AVG Loss:     0.000194 \n",
      "\n",
      "Epoch [1580/5000] | Train Loss: 0.207092\n",
      "Validation AVG Loss:     0.000194 \n",
      "\n",
      "Epoch [1581/5000] | Train Loss: 0.206997\n",
      "Validation AVG Loss:     0.000194 \n",
      "\n",
      "Epoch [1582/5000] | Train Loss: 0.206902\n",
      "Validation AVG Loss:     0.000193 \n",
      "\n",
      "Epoch [1583/5000] | Train Loss: 0.206806\n",
      "Validation AVG Loss:     0.000193 \n",
      "\n",
      "Epoch [1584/5000] | Train Loss: 0.206711\n",
      "Validation AVG Loss:     0.000193 \n",
      "\n",
      "Epoch [1585/5000] | Train Loss: 0.206615\n",
      "Validation AVG Loss:     0.000193 \n",
      "\n",
      "Epoch [1586/5000] | Train Loss: 0.206520\n",
      "Validation AVG Loss:     0.000193 \n",
      "\n",
      "Epoch [1587/5000] | Train Loss: 0.206425\n",
      "Validation AVG Loss:     0.000193 \n",
      "\n",
      "Epoch [1588/5000] | Train Loss: 0.206329\n",
      "Validation AVG Loss:     0.000193 \n",
      "\n",
      "Epoch [1589/5000] | Train Loss: 0.206234\n",
      "Validation AVG Loss:     0.000193 \n",
      "\n",
      "Epoch [1590/5000] | Train Loss: 0.206138\n",
      "Validation AVG Loss:     0.000193 \n",
      "\n",
      "Epoch [1591/5000] | Train Loss: 0.206043\n",
      "Validation AVG Loss:     0.000193 \n",
      "\n",
      "Epoch [1592/5000] | Train Loss: 0.205947\n",
      "Validation AVG Loss:     0.000193 \n",
      "\n",
      "Epoch [1593/5000] | Train Loss: 0.205852\n",
      "Validation AVG Loss:     0.000192 \n",
      "\n",
      "Epoch [1594/5000] | Train Loss: 0.205757\n",
      "Validation AVG Loss:     0.000192 \n",
      "\n",
      "Epoch [1595/5000] | Train Loss: 0.205661\n",
      "Validation AVG Loss:     0.000192 \n",
      "\n",
      "Epoch [1596/5000] | Train Loss: 0.205566\n",
      "Validation AVG Loss:     0.000192 \n",
      "\n",
      "Epoch [1597/5000] | Train Loss: 0.205470\n",
      "Validation AVG Loss:     0.000192 \n",
      "\n",
      "Epoch [1598/5000] | Train Loss: 0.205375\n",
      "Validation AVG Loss:     0.000192 \n",
      "\n",
      "Epoch [1599/5000] | Train Loss: 0.205279\n",
      "Validation AVG Loss:     0.000192 \n",
      "\n",
      "Epoch [1600/5000] | Train Loss: 0.205184\n",
      "Validation AVG Loss:     0.000192 \n",
      "\n",
      "Epoch [1601/5000] | Train Loss: 0.205089\n",
      "Validation AVG Loss:     0.000192 \n",
      "\n",
      "Epoch [1602/5000] | Train Loss: 0.204993\n",
      "Validation AVG Loss:     0.000192 \n",
      "\n",
      "Epoch [1603/5000] | Train Loss: 0.204898\n",
      "Validation AVG Loss:     0.000192 \n",
      "\n",
      "Epoch [1604/5000] | Train Loss: 0.204802\n",
      "Validation AVG Loss:     0.000191 \n",
      "\n",
      "Epoch [1605/5000] | Train Loss: 0.204707\n",
      "Validation AVG Loss:     0.000191 \n",
      "\n",
      "Epoch [1606/5000] | Train Loss: 0.204611\n",
      "Validation AVG Loss:     0.000191 \n",
      "\n",
      "Epoch [1607/5000] | Train Loss: 0.204516\n",
      "Validation AVG Loss:     0.000191 \n",
      "\n",
      "Epoch [1608/5000] | Train Loss: 0.204420\n",
      "Validation AVG Loss:     0.000191 \n",
      "\n",
      "Epoch [1609/5000] | Train Loss: 0.204325\n",
      "Validation AVG Loss:     0.000191 \n",
      "\n",
      "Epoch [1610/5000] | Train Loss: 0.204229\n",
      "Validation AVG Loss:     0.000191 \n",
      "\n",
      "Epoch [1611/5000] | Train Loss: 0.204134\n",
      "Validation AVG Loss:     0.000191 \n",
      "\n",
      "Epoch [1612/5000] | Train Loss: 0.204038\n",
      "Validation AVG Loss:     0.000191 \n",
      "\n",
      "Epoch [1613/5000] | Train Loss: 0.203943\n",
      "Validation AVG Loss:     0.000191 \n",
      "\n",
      "Epoch [1614/5000] | Train Loss: 0.203847\n",
      "Validation AVG Loss:     0.000191 \n",
      "\n",
      "Epoch [1615/5000] | Train Loss: 0.203752\n",
      "Validation AVG Loss:     0.000190 \n",
      "\n",
      "Epoch [1616/5000] | Train Loss: 0.203656\n",
      "Validation AVG Loss:     0.000190 \n",
      "\n",
      "Epoch [1617/5000] | Train Loss: 0.203561\n",
      "Validation AVG Loss:     0.000190 \n",
      "\n",
      "Epoch [1618/5000] | Train Loss: 0.203465\n",
      "Validation AVG Loss:     0.000190 \n",
      "\n",
      "Epoch [1619/5000] | Train Loss: 0.203370\n",
      "Validation AVG Loss:     0.000190 \n",
      "\n",
      "Epoch [1620/5000] | Train Loss: 0.203274\n",
      "Validation AVG Loss:     0.000190 \n",
      "\n",
      "Epoch [1621/5000] | Train Loss: 0.203179\n",
      "Validation AVG Loss:     0.000190 \n",
      "\n",
      "Epoch [1622/5000] | Train Loss: 0.203083\n",
      "Validation AVG Loss:     0.000190 \n",
      "\n",
      "Epoch [1623/5000] | Train Loss: 0.202988\n",
      "Validation AVG Loss:     0.000190 \n",
      "\n",
      "Epoch [1624/5000] | Train Loss: 0.202892\n",
      "Validation AVG Loss:     0.000190 \n",
      "\n",
      "Epoch [1625/5000] | Train Loss: 0.202796\n",
      "Validation AVG Loss:     0.000190 \n",
      "\n",
      "Epoch [1626/5000] | Train Loss: 0.202701\n",
      "Validation AVG Loss:     0.000189 \n",
      "\n",
      "Epoch [1627/5000] | Train Loss: 0.202605\n",
      "Validation AVG Loss:     0.000189 \n",
      "\n",
      "Epoch [1628/5000] | Train Loss: 0.202510\n",
      "Validation AVG Loss:     0.000189 \n",
      "\n",
      "Epoch [1629/5000] | Train Loss: 0.202414\n",
      "Validation AVG Loss:     0.000189 \n",
      "\n",
      "Epoch [1630/5000] | Train Loss: 0.202319\n",
      "Validation AVG Loss:     0.000189 \n",
      "\n",
      "Epoch [1631/5000] | Train Loss: 0.202223\n",
      "Validation AVG Loss:     0.000189 \n",
      "\n",
      "Epoch [1632/5000] | Train Loss: 0.202127\n",
      "Validation AVG Loss:     0.000189 \n",
      "\n",
      "Epoch [1633/5000] | Train Loss: 0.202032\n",
      "Validation AVG Loss:     0.000189 \n",
      "\n",
      "Epoch [1634/5000] | Train Loss: 0.201936\n",
      "Validation AVG Loss:     0.000189 \n",
      "\n",
      "Epoch [1635/5000] | Train Loss: 0.201841\n",
      "Validation AVG Loss:     0.000189 \n",
      "\n",
      "Epoch [1636/5000] | Train Loss: 0.201745\n",
      "Validation AVG Loss:     0.000189 \n",
      "\n",
      "Epoch [1637/5000] | Train Loss: 0.201649\n",
      "Validation AVG Loss:     0.000188 \n",
      "\n",
      "Epoch [1638/5000] | Train Loss: 0.201554\n",
      "Validation AVG Loss:     0.000188 \n",
      "\n",
      "Epoch [1639/5000] | Train Loss: 0.201458\n",
      "Validation AVG Loss:     0.000188 \n",
      "\n",
      "Epoch [1640/5000] | Train Loss: 0.201362\n",
      "Validation AVG Loss:     0.000188 \n",
      "\n",
      "Epoch [1641/5000] | Train Loss: 0.201267\n",
      "Validation AVG Loss:     0.000188 \n",
      "\n",
      "Epoch [1642/5000] | Train Loss: 0.201171\n",
      "Validation AVG Loss:     0.000188 \n",
      "\n",
      "Epoch [1643/5000] | Train Loss: 0.201075\n",
      "Validation AVG Loss:     0.000188 \n",
      "\n",
      "Epoch [1644/5000] | Train Loss: 0.200980\n",
      "Validation AVG Loss:     0.000188 \n",
      "\n",
      "Epoch [1645/5000] | Train Loss: 0.200884\n",
      "Validation AVG Loss:     0.000188 \n",
      "\n",
      "Epoch [1646/5000] | Train Loss: 0.200788\n",
      "Validation AVG Loss:     0.000188 \n",
      "\n",
      "Epoch [1647/5000] | Train Loss: 0.200693\n",
      "Validation AVG Loss:     0.000187 \n",
      "\n",
      "Epoch [1648/5000] | Train Loss: 0.200597\n",
      "Validation AVG Loss:     0.000187 \n",
      "\n",
      "Epoch [1649/5000] | Train Loss: 0.200501\n",
      "Validation AVG Loss:     0.000187 \n",
      "\n",
      "Epoch [1650/5000] | Train Loss: 0.200406\n",
      "Validation AVG Loss:     0.000187 \n",
      "\n",
      "Epoch [1651/5000] | Train Loss: 0.200310\n",
      "Validation AVG Loss:     0.000187 \n",
      "\n",
      "Epoch [1652/5000] | Train Loss: 0.200214\n",
      "Validation AVG Loss:     0.000187 \n",
      "\n",
      "Epoch [1653/5000] | Train Loss: 0.200119\n",
      "Validation AVG Loss:     0.000187 \n",
      "\n",
      "Epoch [1654/5000] | Train Loss: 0.200023\n",
      "Validation AVG Loss:     0.000187 \n",
      "\n",
      "Epoch [1655/5000] | Train Loss: 0.199927\n",
      "Validation AVG Loss:     0.000187 \n",
      "\n",
      "Epoch [1656/5000] | Train Loss: 0.199832\n",
      "Validation AVG Loss:     0.000187 \n",
      "\n",
      "Epoch [1657/5000] | Train Loss: 0.199736\n",
      "Validation AVG Loss:     0.000187 \n",
      "\n",
      "Epoch [1658/5000] | Train Loss: 0.199640\n",
      "Validation AVG Loss:     0.000186 \n",
      "\n",
      "Epoch [1659/5000] | Train Loss: 0.199544\n",
      "Validation AVG Loss:     0.000186 \n",
      "\n",
      "Epoch [1660/5000] | Train Loss: 0.199449\n",
      "Validation AVG Loss:     0.000186 \n",
      "\n",
      "Epoch [1661/5000] | Train Loss: 0.199353\n",
      "Validation AVG Loss:     0.000186 \n",
      "\n",
      "Epoch [1662/5000] | Train Loss: 0.199257\n",
      "Validation AVG Loss:     0.000186 \n",
      "\n",
      "Epoch [1663/5000] | Train Loss: 0.199162\n",
      "Validation AVG Loss:     0.000186 \n",
      "\n",
      "Epoch [1664/5000] | Train Loss: 0.199066\n",
      "Validation AVG Loss:     0.000186 \n",
      "\n",
      "Epoch [1665/5000] | Train Loss: 0.198970\n",
      "Validation AVG Loss:     0.000186 \n",
      "\n",
      "Epoch [1666/5000] | Train Loss: 0.198874\n",
      "Validation AVG Loss:     0.000186 \n",
      "\n",
      "Epoch [1667/5000] | Train Loss: 0.198779\n",
      "Validation AVG Loss:     0.000186 \n",
      "\n",
      "Epoch [1668/5000] | Train Loss: 0.198683\n",
      "Validation AVG Loss:     0.000186 \n",
      "\n",
      "Epoch [1669/5000] | Train Loss: 0.198587\n",
      "Validation AVG Loss:     0.000185 \n",
      "\n",
      "Epoch [1670/5000] | Train Loss: 0.198491\n",
      "Validation AVG Loss:     0.000185 \n",
      "\n",
      "Epoch [1671/5000] | Train Loss: 0.198395\n",
      "Validation AVG Loss:     0.000185 \n",
      "\n",
      "Epoch [1672/5000] | Train Loss: 0.198300\n",
      "Validation AVG Loss:     0.000185 \n",
      "\n",
      "Epoch [1673/5000] | Train Loss: 0.198204\n",
      "Validation AVG Loss:     0.000185 \n",
      "\n",
      "Epoch [1674/5000] | Train Loss: 0.198108\n",
      "Validation AVG Loss:     0.000185 \n",
      "\n",
      "Epoch [1675/5000] | Train Loss: 0.198012\n",
      "Validation AVG Loss:     0.000185 \n",
      "\n",
      "Epoch [1676/5000] | Train Loss: 0.197916\n",
      "Validation AVG Loss:     0.000185 \n",
      "\n",
      "Epoch [1677/5000] | Train Loss: 0.197821\n",
      "Validation AVG Loss:     0.000185 \n",
      "\n",
      "Epoch [1678/5000] | Train Loss: 0.197725\n",
      "Validation AVG Loss:     0.000185 \n",
      "\n",
      "Epoch [1679/5000] | Train Loss: 0.197629\n",
      "Validation AVG Loss:     0.000185 \n",
      "\n",
      "Epoch [1680/5000] | Train Loss: 0.197533\n",
      "Validation AVG Loss:     0.000184 \n",
      "\n",
      "Epoch [1681/5000] | Train Loss: 0.197437\n",
      "Validation AVG Loss:     0.000184 \n",
      "\n",
      "Epoch [1682/5000] | Train Loss: 0.197342\n",
      "Validation AVG Loss:     0.000184 \n",
      "\n",
      "Epoch [1683/5000] | Train Loss: 0.197246\n",
      "Validation AVG Loss:     0.000184 \n",
      "\n",
      "Epoch [1684/5000] | Train Loss: 0.197150\n",
      "Validation AVG Loss:     0.000184 \n",
      "\n",
      "Epoch [1685/5000] | Train Loss: 0.197054\n",
      "Validation AVG Loss:     0.000184 \n",
      "\n",
      "Epoch [1686/5000] | Train Loss: 0.196958\n",
      "Validation AVG Loss:     0.000184 \n",
      "\n",
      "Epoch [1687/5000] | Train Loss: 0.196863\n",
      "Validation AVG Loss:     0.000184 \n",
      "\n",
      "Epoch [1688/5000] | Train Loss: 0.196767\n",
      "Validation AVG Loss:     0.000184 \n",
      "\n",
      "Epoch [1689/5000] | Train Loss: 0.196671\n",
      "Validation AVG Loss:     0.000184 \n",
      "\n",
      "Epoch [1690/5000] | Train Loss: 0.196575\n",
      "Validation AVG Loss:     0.000184 \n",
      "\n",
      "Epoch [1691/5000] | Train Loss: 0.196479\n",
      "Validation AVG Loss:     0.000183 \n",
      "\n",
      "Epoch [1692/5000] | Train Loss: 0.196383\n",
      "Validation AVG Loss:     0.000183 \n",
      "\n",
      "Epoch [1693/5000] | Train Loss: 0.196288\n",
      "Validation AVG Loss:     0.000183 \n",
      "\n",
      "Epoch [1694/5000] | Train Loss: 0.196192\n",
      "Validation AVG Loss:     0.000183 \n",
      "\n",
      "Epoch [1695/5000] | Train Loss: 0.196096\n",
      "Validation AVG Loss:     0.000183 \n",
      "\n",
      "Epoch [1696/5000] | Train Loss: 0.196000\n",
      "Validation AVG Loss:     0.000183 \n",
      "\n",
      "Epoch [1697/5000] | Train Loss: 0.195904\n",
      "Validation AVG Loss:     0.000183 \n",
      "\n",
      "Epoch [1698/5000] | Train Loss: 0.195809\n",
      "Validation AVG Loss:     0.000183 \n",
      "\n",
      "Epoch [1699/5000] | Train Loss: 0.195713\n",
      "Validation AVG Loss:     0.000183 \n",
      "\n",
      "Epoch [1700/5000] | Train Loss: 0.195617\n",
      "Validation AVG Loss:     0.000183 \n",
      "\n",
      "Epoch [1701/5000] | Train Loss: 0.195521\n",
      "Validation AVG Loss:     0.000183 \n",
      "\n",
      "Epoch [1702/5000] | Train Loss: 0.195425\n",
      "Validation AVG Loss:     0.000182 \n",
      "\n",
      "Epoch [1703/5000] | Train Loss: 0.195329\n",
      "Validation AVG Loss:     0.000182 \n",
      "\n",
      "Epoch [1704/5000] | Train Loss: 0.195234\n",
      "Validation AVG Loss:     0.000182 \n",
      "\n",
      "Epoch [1705/5000] | Train Loss: 0.195138\n",
      "Validation AVG Loss:     0.000182 \n",
      "\n",
      "Epoch [1706/5000] | Train Loss: 0.195042\n",
      "Validation AVG Loss:     0.000182 \n",
      "\n",
      "Epoch [1707/5000] | Train Loss: 0.194946\n",
      "Validation AVG Loss:     0.000182 \n",
      "\n",
      "Epoch [1708/5000] | Train Loss: 0.194850\n",
      "Validation AVG Loss:     0.000182 \n",
      "\n",
      "Epoch [1709/5000] | Train Loss: 0.194754\n",
      "Validation AVG Loss:     0.000182 \n",
      "\n",
      "Epoch [1710/5000] | Train Loss: 0.194658\n",
      "Validation AVG Loss:     0.000182 \n",
      "\n",
      "Epoch [1711/5000] | Train Loss: 0.194563\n",
      "Validation AVG Loss:     0.000182 \n",
      "\n",
      "Epoch [1712/5000] | Train Loss: 0.194467\n",
      "Validation AVG Loss:     0.000182 \n",
      "\n",
      "Epoch [1713/5000] | Train Loss: 0.194371\n",
      "Validation AVG Loss:     0.000181 \n",
      "\n",
      "Epoch [1714/5000] | Train Loss: 0.194275\n",
      "Validation AVG Loss:     0.000181 \n",
      "\n",
      "Epoch [1715/5000] | Train Loss: 0.194179\n",
      "Validation AVG Loss:     0.000181 \n",
      "\n",
      "Epoch [1716/5000] | Train Loss: 0.194083\n",
      "Validation AVG Loss:     0.000181 \n",
      "\n",
      "Epoch [1717/5000] | Train Loss: 0.193987\n",
      "Validation AVG Loss:     0.000181 \n",
      "\n",
      "Epoch [1718/5000] | Train Loss: 0.193891\n",
      "Validation AVG Loss:     0.000181 \n",
      "\n",
      "Epoch [1719/5000] | Train Loss: 0.193795\n",
      "Validation AVG Loss:     0.000181 \n",
      "\n",
      "Epoch [1720/5000] | Train Loss: 0.193700\n",
      "Validation AVG Loss:     0.000181 \n",
      "\n",
      "Epoch [1721/5000] | Train Loss: 0.193604\n",
      "Validation AVG Loss:     0.000181 \n",
      "\n",
      "Epoch [1722/5000] | Train Loss: 0.193508\n",
      "Validation AVG Loss:     0.000181 \n",
      "\n",
      "Epoch [1723/5000] | Train Loss: 0.193412\n",
      "Validation AVG Loss:     0.000181 \n",
      "\n",
      "Epoch [1724/5000] | Train Loss: 0.193316\n",
      "Validation AVG Loss:     0.000180 \n",
      "\n",
      "Epoch [1725/5000] | Train Loss: 0.193220\n",
      "Validation AVG Loss:     0.000180 \n",
      "\n",
      "Epoch [1726/5000] | Train Loss: 0.193124\n",
      "Validation AVG Loss:     0.000180 \n",
      "\n",
      "Epoch [1727/5000] | Train Loss: 0.193028\n",
      "Validation AVG Loss:     0.000180 \n",
      "\n",
      "Epoch [1728/5000] | Train Loss: 0.192932\n",
      "Validation AVG Loss:     0.000180 \n",
      "\n",
      "Epoch [1729/5000] | Train Loss: 0.192836\n",
      "Validation AVG Loss:     0.000180 \n",
      "\n",
      "Epoch [1730/5000] | Train Loss: 0.192741\n",
      "Validation AVG Loss:     0.000180 \n",
      "\n",
      "Epoch [1731/5000] | Train Loss: 0.192645\n",
      "Validation AVG Loss:     0.000180 \n",
      "\n",
      "Epoch [1732/5000] | Train Loss: 0.192549\n",
      "Validation AVG Loss:     0.000180 \n",
      "\n",
      "Epoch [1733/5000] | Train Loss: 0.192453\n",
      "Validation AVG Loss:     0.000180 \n",
      "\n",
      "Epoch [1734/5000] | Train Loss: 0.192357\n",
      "Validation AVG Loss:     0.000180 \n",
      "\n",
      "Epoch [1735/5000] | Train Loss: 0.192261\n",
      "Validation AVG Loss:     0.000179 \n",
      "\n",
      "Epoch [1736/5000] | Train Loss: 0.192165\n",
      "Validation AVG Loss:     0.000179 \n",
      "\n",
      "Epoch [1737/5000] | Train Loss: 0.192069\n",
      "Validation AVG Loss:     0.000179 \n",
      "\n",
      "Epoch [1738/5000] | Train Loss: 0.191973\n",
      "Validation AVG Loss:     0.000179 \n",
      "\n",
      "Epoch [1739/5000] | Train Loss: 0.191877\n",
      "Validation AVG Loss:     0.000179 \n",
      "\n",
      "Epoch [1740/5000] | Train Loss: 0.191781\n",
      "Validation AVG Loss:     0.000179 \n",
      "\n",
      "Epoch [1741/5000] | Train Loss: 0.191686\n",
      "Validation AVG Loss:     0.000179 \n",
      "\n",
      "Epoch [1742/5000] | Train Loss: 0.191590\n",
      "Validation AVG Loss:     0.000179 \n",
      "\n",
      "Epoch [1743/5000] | Train Loss: 0.191494\n",
      "Validation AVG Loss:     0.000179 \n",
      "\n",
      "Epoch [1744/5000] | Train Loss: 0.191398\n",
      "Validation AVG Loss:     0.000179 \n",
      "\n",
      "Epoch [1745/5000] | Train Loss: 0.191302\n",
      "Validation AVG Loss:     0.000178 \n",
      "\n",
      "Epoch [1746/5000] | Train Loss: 0.191206\n",
      "Validation AVG Loss:     0.000178 \n",
      "\n",
      "Epoch [1747/5000] | Train Loss: 0.191110\n",
      "Validation AVG Loss:     0.000178 \n",
      "\n",
      "Epoch [1748/5000] | Train Loss: 0.191014\n",
      "Validation AVG Loss:     0.000178 \n",
      "\n",
      "Epoch [1749/5000] | Train Loss: 0.190918\n",
      "Validation AVG Loss:     0.000178 \n",
      "\n",
      "Epoch [1750/5000] | Train Loss: 0.190822\n",
      "Validation AVG Loss:     0.000178 \n",
      "\n",
      "Epoch [1751/5000] | Train Loss: 0.190726\n",
      "Validation AVG Loss:     0.000178 \n",
      "\n",
      "Epoch [1752/5000] | Train Loss: 0.190631\n",
      "Validation AVG Loss:     0.000178 \n",
      "\n",
      "Epoch [1753/5000] | Train Loss: 0.190535\n",
      "Validation AVG Loss:     0.000178 \n",
      "\n",
      "Epoch [1754/5000] | Train Loss: 0.190439\n",
      "Validation AVG Loss:     0.000178 \n",
      "\n",
      "Epoch [1755/5000] | Train Loss: 0.190343\n",
      "Validation AVG Loss:     0.000178 \n",
      "\n",
      "Epoch [1756/5000] | Train Loss: 0.190247\n",
      "Validation AVG Loss:     0.000177 \n",
      "\n",
      "Epoch [1757/5000] | Train Loss: 0.190151\n",
      "Validation AVG Loss:     0.000177 \n",
      "\n",
      "Epoch [1758/5000] | Train Loss: 0.190055\n",
      "Validation AVG Loss:     0.000177 \n",
      "\n",
      "Epoch [1759/5000] | Train Loss: 0.189959\n",
      "Validation AVG Loss:     0.000177 \n",
      "\n",
      "Epoch [1760/5000] | Train Loss: 0.189863\n",
      "Validation AVG Loss:     0.000177 \n",
      "\n",
      "Epoch [1761/5000] | Train Loss: 0.189767\n",
      "Validation AVG Loss:     0.000177 \n",
      "\n",
      "Epoch [1762/5000] | Train Loss: 0.189671\n",
      "Validation AVG Loss:     0.000177 \n",
      "\n",
      "Epoch [1763/5000] | Train Loss: 0.189575\n",
      "Validation AVG Loss:     0.000177 \n",
      "\n",
      "Epoch [1764/5000] | Train Loss: 0.189479\n",
      "Validation AVG Loss:     0.000177 \n",
      "\n",
      "Epoch [1765/5000] | Train Loss: 0.189383\n",
      "Validation AVG Loss:     0.000177 \n",
      "\n",
      "Epoch [1766/5000] | Train Loss: 0.189287\n",
      "Validation AVG Loss:     0.000177 \n",
      "\n",
      "Epoch [1767/5000] | Train Loss: 0.189192\n",
      "Validation AVG Loss:     0.000176 \n",
      "\n",
      "Epoch [1768/5000] | Train Loss: 0.189096\n",
      "Validation AVG Loss:     0.000176 \n",
      "\n",
      "Epoch [1769/5000] | Train Loss: 0.189000\n",
      "Validation AVG Loss:     0.000176 \n",
      "\n",
      "Epoch [1770/5000] | Train Loss: 0.188904\n",
      "Validation AVG Loss:     0.000176 \n",
      "\n",
      "Epoch [1771/5000] | Train Loss: 0.188808\n",
      "Validation AVG Loss:     0.000176 \n",
      "\n",
      "Epoch [1772/5000] | Train Loss: 0.188712\n",
      "Validation AVG Loss:     0.000176 \n",
      "\n",
      "Epoch [1773/5000] | Train Loss: 0.188616\n",
      "Validation AVG Loss:     0.000176 \n",
      "\n",
      "Epoch [1774/5000] | Train Loss: 0.188520\n",
      "Validation AVG Loss:     0.000176 \n",
      "\n",
      "Epoch [1775/5000] | Train Loss: 0.188424\n",
      "Validation AVG Loss:     0.000176 \n",
      "\n",
      "Epoch [1776/5000] | Train Loss: 0.188328\n",
      "Validation AVG Loss:     0.000176 \n",
      "\n",
      "Epoch [1777/5000] | Train Loss: 0.188232\n",
      "Validation AVG Loss:     0.000176 \n",
      "\n",
      "Epoch [1778/5000] | Train Loss: 0.188136\n",
      "Validation AVG Loss:     0.000175 \n",
      "\n",
      "Epoch [1779/5000] | Train Loss: 0.188040\n",
      "Validation AVG Loss:     0.000175 \n",
      "\n",
      "Epoch [1780/5000] | Train Loss: 0.187944\n",
      "Validation AVG Loss:     0.000175 \n",
      "\n",
      "Epoch [1781/5000] | Train Loss: 0.187849\n",
      "Validation AVG Loss:     0.000175 \n",
      "\n",
      "Epoch [1782/5000] | Train Loss: 0.187753\n",
      "Validation AVG Loss:     0.000175 \n",
      "\n",
      "Epoch [1783/5000] | Train Loss: 0.187657\n",
      "Validation AVG Loss:     0.000175 \n",
      "\n",
      "Epoch [1784/5000] | Train Loss: 0.187561\n",
      "Validation AVG Loss:     0.000175 \n",
      "\n",
      "Epoch [1785/5000] | Train Loss: 0.187465\n",
      "Validation AVG Loss:     0.000175 \n",
      "\n",
      "Epoch [1786/5000] | Train Loss: 0.187369\n",
      "Validation AVG Loss:     0.000175 \n",
      "\n",
      "Epoch [1787/5000] | Train Loss: 0.187273\n",
      "Validation AVG Loss:     0.000175 \n",
      "\n",
      "Epoch [1788/5000] | Train Loss: 0.187177\n",
      "Validation AVG Loss:     0.000175 \n",
      "\n",
      "Epoch [1789/5000] | Train Loss: 0.187081\n",
      "Validation AVG Loss:     0.000174 \n",
      "\n",
      "Epoch [1790/5000] | Train Loss: 0.186985\n",
      "Validation AVG Loss:     0.000174 \n",
      "\n",
      "Epoch [1791/5000] | Train Loss: 0.186889\n",
      "Validation AVG Loss:     0.000174 \n",
      "\n",
      "Epoch [1792/5000] | Train Loss: 0.186794\n",
      "Validation AVG Loss:     0.000174 \n",
      "\n",
      "Epoch [1793/5000] | Train Loss: 0.186698\n",
      "Validation AVG Loss:     0.000174 \n",
      "\n",
      "Epoch [1794/5000] | Train Loss: 0.186602\n",
      "Validation AVG Loss:     0.000174 \n",
      "\n",
      "Epoch [1795/5000] | Train Loss: 0.186506\n",
      "Validation AVG Loss:     0.000174 \n",
      "\n",
      "Epoch [1796/5000] | Train Loss: 0.186410\n",
      "Validation AVG Loss:     0.000174 \n",
      "\n",
      "Epoch [1797/5000] | Train Loss: 0.186314\n",
      "Validation AVG Loss:     0.000174 \n",
      "\n",
      "Epoch [1798/5000] | Train Loss: 0.186218\n",
      "Validation AVG Loss:     0.000174 \n",
      "\n",
      "Epoch [1799/5000] | Train Loss: 0.186122\n",
      "Validation AVG Loss:     0.000174 \n",
      "\n",
      "Epoch [1800/5000] | Train Loss: 0.186026\n",
      "Validation AVG Loss:     0.000173 \n",
      "\n",
      "Epoch [1801/5000] | Train Loss: 0.185930\n",
      "Validation AVG Loss:     0.000173 \n",
      "\n",
      "Epoch [1802/5000] | Train Loss: 0.185834\n",
      "Validation AVG Loss:     0.000173 \n",
      "\n",
      "Epoch [1803/5000] | Train Loss: 0.185739\n",
      "Validation AVG Loss:     0.000173 \n",
      "\n",
      "Epoch [1804/5000] | Train Loss: 0.185643\n",
      "Validation AVG Loss:     0.000173 \n",
      "\n",
      "Epoch [1805/5000] | Train Loss: 0.185547\n",
      "Validation AVG Loss:     0.000173 \n",
      "\n",
      "Epoch [1806/5000] | Train Loss: 0.185451\n",
      "Validation AVG Loss:     0.000173 \n",
      "\n",
      "Epoch [1807/5000] | Train Loss: 0.185355\n",
      "Validation AVG Loss:     0.000173 \n",
      "\n",
      "Epoch [1808/5000] | Train Loss: 0.185259\n",
      "Validation AVG Loss:     0.000173 \n",
      "\n",
      "Epoch [1809/5000] | Train Loss: 0.185163\n",
      "Validation AVG Loss:     0.000173 \n",
      "\n",
      "Epoch [1810/5000] | Train Loss: 0.185067\n",
      "Validation AVG Loss:     0.000173 \n",
      "\n",
      "Epoch [1811/5000] | Train Loss: 0.184971\n",
      "Validation AVG Loss:     0.000172 \n",
      "\n",
      "Epoch [1812/5000] | Train Loss: 0.184875\n",
      "Validation AVG Loss:     0.000172 \n",
      "\n",
      "Epoch [1813/5000] | Train Loss: 0.184779\n",
      "Validation AVG Loss:     0.000172 \n",
      "\n",
      "Epoch [1814/5000] | Train Loss: 0.184683\n",
      "Validation AVG Loss:     0.000172 \n",
      "\n",
      "Epoch [1815/5000] | Train Loss: 0.184587\n",
      "Validation AVG Loss:     0.000172 \n",
      "\n",
      "Epoch [1816/5000] | Train Loss: 0.184491\n",
      "Validation AVG Loss:     0.000172 \n",
      "\n",
      "Epoch [1817/5000] | Train Loss: 0.184395\n",
      "Validation AVG Loss:     0.000172 \n",
      "\n",
      "Epoch [1818/5000] | Train Loss: 0.184300\n",
      "Validation AVG Loss:     0.000172 \n",
      "\n",
      "Epoch [1819/5000] | Train Loss: 0.184204\n",
      "Validation AVG Loss:     0.000172 \n",
      "\n",
      "Epoch [1820/5000] | Train Loss: 0.184108\n",
      "Validation AVG Loss:     0.000172 \n",
      "\n",
      "Epoch [1821/5000] | Train Loss: 0.184012\n",
      "Validation AVG Loss:     0.000172 \n",
      "\n",
      "Epoch [1822/5000] | Train Loss: 0.183916\n",
      "Validation AVG Loss:     0.000171 \n",
      "\n",
      "Epoch [1823/5000] | Train Loss: 0.183820\n",
      "Validation AVG Loss:     0.000171 \n",
      "\n",
      "Epoch [1824/5000] | Train Loss: 0.183724\n",
      "Validation AVG Loss:     0.000171 \n",
      "\n",
      "Epoch [1825/5000] | Train Loss: 0.183628\n",
      "Validation AVG Loss:     0.000171 \n",
      "\n",
      "Epoch [1826/5000] | Train Loss: 0.183532\n",
      "Validation AVG Loss:     0.000171 \n",
      "\n",
      "Epoch [1827/5000] | Train Loss: 0.183436\n",
      "Validation AVG Loss:     0.000171 \n",
      "\n",
      "Epoch [1828/5000] | Train Loss: 0.183340\n",
      "Validation AVG Loss:     0.000171 \n",
      "\n",
      "Epoch [1829/5000] | Train Loss: 0.183244\n",
      "Validation AVG Loss:     0.000171 \n",
      "\n",
      "Epoch [1830/5000] | Train Loss: 0.183148\n",
      "Validation AVG Loss:     0.000171 \n",
      "\n",
      "Epoch [1831/5000] | Train Loss: 0.183052\n",
      "Validation AVG Loss:     0.000171 \n",
      "\n",
      "Epoch [1832/5000] | Train Loss: 0.182956\n",
      "Validation AVG Loss:     0.000171 \n",
      "\n",
      "Epoch [1833/5000] | Train Loss: 0.182861\n",
      "Validation AVG Loss:     0.000170 \n",
      "\n",
      "Epoch [1834/5000] | Train Loss: 0.182765\n",
      "Validation AVG Loss:     0.000170 \n",
      "\n",
      "Epoch [1835/5000] | Train Loss: 0.182669\n",
      "Validation AVG Loss:     0.000170 \n",
      "\n",
      "Epoch [1836/5000] | Train Loss: 0.182573\n",
      "Validation AVG Loss:     0.000170 \n",
      "\n",
      "Epoch [1837/5000] | Train Loss: 0.182477\n",
      "Validation AVG Loss:     0.000170 \n",
      "\n",
      "Epoch [1838/5000] | Train Loss: 0.182381\n",
      "Validation AVG Loss:     0.000170 \n",
      "\n",
      "Epoch [1839/5000] | Train Loss: 0.182285\n",
      "Validation AVG Loss:     0.000170 \n",
      "\n",
      "Epoch [1840/5000] | Train Loss: 0.182189\n",
      "Validation AVG Loss:     0.000170 \n",
      "\n",
      "Epoch [1841/5000] | Train Loss: 0.182093\n",
      "Validation AVG Loss:     0.000170 \n",
      "\n",
      "Epoch [1842/5000] | Train Loss: 0.181998\n",
      "Validation AVG Loss:     0.000170 \n",
      "\n",
      "Epoch [1843/5000] | Train Loss: 0.181902\n",
      "Validation AVG Loss:     0.000169 \n",
      "\n",
      "Epoch [1844/5000] | Train Loss: 0.181806\n",
      "Validation AVG Loss:     0.000169 \n",
      "\n",
      "Epoch [1845/5000] | Train Loss: 0.181710\n",
      "Validation AVG Loss:     0.000169 \n",
      "\n",
      "Epoch [1846/5000] | Train Loss: 0.181614\n",
      "Validation AVG Loss:     0.000169 \n",
      "\n",
      "Epoch [1847/5000] | Train Loss: 0.181518\n",
      "Validation AVG Loss:     0.000169 \n",
      "\n",
      "Epoch [1848/5000] | Train Loss: 0.181422\n",
      "Validation AVG Loss:     0.000169 \n",
      "\n",
      "Epoch [1849/5000] | Train Loss: 0.181326\n",
      "Validation AVG Loss:     0.000169 \n",
      "\n",
      "Epoch [1850/5000] | Train Loss: 0.181231\n",
      "Validation AVG Loss:     0.000169 \n",
      "\n",
      "Epoch [1851/5000] | Train Loss: 0.181135\n",
      "Validation AVG Loss:     0.000169 \n",
      "\n",
      "Epoch [1852/5000] | Train Loss: 0.181039\n",
      "Validation AVG Loss:     0.000169 \n",
      "\n",
      "Epoch [1853/5000] | Train Loss: 0.180943\n",
      "Validation AVG Loss:     0.000169 \n",
      "\n",
      "Epoch [1854/5000] | Train Loss: 0.180847\n",
      "Validation AVG Loss:     0.000168 \n",
      "\n",
      "Epoch [1855/5000] | Train Loss: 0.180751\n",
      "Validation AVG Loss:     0.000168 \n",
      "\n",
      "Epoch [1856/5000] | Train Loss: 0.180655\n",
      "Validation AVG Loss:     0.000168 \n",
      "\n",
      "Epoch [1857/5000] | Train Loss: 0.180559\n",
      "Validation AVG Loss:     0.000168 \n",
      "\n",
      "Epoch [1858/5000] | Train Loss: 0.180464\n",
      "Validation AVG Loss:     0.000168 \n",
      "\n",
      "Epoch [1859/5000] | Train Loss: 0.180368\n",
      "Validation AVG Loss:     0.000168 \n",
      "\n",
      "Epoch [1860/5000] | Train Loss: 0.180272\n",
      "Validation AVG Loss:     0.000168 \n",
      "\n",
      "Epoch [1861/5000] | Train Loss: 0.180176\n",
      "Validation AVG Loss:     0.000168 \n",
      "\n",
      "Epoch [1862/5000] | Train Loss: 0.180080\n",
      "Validation AVG Loss:     0.000168 \n",
      "\n",
      "Epoch [1863/5000] | Train Loss: 0.179984\n",
      "Validation AVG Loss:     0.000168 \n",
      "\n",
      "Epoch [1864/5000] | Train Loss: 0.179888\n",
      "Validation AVG Loss:     0.000168 \n",
      "\n",
      "Epoch [1865/5000] | Train Loss: 0.179793\n",
      "Validation AVG Loss:     0.000167 \n",
      "\n",
      "Epoch [1866/5000] | Train Loss: 0.179697\n",
      "Validation AVG Loss:     0.000167 \n",
      "\n",
      "Epoch [1867/5000] | Train Loss: 0.179601\n",
      "Validation AVG Loss:     0.000167 \n",
      "\n",
      "Epoch [1868/5000] | Train Loss: 0.179505\n",
      "Validation AVG Loss:     0.000167 \n",
      "\n",
      "Epoch [1869/5000] | Train Loss: 0.179409\n",
      "Validation AVG Loss:     0.000167 \n",
      "\n",
      "Epoch [1870/5000] | Train Loss: 0.179313\n",
      "Validation AVG Loss:     0.000167 \n",
      "\n",
      "Epoch [1871/5000] | Train Loss: 0.179218\n",
      "Validation AVG Loss:     0.000167 \n",
      "\n",
      "Epoch [1872/5000] | Train Loss: 0.179122\n",
      "Validation AVG Loss:     0.000167 \n",
      "\n",
      "Epoch [1873/5000] | Train Loss: 0.179026\n",
      "Validation AVG Loss:     0.000167 \n",
      "\n",
      "Epoch [1874/5000] | Train Loss: 0.178930\n",
      "Validation AVG Loss:     0.000167 \n",
      "\n",
      "Epoch [1875/5000] | Train Loss: 0.178834\n",
      "Validation AVG Loss:     0.000167 \n",
      "\n",
      "Epoch [1876/5000] | Train Loss: 0.178738\n",
      "Validation AVG Loss:     0.000166 \n",
      "\n",
      "Epoch [1877/5000] | Train Loss: 0.178643\n",
      "Validation AVG Loss:     0.000166 \n",
      "\n",
      "Epoch [1878/5000] | Train Loss: 0.178547\n",
      "Validation AVG Loss:     0.000166 \n",
      "\n",
      "Epoch [1879/5000] | Train Loss: 0.178451\n",
      "Validation AVG Loss:     0.000166 \n",
      "\n",
      "Epoch [1880/5000] | Train Loss: 0.178355\n",
      "Validation AVG Loss:     0.000166 \n",
      "\n",
      "Epoch [1881/5000] | Train Loss: 0.178259\n",
      "Validation AVG Loss:     0.000166 \n",
      "\n",
      "Epoch [1882/5000] | Train Loss: 0.178163\n",
      "Validation AVG Loss:     0.000166 \n",
      "\n",
      "Epoch [1883/5000] | Train Loss: 0.178068\n",
      "Validation AVG Loss:     0.000166 \n",
      "\n",
      "Epoch [1884/5000] | Train Loss: 0.177972\n",
      "Validation AVG Loss:     0.000166 \n",
      "\n",
      "Epoch [1885/5000] | Train Loss: 0.177876\n",
      "Validation AVG Loss:     0.000166 \n",
      "\n",
      "Epoch [1886/5000] | Train Loss: 0.177780\n",
      "Validation AVG Loss:     0.000166 \n",
      "\n",
      "Epoch [1887/5000] | Train Loss: 0.177684\n",
      "Validation AVG Loss:     0.000165 \n",
      "\n",
      "Epoch [1888/5000] | Train Loss: 0.177588\n",
      "Validation AVG Loss:     0.000165 \n",
      "\n",
      "Epoch [1889/5000] | Train Loss: 0.177493\n",
      "Validation AVG Loss:     0.000165 \n",
      "\n",
      "Epoch [1890/5000] | Train Loss: 0.177397\n",
      "Validation AVG Loss:     0.000165 \n",
      "\n",
      "Epoch [1891/5000] | Train Loss: 0.177301\n",
      "Validation AVG Loss:     0.000165 \n",
      "\n",
      "Epoch [1892/5000] | Train Loss: 0.177205\n",
      "Validation AVG Loss:     0.000165 \n",
      "\n",
      "Epoch [1893/5000] | Train Loss: 0.177109\n",
      "Validation AVG Loss:     0.000165 \n",
      "\n",
      "Epoch [1894/5000] | Train Loss: 0.177014\n",
      "Validation AVG Loss:     0.000165 \n",
      "\n",
      "Epoch [1895/5000] | Train Loss: 0.176918\n",
      "Validation AVG Loss:     0.000165 \n",
      "\n",
      "Epoch [1896/5000] | Train Loss: 0.176822\n",
      "Validation AVG Loss:     0.000165 \n",
      "\n",
      "Epoch [1897/5000] | Train Loss: 0.176726\n",
      "Validation AVG Loss:     0.000165 \n",
      "\n",
      "Epoch [1898/5000] | Train Loss: 0.176630\n",
      "Validation AVG Loss:     0.000164 \n",
      "\n",
      "Epoch [1899/5000] | Train Loss: 0.176535\n",
      "Validation AVG Loss:     0.000164 \n",
      "\n",
      "Epoch [1900/5000] | Train Loss: 0.176439\n",
      "Validation AVG Loss:     0.000164 \n",
      "\n",
      "Epoch [1901/5000] | Train Loss: 0.176343\n",
      "Validation AVG Loss:     0.000164 \n",
      "\n",
      "Epoch [1902/5000] | Train Loss: 0.176247\n",
      "Validation AVG Loss:     0.000164 \n",
      "\n",
      "Epoch [1903/5000] | Train Loss: 0.176151\n",
      "Validation AVG Loss:     0.000164 \n",
      "\n",
      "Epoch [1904/5000] | Train Loss: 0.176056\n",
      "Validation AVG Loss:     0.000164 \n",
      "\n",
      "Epoch [1905/5000] | Train Loss: 0.175960\n",
      "Validation AVG Loss:     0.000164 \n",
      "\n",
      "Epoch [1906/5000] | Train Loss: 0.175864\n",
      "Validation AVG Loss:     0.000164 \n",
      "\n",
      "Epoch [1907/5000] | Train Loss: 0.175768\n",
      "Validation AVG Loss:     0.000164 \n",
      "\n",
      "Epoch [1908/5000] | Train Loss: 0.175673\n",
      "Validation AVG Loss:     0.000164 \n",
      "\n",
      "Epoch [1909/5000] | Train Loss: 0.175577\n",
      "Validation AVG Loss:     0.000163 \n",
      "\n",
      "Epoch [1910/5000] | Train Loss: 0.175481\n",
      "Validation AVG Loss:     0.000163 \n",
      "\n",
      "Epoch [1911/5000] | Train Loss: 0.175385\n",
      "Validation AVG Loss:     0.000163 \n",
      "\n",
      "Epoch [1912/5000] | Train Loss: 0.175289\n",
      "Validation AVG Loss:     0.000163 \n",
      "\n",
      "Epoch [1913/5000] | Train Loss: 0.175194\n",
      "Validation AVG Loss:     0.000163 \n",
      "\n",
      "Epoch [1914/5000] | Train Loss: 0.175098\n",
      "Validation AVG Loss:     0.000163 \n",
      "\n",
      "Epoch [1915/5000] | Train Loss: 0.175002\n",
      "Validation AVG Loss:     0.000163 \n",
      "\n",
      "Epoch [1916/5000] | Train Loss: 0.174906\n",
      "Validation AVG Loss:     0.000163 \n",
      "\n",
      "Epoch [1917/5000] | Train Loss: 0.174811\n",
      "Validation AVG Loss:     0.000163 \n",
      "\n",
      "Epoch [1918/5000] | Train Loss: 0.174715\n",
      "Validation AVG Loss:     0.000163 \n",
      "\n",
      "Epoch [1919/5000] | Train Loss: 0.174619\n",
      "Validation AVG Loss:     0.000163 \n",
      "\n",
      "Epoch [1920/5000] | Train Loss: 0.174524\n",
      "Validation AVG Loss:     0.000162 \n",
      "\n",
      "Epoch [1921/5000] | Train Loss: 0.174428\n",
      "Validation AVG Loss:     0.000162 \n",
      "\n",
      "Epoch [1922/5000] | Train Loss: 0.174332\n",
      "Validation AVG Loss:     0.000162 \n",
      "\n",
      "Epoch [1923/5000] | Train Loss: 0.174236\n",
      "Validation AVG Loss:     0.000162 \n",
      "\n",
      "Epoch [1924/5000] | Train Loss: 0.174141\n",
      "Validation AVG Loss:     0.000162 \n",
      "\n",
      "Epoch [1925/5000] | Train Loss: 0.174045\n",
      "Validation AVG Loss:     0.000162 \n",
      "\n",
      "Epoch [1926/5000] | Train Loss: 0.173949\n",
      "Validation AVG Loss:     0.000162 \n",
      "\n",
      "Epoch [1927/5000] | Train Loss: 0.173854\n",
      "Validation AVG Loss:     0.000162 \n",
      "\n",
      "Epoch [1928/5000] | Train Loss: 0.173758\n",
      "Validation AVG Loss:     0.000162 \n",
      "\n",
      "Epoch [1929/5000] | Train Loss: 0.173662\n",
      "Validation AVG Loss:     0.000162 \n",
      "\n",
      "Epoch [1930/5000] | Train Loss: 0.173567\n",
      "Validation AVG Loss:     0.000162 \n",
      "\n",
      "Epoch [1931/5000] | Train Loss: 0.173471\n",
      "Validation AVG Loss:     0.000161 \n",
      "\n",
      "Epoch [1932/5000] | Train Loss: 0.173375\n",
      "Validation AVG Loss:     0.000161 \n",
      "\n",
      "Epoch [1933/5000] | Train Loss: 0.173280\n",
      "Validation AVG Loss:     0.000161 \n",
      "\n",
      "Epoch [1934/5000] | Train Loss: 0.173184\n",
      "Validation AVG Loss:     0.000161 \n",
      "\n",
      "Epoch [1935/5000] | Train Loss: 0.173088\n",
      "Validation AVG Loss:     0.000161 \n",
      "\n",
      "Epoch [1936/5000] | Train Loss: 0.172993\n",
      "Validation AVG Loss:     0.000161 \n",
      "\n",
      "Epoch [1937/5000] | Train Loss: 0.172897\n",
      "Validation AVG Loss:     0.000161 \n",
      "\n",
      "Epoch [1938/5000] | Train Loss: 0.172801\n",
      "Validation AVG Loss:     0.000161 \n",
      "\n",
      "Epoch [1939/5000] | Train Loss: 0.172706\n",
      "Validation AVG Loss:     0.000161 \n",
      "\n",
      "Epoch [1940/5000] | Train Loss: 0.172610\n",
      "Validation AVG Loss:     0.000161 \n",
      "\n",
      "Epoch [1941/5000] | Train Loss: 0.172515\n",
      "Validation AVG Loss:     0.000161 \n",
      "\n",
      "Epoch [1942/5000] | Train Loss: 0.172419\n",
      "Validation AVG Loss:     0.000160 \n",
      "\n",
      "Epoch [1943/5000] | Train Loss: 0.172323\n",
      "Validation AVG Loss:     0.000160 \n",
      "\n",
      "Epoch [1944/5000] | Train Loss: 0.172228\n",
      "Validation AVG Loss:     0.000160 \n",
      "\n",
      "Epoch [1945/5000] | Train Loss: 0.172132\n",
      "Validation AVG Loss:     0.000160 \n",
      "\n",
      "Epoch [1946/5000] | Train Loss: 0.172037\n",
      "Validation AVG Loss:     0.000160 \n",
      "\n",
      "Epoch [1947/5000] | Train Loss: 0.171941\n",
      "Validation AVG Loss:     0.000160 \n",
      "\n",
      "Epoch [1948/5000] | Train Loss: 0.171846\n",
      "Validation AVG Loss:     0.000160 \n",
      "\n",
      "Epoch [1949/5000] | Train Loss: 0.171750\n",
      "Validation AVG Loss:     0.000160 \n",
      "\n",
      "Epoch [1950/5000] | Train Loss: 0.171654\n",
      "Validation AVG Loss:     0.000160 \n",
      "\n",
      "Epoch [1951/5000] | Train Loss: 0.171559\n",
      "Validation AVG Loss:     0.000160 \n",
      "\n",
      "Epoch [1952/5000] | Train Loss: 0.171463\n",
      "Validation AVG Loss:     0.000160 \n",
      "\n",
      "Epoch [1953/5000] | Train Loss: 0.171368\n",
      "Validation AVG Loss:     0.000159 \n",
      "\n",
      "Epoch [1954/5000] | Train Loss: 0.171272\n",
      "Validation AVG Loss:     0.000159 \n",
      "\n",
      "Epoch [1955/5000] | Train Loss: 0.171177\n",
      "Validation AVG Loss:     0.000159 \n",
      "\n",
      "Epoch [1956/5000] | Train Loss: 0.171081\n",
      "Validation AVG Loss:     0.000159 \n",
      "\n",
      "Epoch [1957/5000] | Train Loss: 0.170986\n",
      "Validation AVG Loss:     0.000159 \n",
      "\n",
      "Epoch [1958/5000] | Train Loss: 0.170890\n",
      "Validation AVG Loss:     0.000159 \n",
      "\n",
      "Epoch [1959/5000] | Train Loss: 0.170795\n",
      "Validation AVG Loss:     0.000159 \n",
      "\n",
      "Epoch [1960/5000] | Train Loss: 0.170699\n",
      "Validation AVG Loss:     0.000159 \n",
      "\n",
      "Epoch [1961/5000] | Train Loss: 0.170604\n",
      "Validation AVG Loss:     0.000159 \n",
      "\n",
      "Epoch [1962/5000] | Train Loss: 0.170508\n",
      "Validation AVG Loss:     0.000159 \n",
      "\n",
      "Epoch [1963/5000] | Train Loss: 0.170412\n",
      "Validation AVG Loss:     0.000159 \n",
      "\n",
      "Epoch [1964/5000] | Train Loss: 0.170317\n",
      "Validation AVG Loss:     0.000158 \n",
      "\n",
      "Epoch [1965/5000] | Train Loss: 0.170221\n",
      "Validation AVG Loss:     0.000158 \n",
      "\n",
      "Epoch [1966/5000] | Train Loss: 0.170126\n",
      "Validation AVG Loss:     0.000158 \n",
      "\n",
      "Epoch [1967/5000] | Train Loss: 0.170030\n",
      "Validation AVG Loss:     0.000158 \n",
      "\n",
      "Epoch [1968/5000] | Train Loss: 0.169935\n",
      "Validation AVG Loss:     0.000158 \n",
      "\n",
      "Epoch [1969/5000] | Train Loss: 0.169840\n",
      "Validation AVG Loss:     0.000158 \n",
      "\n",
      "Epoch [1970/5000] | Train Loss: 0.169744\n",
      "Validation AVG Loss:     0.000158 \n",
      "\n",
      "Epoch [1971/5000] | Train Loss: 0.169649\n",
      "Validation AVG Loss:     0.000158 \n",
      "\n",
      "Epoch [1972/5000] | Train Loss: 0.169553\n",
      "Validation AVG Loss:     0.000158 \n",
      "\n",
      "Epoch [1973/5000] | Train Loss: 0.169458\n",
      "Validation AVG Loss:     0.000158 \n",
      "\n",
      "Epoch [1974/5000] | Train Loss: 0.169362\n",
      "Validation AVG Loss:     0.000158 \n",
      "\n",
      "Epoch [1975/5000] | Train Loss: 0.169267\n",
      "Validation AVG Loss:     0.000157 \n",
      "\n",
      "Epoch [1976/5000] | Train Loss: 0.169171\n",
      "Validation AVG Loss:     0.000157 \n",
      "\n",
      "Epoch [1977/5000] | Train Loss: 0.169076\n",
      "Validation AVG Loss:     0.000157 \n",
      "\n",
      "Epoch [1978/5000] | Train Loss: 0.168980\n",
      "Validation AVG Loss:     0.000157 \n",
      "\n",
      "Epoch [1979/5000] | Train Loss: 0.168885\n",
      "Validation AVG Loss:     0.000157 \n",
      "\n",
      "Epoch [1980/5000] | Train Loss: 0.168789\n",
      "Validation AVG Loss:     0.000157 \n",
      "\n",
      "Epoch [1981/5000] | Train Loss: 0.168694\n",
      "Validation AVG Loss:     0.000157 \n",
      "\n",
      "Epoch [1982/5000] | Train Loss: 0.168599\n",
      "Validation AVG Loss:     0.000157 \n",
      "\n",
      "Epoch [1983/5000] | Train Loss: 0.168503\n",
      "Validation AVG Loss:     0.000157 \n",
      "\n",
      "Epoch [1984/5000] | Train Loss: 0.168408\n",
      "Validation AVG Loss:     0.000157 \n",
      "\n",
      "Epoch [1985/5000] | Train Loss: 0.168312\n",
      "Validation AVG Loss:     0.000156 \n",
      "\n",
      "Epoch [1986/5000] | Train Loss: 0.168217\n",
      "Validation AVG Loss:     0.000156 \n",
      "\n",
      "Epoch [1987/5000] | Train Loss: 0.168122\n",
      "Validation AVG Loss:     0.000156 \n",
      "\n",
      "Epoch [1988/5000] | Train Loss: 0.168026\n",
      "Validation AVG Loss:     0.000156 \n",
      "\n",
      "Epoch [1989/5000] | Train Loss: 0.167931\n",
      "Validation AVG Loss:     0.000156 \n",
      "\n",
      "Epoch [1990/5000] | Train Loss: 0.167836\n",
      "Validation AVG Loss:     0.000156 \n",
      "\n",
      "Epoch [1991/5000] | Train Loss: 0.167740\n",
      "Validation AVG Loss:     0.000156 \n",
      "\n",
      "Epoch [1992/5000] | Train Loss: 0.167645\n",
      "Validation AVG Loss:     0.000156 \n",
      "\n",
      "Epoch [1993/5000] | Train Loss: 0.167550\n",
      "Validation AVG Loss:     0.000156 \n",
      "\n",
      "Epoch [1994/5000] | Train Loss: 0.167454\n",
      "Validation AVG Loss:     0.000156 \n",
      "\n",
      "Epoch [1995/5000] | Train Loss: 0.167359\n",
      "Validation AVG Loss:     0.000156 \n",
      "\n",
      "Epoch [1996/5000] | Train Loss: 0.167264\n",
      "Validation AVG Loss:     0.000155 \n",
      "\n",
      "Epoch [1997/5000] | Train Loss: 0.167168\n",
      "Validation AVG Loss:     0.000155 \n",
      "\n",
      "Epoch [1998/5000] | Train Loss: 0.167073\n",
      "Validation AVG Loss:     0.000155 \n",
      "\n",
      "Epoch [1999/5000] | Train Loss: 0.166978\n",
      "Validation AVG Loss:     0.000155 \n",
      "\n",
      "Epoch [2000/5000] | Train Loss: 0.166882\n",
      "Validation AVG Loss:     0.000155 \n",
      "\n",
      "Epoch [2001/5000] | Train Loss: 0.166787\n",
      "Validation AVG Loss:     0.000155 \n",
      "\n",
      "Epoch [2002/5000] | Train Loss: 0.166692\n",
      "Validation AVG Loss:     0.000155 \n",
      "\n",
      "Epoch [2003/5000] | Train Loss: 0.166597\n",
      "Validation AVG Loss:     0.000155 \n",
      "\n",
      "Epoch [2004/5000] | Train Loss: 0.166501\n",
      "Validation AVG Loss:     0.000155 \n",
      "\n",
      "Epoch [2005/5000] | Train Loss: 0.166406\n",
      "Validation AVG Loss:     0.000155 \n",
      "\n",
      "Epoch [2006/5000] | Train Loss: 0.166311\n",
      "Validation AVG Loss:     0.000155 \n",
      "\n",
      "Epoch [2007/5000] | Train Loss: 0.166216\n",
      "Validation AVG Loss:     0.000154 \n",
      "\n",
      "Epoch [2008/5000] | Train Loss: 0.166120\n",
      "Validation AVG Loss:     0.000154 \n",
      "\n",
      "Epoch [2009/5000] | Train Loss: 0.166025\n",
      "Validation AVG Loss:     0.000154 \n",
      "\n",
      "Epoch [2010/5000] | Train Loss: 0.165930\n",
      "Validation AVG Loss:     0.000154 \n",
      "\n",
      "Epoch [2011/5000] | Train Loss: 0.165835\n",
      "Validation AVG Loss:     0.000154 \n",
      "\n",
      "Epoch [2012/5000] | Train Loss: 0.165740\n",
      "Validation AVG Loss:     0.000154 \n",
      "\n",
      "Epoch [2013/5000] | Train Loss: 0.165644\n",
      "Validation AVG Loss:     0.000154 \n",
      "\n",
      "Epoch [2014/5000] | Train Loss: 0.165549\n",
      "Validation AVG Loss:     0.000154 \n",
      "\n",
      "Epoch [2015/5000] | Train Loss: 0.165454\n",
      "Validation AVG Loss:     0.000154 \n",
      "\n",
      "Epoch [2016/5000] | Train Loss: 0.165359\n",
      "Validation AVG Loss:     0.000154 \n",
      "\n",
      "Epoch [2017/5000] | Train Loss: 0.165264\n",
      "Validation AVG Loss:     0.000154 \n",
      "\n",
      "Epoch [2018/5000] | Train Loss: 0.165169\n",
      "Validation AVG Loss:     0.000153 \n",
      "\n",
      "Epoch [2019/5000] | Train Loss: 0.165073\n",
      "Validation AVG Loss:     0.000153 \n",
      "\n",
      "Epoch [2020/5000] | Train Loss: 0.164978\n",
      "Validation AVG Loss:     0.000153 \n",
      "\n",
      "Epoch [2021/5000] | Train Loss: 0.164883\n",
      "Validation AVG Loss:     0.000153 \n",
      "\n",
      "Epoch [2022/5000] | Train Loss: 0.164788\n",
      "Validation AVG Loss:     0.000153 \n",
      "\n",
      "Epoch [2023/5000] | Train Loss: 0.164693\n",
      "Validation AVG Loss:     0.000153 \n",
      "\n",
      "Epoch [2024/5000] | Train Loss: 0.164598\n",
      "Validation AVG Loss:     0.000153 \n",
      "\n",
      "Epoch [2025/5000] | Train Loss: 0.164503\n",
      "Validation AVG Loss:     0.000153 \n",
      "\n",
      "Epoch [2026/5000] | Train Loss: 0.164408\n",
      "Validation AVG Loss:     0.000153 \n",
      "\n",
      "Epoch [2027/5000] | Train Loss: 0.164312\n",
      "Validation AVG Loss:     0.000153 \n",
      "\n",
      "Epoch [2028/5000] | Train Loss: 0.164217\n",
      "Validation AVG Loss:     0.000153 \n",
      "\n",
      "Epoch [2029/5000] | Train Loss: 0.164122\n",
      "Validation AVG Loss:     0.000152 \n",
      "\n",
      "Epoch [2030/5000] | Train Loss: 0.164027\n",
      "Validation AVG Loss:     0.000152 \n",
      "\n",
      "Epoch [2031/5000] | Train Loss: 0.163932\n",
      "Validation AVG Loss:     0.000152 \n",
      "\n",
      "Epoch [2032/5000] | Train Loss: 0.163837\n",
      "Validation AVG Loss:     0.000152 \n",
      "\n",
      "Epoch [2033/5000] | Train Loss: 0.163742\n",
      "Validation AVG Loss:     0.000152 \n",
      "\n",
      "Epoch [2034/5000] | Train Loss: 0.163647\n",
      "Validation AVG Loss:     0.000152 \n",
      "\n",
      "Epoch [2035/5000] | Train Loss: 0.163552\n",
      "Validation AVG Loss:     0.000152 \n",
      "\n",
      "Epoch [2036/5000] | Train Loss: 0.163457\n",
      "Validation AVG Loss:     0.000152 \n",
      "\n",
      "Epoch [2037/5000] | Train Loss: 0.163362\n",
      "Validation AVG Loss:     0.000152 \n",
      "\n",
      "Epoch [2038/5000] | Train Loss: 0.163267\n",
      "Validation AVG Loss:     0.000152 \n",
      "\n",
      "Epoch [2039/5000] | Train Loss: 0.163172\n",
      "Validation AVG Loss:     0.000152 \n",
      "\n",
      "Epoch [2040/5000] | Train Loss: 0.163077\n",
      "Validation AVG Loss:     0.000151 \n",
      "\n",
      "Epoch [2041/5000] | Train Loss: 0.162982\n",
      "Validation AVG Loss:     0.000151 \n",
      "\n",
      "Epoch [2042/5000] | Train Loss: 0.162887\n",
      "Validation AVG Loss:     0.000151 \n",
      "\n",
      "Epoch [2043/5000] | Train Loss: 0.162792\n",
      "Validation AVG Loss:     0.000151 \n",
      "\n",
      "Epoch [2044/5000] | Train Loss: 0.162697\n",
      "Validation AVG Loss:     0.000151 \n",
      "\n",
      "Epoch [2045/5000] | Train Loss: 0.162602\n",
      "Validation AVG Loss:     0.000151 \n",
      "\n",
      "Epoch [2046/5000] | Train Loss: 0.162508\n",
      "Validation AVG Loss:     0.000151 \n",
      "\n",
      "Epoch [2047/5000] | Train Loss: 0.162413\n",
      "Validation AVG Loss:     0.000151 \n",
      "\n",
      "Epoch [2048/5000] | Train Loss: 0.162318\n",
      "Validation AVG Loss:     0.000151 \n",
      "\n",
      "Epoch [2049/5000] | Train Loss: 0.162223\n",
      "Validation AVG Loss:     0.000151 \n",
      "\n",
      "Epoch [2050/5000] | Train Loss: 0.162128\n",
      "Validation AVG Loss:     0.000151 \n",
      "\n",
      "Epoch [2051/5000] | Train Loss: 0.162033\n",
      "Validation AVG Loss:     0.000150 \n",
      "\n",
      "Epoch [2052/5000] | Train Loss: 0.161938\n",
      "Validation AVG Loss:     0.000150 \n",
      "\n",
      "Epoch [2053/5000] | Train Loss: 0.161843\n",
      "Validation AVG Loss:     0.000150 \n",
      "\n",
      "Epoch [2054/5000] | Train Loss: 0.161748\n",
      "Validation AVG Loss:     0.000150 \n",
      "\n",
      "Epoch [2055/5000] | Train Loss: 0.161654\n",
      "Validation AVG Loss:     0.000150 \n",
      "\n",
      "Epoch [2056/5000] | Train Loss: 0.161559\n",
      "Validation AVG Loss:     0.000150 \n",
      "\n",
      "Epoch [2057/5000] | Train Loss: 0.161464\n",
      "Validation AVG Loss:     0.000150 \n",
      "\n",
      "Epoch [2058/5000] | Train Loss: 0.161369\n",
      "Validation AVG Loss:     0.000150 \n",
      "\n",
      "Epoch [2059/5000] | Train Loss: 0.161274\n",
      "Validation AVG Loss:     0.000150 \n",
      "\n",
      "Epoch [2060/5000] | Train Loss: 0.161179\n",
      "Validation AVG Loss:     0.000150 \n",
      "\n",
      "Epoch [2061/5000] | Train Loss: 0.161085\n",
      "Validation AVG Loss:     0.000150 \n",
      "\n",
      "Epoch [2062/5000] | Train Loss: 0.160990\n",
      "Validation AVG Loss:     0.000150 \n",
      "\n",
      "Epoch [2063/5000] | Train Loss: 0.160895\n",
      "Validation AVG Loss:     0.000149 \n",
      "\n",
      "Epoch [2064/5000] | Train Loss: 0.160800\n",
      "Validation AVG Loss:     0.000149 \n",
      "\n",
      "Epoch [2065/5000] | Train Loss: 0.160706\n",
      "Validation AVG Loss:     0.000149 \n",
      "\n",
      "Epoch [2066/5000] | Train Loss: 0.160611\n",
      "Validation AVG Loss:     0.000149 \n",
      "\n",
      "Epoch [2067/5000] | Train Loss: 0.160516\n",
      "Validation AVG Loss:     0.000149 \n",
      "\n",
      "Epoch [2068/5000] | Train Loss: 0.160421\n",
      "Validation AVG Loss:     0.000149 \n",
      "\n",
      "Epoch [2069/5000] | Train Loss: 0.160327\n",
      "Validation AVG Loss:     0.000149 \n",
      "\n",
      "Epoch [2070/5000] | Train Loss: 0.160232\n",
      "Validation AVG Loss:     0.000149 \n",
      "\n",
      "Epoch [2071/5000] | Train Loss: 0.160137\n",
      "Validation AVG Loss:     0.000149 \n",
      "\n",
      "Epoch [2072/5000] | Train Loss: 0.160043\n",
      "Validation AVG Loss:     0.000149 \n",
      "\n",
      "Epoch [2073/5000] | Train Loss: 0.159948\n",
      "Validation AVG Loss:     0.000149 \n",
      "\n",
      "Epoch [2074/5000] | Train Loss: 0.159853\n",
      "Validation AVG Loss:     0.000148 \n",
      "\n",
      "Epoch [2075/5000] | Train Loss: 0.159759\n",
      "Validation AVG Loss:     0.000148 \n",
      "\n",
      "Epoch [2076/5000] | Train Loss: 0.159664\n",
      "Validation AVG Loss:     0.000148 \n",
      "\n",
      "Epoch [2077/5000] | Train Loss: 0.159569\n",
      "Validation AVG Loss:     0.000148 \n",
      "\n",
      "Epoch [2078/5000] | Train Loss: 0.159475\n",
      "Validation AVG Loss:     0.000148 \n",
      "\n",
      "Epoch [2079/5000] | Train Loss: 0.159380\n",
      "Validation AVG Loss:     0.000148 \n",
      "\n",
      "Epoch [2080/5000] | Train Loss: 0.159285\n",
      "Validation AVG Loss:     0.000148 \n",
      "\n",
      "Epoch [2081/5000] | Train Loss: 0.159191\n",
      "Validation AVG Loss:     0.000148 \n",
      "\n",
      "Epoch [2082/5000] | Train Loss: 0.159096\n",
      "Validation AVG Loss:     0.000148 \n",
      "\n",
      "Epoch [2083/5000] | Train Loss: 0.159001\n",
      "Validation AVG Loss:     0.000148 \n",
      "\n",
      "Epoch [2084/5000] | Train Loss: 0.158907\n",
      "Validation AVG Loss:     0.000148 \n",
      "\n",
      "Epoch [2085/5000] | Train Loss: 0.158812\n",
      "Validation AVG Loss:     0.000147 \n",
      "\n",
      "Epoch [2086/5000] | Train Loss: 0.158718\n",
      "Validation AVG Loss:     0.000147 \n",
      "\n",
      "Epoch [2087/5000] | Train Loss: 0.158623\n",
      "Validation AVG Loss:     0.000147 \n",
      "\n",
      "Epoch [2088/5000] | Train Loss: 0.158528\n",
      "Validation AVG Loss:     0.000147 \n",
      "\n",
      "Epoch [2089/5000] | Train Loss: 0.158434\n",
      "Validation AVG Loss:     0.000147 \n",
      "\n",
      "Epoch [2090/5000] | Train Loss: 0.158339\n",
      "Validation AVG Loss:     0.000147 \n",
      "\n",
      "Epoch [2091/5000] | Train Loss: 0.158245\n",
      "Validation AVG Loss:     0.000147 \n",
      "\n",
      "Epoch [2092/5000] | Train Loss: 0.158150\n",
      "Validation AVG Loss:     0.000147 \n",
      "\n",
      "Epoch [2093/5000] | Train Loss: 0.158056\n",
      "Validation AVG Loss:     0.000147 \n",
      "\n",
      "Epoch [2094/5000] | Train Loss: 0.157961\n",
      "Validation AVG Loss:     0.000147 \n",
      "\n",
      "Epoch [2095/5000] | Train Loss: 0.157867\n",
      "Validation AVG Loss:     0.000147 \n",
      "\n",
      "Epoch [2096/5000] | Train Loss: 0.157772\n",
      "Validation AVG Loss:     0.000146 \n",
      "\n",
      "Epoch [2097/5000] | Train Loss: 0.157678\n",
      "Validation AVG Loss:     0.000146 \n",
      "\n",
      "Epoch [2098/5000] | Train Loss: 0.157583\n",
      "Validation AVG Loss:     0.000146 \n",
      "\n",
      "Epoch [2099/5000] | Train Loss: 0.157489\n",
      "Validation AVG Loss:     0.000146 \n",
      "\n",
      "Epoch [2100/5000] | Train Loss: 0.157394\n",
      "Validation AVG Loss:     0.000146 \n",
      "\n",
      "Epoch [2101/5000] | Train Loss: 0.157300\n",
      "Validation AVG Loss:     0.000146 \n",
      "\n",
      "Epoch [2102/5000] | Train Loss: 0.157205\n",
      "Validation AVG Loss:     0.000146 \n",
      "\n",
      "Epoch [2103/5000] | Train Loss: 0.157111\n",
      "Validation AVG Loss:     0.000146 \n",
      "\n",
      "Epoch [2104/5000] | Train Loss: 0.157016\n",
      "Validation AVG Loss:     0.000146 \n",
      "\n",
      "Epoch [2105/5000] | Train Loss: 0.156922\n",
      "Validation AVG Loss:     0.000146 \n",
      "\n",
      "Epoch [2106/5000] | Train Loss: 0.156827\n",
      "Validation AVG Loss:     0.000146 \n",
      "\n",
      "Epoch [2107/5000] | Train Loss: 0.156733\n",
      "Validation AVG Loss:     0.000145 \n",
      "\n",
      "Epoch [2108/5000] | Train Loss: 0.156639\n",
      "Validation AVG Loss:     0.000145 \n",
      "\n",
      "Epoch [2109/5000] | Train Loss: 0.156544\n",
      "Validation AVG Loss:     0.000145 \n",
      "\n",
      "Epoch [2110/5000] | Train Loss: 0.156450\n",
      "Validation AVG Loss:     0.000145 \n",
      "\n",
      "Epoch [2111/5000] | Train Loss: 0.156356\n",
      "Validation AVG Loss:     0.000145 \n",
      "\n",
      "Epoch [2112/5000] | Train Loss: 0.156261\n",
      "Validation AVG Loss:     0.000145 \n",
      "\n",
      "Epoch [2113/5000] | Train Loss: 0.156167\n",
      "Validation AVG Loss:     0.000145 \n",
      "\n",
      "Epoch [2114/5000] | Train Loss: 0.156073\n",
      "Validation AVG Loss:     0.000145 \n",
      "\n",
      "Epoch [2115/5000] | Train Loss: 0.155978\n",
      "Validation AVG Loss:     0.000145 \n",
      "\n",
      "Epoch [2116/5000] | Train Loss: 0.155884\n",
      "Validation AVG Loss:     0.000145 \n",
      "\n",
      "Epoch [2117/5000] | Train Loss: 0.155790\n",
      "Validation AVG Loss:     0.000145 \n",
      "\n",
      "Epoch [2118/5000] | Train Loss: 0.155695\n",
      "Validation AVG Loss:     0.000144 \n",
      "\n",
      "Epoch [2119/5000] | Train Loss: 0.155601\n",
      "Validation AVG Loss:     0.000144 \n",
      "\n",
      "Epoch [2120/5000] | Train Loss: 0.155507\n",
      "Validation AVG Loss:     0.000144 \n",
      "\n",
      "Epoch [2121/5000] | Train Loss: 0.155413\n",
      "Validation AVG Loss:     0.000144 \n",
      "\n",
      "Epoch [2122/5000] | Train Loss: 0.155318\n",
      "Validation AVG Loss:     0.000144 \n",
      "\n",
      "Epoch [2123/5000] | Train Loss: 0.155224\n",
      "Validation AVG Loss:     0.000144 \n",
      "\n",
      "Epoch [2124/5000] | Train Loss: 0.155130\n",
      "Validation AVG Loss:     0.000144 \n",
      "\n",
      "Epoch [2125/5000] | Train Loss: 0.155036\n",
      "Validation AVG Loss:     0.000144 \n",
      "\n",
      "Epoch [2126/5000] | Train Loss: 0.154942\n",
      "Validation AVG Loss:     0.000144 \n",
      "\n",
      "Epoch [2127/5000] | Train Loss: 0.154847\n",
      "Validation AVG Loss:     0.000144 \n",
      "\n",
      "Epoch [2128/5000] | Train Loss: 0.154753\n",
      "Validation AVG Loss:     0.000144 \n",
      "\n",
      "Epoch [2129/5000] | Train Loss: 0.154659\n",
      "Validation AVG Loss:     0.000143 \n",
      "\n",
      "Epoch [2130/5000] | Train Loss: 0.154565\n",
      "Validation AVG Loss:     0.000143 \n",
      "\n",
      "Epoch [2131/5000] | Train Loss: 0.154471\n",
      "Validation AVG Loss:     0.000143 \n",
      "\n",
      "Epoch [2132/5000] | Train Loss: 0.154377\n",
      "Validation AVG Loss:     0.000143 \n",
      "\n",
      "Epoch [2133/5000] | Train Loss: 0.154283\n",
      "Validation AVG Loss:     0.000143 \n",
      "\n",
      "Epoch [2134/5000] | Train Loss: 0.154188\n",
      "Validation AVG Loss:     0.000143 \n",
      "\n",
      "Epoch [2135/5000] | Train Loss: 0.154094\n",
      "Validation AVG Loss:     0.000143 \n",
      "\n",
      "Epoch [2136/5000] | Train Loss: 0.154000\n",
      "Validation AVG Loss:     0.000143 \n",
      "\n",
      "Epoch [2137/5000] | Train Loss: 0.153906\n",
      "Validation AVG Loss:     0.000143 \n",
      "\n",
      "Epoch [2138/5000] | Train Loss: 0.153812\n",
      "Validation AVG Loss:     0.000143 \n",
      "\n",
      "Epoch [2139/5000] | Train Loss: 0.153718\n",
      "Validation AVG Loss:     0.000143 \n",
      "\n",
      "Epoch [2140/5000] | Train Loss: 0.153624\n",
      "Validation AVG Loss:     0.000142 \n",
      "\n",
      "Epoch [2141/5000] | Train Loss: 0.153530\n",
      "Validation AVG Loss:     0.000142 \n",
      "\n",
      "Epoch [2142/5000] | Train Loss: 0.153436\n",
      "Validation AVG Loss:     0.000142 \n",
      "\n",
      "Epoch [2143/5000] | Train Loss: 0.153342\n",
      "Validation AVG Loss:     0.000142 \n",
      "\n",
      "Epoch [2144/5000] | Train Loss: 0.153248\n",
      "Validation AVG Loss:     0.000142 \n",
      "\n",
      "Epoch [2145/5000] | Train Loss: 0.153154\n",
      "Validation AVG Loss:     0.000142 \n",
      "\n",
      "Epoch [2146/5000] | Train Loss: 0.153060\n",
      "Validation AVG Loss:     0.000142 \n",
      "\n",
      "Epoch [2147/5000] | Train Loss: 0.152966\n",
      "Validation AVG Loss:     0.000142 \n",
      "\n",
      "Epoch [2148/5000] | Train Loss: 0.152872\n",
      "Validation AVG Loss:     0.000142 \n",
      "\n",
      "Epoch [2149/5000] | Train Loss: 0.152778\n",
      "Validation AVG Loss:     0.000142 \n",
      "\n",
      "Epoch [2150/5000] | Train Loss: 0.152685\n",
      "Validation AVG Loss:     0.000142 \n",
      "\n",
      "Epoch [2151/5000] | Train Loss: 0.152591\n",
      "Validation AVG Loss:     0.000141 \n",
      "\n",
      "Epoch [2152/5000] | Train Loss: 0.152497\n",
      "Validation AVG Loss:     0.000141 \n",
      "\n",
      "Epoch [2153/5000] | Train Loss: 0.152403\n",
      "Validation AVG Loss:     0.000141 \n",
      "\n",
      "Epoch [2154/5000] | Train Loss: 0.152309\n",
      "Validation AVG Loss:     0.000141 \n",
      "\n",
      "Epoch [2155/5000] | Train Loss: 0.152215\n",
      "Validation AVG Loss:     0.000141 \n",
      "\n",
      "Epoch [2156/5000] | Train Loss: 0.152122\n",
      "Validation AVG Loss:     0.000141 \n",
      "\n",
      "Epoch [2157/5000] | Train Loss: 0.152028\n",
      "Validation AVG Loss:     0.000141 \n",
      "\n",
      "Epoch [2158/5000] | Train Loss: 0.151934\n",
      "Validation AVG Loss:     0.000141 \n",
      "\n",
      "Epoch [2159/5000] | Train Loss: 0.151840\n",
      "Validation AVG Loss:     0.000141 \n",
      "\n",
      "Epoch [2160/5000] | Train Loss: 0.151746\n",
      "Validation AVG Loss:     0.000141 \n",
      "\n",
      "Epoch [2161/5000] | Train Loss: 0.151653\n",
      "Validation AVG Loss:     0.000141 \n",
      "\n",
      "Epoch [2162/5000] | Train Loss: 0.151559\n",
      "Validation AVG Loss:     0.000140 \n",
      "\n",
      "Epoch [2163/5000] | Train Loss: 0.151465\n",
      "Validation AVG Loss:     0.000140 \n",
      "\n",
      "Epoch [2164/5000] | Train Loss: 0.151371\n",
      "Validation AVG Loss:     0.000140 \n",
      "\n",
      "Epoch [2165/5000] | Train Loss: 0.151278\n",
      "Validation AVG Loss:     0.000140 \n",
      "\n",
      "Epoch [2166/5000] | Train Loss: 0.151184\n",
      "Validation AVG Loss:     0.000140 \n",
      "\n",
      "Epoch [2167/5000] | Train Loss: 0.151090\n",
      "Validation AVG Loss:     0.000140 \n",
      "\n",
      "Epoch [2168/5000] | Train Loss: 0.150997\n",
      "Validation AVG Loss:     0.000140 \n",
      "\n",
      "Epoch [2169/5000] | Train Loss: 0.150903\n",
      "Validation AVG Loss:     0.000140 \n",
      "\n",
      "Epoch [2170/5000] | Train Loss: 0.150809\n",
      "Validation AVG Loss:     0.000140 \n",
      "\n",
      "Epoch [2171/5000] | Train Loss: 0.150716\n",
      "Validation AVG Loss:     0.000140 \n",
      "\n",
      "Epoch [2172/5000] | Train Loss: 0.150622\n",
      "Validation AVG Loss:     0.000140 \n",
      "\n",
      "Epoch [2173/5000] | Train Loss: 0.150529\n",
      "Validation AVG Loss:     0.000140 \n",
      "\n",
      "Epoch [2174/5000] | Train Loss: 0.150435\n",
      "Validation AVG Loss:     0.000139 \n",
      "\n",
      "Epoch [2175/5000] | Train Loss: 0.150341\n",
      "Validation AVG Loss:     0.000139 \n",
      "\n",
      "Epoch [2176/5000] | Train Loss: 0.150248\n",
      "Validation AVG Loss:     0.000139 \n",
      "\n",
      "Epoch [2177/5000] | Train Loss: 0.150154\n",
      "Validation AVG Loss:     0.000139 \n",
      "\n",
      "Epoch [2178/5000] | Train Loss: 0.150061\n",
      "Validation AVG Loss:     0.000139 \n",
      "\n",
      "Epoch [2179/5000] | Train Loss: 0.149967\n",
      "Validation AVG Loss:     0.000139 \n",
      "\n",
      "Epoch [2180/5000] | Train Loss: 0.149874\n",
      "Validation AVG Loss:     0.000139 \n",
      "\n",
      "Epoch [2181/5000] | Train Loss: 0.149780\n",
      "Validation AVG Loss:     0.000139 \n",
      "\n",
      "Epoch [2182/5000] | Train Loss: 0.149687\n",
      "Validation AVG Loss:     0.000139 \n",
      "\n",
      "Epoch [2183/5000] | Train Loss: 0.149593\n",
      "Validation AVG Loss:     0.000139 \n",
      "\n",
      "Epoch [2184/5000] | Train Loss: 0.149500\n",
      "Validation AVG Loss:     0.000139 \n",
      "\n",
      "Epoch [2185/5000] | Train Loss: 0.149406\n",
      "Validation AVG Loss:     0.000138 \n",
      "\n",
      "Epoch [2186/5000] | Train Loss: 0.149313\n",
      "Validation AVG Loss:     0.000138 \n",
      "\n",
      "Epoch [2187/5000] | Train Loss: 0.149220\n",
      "Validation AVG Loss:     0.000138 \n",
      "\n",
      "Epoch [2188/5000] | Train Loss: 0.149126\n",
      "Validation AVG Loss:     0.000138 \n",
      "\n",
      "Epoch [2189/5000] | Train Loss: 0.149033\n",
      "Validation AVG Loss:     0.000138 \n",
      "\n",
      "Epoch [2190/5000] | Train Loss: 0.148940\n",
      "Validation AVG Loss:     0.000138 \n",
      "\n",
      "Epoch [2191/5000] | Train Loss: 0.148846\n",
      "Validation AVG Loss:     0.000138 \n",
      "\n",
      "Epoch [2192/5000] | Train Loss: 0.148753\n",
      "Validation AVG Loss:     0.000138 \n",
      "\n",
      "Epoch [2193/5000] | Train Loss: 0.148659\n",
      "Validation AVG Loss:     0.000138 \n",
      "\n",
      "Epoch [2194/5000] | Train Loss: 0.148566\n",
      "Validation AVG Loss:     0.000138 \n",
      "\n",
      "Epoch [2195/5000] | Train Loss: 0.148473\n",
      "Validation AVG Loss:     0.000138 \n",
      "\n",
      "Epoch [2196/5000] | Train Loss: 0.148380\n",
      "Validation AVG Loss:     0.000137 \n",
      "\n",
      "Epoch [2197/5000] | Train Loss: 0.148286\n",
      "Validation AVG Loss:     0.000137 \n",
      "\n",
      "Epoch [2198/5000] | Train Loss: 0.148193\n",
      "Validation AVG Loss:     0.000137 \n",
      "\n",
      "Epoch [2199/5000] | Train Loss: 0.148100\n",
      "Validation AVG Loss:     0.000137 \n",
      "\n",
      "Epoch [2200/5000] | Train Loss: 0.148007\n",
      "Validation AVG Loss:     0.000137 \n",
      "\n",
      "Epoch [2201/5000] | Train Loss: 0.147914\n",
      "Validation AVG Loss:     0.000137 \n",
      "\n",
      "Epoch [2202/5000] | Train Loss: 0.147820\n",
      "Validation AVG Loss:     0.000137 \n",
      "\n",
      "Epoch [2203/5000] | Train Loss: 0.147727\n",
      "Validation AVG Loss:     0.000137 \n",
      "\n",
      "Epoch [2204/5000] | Train Loss: 0.147634\n",
      "Validation AVG Loss:     0.000137 \n",
      "\n",
      "Epoch [2205/5000] | Train Loss: 0.147541\n",
      "Validation AVG Loss:     0.000137 \n",
      "\n",
      "Epoch [2206/5000] | Train Loss: 0.147448\n",
      "Validation AVG Loss:     0.000137 \n",
      "\n",
      "Epoch [2207/5000] | Train Loss: 0.147355\n",
      "Validation AVG Loss:     0.000136 \n",
      "\n",
      "Epoch [2208/5000] | Train Loss: 0.147262\n",
      "Validation AVG Loss:     0.000136 \n",
      "\n",
      "Epoch [2209/5000] | Train Loss: 0.147169\n",
      "Validation AVG Loss:     0.000136 \n",
      "\n",
      "Epoch [2210/5000] | Train Loss: 0.147076\n",
      "Validation AVG Loss:     0.000136 \n",
      "\n",
      "Epoch [2211/5000] | Train Loss: 0.146982\n",
      "Validation AVG Loss:     0.000136 \n",
      "\n",
      "Epoch [2212/5000] | Train Loss: 0.146889\n",
      "Validation AVG Loss:     0.000136 \n",
      "\n",
      "Epoch [2213/5000] | Train Loss: 0.146796\n",
      "Validation AVG Loss:     0.000136 \n",
      "\n",
      "Epoch [2214/5000] | Train Loss: 0.146703\n",
      "Validation AVG Loss:     0.000136 \n",
      "\n",
      "Epoch [2215/5000] | Train Loss: 0.146610\n",
      "Validation AVG Loss:     0.000136 \n",
      "\n",
      "Epoch [2216/5000] | Train Loss: 0.146518\n",
      "Validation AVG Loss:     0.000136 \n",
      "\n",
      "Epoch [2217/5000] | Train Loss: 0.146425\n",
      "Validation AVG Loss:     0.000136 \n",
      "\n",
      "Epoch [2218/5000] | Train Loss: 0.146332\n",
      "Validation AVG Loss:     0.000136 \n",
      "\n",
      "Epoch [2219/5000] | Train Loss: 0.146239\n",
      "Validation AVG Loss:     0.000135 \n",
      "\n",
      "Epoch [2220/5000] | Train Loss: 0.146146\n",
      "Validation AVG Loss:     0.000135 \n",
      "\n",
      "Epoch [2221/5000] | Train Loss: 0.146053\n",
      "Validation AVG Loss:     0.000135 \n",
      "\n",
      "Epoch [2222/5000] | Train Loss: 0.145960\n",
      "Validation AVG Loss:     0.000135 \n",
      "\n",
      "Epoch [2223/5000] | Train Loss: 0.145867\n",
      "Validation AVG Loss:     0.000135 \n",
      "\n",
      "Epoch [2224/5000] | Train Loss: 0.145774\n",
      "Validation AVG Loss:     0.000135 \n",
      "\n",
      "Epoch [2225/5000] | Train Loss: 0.145682\n",
      "Validation AVG Loss:     0.000135 \n",
      "\n",
      "Epoch [2226/5000] | Train Loss: 0.145589\n",
      "Validation AVG Loss:     0.000135 \n",
      "\n",
      "Epoch [2227/5000] | Train Loss: 0.145496\n",
      "Validation AVG Loss:     0.000135 \n",
      "\n",
      "Epoch [2228/5000] | Train Loss: 0.145403\n",
      "Validation AVG Loss:     0.000135 \n",
      "\n",
      "Epoch [2229/5000] | Train Loss: 0.145311\n",
      "Validation AVG Loss:     0.000135 \n",
      "\n",
      "Epoch [2230/5000] | Train Loss: 0.145218\n",
      "Validation AVG Loss:     0.000134 \n",
      "\n",
      "Epoch [2231/5000] | Train Loss: 0.145125\n",
      "Validation AVG Loss:     0.000134 \n",
      "\n",
      "Epoch [2232/5000] | Train Loss: 0.145032\n",
      "Validation AVG Loss:     0.000134 \n",
      "\n",
      "Epoch [2233/5000] | Train Loss: 0.144940\n",
      "Validation AVG Loss:     0.000134 \n",
      "\n",
      "Epoch [2234/5000] | Train Loss: 0.144847\n",
      "Validation AVG Loss:     0.000134 \n",
      "\n",
      "Epoch [2235/5000] | Train Loss: 0.144754\n",
      "Validation AVG Loss:     0.000134 \n",
      "\n",
      "Epoch [2236/5000] | Train Loss: 0.144662\n",
      "Validation AVG Loss:     0.000134 \n",
      "\n",
      "Epoch [2237/5000] | Train Loss: 0.144569\n",
      "Validation AVG Loss:     0.000134 \n",
      "\n",
      "Epoch [2238/5000] | Train Loss: 0.144477\n",
      "Validation AVG Loss:     0.000134 \n",
      "\n",
      "Epoch [2239/5000] | Train Loss: 0.144384\n",
      "Validation AVG Loss:     0.000134 \n",
      "\n",
      "Epoch [2240/5000] | Train Loss: 0.144292\n",
      "Validation AVG Loss:     0.000134 \n",
      "\n",
      "Epoch [2241/5000] | Train Loss: 0.144199\n",
      "Validation AVG Loss:     0.000133 \n",
      "\n",
      "Epoch [2242/5000] | Train Loss: 0.144106\n",
      "Validation AVG Loss:     0.000133 \n",
      "\n",
      "Epoch [2243/5000] | Train Loss: 0.144014\n",
      "Validation AVG Loss:     0.000133 \n",
      "\n",
      "Epoch [2244/5000] | Train Loss: 0.143921\n",
      "Validation AVG Loss:     0.000133 \n",
      "\n",
      "Epoch [2245/5000] | Train Loss: 0.143829\n",
      "Validation AVG Loss:     0.000133 \n",
      "\n",
      "Epoch [2246/5000] | Train Loss: 0.143737\n",
      "Validation AVG Loss:     0.000133 \n",
      "\n",
      "Epoch [2247/5000] | Train Loss: 0.143644\n",
      "Validation AVG Loss:     0.000133 \n",
      "\n",
      "Epoch [2248/5000] | Train Loss: 0.143552\n",
      "Validation AVG Loss:     0.000133 \n",
      "\n",
      "Epoch [2249/5000] | Train Loss: 0.143459\n",
      "Validation AVG Loss:     0.000133 \n",
      "\n",
      "Epoch [2250/5000] | Train Loss: 0.143367\n",
      "Validation AVG Loss:     0.000133 \n",
      "\n",
      "Epoch [2251/5000] | Train Loss: 0.143274\n",
      "Validation AVG Loss:     0.000133 \n",
      "\n",
      "Epoch [2252/5000] | Train Loss: 0.143182\n",
      "Validation AVG Loss:     0.000133 \n",
      "\n",
      "Epoch [2253/5000] | Train Loss: 0.143090\n",
      "Validation AVG Loss:     0.000132 \n",
      "\n",
      "Epoch [2254/5000] | Train Loss: 0.142997\n",
      "Validation AVG Loss:     0.000132 \n",
      "\n",
      "Epoch [2255/5000] | Train Loss: 0.142905\n",
      "Validation AVG Loss:     0.000132 \n",
      "\n",
      "Epoch [2256/5000] | Train Loss: 0.142813\n",
      "Validation AVG Loss:     0.000132 \n",
      "\n",
      "Epoch [2257/5000] | Train Loss: 0.142721\n",
      "Validation AVG Loss:     0.000132 \n",
      "\n",
      "Epoch [2258/5000] | Train Loss: 0.142628\n",
      "Validation AVG Loss:     0.000132 \n",
      "\n",
      "Epoch [2259/5000] | Train Loss: 0.142536\n",
      "Validation AVG Loss:     0.000132 \n",
      "\n",
      "Epoch [2260/5000] | Train Loss: 0.142444\n",
      "Validation AVG Loss:     0.000132 \n",
      "\n",
      "Epoch [2261/5000] | Train Loss: 0.142352\n",
      "Validation AVG Loss:     0.000132 \n",
      "\n",
      "Epoch [2262/5000] | Train Loss: 0.142259\n",
      "Validation AVG Loss:     0.000132 \n",
      "\n",
      "Epoch [2263/5000] | Train Loss: 0.142167\n",
      "Validation AVG Loss:     0.000132 \n",
      "\n",
      "Epoch [2264/5000] | Train Loss: 0.142075\n",
      "Validation AVG Loss:     0.000131 \n",
      "\n",
      "Epoch [2265/5000] | Train Loss: 0.141983\n",
      "Validation AVG Loss:     0.000131 \n",
      "\n",
      "Epoch [2266/5000] | Train Loss: 0.141891\n",
      "Validation AVG Loss:     0.000131 \n",
      "\n",
      "Epoch [2267/5000] | Train Loss: 0.141799\n",
      "Validation AVG Loss:     0.000131 \n",
      "\n",
      "Epoch [2268/5000] | Train Loss: 0.141707\n",
      "Validation AVG Loss:     0.000131 \n",
      "\n",
      "Epoch [2269/5000] | Train Loss: 0.141614\n",
      "Validation AVG Loss:     0.000131 \n",
      "\n",
      "Epoch [2270/5000] | Train Loss: 0.141522\n",
      "Validation AVG Loss:     0.000131 \n",
      "\n",
      "Epoch [2271/5000] | Train Loss: 0.141430\n",
      "Validation AVG Loss:     0.000131 \n",
      "\n",
      "Epoch [2272/5000] | Train Loss: 0.141338\n",
      "Validation AVG Loss:     0.000131 \n",
      "\n",
      "Epoch [2273/5000] | Train Loss: 0.141246\n",
      "Validation AVG Loss:     0.000131 \n",
      "\n",
      "Epoch [2274/5000] | Train Loss: 0.141154\n",
      "Validation AVG Loss:     0.000131 \n",
      "\n",
      "Epoch [2275/5000] | Train Loss: 0.141062\n",
      "Validation AVG Loss:     0.000130 \n",
      "\n",
      "Epoch [2276/5000] | Train Loss: 0.140970\n",
      "Validation AVG Loss:     0.000130 \n",
      "\n",
      "Epoch [2277/5000] | Train Loss: 0.140878\n",
      "Validation AVG Loss:     0.000130 \n",
      "\n",
      "Epoch [2278/5000] | Train Loss: 0.140786\n",
      "Validation AVG Loss:     0.000130 \n",
      "\n",
      "Epoch [2279/5000] | Train Loss: 0.140695\n",
      "Validation AVG Loss:     0.000130 \n",
      "\n",
      "Epoch [2280/5000] | Train Loss: 0.140603\n",
      "Validation AVG Loss:     0.000130 \n",
      "\n",
      "Epoch [2281/5000] | Train Loss: 0.140511\n",
      "Validation AVG Loss:     0.000130 \n",
      "\n",
      "Epoch [2282/5000] | Train Loss: 0.140419\n",
      "Validation AVG Loss:     0.000130 \n",
      "\n",
      "Epoch [2283/5000] | Train Loss: 0.140327\n",
      "Validation AVG Loss:     0.000130 \n",
      "\n",
      "Epoch [2284/5000] | Train Loss: 0.140235\n",
      "Validation AVG Loss:     0.000130 \n",
      "\n",
      "Epoch [2285/5000] | Train Loss: 0.140143\n",
      "Validation AVG Loss:     0.000130 \n",
      "\n",
      "Epoch [2286/5000] | Train Loss: 0.140052\n",
      "Validation AVG Loss:     0.000130 \n",
      "\n",
      "Epoch [2287/5000] | Train Loss: 0.139960\n",
      "Validation AVG Loss:     0.000129 \n",
      "\n",
      "Epoch [2288/5000] | Train Loss: 0.139868\n",
      "Validation AVG Loss:     0.000129 \n",
      "\n",
      "Epoch [2289/5000] | Train Loss: 0.139776\n",
      "Validation AVG Loss:     0.000129 \n",
      "\n",
      "Epoch [2290/5000] | Train Loss: 0.139685\n",
      "Validation AVG Loss:     0.000129 \n",
      "\n",
      "Epoch [2291/5000] | Train Loss: 0.139593\n",
      "Validation AVG Loss:     0.000129 \n",
      "\n",
      "Epoch [2292/5000] | Train Loss: 0.139501\n",
      "Validation AVG Loss:     0.000129 \n",
      "\n",
      "Epoch [2293/5000] | Train Loss: 0.139410\n",
      "Validation AVG Loss:     0.000129 \n",
      "\n",
      "Epoch [2294/5000] | Train Loss: 0.139318\n",
      "Validation AVG Loss:     0.000129 \n",
      "\n",
      "Epoch [2295/5000] | Train Loss: 0.139226\n",
      "Validation AVG Loss:     0.000129 \n",
      "\n",
      "Epoch [2296/5000] | Train Loss: 0.139135\n",
      "Validation AVG Loss:     0.000129 \n",
      "\n",
      "Epoch [2297/5000] | Train Loss: 0.139043\n",
      "Validation AVG Loss:     0.000129 \n",
      "\n",
      "Epoch [2298/5000] | Train Loss: 0.138952\n",
      "Validation AVG Loss:     0.000128 \n",
      "\n",
      "Epoch [2299/5000] | Train Loss: 0.138860\n",
      "Validation AVG Loss:     0.000128 \n",
      "\n",
      "Epoch [2300/5000] | Train Loss: 0.138768\n",
      "Validation AVG Loss:     0.000128 \n",
      "\n",
      "Epoch [2301/5000] | Train Loss: 0.138677\n",
      "Validation AVG Loss:     0.000128 \n",
      "\n",
      "Epoch [2302/5000] | Train Loss: 0.138585\n",
      "Validation AVG Loss:     0.000128 \n",
      "\n",
      "Epoch [2303/5000] | Train Loss: 0.138494\n",
      "Validation AVG Loss:     0.000128 \n",
      "\n",
      "Epoch [2304/5000] | Train Loss: 0.138402\n",
      "Validation AVG Loss:     0.000128 \n",
      "\n",
      "Epoch [2305/5000] | Train Loss: 0.138311\n",
      "Validation AVG Loss:     0.000128 \n",
      "\n",
      "Epoch [2306/5000] | Train Loss: 0.138220\n",
      "Validation AVG Loss:     0.000128 \n",
      "\n",
      "Epoch [2307/5000] | Train Loss: 0.138128\n",
      "Validation AVG Loss:     0.000128 \n",
      "\n",
      "Epoch [2308/5000] | Train Loss: 0.138037\n",
      "Validation AVG Loss:     0.000128 \n",
      "\n",
      "Epoch [2309/5000] | Train Loss: 0.137945\n",
      "Validation AVG Loss:     0.000128 \n",
      "\n",
      "Epoch [2310/5000] | Train Loss: 0.137854\n",
      "Validation AVG Loss:     0.000127 \n",
      "\n",
      "Epoch [2311/5000] | Train Loss: 0.137763\n",
      "Validation AVG Loss:     0.000127 \n",
      "\n",
      "Epoch [2312/5000] | Train Loss: 0.137671\n",
      "Validation AVG Loss:     0.000127 \n",
      "\n",
      "Epoch [2313/5000] | Train Loss: 0.137580\n",
      "Validation AVG Loss:     0.000127 \n",
      "\n",
      "Epoch [2314/5000] | Train Loss: 0.137489\n",
      "Validation AVG Loss:     0.000127 \n",
      "\n",
      "Epoch [2315/5000] | Train Loss: 0.137397\n",
      "Validation AVG Loss:     0.000127 \n",
      "\n",
      "Epoch [2316/5000] | Train Loss: 0.137306\n",
      "Validation AVG Loss:     0.000127 \n",
      "\n",
      "Epoch [2317/5000] | Train Loss: 0.137215\n",
      "Validation AVG Loss:     0.000127 \n",
      "\n",
      "Epoch [2318/5000] | Train Loss: 0.137124\n",
      "Validation AVG Loss:     0.000127 \n",
      "\n",
      "Epoch [2319/5000] | Train Loss: 0.137032\n",
      "Validation AVG Loss:     0.000127 \n",
      "\n",
      "Epoch [2320/5000] | Train Loss: 0.136941\n",
      "Validation AVG Loss:     0.000127 \n",
      "\n",
      "Epoch [2321/5000] | Train Loss: 0.136850\n",
      "Validation AVG Loss:     0.000126 \n",
      "\n",
      "Epoch [2322/5000] | Train Loss: 0.136759\n",
      "Validation AVG Loss:     0.000126 \n",
      "\n",
      "Epoch [2323/5000] | Train Loss: 0.136668\n",
      "Validation AVG Loss:     0.000126 \n",
      "\n",
      "Epoch [2324/5000] | Train Loss: 0.136577\n",
      "Validation AVG Loss:     0.000126 \n",
      "\n",
      "Epoch [2325/5000] | Train Loss: 0.136486\n",
      "Validation AVG Loss:     0.000126 \n",
      "\n",
      "Epoch [2326/5000] | Train Loss: 0.136394\n",
      "Validation AVG Loss:     0.000126 \n",
      "\n",
      "Epoch [2327/5000] | Train Loss: 0.136303\n",
      "Validation AVG Loss:     0.000126 \n",
      "\n",
      "Epoch [2328/5000] | Train Loss: 0.136212\n",
      "Validation AVG Loss:     0.000126 \n",
      "\n",
      "Epoch [2329/5000] | Train Loss: 0.136121\n",
      "Validation AVG Loss:     0.000126 \n",
      "\n",
      "Epoch [2330/5000] | Train Loss: 0.136030\n",
      "Validation AVG Loss:     0.000126 \n",
      "\n",
      "Epoch [2331/5000] | Train Loss: 0.135939\n",
      "Validation AVG Loss:     0.000126 \n",
      "\n",
      "Epoch [2332/5000] | Train Loss: 0.135849\n",
      "Validation AVG Loss:     0.000126 \n",
      "\n",
      "Epoch [2333/5000] | Train Loss: 0.135758\n",
      "Validation AVG Loss:     0.000125 \n",
      "\n",
      "Epoch [2334/5000] | Train Loss: 0.135667\n",
      "Validation AVG Loss:     0.000125 \n",
      "\n",
      "Epoch [2335/5000] | Train Loss: 0.135576\n",
      "Validation AVG Loss:     0.000125 \n",
      "\n",
      "Epoch [2336/5000] | Train Loss: 0.135485\n",
      "Validation AVG Loss:     0.000125 \n",
      "\n",
      "Epoch [2337/5000] | Train Loss: 0.135394\n",
      "Validation AVG Loss:     0.000125 \n",
      "\n",
      "Epoch [2338/5000] | Train Loss: 0.135303\n",
      "Validation AVG Loss:     0.000125 \n",
      "\n",
      "Epoch [2339/5000] | Train Loss: 0.135212\n",
      "Validation AVG Loss:     0.000125 \n",
      "\n",
      "Epoch [2340/5000] | Train Loss: 0.135122\n",
      "Validation AVG Loss:     0.000125 \n",
      "\n",
      "Epoch [2341/5000] | Train Loss: 0.135031\n",
      "Validation AVG Loss:     0.000125 \n",
      "\n",
      "Epoch [2342/5000] | Train Loss: 0.134940\n",
      "Validation AVG Loss:     0.000125 \n",
      "\n",
      "Epoch [2343/5000] | Train Loss: 0.134849\n",
      "Validation AVG Loss:     0.000125 \n",
      "\n",
      "Epoch [2344/5000] | Train Loss: 0.134759\n",
      "Validation AVG Loss:     0.000124 \n",
      "\n",
      "Epoch [2345/5000] | Train Loss: 0.134668\n",
      "Validation AVG Loss:     0.000124 \n",
      "\n",
      "Epoch [2346/5000] | Train Loss: 0.134577\n",
      "Validation AVG Loss:     0.000124 \n",
      "\n",
      "Epoch [2347/5000] | Train Loss: 0.134487\n",
      "Validation AVG Loss:     0.000124 \n",
      "\n",
      "Epoch [2348/5000] | Train Loss: 0.134396\n",
      "Validation AVG Loss:     0.000124 \n",
      "\n",
      "Epoch [2349/5000] | Train Loss: 0.134306\n",
      "Validation AVG Loss:     0.000124 \n",
      "\n",
      "Epoch [2350/5000] | Train Loss: 0.134215\n",
      "Validation AVG Loss:     0.000124 \n",
      "\n",
      "Epoch [2351/5000] | Train Loss: 0.134124\n",
      "Validation AVG Loss:     0.000124 \n",
      "\n",
      "Epoch [2352/5000] | Train Loss: 0.134034\n",
      "Validation AVG Loss:     0.000124 \n",
      "\n",
      "Epoch [2353/5000] | Train Loss: 0.133943\n",
      "Validation AVG Loss:     0.000124 \n",
      "\n",
      "Epoch [2354/5000] | Train Loss: 0.133853\n",
      "Validation AVG Loss:     0.000124 \n",
      "\n",
      "Epoch [2355/5000] | Train Loss: 0.133762\n",
      "Validation AVG Loss:     0.000124 \n",
      "\n",
      "Epoch [2356/5000] | Train Loss: 0.133672\n",
      "Validation AVG Loss:     0.000123 \n",
      "\n",
      "Epoch [2357/5000] | Train Loss: 0.133581\n",
      "Validation AVG Loss:     0.000123 \n",
      "\n",
      "Epoch [2358/5000] | Train Loss: 0.133491\n",
      "Validation AVG Loss:     0.000123 \n",
      "\n",
      "Epoch [2359/5000] | Train Loss: 0.133401\n",
      "Validation AVG Loss:     0.000123 \n",
      "\n",
      "Epoch [2360/5000] | Train Loss: 0.133310\n",
      "Validation AVG Loss:     0.000123 \n",
      "\n",
      "Epoch [2361/5000] | Train Loss: 0.133220\n",
      "Validation AVG Loss:     0.000123 \n",
      "\n",
      "Epoch [2362/5000] | Train Loss: 0.133130\n",
      "Validation AVG Loss:     0.000123 \n",
      "\n",
      "Epoch [2363/5000] | Train Loss: 0.133039\n",
      "Validation AVG Loss:     0.000123 \n",
      "\n",
      "Epoch [2364/5000] | Train Loss: 0.132949\n",
      "Validation AVG Loss:     0.000123 \n",
      "\n",
      "Epoch [2365/5000] | Train Loss: 0.132859\n",
      "Validation AVG Loss:     0.000123 \n",
      "\n",
      "Epoch [2366/5000] | Train Loss: 0.132768\n",
      "Validation AVG Loss:     0.000123 \n",
      "\n",
      "Epoch [2367/5000] | Train Loss: 0.132678\n",
      "Validation AVG Loss:     0.000123 \n",
      "\n",
      "Epoch [2368/5000] | Train Loss: 0.132588\n",
      "Validation AVG Loss:     0.000122 \n",
      "\n",
      "Epoch [2369/5000] | Train Loss: 0.132498\n",
      "Validation AVG Loss:     0.000122 \n",
      "\n",
      "Epoch [2370/5000] | Train Loss: 0.132408\n",
      "Validation AVG Loss:     0.000122 \n",
      "\n",
      "Epoch [2371/5000] | Train Loss: 0.132317\n",
      "Validation AVG Loss:     0.000122 \n",
      "\n",
      "Epoch [2372/5000] | Train Loss: 0.132227\n",
      "Validation AVG Loss:     0.000122 \n",
      "\n",
      "Epoch [2373/5000] | Train Loss: 0.132137\n",
      "Validation AVG Loss:     0.000122 \n",
      "\n",
      "Epoch [2374/5000] | Train Loss: 0.132047\n",
      "Validation AVG Loss:     0.000122 \n",
      "\n",
      "Epoch [2375/5000] | Train Loss: 0.131957\n",
      "Validation AVG Loss:     0.000122 \n",
      "\n",
      "Epoch [2376/5000] | Train Loss: 0.131867\n",
      "Validation AVG Loss:     0.000122 \n",
      "\n",
      "Epoch [2377/5000] | Train Loss: 0.131777\n",
      "Validation AVG Loss:     0.000122 \n",
      "\n",
      "Epoch [2378/5000] | Train Loss: 0.131687\n",
      "Validation AVG Loss:     0.000122 \n",
      "\n",
      "Epoch [2379/5000] | Train Loss: 0.131597\n",
      "Validation AVG Loss:     0.000121 \n",
      "\n",
      "Epoch [2380/5000] | Train Loss: 0.131507\n",
      "Validation AVG Loss:     0.000121 \n",
      "\n",
      "Epoch [2381/5000] | Train Loss: 0.131417\n",
      "Validation AVG Loss:     0.000121 \n",
      "\n",
      "Epoch [2382/5000] | Train Loss: 0.131327\n",
      "Validation AVG Loss:     0.000121 \n",
      "\n",
      "Epoch [2383/5000] | Train Loss: 0.131237\n",
      "Validation AVG Loss:     0.000121 \n",
      "\n",
      "Epoch [2384/5000] | Train Loss: 0.131147\n",
      "Validation AVG Loss:     0.000121 \n",
      "\n",
      "Epoch [2385/5000] | Train Loss: 0.131057\n",
      "Validation AVG Loss:     0.000121 \n",
      "\n",
      "Epoch [2386/5000] | Train Loss: 0.130967\n",
      "Validation AVG Loss:     0.000121 \n",
      "\n",
      "Epoch [2387/5000] | Train Loss: 0.130878\n",
      "Validation AVG Loss:     0.000121 \n",
      "\n",
      "Epoch [2388/5000] | Train Loss: 0.130788\n",
      "Validation AVG Loss:     0.000121 \n",
      "\n",
      "Epoch [2389/5000] | Train Loss: 0.130698\n",
      "Validation AVG Loss:     0.000121 \n",
      "\n",
      "Epoch [2390/5000] | Train Loss: 0.130608\n",
      "Validation AVG Loss:     0.000121 \n",
      "\n",
      "Epoch [2391/5000] | Train Loss: 0.130519\n",
      "Validation AVG Loss:     0.000120 \n",
      "\n",
      "Epoch [2392/5000] | Train Loss: 0.130429\n",
      "Validation AVG Loss:     0.000120 \n",
      "\n",
      "Epoch [2393/5000] | Train Loss: 0.130339\n",
      "Validation AVG Loss:     0.000120 \n",
      "\n",
      "Epoch [2394/5000] | Train Loss: 0.130249\n",
      "Validation AVG Loss:     0.000120 \n",
      "\n",
      "Epoch [2395/5000] | Train Loss: 0.130160\n",
      "Validation AVG Loss:     0.000120 \n",
      "\n",
      "Epoch [2396/5000] | Train Loss: 0.130070\n",
      "Validation AVG Loss:     0.000120 \n",
      "\n",
      "Epoch [2397/5000] | Train Loss: 0.129981\n",
      "Validation AVG Loss:     0.000120 \n",
      "\n",
      "Epoch [2398/5000] | Train Loss: 0.129891\n",
      "Validation AVG Loss:     0.000120 \n",
      "\n",
      "Epoch [2399/5000] | Train Loss: 0.129801\n",
      "Validation AVG Loss:     0.000120 \n",
      "\n",
      "Epoch [2400/5000] | Train Loss: 0.129712\n",
      "Validation AVG Loss:     0.000120 \n",
      "\n",
      "Epoch [2401/5000] | Train Loss: 0.129622\n",
      "Validation AVG Loss:     0.000120 \n",
      "\n",
      "Epoch [2402/5000] | Train Loss: 0.129533\n",
      "Validation AVG Loss:     0.000120 \n",
      "\n",
      "Epoch [2403/5000] | Train Loss: 0.129443\n",
      "Validation AVG Loss:     0.000119 \n",
      "\n",
      "Epoch [2404/5000] | Train Loss: 0.129354\n",
      "Validation AVG Loss:     0.000119 \n",
      "\n",
      "Epoch [2405/5000] | Train Loss: 0.129264\n",
      "Validation AVG Loss:     0.000119 \n",
      "\n",
      "Epoch [2406/5000] | Train Loss: 0.129175\n",
      "Validation AVG Loss:     0.000119 \n",
      "\n",
      "Epoch [2407/5000] | Train Loss: 0.129086\n",
      "Validation AVG Loss:     0.000119 \n",
      "\n",
      "Epoch [2408/5000] | Train Loss: 0.128996\n",
      "Validation AVG Loss:     0.000119 \n",
      "\n",
      "Epoch [2409/5000] | Train Loss: 0.128907\n",
      "Validation AVG Loss:     0.000119 \n",
      "\n",
      "Epoch [2410/5000] | Train Loss: 0.128818\n",
      "Validation AVG Loss:     0.000119 \n",
      "\n",
      "Epoch [2411/5000] | Train Loss: 0.128728\n",
      "Validation AVG Loss:     0.000119 \n",
      "\n",
      "Epoch [2412/5000] | Train Loss: 0.128639\n",
      "Validation AVG Loss:     0.000119 \n",
      "\n",
      "Epoch [2413/5000] | Train Loss: 0.128550\n",
      "Validation AVG Loss:     0.000119 \n",
      "\n",
      "Epoch [2414/5000] | Train Loss: 0.128461\n",
      "Validation AVG Loss:     0.000118 \n",
      "\n",
      "Epoch [2415/5000] | Train Loss: 0.128371\n",
      "Validation AVG Loss:     0.000118 \n",
      "\n",
      "Epoch [2416/5000] | Train Loss: 0.128282\n",
      "Validation AVG Loss:     0.000118 \n",
      "\n",
      "Epoch [2417/5000] | Train Loss: 0.128193\n",
      "Validation AVG Loss:     0.000118 \n",
      "\n",
      "Epoch [2418/5000] | Train Loss: 0.128104\n",
      "Validation AVG Loss:     0.000118 \n",
      "\n",
      "Epoch [2419/5000] | Train Loss: 0.128015\n",
      "Validation AVG Loss:     0.000118 \n",
      "\n",
      "Epoch [2420/5000] | Train Loss: 0.127926\n",
      "Validation AVG Loss:     0.000118 \n",
      "\n",
      "Epoch [2421/5000] | Train Loss: 0.127837\n",
      "Validation AVG Loss:     0.000118 \n",
      "\n",
      "Epoch [2422/5000] | Train Loss: 0.127748\n",
      "Validation AVG Loss:     0.000118 \n",
      "\n",
      "Epoch [2423/5000] | Train Loss: 0.127658\n",
      "Validation AVG Loss:     0.000118 \n",
      "\n",
      "Epoch [2424/5000] | Train Loss: 0.127569\n",
      "Validation AVG Loss:     0.000118 \n",
      "\n",
      "Epoch [2425/5000] | Train Loss: 0.127480\n",
      "Validation AVG Loss:     0.000118 \n",
      "\n",
      "Epoch [2426/5000] | Train Loss: 0.127392\n",
      "Validation AVG Loss:     0.000117 \n",
      "\n",
      "Epoch [2427/5000] | Train Loss: 0.127303\n",
      "Validation AVG Loss:     0.000117 \n",
      "\n",
      "Epoch [2428/5000] | Train Loss: 0.127214\n",
      "Validation AVG Loss:     0.000117 \n",
      "\n",
      "Epoch [2429/5000] | Train Loss: 0.127125\n",
      "Validation AVG Loss:     0.000117 \n",
      "\n",
      "Epoch [2430/5000] | Train Loss: 0.127036\n",
      "Validation AVG Loss:     0.000117 \n",
      "\n",
      "Epoch [2431/5000] | Train Loss: 0.126947\n",
      "Validation AVG Loss:     0.000117 \n",
      "\n",
      "Epoch [2432/5000] | Train Loss: 0.126858\n",
      "Validation AVG Loss:     0.000117 \n",
      "\n",
      "Epoch [2433/5000] | Train Loss: 0.126769\n",
      "Validation AVG Loss:     0.000117 \n",
      "\n",
      "Epoch [2434/5000] | Train Loss: 0.126681\n",
      "Validation AVG Loss:     0.000117 \n",
      "\n",
      "Epoch [2435/5000] | Train Loss: 0.126592\n",
      "Validation AVG Loss:     0.000117 \n",
      "\n",
      "Epoch [2436/5000] | Train Loss: 0.126503\n",
      "Validation AVG Loss:     0.000117 \n",
      "\n",
      "Epoch [2437/5000] | Train Loss: 0.126414\n",
      "Validation AVG Loss:     0.000117 \n",
      "\n",
      "Epoch [2438/5000] | Train Loss: 0.126326\n",
      "Validation AVG Loss:     0.000116 \n",
      "\n",
      "Epoch [2439/5000] | Train Loss: 0.126237\n",
      "Validation AVG Loss:     0.000116 \n",
      "\n",
      "Epoch [2440/5000] | Train Loss: 0.126148\n",
      "Validation AVG Loss:     0.000116 \n",
      "\n",
      "Epoch [2441/5000] | Train Loss: 0.126060\n",
      "Validation AVG Loss:     0.000116 \n",
      "\n",
      "Epoch [2442/5000] | Train Loss: 0.125971\n",
      "Validation AVG Loss:     0.000116 \n",
      "\n",
      "Epoch [2443/5000] | Train Loss: 0.125883\n",
      "Validation AVG Loss:     0.000116 \n",
      "\n",
      "Epoch [2444/5000] | Train Loss: 0.125794\n",
      "Validation AVG Loss:     0.000116 \n",
      "\n",
      "Epoch [2445/5000] | Train Loss: 0.125705\n",
      "Validation AVG Loss:     0.000116 \n",
      "\n",
      "Epoch [2446/5000] | Train Loss: 0.125617\n",
      "Validation AVG Loss:     0.000116 \n",
      "\n",
      "Epoch [2447/5000] | Train Loss: 0.125528\n",
      "Validation AVG Loss:     0.000116 \n",
      "\n",
      "Epoch [2448/5000] | Train Loss: 0.125440\n",
      "Validation AVG Loss:     0.000116 \n",
      "\n",
      "Epoch [2449/5000] | Train Loss: 0.125352\n",
      "Validation AVG Loss:     0.000116 \n",
      "\n",
      "Epoch [2450/5000] | Train Loss: 0.125263\n",
      "Validation AVG Loss:     0.000115 \n",
      "\n",
      "Epoch [2451/5000] | Train Loss: 0.125175\n",
      "Validation AVG Loss:     0.000115 \n",
      "\n",
      "Epoch [2452/5000] | Train Loss: 0.125086\n",
      "Validation AVG Loss:     0.000115 \n",
      "\n",
      "Epoch [2453/5000] | Train Loss: 0.124998\n",
      "Validation AVG Loss:     0.000115 \n",
      "\n",
      "Epoch [2454/5000] | Train Loss: 0.124910\n",
      "Validation AVG Loss:     0.000115 \n",
      "\n",
      "Epoch [2455/5000] | Train Loss: 0.124821\n",
      "Validation AVG Loss:     0.000115 \n",
      "\n",
      "Epoch [2456/5000] | Train Loss: 0.124733\n",
      "Validation AVG Loss:     0.000115 \n",
      "\n",
      "Epoch [2457/5000] | Train Loss: 0.124645\n",
      "Validation AVG Loss:     0.000115 \n",
      "\n",
      "Epoch [2458/5000] | Train Loss: 0.124557\n",
      "Validation AVG Loss:     0.000115 \n",
      "\n",
      "Epoch [2459/5000] | Train Loss: 0.124469\n",
      "Validation AVG Loss:     0.000115 \n",
      "\n",
      "Epoch [2460/5000] | Train Loss: 0.124380\n",
      "Validation AVG Loss:     0.000115 \n",
      "\n",
      "Epoch [2461/5000] | Train Loss: 0.124292\n",
      "Validation AVG Loss:     0.000115 \n",
      "\n",
      "Epoch [2462/5000] | Train Loss: 0.124204\n",
      "Validation AVG Loss:     0.000114 \n",
      "\n",
      "Epoch [2463/5000] | Train Loss: 0.124116\n",
      "Validation AVG Loss:     0.000114 \n",
      "\n",
      "Epoch [2464/5000] | Train Loss: 0.124028\n",
      "Validation AVG Loss:     0.000114 \n",
      "\n",
      "Epoch [2465/5000] | Train Loss: 0.123940\n",
      "Validation AVG Loss:     0.000114 \n",
      "\n",
      "Epoch [2466/5000] | Train Loss: 0.123852\n",
      "Validation AVG Loss:     0.000114 \n",
      "\n",
      "Epoch [2467/5000] | Train Loss: 0.123764\n",
      "Validation AVG Loss:     0.000114 \n",
      "\n",
      "Epoch [2468/5000] | Train Loss: 0.123676\n",
      "Validation AVG Loss:     0.000114 \n",
      "\n",
      "Epoch [2469/5000] | Train Loss: 0.123588\n",
      "Validation AVG Loss:     0.000114 \n",
      "\n",
      "Epoch [2470/5000] | Train Loss: 0.123500\n",
      "Validation AVG Loss:     0.000114 \n",
      "\n",
      "Epoch [2471/5000] | Train Loss: 0.123412\n",
      "Validation AVG Loss:     0.000114 \n",
      "\n",
      "Epoch [2472/5000] | Train Loss: 0.123324\n",
      "Validation AVG Loss:     0.000114 \n",
      "\n",
      "Epoch [2473/5000] | Train Loss: 0.123236\n",
      "Validation AVG Loss:     0.000114 \n",
      "\n",
      "Epoch [2474/5000] | Train Loss: 0.123148\n",
      "Validation AVG Loss:     0.000113 \n",
      "\n",
      "Epoch [2475/5000] | Train Loss: 0.123060\n",
      "Validation AVG Loss:     0.000113 \n",
      "\n",
      "Epoch [2476/5000] | Train Loss: 0.122973\n",
      "Validation AVG Loss:     0.000113 \n",
      "\n",
      "Epoch [2477/5000] | Train Loss: 0.122885\n",
      "Validation AVG Loss:     0.000113 \n",
      "\n",
      "Epoch [2478/5000] | Train Loss: 0.122797\n",
      "Validation AVG Loss:     0.000113 \n",
      "\n",
      "Epoch [2479/5000] | Train Loss: 0.122709\n",
      "Validation AVG Loss:     0.000113 \n",
      "\n",
      "Epoch [2480/5000] | Train Loss: 0.122622\n",
      "Validation AVG Loss:     0.000113 \n",
      "\n",
      "Epoch [2481/5000] | Train Loss: 0.122534\n",
      "Validation AVG Loss:     0.000113 \n",
      "\n",
      "Epoch [2482/5000] | Train Loss: 0.122446\n",
      "Validation AVG Loss:     0.000113 \n",
      "\n",
      "Epoch [2483/5000] | Train Loss: 0.122359\n",
      "Validation AVG Loss:     0.000113 \n",
      "\n",
      "Epoch [2484/5000] | Train Loss: 0.122271\n",
      "Validation AVG Loss:     0.000113 \n",
      "\n",
      "Epoch [2485/5000] | Train Loss: 0.122183\n",
      "Validation AVG Loss:     0.000113 \n",
      "\n",
      "Epoch [2486/5000] | Train Loss: 0.122096\n",
      "Validation AVG Loss:     0.000112 \n",
      "\n",
      "Epoch [2487/5000] | Train Loss: 0.122008\n",
      "Validation AVG Loss:     0.000112 \n",
      "\n",
      "Epoch [2488/5000] | Train Loss: 0.121921\n",
      "Validation AVG Loss:     0.000112 \n",
      "\n",
      "Epoch [2489/5000] | Train Loss: 0.121833\n",
      "Validation AVG Loss:     0.000112 \n",
      "\n",
      "Epoch [2490/5000] | Train Loss: 0.121746\n",
      "Validation AVG Loss:     0.000112 \n",
      "\n",
      "Epoch [2491/5000] | Train Loss: 0.121658\n",
      "Validation AVG Loss:     0.000112 \n",
      "\n",
      "Epoch [2492/5000] | Train Loss: 0.121571\n",
      "Validation AVG Loss:     0.000112 \n",
      "\n",
      "Epoch [2493/5000] | Train Loss: 0.121483\n",
      "Validation AVG Loss:     0.000112 \n",
      "\n",
      "Epoch [2494/5000] | Train Loss: 0.121396\n",
      "Validation AVG Loss:     0.000112 \n",
      "\n",
      "Epoch [2495/5000] | Train Loss: 0.121309\n",
      "Validation AVG Loss:     0.000112 \n",
      "\n",
      "Epoch [2496/5000] | Train Loss: 0.121221\n",
      "Validation AVG Loss:     0.000112 \n",
      "\n",
      "Epoch [2497/5000] | Train Loss: 0.121134\n",
      "Validation AVG Loss:     0.000112 \n",
      "\n",
      "Epoch [2498/5000] | Train Loss: 0.121047\n",
      "Validation AVG Loss:     0.000111 \n",
      "\n",
      "Epoch [2499/5000] | Train Loss: 0.120959\n",
      "Validation AVG Loss:     0.000111 \n",
      "\n",
      "Epoch [2500/5000] | Train Loss: 0.120872\n",
      "Validation AVG Loss:     0.000111 \n",
      "\n",
      "Epoch [2501/5000] | Train Loss: 0.120785\n",
      "Validation AVG Loss:     0.000111 \n",
      "\n",
      "Epoch [2502/5000] | Train Loss: 0.120698\n",
      "Validation AVG Loss:     0.000111 \n",
      "\n",
      "Epoch [2503/5000] | Train Loss: 0.120611\n",
      "Validation AVG Loss:     0.000111 \n",
      "\n",
      "Epoch [2504/5000] | Train Loss: 0.120523\n",
      "Validation AVG Loss:     0.000111 \n",
      "\n",
      "Epoch [2505/5000] | Train Loss: 0.120436\n",
      "Validation AVG Loss:     0.000111 \n",
      "\n",
      "Epoch [2506/5000] | Train Loss: 0.120349\n",
      "Validation AVG Loss:     0.000111 \n",
      "\n",
      "Epoch [2507/5000] | Train Loss: 0.120262\n",
      "Validation AVG Loss:     0.000111 \n",
      "\n",
      "Epoch [2508/5000] | Train Loss: 0.120175\n",
      "Validation AVG Loss:     0.000111 \n",
      "\n",
      "Epoch [2509/5000] | Train Loss: 0.120088\n",
      "Validation AVG Loss:     0.000111 \n",
      "\n",
      "Epoch [2510/5000] | Train Loss: 0.120001\n",
      "Validation AVG Loss:     0.000110 \n",
      "\n",
      "Epoch [2511/5000] | Train Loss: 0.119914\n",
      "Validation AVG Loss:     0.000110 \n",
      "\n",
      "Epoch [2512/5000] | Train Loss: 0.119827\n",
      "Validation AVG Loss:     0.000110 \n",
      "\n",
      "Epoch [2513/5000] | Train Loss: 0.119740\n",
      "Validation AVG Loss:     0.000110 \n",
      "\n",
      "Epoch [2514/5000] | Train Loss: 0.119653\n",
      "Validation AVG Loss:     0.000110 \n",
      "\n",
      "Epoch [2515/5000] | Train Loss: 0.119566\n",
      "Validation AVG Loss:     0.000110 \n",
      "\n",
      "Epoch [2516/5000] | Train Loss: 0.119480\n",
      "Validation AVG Loss:     0.000110 \n",
      "\n",
      "Epoch [2517/5000] | Train Loss: 0.119393\n",
      "Validation AVG Loss:     0.000110 \n",
      "\n",
      "Epoch [2518/5000] | Train Loss: 0.119306\n",
      "Validation AVG Loss:     0.000110 \n",
      "\n",
      "Epoch [2519/5000] | Train Loss: 0.119219\n",
      "Validation AVG Loss:     0.000110 \n",
      "\n",
      "Epoch [2520/5000] | Train Loss: 0.119132\n",
      "Validation AVG Loss:     0.000110 \n",
      "\n",
      "Epoch [2521/5000] | Train Loss: 0.119046\n",
      "Validation AVG Loss:     0.000110 \n",
      "\n",
      "Epoch [2522/5000] | Train Loss: 0.118959\n",
      "Validation AVG Loss:     0.000109 \n",
      "\n",
      "Epoch [2523/5000] | Train Loss: 0.118872\n",
      "Validation AVG Loss:     0.000109 \n",
      "\n",
      "Epoch [2524/5000] | Train Loss: 0.118786\n",
      "Validation AVG Loss:     0.000109 \n",
      "\n",
      "Epoch [2525/5000] | Train Loss: 0.118699\n",
      "Validation AVG Loss:     0.000109 \n",
      "\n",
      "Epoch [2526/5000] | Train Loss: 0.118613\n",
      "Validation AVG Loss:     0.000109 \n",
      "\n",
      "Epoch [2527/5000] | Train Loss: 0.118526\n",
      "Validation AVG Loss:     0.000109 \n",
      "\n",
      "Epoch [2528/5000] | Train Loss: 0.118439\n",
      "Validation AVG Loss:     0.000109 \n",
      "\n",
      "Epoch [2529/5000] | Train Loss: 0.118353\n",
      "Validation AVG Loss:     0.000109 \n",
      "\n",
      "Epoch [2530/5000] | Train Loss: 0.118266\n",
      "Validation AVG Loss:     0.000109 \n",
      "\n",
      "Epoch [2531/5000] | Train Loss: 0.118180\n",
      "Validation AVG Loss:     0.000109 \n",
      "\n",
      "Epoch [2532/5000] | Train Loss: 0.118093\n",
      "Validation AVG Loss:     0.000109 \n",
      "\n",
      "Epoch [2533/5000] | Train Loss: 0.118007\n",
      "Validation AVG Loss:     0.000109 \n",
      "\n",
      "Epoch [2534/5000] | Train Loss: 0.117921\n",
      "Validation AVG Loss:     0.000108 \n",
      "\n",
      "Epoch [2535/5000] | Train Loss: 0.117834\n",
      "Validation AVG Loss:     0.000108 \n",
      "\n",
      "Epoch [2536/5000] | Train Loss: 0.117748\n",
      "Validation AVG Loss:     0.000108 \n",
      "\n",
      "Epoch [2537/5000] | Train Loss: 0.117662\n",
      "Validation AVG Loss:     0.000108 \n",
      "\n",
      "Epoch [2538/5000] | Train Loss: 0.117575\n",
      "Validation AVG Loss:     0.000108 \n",
      "\n",
      "Epoch [2539/5000] | Train Loss: 0.117489\n",
      "Validation AVG Loss:     0.000108 \n",
      "\n",
      "Epoch [2540/5000] | Train Loss: 0.117403\n",
      "Validation AVG Loss:     0.000108 \n",
      "\n",
      "Epoch [2541/5000] | Train Loss: 0.117317\n",
      "Validation AVG Loss:     0.000108 \n",
      "\n",
      "Epoch [2542/5000] | Train Loss: 0.117230\n",
      "Validation AVG Loss:     0.000108 \n",
      "\n",
      "Epoch [2543/5000] | Train Loss: 0.117144\n",
      "Validation AVG Loss:     0.000108 \n",
      "\n",
      "Epoch [2544/5000] | Train Loss: 0.117058\n",
      "Validation AVG Loss:     0.000108 \n",
      "\n",
      "Epoch [2545/5000] | Train Loss: 0.116972\n",
      "Validation AVG Loss:     0.000108 \n",
      "\n",
      "Epoch [2546/5000] | Train Loss: 0.116886\n",
      "Validation AVG Loss:     0.000107 \n",
      "\n",
      "Epoch [2547/5000] | Train Loss: 0.116800\n",
      "Validation AVG Loss:     0.000107 \n",
      "\n",
      "Epoch [2548/5000] | Train Loss: 0.116714\n",
      "Validation AVG Loss:     0.000107 \n",
      "\n",
      "Epoch [2549/5000] | Train Loss: 0.116628\n",
      "Validation AVG Loss:     0.000107 \n",
      "\n",
      "Epoch [2550/5000] | Train Loss: 0.116542\n",
      "Validation AVG Loss:     0.000107 \n",
      "\n",
      "Epoch [2551/5000] | Train Loss: 0.116456\n",
      "Validation AVG Loss:     0.000107 \n",
      "\n",
      "Epoch [2552/5000] | Train Loss: 0.116370\n",
      "Validation AVG Loss:     0.000107 \n",
      "\n",
      "Epoch [2553/5000] | Train Loss: 0.116284\n",
      "Validation AVG Loss:     0.000107 \n",
      "\n",
      "Epoch [2554/5000] | Train Loss: 0.116198\n",
      "Validation AVG Loss:     0.000107 \n",
      "\n",
      "Epoch [2555/5000] | Train Loss: 0.116112\n",
      "Validation AVG Loss:     0.000107 \n",
      "\n",
      "Epoch [2556/5000] | Train Loss: 0.116026\n",
      "Validation AVG Loss:     0.000107 \n",
      "\n",
      "Epoch [2557/5000] | Train Loss: 0.115941\n",
      "Validation AVG Loss:     0.000107 \n",
      "\n",
      "Epoch [2558/5000] | Train Loss: 0.115855\n",
      "Validation AVG Loss:     0.000107 \n",
      "\n",
      "Epoch [2559/5000] | Train Loss: 0.115769\n",
      "Validation AVG Loss:     0.000106 \n",
      "\n",
      "Epoch [2560/5000] | Train Loss: 0.115684\n",
      "Validation AVG Loss:     0.000106 \n",
      "\n",
      "Epoch [2561/5000] | Train Loss: 0.115598\n",
      "Validation AVG Loss:     0.000106 \n",
      "\n",
      "Epoch [2562/5000] | Train Loss: 0.115512\n",
      "Validation AVG Loss:     0.000106 \n",
      "\n",
      "Epoch [2563/5000] | Train Loss: 0.115427\n",
      "Validation AVG Loss:     0.000106 \n",
      "\n",
      "Epoch [2564/5000] | Train Loss: 0.115341\n",
      "Validation AVG Loss:     0.000106 \n",
      "\n",
      "Epoch [2565/5000] | Train Loss: 0.115255\n",
      "Validation AVG Loss:     0.000106 \n",
      "\n",
      "Epoch [2566/5000] | Train Loss: 0.115170\n",
      "Validation AVG Loss:     0.000106 \n",
      "\n",
      "Epoch [2567/5000] | Train Loss: 0.115084\n",
      "Validation AVG Loss:     0.000106 \n",
      "\n",
      "Epoch [2568/5000] | Train Loss: 0.114999\n",
      "Validation AVG Loss:     0.000106 \n",
      "\n",
      "Epoch [2569/5000] | Train Loss: 0.114913\n",
      "Validation AVG Loss:     0.000106 \n",
      "\n",
      "Epoch [2570/5000] | Train Loss: 0.114828\n",
      "Validation AVG Loss:     0.000106 \n",
      "\n",
      "Epoch [2571/5000] | Train Loss: 0.114743\n",
      "Validation AVG Loss:     0.000105 \n",
      "\n",
      "Epoch [2572/5000] | Train Loss: 0.114657\n",
      "Validation AVG Loss:     0.000105 \n",
      "\n",
      "Epoch [2573/5000] | Train Loss: 0.114572\n",
      "Validation AVG Loss:     0.000105 \n",
      "\n",
      "Epoch [2574/5000] | Train Loss: 0.114487\n",
      "Validation AVG Loss:     0.000105 \n",
      "\n",
      "Epoch [2575/5000] | Train Loss: 0.114401\n",
      "Validation AVG Loss:     0.000105 \n",
      "\n",
      "Epoch [2576/5000] | Train Loss: 0.114316\n",
      "Validation AVG Loss:     0.000105 \n",
      "\n",
      "Epoch [2577/5000] | Train Loss: 0.114231\n",
      "Validation AVG Loss:     0.000105 \n",
      "\n",
      "Epoch [2578/5000] | Train Loss: 0.114146\n",
      "Validation AVG Loss:     0.000105 \n",
      "\n",
      "Epoch [2579/5000] | Train Loss: 0.114061\n",
      "Validation AVG Loss:     0.000105 \n",
      "\n",
      "Epoch [2580/5000] | Train Loss: 0.113975\n",
      "Validation AVG Loss:     0.000105 \n",
      "\n",
      "Epoch [2581/5000] | Train Loss: 0.113890\n",
      "Validation AVG Loss:     0.000105 \n",
      "\n",
      "Epoch [2582/5000] | Train Loss: 0.113805\n",
      "Validation AVG Loss:     0.000105 \n",
      "\n",
      "Epoch [2583/5000] | Train Loss: 0.113720\n",
      "Validation AVG Loss:     0.000104 \n",
      "\n",
      "Epoch [2584/5000] | Train Loss: 0.113635\n",
      "Validation AVG Loss:     0.000104 \n",
      "\n",
      "Epoch [2585/5000] | Train Loss: 0.113550\n",
      "Validation AVG Loss:     0.000104 \n",
      "\n",
      "Epoch [2586/5000] | Train Loss: 0.113465\n",
      "Validation AVG Loss:     0.000104 \n",
      "\n",
      "Epoch [2587/5000] | Train Loss: 0.113380\n",
      "Validation AVG Loss:     0.000104 \n",
      "\n",
      "Epoch [2588/5000] | Train Loss: 0.113295\n",
      "Validation AVG Loss:     0.000104 \n",
      "\n",
      "Epoch [2589/5000] | Train Loss: 0.113211\n",
      "Validation AVG Loss:     0.000104 \n",
      "\n",
      "Epoch [2590/5000] | Train Loss: 0.113126\n",
      "Validation AVG Loss:     0.000104 \n",
      "\n",
      "Epoch [2591/5000] | Train Loss: 0.113041\n",
      "Validation AVG Loss:     0.000104 \n",
      "\n",
      "Epoch [2592/5000] | Train Loss: 0.112956\n",
      "Validation AVG Loss:     0.000104 \n",
      "\n",
      "Epoch [2593/5000] | Train Loss: 0.112871\n",
      "Validation AVG Loss:     0.000104 \n",
      "\n",
      "Epoch [2594/5000] | Train Loss: 0.112787\n",
      "Validation AVG Loss:     0.000104 \n",
      "\n",
      "Epoch [2595/5000] | Train Loss: 0.112702\n",
      "Validation AVG Loss:     0.000104 \n",
      "\n",
      "Epoch [2596/5000] | Train Loss: 0.112617\n",
      "Validation AVG Loss:     0.000103 \n",
      "\n",
      "Epoch [2597/5000] | Train Loss: 0.112533\n",
      "Validation AVG Loss:     0.000103 \n",
      "\n",
      "Epoch [2598/5000] | Train Loss: 0.112448\n",
      "Validation AVG Loss:     0.000103 \n",
      "\n",
      "Epoch [2599/5000] | Train Loss: 0.112363\n",
      "Validation AVG Loss:     0.000103 \n",
      "\n",
      "Epoch [2600/5000] | Train Loss: 0.112279\n",
      "Validation AVG Loss:     0.000103 \n",
      "\n",
      "Epoch [2601/5000] | Train Loss: 0.112194\n",
      "Validation AVG Loss:     0.000103 \n",
      "\n",
      "Epoch [2602/5000] | Train Loss: 0.112110\n",
      "Validation AVG Loss:     0.000103 \n",
      "\n",
      "Epoch [2603/5000] | Train Loss: 0.112025\n",
      "Validation AVG Loss:     0.000103 \n",
      "\n",
      "Epoch [2604/5000] | Train Loss: 0.111941\n",
      "Validation AVG Loss:     0.000103 \n",
      "\n",
      "Epoch [2605/5000] | Train Loss: 0.111856\n",
      "Validation AVG Loss:     0.000103 \n",
      "\n",
      "Epoch [2606/5000] | Train Loss: 0.111772\n",
      "Validation AVG Loss:     0.000103 \n",
      "\n",
      "Epoch [2607/5000] | Train Loss: 0.111688\n",
      "Validation AVG Loss:     0.000103 \n",
      "\n",
      "Epoch [2608/5000] | Train Loss: 0.111603\n",
      "Validation AVG Loss:     0.000102 \n",
      "\n",
      "Epoch [2609/5000] | Train Loss: 0.111519\n",
      "Validation AVG Loss:     0.000102 \n",
      "\n",
      "Epoch [2610/5000] | Train Loss: 0.111435\n",
      "Validation AVG Loss:     0.000102 \n",
      "\n",
      "Epoch [2611/5000] | Train Loss: 0.111351\n",
      "Validation AVG Loss:     0.000102 \n",
      "\n",
      "Epoch [2612/5000] | Train Loss: 0.111266\n",
      "Validation AVG Loss:     0.000102 \n",
      "\n",
      "Epoch [2613/5000] | Train Loss: 0.111182\n",
      "Validation AVG Loss:     0.000102 \n",
      "\n",
      "Epoch [2614/5000] | Train Loss: 0.111098\n",
      "Validation AVG Loss:     0.000102 \n",
      "\n",
      "Epoch [2615/5000] | Train Loss: 0.111014\n",
      "Validation AVG Loss:     0.000102 \n",
      "\n",
      "Epoch [2616/5000] | Train Loss: 0.110930\n",
      "Validation AVG Loss:     0.000102 \n",
      "\n",
      "Epoch [2617/5000] | Train Loss: 0.110846\n",
      "Validation AVG Loss:     0.000102 \n",
      "\n",
      "Epoch [2618/5000] | Train Loss: 0.110762\n",
      "Validation AVG Loss:     0.000102 \n",
      "\n",
      "Epoch [2619/5000] | Train Loss: 0.110678\n",
      "Validation AVG Loss:     0.000102 \n",
      "\n",
      "Epoch [2620/5000] | Train Loss: 0.110594\n",
      "Validation AVG Loss:     0.000102 \n",
      "\n",
      "Epoch [2621/5000] | Train Loss: 0.110510\n",
      "Validation AVG Loss:     0.000101 \n",
      "\n",
      "Epoch [2622/5000] | Train Loss: 0.110426\n",
      "Validation AVG Loss:     0.000101 \n",
      "\n",
      "Epoch [2623/5000] | Train Loss: 0.110342\n",
      "Validation AVG Loss:     0.000101 \n",
      "\n",
      "Epoch [2624/5000] | Train Loss: 0.110258\n",
      "Validation AVG Loss:     0.000101 \n",
      "\n",
      "Epoch [2625/5000] | Train Loss: 0.110174\n",
      "Validation AVG Loss:     0.000101 \n",
      "\n",
      "Epoch [2626/5000] | Train Loss: 0.110090\n",
      "Validation AVG Loss:     0.000101 \n",
      "\n",
      "Epoch [2627/5000] | Train Loss: 0.110006\n",
      "Validation AVG Loss:     0.000101 \n",
      "\n",
      "Epoch [2628/5000] | Train Loss: 0.109922\n",
      "Validation AVG Loss:     0.000101 \n",
      "\n",
      "Epoch [2629/5000] | Train Loss: 0.109839\n",
      "Validation AVG Loss:     0.000101 \n",
      "\n",
      "Epoch [2630/5000] | Train Loss: 0.109755\n",
      "Validation AVG Loss:     0.000101 \n",
      "\n",
      "Epoch [2631/5000] | Train Loss: 0.109671\n",
      "Validation AVG Loss:     0.000101 \n",
      "\n",
      "Epoch [2632/5000] | Train Loss: 0.109588\n",
      "Validation AVG Loss:     0.000101 \n",
      "\n",
      "Epoch [2633/5000] | Train Loss: 0.109504\n",
      "Validation AVG Loss:     0.000100 \n",
      "\n",
      "Epoch [2634/5000] | Train Loss: 0.109420\n",
      "Validation AVG Loss:     0.000100 \n",
      "\n",
      "Epoch [2635/5000] | Train Loss: 0.109337\n",
      "Validation AVG Loss:     0.000100 \n",
      "\n",
      "Epoch [2636/5000] | Train Loss: 0.109253\n",
      "Validation AVG Loss:     0.000100 \n",
      "\n",
      "Epoch [2637/5000] | Train Loss: 0.109170\n",
      "Validation AVG Loss:     0.000100 \n",
      "\n",
      "Epoch [2638/5000] | Train Loss: 0.109086\n",
      "Validation AVG Loss:     0.000100 \n",
      "\n",
      "Epoch [2639/5000] | Train Loss: 0.109003\n",
      "Validation AVG Loss:     0.000100 \n",
      "\n",
      "Epoch [2640/5000] | Train Loss: 0.108919\n",
      "Validation AVG Loss:     0.000100 \n",
      "\n",
      "Epoch [2641/5000] | Train Loss: 0.108836\n",
      "Validation AVG Loss:     0.000100 \n",
      "\n",
      "Epoch [2642/5000] | Train Loss: 0.108753\n",
      "Validation AVG Loss:     0.000100 \n",
      "\n",
      "Epoch [2643/5000] | Train Loss: 0.108669\n",
      "Validation AVG Loss:     0.000100 \n",
      "\n",
      "Epoch [2644/5000] | Train Loss: 0.108586\n",
      "Validation AVG Loss:     0.000100 \n",
      "\n",
      "Epoch [2645/5000] | Train Loss: 0.108503\n",
      "Validation AVG Loss:     0.000100 \n",
      "\n",
      "Epoch [2646/5000] | Train Loss: 0.108419\n",
      "Validation AVG Loss:     0.000099 \n",
      "\n",
      "Epoch [2647/5000] | Train Loss: 0.108336\n",
      "Validation AVG Loss:     0.000099 \n",
      "\n",
      "Epoch [2648/5000] | Train Loss: 0.108253\n",
      "Validation AVG Loss:     0.000099 \n",
      "\n",
      "Epoch [2649/5000] | Train Loss: 0.108170\n",
      "Validation AVG Loss:     0.000099 \n",
      "\n",
      "Epoch [2650/5000] | Train Loss: 0.108087\n",
      "Validation AVG Loss:     0.000099 \n",
      "\n",
      "Epoch [2651/5000] | Train Loss: 0.108004\n",
      "Validation AVG Loss:     0.000099 \n",
      "\n",
      "Epoch [2652/5000] | Train Loss: 0.107921\n",
      "Validation AVG Loss:     0.000099 \n",
      "\n",
      "Epoch [2653/5000] | Train Loss: 0.107837\n",
      "Validation AVG Loss:     0.000099 \n",
      "\n",
      "Epoch [2654/5000] | Train Loss: 0.107754\n",
      "Validation AVG Loss:     0.000099 \n",
      "\n",
      "Epoch [2655/5000] | Train Loss: 0.107671\n",
      "Validation AVG Loss:     0.000099 \n",
      "\n",
      "Epoch [2656/5000] | Train Loss: 0.107589\n",
      "Validation AVG Loss:     0.000099 \n",
      "\n",
      "Epoch [2657/5000] | Train Loss: 0.107506\n",
      "Validation AVG Loss:     0.000099 \n",
      "\n",
      "Epoch [2658/5000] | Train Loss: 0.107423\n",
      "Validation AVG Loss:     0.000099 \n",
      "\n",
      "Epoch [2659/5000] | Train Loss: 0.107340\n",
      "Validation AVG Loss:     0.000098 \n",
      "\n",
      "Epoch [2660/5000] | Train Loss: 0.107257\n",
      "Validation AVG Loss:     0.000098 \n",
      "\n",
      "Epoch [2661/5000] | Train Loss: 0.107174\n",
      "Validation AVG Loss:     0.000098 \n",
      "\n",
      "Epoch [2662/5000] | Train Loss: 0.107091\n",
      "Validation AVG Loss:     0.000098 \n",
      "\n",
      "Epoch [2663/5000] | Train Loss: 0.107009\n",
      "Validation AVG Loss:     0.000098 \n",
      "\n",
      "Epoch [2664/5000] | Train Loss: 0.106926\n",
      "Validation AVG Loss:     0.000098 \n",
      "\n",
      "Epoch [2665/5000] | Train Loss: 0.106843\n",
      "Validation AVG Loss:     0.000098 \n",
      "\n",
      "Epoch [2666/5000] | Train Loss: 0.106761\n",
      "Validation AVG Loss:     0.000098 \n",
      "\n",
      "Epoch [2667/5000] | Train Loss: 0.106678\n",
      "Validation AVG Loss:     0.000098 \n",
      "\n",
      "Epoch [2668/5000] | Train Loss: 0.106596\n",
      "Validation AVG Loss:     0.000098 \n",
      "\n",
      "Epoch [2669/5000] | Train Loss: 0.106513\n",
      "Validation AVG Loss:     0.000098 \n",
      "\n",
      "Epoch [2670/5000] | Train Loss: 0.106430\n",
      "Validation AVG Loss:     0.000098 \n",
      "\n",
      "Epoch [2671/5000] | Train Loss: 0.106348\n",
      "Validation AVG Loss:     0.000098 \n",
      "\n",
      "Epoch [2672/5000] | Train Loss: 0.106266\n",
      "Validation AVG Loss:     0.000097 \n",
      "\n",
      "Epoch [2673/5000] | Train Loss: 0.106183\n",
      "Validation AVG Loss:     0.000097 \n",
      "\n",
      "Epoch [2674/5000] | Train Loss: 0.106101\n",
      "Validation AVG Loss:     0.000097 \n",
      "\n",
      "Epoch [2675/5000] | Train Loss: 0.106018\n",
      "Validation AVG Loss:     0.000097 \n",
      "\n",
      "Epoch [2676/5000] | Train Loss: 0.105936\n",
      "Validation AVG Loss:     0.000097 \n",
      "\n",
      "Epoch [2677/5000] | Train Loss: 0.105854\n",
      "Validation AVG Loss:     0.000097 \n",
      "\n",
      "Epoch [2678/5000] | Train Loss: 0.105771\n",
      "Validation AVG Loss:     0.000097 \n",
      "\n",
      "Epoch [2679/5000] | Train Loss: 0.105689\n",
      "Validation AVG Loss:     0.000097 \n",
      "\n",
      "Epoch [2680/5000] | Train Loss: 0.105607\n",
      "Validation AVG Loss:     0.000097 \n",
      "\n",
      "Epoch [2681/5000] | Train Loss: 0.105525\n",
      "Validation AVG Loss:     0.000097 \n",
      "\n",
      "Epoch [2682/5000] | Train Loss: 0.105443\n",
      "Validation AVG Loss:     0.000097 \n",
      "\n",
      "Epoch [2683/5000] | Train Loss: 0.105361\n",
      "Validation AVG Loss:     0.000097 \n",
      "\n",
      "Epoch [2684/5000] | Train Loss: 0.105278\n",
      "Validation AVG Loss:     0.000096 \n",
      "\n",
      "Epoch [2685/5000] | Train Loss: 0.105196\n",
      "Validation AVG Loss:     0.000096 \n",
      "\n",
      "Epoch [2686/5000] | Train Loss: 0.105114\n",
      "Validation AVG Loss:     0.000096 \n",
      "\n",
      "Epoch [2687/5000] | Train Loss: 0.105032\n",
      "Validation AVG Loss:     0.000096 \n",
      "\n",
      "Epoch [2688/5000] | Train Loss: 0.104950\n",
      "Validation AVG Loss:     0.000096 \n",
      "\n",
      "Epoch [2689/5000] | Train Loss: 0.104869\n",
      "Validation AVG Loss:     0.000096 \n",
      "\n",
      "Epoch [2690/5000] | Train Loss: 0.104787\n",
      "Validation AVG Loss:     0.000096 \n",
      "\n",
      "Epoch [2691/5000] | Train Loss: 0.104705\n",
      "Validation AVG Loss:     0.000096 \n",
      "\n",
      "Epoch [2692/5000] | Train Loss: 0.104623\n",
      "Validation AVG Loss:     0.000096 \n",
      "\n",
      "Epoch [2693/5000] | Train Loss: 0.104541\n",
      "Validation AVG Loss:     0.000096 \n",
      "\n",
      "Epoch [2694/5000] | Train Loss: 0.104459\n",
      "Validation AVG Loss:     0.000096 \n",
      "\n",
      "Epoch [2695/5000] | Train Loss: 0.104378\n",
      "Validation AVG Loss:     0.000096 \n",
      "\n",
      "Epoch [2696/5000] | Train Loss: 0.104296\n",
      "Validation AVG Loss:     0.000096 \n",
      "\n",
      "Epoch [2697/5000] | Train Loss: 0.104214\n",
      "Validation AVG Loss:     0.000095 \n",
      "\n",
      "Epoch [2698/5000] | Train Loss: 0.104133\n",
      "Validation AVG Loss:     0.000095 \n",
      "\n",
      "Epoch [2699/5000] | Train Loss: 0.104051\n",
      "Validation AVG Loss:     0.000095 \n",
      "\n",
      "Epoch [2700/5000] | Train Loss: 0.103970\n",
      "Validation AVG Loss:     0.000095 \n",
      "\n",
      "Epoch [2701/5000] | Train Loss: 0.103888\n",
      "Validation AVG Loss:     0.000095 \n",
      "\n",
      "Epoch [2702/5000] | Train Loss: 0.103806\n",
      "Validation AVG Loss:     0.000095 \n",
      "\n",
      "Epoch [2703/5000] | Train Loss: 0.103725\n",
      "Validation AVG Loss:     0.000095 \n",
      "\n",
      "Epoch [2704/5000] | Train Loss: 0.103644\n",
      "Validation AVG Loss:     0.000095 \n",
      "\n",
      "Epoch [2705/5000] | Train Loss: 0.103562\n",
      "Validation AVG Loss:     0.000095 \n",
      "\n",
      "Epoch [2706/5000] | Train Loss: 0.103481\n",
      "Validation AVG Loss:     0.000095 \n",
      "\n",
      "Epoch [2707/5000] | Train Loss: 0.103399\n",
      "Validation AVG Loss:     0.000095 \n",
      "\n",
      "Epoch [2708/5000] | Train Loss: 0.103318\n",
      "Validation AVG Loss:     0.000095 \n",
      "\n",
      "Epoch [2709/5000] | Train Loss: 0.103237\n",
      "Validation AVG Loss:     0.000095 \n",
      "\n",
      "Epoch [2710/5000] | Train Loss: 0.103156\n",
      "Validation AVG Loss:     0.000094 \n",
      "\n",
      "Epoch [2711/5000] | Train Loss: 0.103074\n",
      "Validation AVG Loss:     0.000094 \n",
      "\n",
      "Epoch [2712/5000] | Train Loss: 0.102993\n",
      "Validation AVG Loss:     0.000094 \n",
      "\n",
      "Epoch [2713/5000] | Train Loss: 0.102912\n",
      "Validation AVG Loss:     0.000094 \n",
      "\n",
      "Epoch [2714/5000] | Train Loss: 0.102831\n",
      "Validation AVG Loss:     0.000094 \n",
      "\n",
      "Epoch [2715/5000] | Train Loss: 0.102750\n",
      "Validation AVG Loss:     0.000094 \n",
      "\n",
      "Epoch [2716/5000] | Train Loss: 0.102669\n",
      "Validation AVG Loss:     0.000094 \n",
      "\n",
      "Epoch [2717/5000] | Train Loss: 0.102588\n",
      "Validation AVG Loss:     0.000094 \n",
      "\n",
      "Epoch [2718/5000] | Train Loss: 0.102507\n",
      "Validation AVG Loss:     0.000094 \n",
      "\n",
      "Epoch [2719/5000] | Train Loss: 0.102426\n",
      "Validation AVG Loss:     0.000094 \n",
      "\n",
      "Epoch [2720/5000] | Train Loss: 0.102345\n",
      "Validation AVG Loss:     0.000094 \n",
      "\n",
      "Epoch [2721/5000] | Train Loss: 0.102264\n",
      "Validation AVG Loss:     0.000094 \n",
      "\n",
      "Epoch [2722/5000] | Train Loss: 0.102183\n",
      "Validation AVG Loss:     0.000094 \n",
      "\n",
      "Epoch [2723/5000] | Train Loss: 0.102102\n",
      "Validation AVG Loss:     0.000093 \n",
      "\n",
      "Epoch [2724/5000] | Train Loss: 0.102022\n",
      "Validation AVG Loss:     0.000093 \n",
      "\n",
      "Epoch [2725/5000] | Train Loss: 0.101941\n",
      "Validation AVG Loss:     0.000093 \n",
      "\n",
      "Epoch [2726/5000] | Train Loss: 0.101860\n",
      "Validation AVG Loss:     0.000093 \n",
      "\n",
      "Epoch [2727/5000] | Train Loss: 0.101779\n",
      "Validation AVG Loss:     0.000093 \n",
      "\n",
      "Epoch [2728/5000] | Train Loss: 0.101699\n",
      "Validation AVG Loss:     0.000093 \n",
      "\n",
      "Epoch [2729/5000] | Train Loss: 0.101618\n",
      "Validation AVG Loss:     0.000093 \n",
      "\n",
      "Epoch [2730/5000] | Train Loss: 0.101538\n",
      "Validation AVG Loss:     0.000093 \n",
      "\n",
      "Epoch [2731/5000] | Train Loss: 0.101457\n",
      "Validation AVG Loss:     0.000093 \n",
      "\n",
      "Epoch [2732/5000] | Train Loss: 0.101376\n",
      "Validation AVG Loss:     0.000093 \n",
      "\n",
      "Epoch [2733/5000] | Train Loss: 0.101296\n",
      "Validation AVG Loss:     0.000093 \n",
      "\n",
      "Epoch [2734/5000] | Train Loss: 0.101215\n",
      "Validation AVG Loss:     0.000093 \n",
      "\n",
      "Epoch [2735/5000] | Train Loss: 0.101135\n",
      "Validation AVG Loss:     0.000093 \n",
      "\n",
      "Epoch [2736/5000] | Train Loss: 0.101055\n",
      "Validation AVG Loss:     0.000093 \n",
      "\n",
      "Epoch [2737/5000] | Train Loss: 0.100974\n",
      "Validation AVG Loss:     0.000092 \n",
      "\n",
      "Epoch [2738/5000] | Train Loss: 0.100894\n",
      "Validation AVG Loss:     0.000092 \n",
      "\n",
      "Epoch [2739/5000] | Train Loss: 0.100814\n",
      "Validation AVG Loss:     0.000092 \n",
      "\n",
      "Epoch [2740/5000] | Train Loss: 0.100733\n",
      "Validation AVG Loss:     0.000092 \n",
      "\n",
      "Epoch [2741/5000] | Train Loss: 0.100653\n",
      "Validation AVG Loss:     0.000092 \n",
      "\n",
      "Epoch [2742/5000] | Train Loss: 0.100573\n",
      "Validation AVG Loss:     0.000092 \n",
      "\n",
      "Epoch [2743/5000] | Train Loss: 0.100493\n",
      "Validation AVG Loss:     0.000092 \n",
      "\n",
      "Epoch [2744/5000] | Train Loss: 0.100413\n",
      "Validation AVG Loss:     0.000092 \n",
      "\n",
      "Epoch [2745/5000] | Train Loss: 0.100332\n",
      "Validation AVG Loss:     0.000092 \n",
      "\n",
      "Epoch [2746/5000] | Train Loss: 0.100252\n",
      "Validation AVG Loss:     0.000092 \n",
      "\n",
      "Epoch [2747/5000] | Train Loss: 0.100172\n",
      "Validation AVG Loss:     0.000092 \n",
      "\n",
      "Epoch [2748/5000] | Train Loss: 0.100092\n",
      "Validation AVG Loss:     0.000092 \n",
      "\n",
      "Epoch [2749/5000] | Train Loss: 0.100012\n",
      "Validation AVG Loss:     0.000092 \n",
      "\n",
      "Epoch [2750/5000] | Train Loss: 0.099932\n",
      "Validation AVG Loss:     0.000091 \n",
      "\n",
      "Epoch [2751/5000] | Train Loss: 0.099852\n",
      "Validation AVG Loss:     0.000091 \n",
      "\n",
      "Epoch [2752/5000] | Train Loss: 0.099772\n",
      "Validation AVG Loss:     0.000091 \n",
      "\n",
      "Epoch [2753/5000] | Train Loss: 0.099693\n",
      "Validation AVG Loss:     0.000091 \n",
      "\n",
      "Epoch [2754/5000] | Train Loss: 0.099613\n",
      "Validation AVG Loss:     0.000091 \n",
      "\n",
      "Epoch [2755/5000] | Train Loss: 0.099533\n",
      "Validation AVG Loss:     0.000091 \n",
      "\n",
      "Epoch [2756/5000] | Train Loss: 0.099453\n",
      "Validation AVG Loss:     0.000091 \n",
      "\n",
      "Epoch [2757/5000] | Train Loss: 0.099373\n",
      "Validation AVG Loss:     0.000091 \n",
      "\n",
      "Epoch [2758/5000] | Train Loss: 0.099294\n",
      "Validation AVG Loss:     0.000091 \n",
      "\n",
      "Epoch [2759/5000] | Train Loss: 0.099214\n",
      "Validation AVG Loss:     0.000091 \n",
      "\n",
      "Epoch [2760/5000] | Train Loss: 0.099134\n",
      "Validation AVG Loss:     0.000091 \n",
      "\n",
      "Epoch [2761/5000] | Train Loss: 0.099055\n",
      "Validation AVG Loss:     0.000091 \n",
      "\n",
      "Epoch [2762/5000] | Train Loss: 0.098975\n",
      "Validation AVG Loss:     0.000091 \n",
      "\n",
      "Epoch [2763/5000] | Train Loss: 0.098896\n",
      "Validation AVG Loss:     0.000090 \n",
      "\n",
      "Epoch [2764/5000] | Train Loss: 0.098816\n",
      "Validation AVG Loss:     0.000090 \n",
      "\n",
      "Epoch [2765/5000] | Train Loss: 0.098737\n",
      "Validation AVG Loss:     0.000090 \n",
      "\n",
      "Epoch [2766/5000] | Train Loss: 0.098657\n",
      "Validation AVG Loss:     0.000090 \n",
      "\n",
      "Epoch [2767/5000] | Train Loss: 0.098578\n",
      "Validation AVG Loss:     0.000090 \n",
      "\n",
      "Epoch [2768/5000] | Train Loss: 0.098499\n",
      "Validation AVG Loss:     0.000090 \n",
      "\n",
      "Epoch [2769/5000] | Train Loss: 0.098419\n",
      "Validation AVG Loss:     0.000090 \n",
      "\n",
      "Epoch [2770/5000] | Train Loss: 0.098340\n",
      "Validation AVG Loss:     0.000090 \n",
      "\n",
      "Epoch [2771/5000] | Train Loss: 0.098261\n",
      "Validation AVG Loss:     0.000090 \n",
      "\n",
      "Epoch [2772/5000] | Train Loss: 0.098182\n",
      "Validation AVG Loss:     0.000090 \n",
      "\n",
      "Epoch [2773/5000] | Train Loss: 0.098102\n",
      "Validation AVG Loss:     0.000090 \n",
      "\n",
      "Epoch [2774/5000] | Train Loss: 0.098023\n",
      "Validation AVG Loss:     0.000090 \n",
      "\n",
      "Epoch [2775/5000] | Train Loss: 0.097944\n",
      "Validation AVG Loss:     0.000090 \n",
      "\n",
      "Epoch [2776/5000] | Train Loss: 0.097865\n",
      "Validation AVG Loss:     0.000089 \n",
      "\n",
      "Epoch [2777/5000] | Train Loss: 0.097786\n",
      "Validation AVG Loss:     0.000089 \n",
      "\n",
      "Epoch [2778/5000] | Train Loss: 0.097707\n",
      "Validation AVG Loss:     0.000089 \n",
      "\n",
      "Epoch [2779/5000] | Train Loss: 0.097628\n",
      "Validation AVG Loss:     0.000089 \n",
      "\n",
      "Epoch [2780/5000] | Train Loss: 0.097549\n",
      "Validation AVG Loss:     0.000089 \n",
      "\n",
      "Epoch [2781/5000] | Train Loss: 0.097470\n",
      "Validation AVG Loss:     0.000089 \n",
      "\n",
      "Epoch [2782/5000] | Train Loss: 0.097391\n",
      "Validation AVG Loss:     0.000089 \n",
      "\n",
      "Epoch [2783/5000] | Train Loss: 0.097312\n",
      "Validation AVG Loss:     0.000089 \n",
      "\n",
      "Epoch [2784/5000] | Train Loss: 0.097234\n",
      "Validation AVG Loss:     0.000089 \n",
      "\n",
      "Epoch [2785/5000] | Train Loss: 0.097155\n",
      "Validation AVG Loss:     0.000089 \n",
      "\n",
      "Epoch [2786/5000] | Train Loss: 0.097076\n",
      "Validation AVG Loss:     0.000089 \n",
      "\n",
      "Epoch [2787/5000] | Train Loss: 0.096997\n",
      "Validation AVG Loss:     0.000089 \n",
      "\n",
      "Epoch [2788/5000] | Train Loss: 0.096919\n",
      "Validation AVG Loss:     0.000089 \n",
      "\n",
      "Epoch [2789/5000] | Train Loss: 0.096840\n",
      "Validation AVG Loss:     0.000089 \n",
      "\n",
      "Epoch [2790/5000] | Train Loss: 0.096761\n",
      "Validation AVG Loss:     0.000088 \n",
      "\n",
      "Epoch [2791/5000] | Train Loss: 0.096683\n",
      "Validation AVG Loss:     0.000088 \n",
      "\n",
      "Epoch [2792/5000] | Train Loss: 0.096604\n",
      "Validation AVG Loss:     0.000088 \n",
      "\n",
      "Epoch [2793/5000] | Train Loss: 0.096526\n",
      "Validation AVG Loss:     0.000088 \n",
      "\n",
      "Epoch [2794/5000] | Train Loss: 0.096447\n",
      "Validation AVG Loss:     0.000088 \n",
      "\n",
      "Epoch [2795/5000] | Train Loss: 0.096369\n",
      "Validation AVG Loss:     0.000088 \n",
      "\n",
      "Epoch [2796/5000] | Train Loss: 0.096291\n",
      "Validation AVG Loss:     0.000088 \n",
      "\n",
      "Epoch [2797/5000] | Train Loss: 0.096212\n",
      "Validation AVG Loss:     0.000088 \n",
      "\n",
      "Epoch [2798/5000] | Train Loss: 0.096134\n",
      "Validation AVG Loss:     0.000088 \n",
      "\n",
      "Epoch [2799/5000] | Train Loss: 0.096056\n",
      "Validation AVG Loss:     0.000088 \n",
      "\n",
      "Epoch [2800/5000] | Train Loss: 0.095977\n",
      "Validation AVG Loss:     0.000088 \n",
      "\n",
      "Epoch [2801/5000] | Train Loss: 0.095899\n",
      "Validation AVG Loss:     0.000088 \n",
      "\n",
      "Epoch [2802/5000] | Train Loss: 0.095821\n",
      "Validation AVG Loss:     0.000088 \n",
      "\n",
      "Epoch [2803/5000] | Train Loss: 0.095743\n",
      "Validation AVG Loss:     0.000087 \n",
      "\n",
      "Epoch [2804/5000] | Train Loss: 0.095665\n",
      "Validation AVG Loss:     0.000087 \n",
      "\n",
      "Epoch [2805/5000] | Train Loss: 0.095587\n",
      "Validation AVG Loss:     0.000087 \n",
      "\n",
      "Epoch [2806/5000] | Train Loss: 0.095509\n",
      "Validation AVG Loss:     0.000087 \n",
      "\n",
      "Epoch [2807/5000] | Train Loss: 0.095431\n",
      "Validation AVG Loss:     0.000087 \n",
      "\n",
      "Epoch [2808/5000] | Train Loss: 0.095353\n",
      "Validation AVG Loss:     0.000087 \n",
      "\n",
      "Epoch [2809/5000] | Train Loss: 0.095275\n",
      "Validation AVG Loss:     0.000087 \n",
      "\n",
      "Epoch [2810/5000] | Train Loss: 0.095197\n",
      "Validation AVG Loss:     0.000087 \n",
      "\n",
      "Epoch [2811/5000] | Train Loss: 0.095119\n",
      "Validation AVG Loss:     0.000087 \n",
      "\n",
      "Epoch [2812/5000] | Train Loss: 0.095041\n",
      "Validation AVG Loss:     0.000087 \n",
      "\n",
      "Epoch [2813/5000] | Train Loss: 0.094963\n",
      "Validation AVG Loss:     0.000087 \n",
      "\n",
      "Epoch [2814/5000] | Train Loss: 0.094885\n",
      "Validation AVG Loss:     0.000087 \n",
      "\n",
      "Epoch [2815/5000] | Train Loss: 0.094808\n",
      "Validation AVG Loss:     0.000087 \n",
      "\n",
      "Epoch [2816/5000] | Train Loss: 0.094730\n",
      "Validation AVG Loss:     0.000087 \n",
      "\n",
      "Epoch [2817/5000] | Train Loss: 0.094652\n",
      "Validation AVG Loss:     0.000086 \n",
      "\n",
      "Epoch [2818/5000] | Train Loss: 0.094575\n",
      "Validation AVG Loss:     0.000086 \n",
      "\n",
      "Epoch [2819/5000] | Train Loss: 0.094497\n",
      "Validation AVG Loss:     0.000086 \n",
      "\n",
      "Epoch [2820/5000] | Train Loss: 0.094420\n",
      "Validation AVG Loss:     0.000086 \n",
      "\n",
      "Epoch [2821/5000] | Train Loss: 0.094342\n",
      "Validation AVG Loss:     0.000086 \n",
      "\n",
      "Epoch [2822/5000] | Train Loss: 0.094265\n",
      "Validation AVG Loss:     0.000086 \n",
      "\n",
      "Epoch [2823/5000] | Train Loss: 0.094187\n",
      "Validation AVG Loss:     0.000086 \n",
      "\n",
      "Epoch [2824/5000] | Train Loss: 0.094110\n",
      "Validation AVG Loss:     0.000086 \n",
      "\n",
      "Epoch [2825/5000] | Train Loss: 0.094032\n",
      "Validation AVG Loss:     0.000086 \n",
      "\n",
      "Epoch [2826/5000] | Train Loss: 0.093955\n",
      "Validation AVG Loss:     0.000086 \n",
      "\n",
      "Epoch [2827/5000] | Train Loss: 0.093878\n",
      "Validation AVG Loss:     0.000086 \n",
      "\n",
      "Epoch [2828/5000] | Train Loss: 0.093800\n",
      "Validation AVG Loss:     0.000086 \n",
      "\n",
      "Epoch [2829/5000] | Train Loss: 0.093723\n",
      "Validation AVG Loss:     0.000086 \n",
      "\n",
      "Epoch [2830/5000] | Train Loss: 0.093646\n",
      "Validation AVG Loss:     0.000085 \n",
      "\n",
      "Epoch [2831/5000] | Train Loss: 0.093569\n",
      "Validation AVG Loss:     0.000085 \n",
      "\n",
      "Epoch [2832/5000] | Train Loss: 0.093492\n",
      "Validation AVG Loss:     0.000085 \n",
      "\n",
      "Epoch [2833/5000] | Train Loss: 0.093414\n",
      "Validation AVG Loss:     0.000085 \n",
      "\n",
      "Epoch [2834/5000] | Train Loss: 0.093337\n",
      "Validation AVG Loss:     0.000085 \n",
      "\n",
      "Epoch [2835/5000] | Train Loss: 0.093260\n",
      "Validation AVG Loss:     0.000085 \n",
      "\n",
      "Epoch [2836/5000] | Train Loss: 0.093183\n",
      "Validation AVG Loss:     0.000085 \n",
      "\n",
      "Epoch [2837/5000] | Train Loss: 0.093106\n",
      "Validation AVG Loss:     0.000085 \n",
      "\n",
      "Epoch [2838/5000] | Train Loss: 0.093029\n",
      "Validation AVG Loss:     0.000085 \n",
      "\n",
      "Epoch [2839/5000] | Train Loss: 0.092952\n",
      "Validation AVG Loss:     0.000085 \n",
      "\n",
      "Epoch [2840/5000] | Train Loss: 0.092876\n",
      "Validation AVG Loss:     0.000085 \n",
      "\n",
      "Epoch [2841/5000] | Train Loss: 0.092799\n",
      "Validation AVG Loss:     0.000085 \n",
      "\n",
      "Epoch [2842/5000] | Train Loss: 0.092722\n",
      "Validation AVG Loss:     0.000085 \n",
      "\n",
      "Epoch [2843/5000] | Train Loss: 0.092645\n",
      "Validation AVG Loss:     0.000085 \n",
      "\n",
      "Epoch [2844/5000] | Train Loss: 0.092569\n",
      "Validation AVG Loss:     0.000084 \n",
      "\n",
      "Epoch [2845/5000] | Train Loss: 0.092492\n",
      "Validation AVG Loss:     0.000084 \n",
      "\n",
      "Epoch [2846/5000] | Train Loss: 0.092415\n",
      "Validation AVG Loss:     0.000084 \n",
      "\n",
      "Epoch [2847/5000] | Train Loss: 0.092339\n",
      "Validation AVG Loss:     0.000084 \n",
      "\n",
      "Epoch [2848/5000] | Train Loss: 0.092262\n",
      "Validation AVG Loss:     0.000084 \n",
      "\n",
      "Epoch [2849/5000] | Train Loss: 0.092185\n",
      "Validation AVG Loss:     0.000084 \n",
      "\n",
      "Epoch [2850/5000] | Train Loss: 0.092109\n",
      "Validation AVG Loss:     0.000084 \n",
      "\n",
      "Epoch [2851/5000] | Train Loss: 0.092032\n",
      "Validation AVG Loss:     0.000084 \n",
      "\n",
      "Epoch [2852/5000] | Train Loss: 0.091956\n",
      "Validation AVG Loss:     0.000084 \n",
      "\n",
      "Epoch [2853/5000] | Train Loss: 0.091880\n",
      "Validation AVG Loss:     0.000084 \n",
      "\n",
      "Epoch [2854/5000] | Train Loss: 0.091803\n",
      "Validation AVG Loss:     0.000084 \n",
      "\n",
      "Epoch [2855/5000] | Train Loss: 0.091727\n",
      "Validation AVG Loss:     0.000084 \n",
      "\n",
      "Epoch [2856/5000] | Train Loss: 0.091651\n",
      "Validation AVG Loss:     0.000084 \n",
      "\n",
      "Epoch [2857/5000] | Train Loss: 0.091574\n",
      "Validation AVG Loss:     0.000084 \n",
      "\n",
      "Epoch [2858/5000] | Train Loss: 0.091498\n",
      "Validation AVG Loss:     0.000083 \n",
      "\n",
      "Epoch [2859/5000] | Train Loss: 0.091422\n",
      "Validation AVG Loss:     0.000083 \n",
      "\n",
      "Epoch [2860/5000] | Train Loss: 0.091346\n",
      "Validation AVG Loss:     0.000083 \n",
      "\n",
      "Epoch [2861/5000] | Train Loss: 0.091270\n",
      "Validation AVG Loss:     0.000083 \n",
      "\n",
      "Epoch [2862/5000] | Train Loss: 0.091194\n",
      "Validation AVG Loss:     0.000083 \n",
      "\n",
      "Epoch [2863/5000] | Train Loss: 0.091117\n",
      "Validation AVG Loss:     0.000083 \n",
      "\n",
      "Epoch [2864/5000] | Train Loss: 0.091041\n",
      "Validation AVG Loss:     0.000083 \n",
      "\n",
      "Epoch [2865/5000] | Train Loss: 0.090965\n",
      "Validation AVG Loss:     0.000083 \n",
      "\n",
      "Epoch [2866/5000] | Train Loss: 0.090890\n",
      "Validation AVG Loss:     0.000083 \n",
      "\n",
      "Epoch [2867/5000] | Train Loss: 0.090814\n",
      "Validation AVG Loss:     0.000083 \n",
      "\n",
      "Epoch [2868/5000] | Train Loss: 0.090738\n",
      "Validation AVG Loss:     0.000083 \n",
      "\n",
      "Epoch [2869/5000] | Train Loss: 0.090662\n",
      "Validation AVG Loss:     0.000083 \n",
      "\n",
      "Epoch [2870/5000] | Train Loss: 0.090586\n",
      "Validation AVG Loss:     0.000083 \n",
      "\n",
      "Epoch [2871/5000] | Train Loss: 0.090510\n",
      "Validation AVG Loss:     0.000083 \n",
      "\n",
      "Epoch [2872/5000] | Train Loss: 0.090435\n",
      "Validation AVG Loss:     0.000082 \n",
      "\n",
      "Epoch [2873/5000] | Train Loss: 0.090359\n",
      "Validation AVG Loss:     0.000082 \n",
      "\n",
      "Epoch [2874/5000] | Train Loss: 0.090283\n",
      "Validation AVG Loss:     0.000082 \n",
      "\n",
      "Epoch [2875/5000] | Train Loss: 0.090208\n",
      "Validation AVG Loss:     0.000082 \n",
      "\n",
      "Epoch [2876/5000] | Train Loss: 0.090132\n",
      "Validation AVG Loss:     0.000082 \n",
      "\n",
      "Epoch [2877/5000] | Train Loss: 0.090057\n",
      "Validation AVG Loss:     0.000082 \n",
      "\n",
      "Epoch [2878/5000] | Train Loss: 0.089981\n",
      "Validation AVG Loss:     0.000082 \n",
      "\n",
      "Epoch [2879/5000] | Train Loss: 0.089906\n",
      "Validation AVG Loss:     0.000082 \n",
      "\n",
      "Epoch [2880/5000] | Train Loss: 0.089830\n",
      "Validation AVG Loss:     0.000082 \n",
      "\n",
      "Epoch [2881/5000] | Train Loss: 0.089755\n",
      "Validation AVG Loss:     0.000082 \n",
      "\n",
      "Epoch [2882/5000] | Train Loss: 0.089679\n",
      "Validation AVG Loss:     0.000082 \n",
      "\n",
      "Epoch [2883/5000] | Train Loss: 0.089604\n",
      "Validation AVG Loss:     0.000082 \n",
      "\n",
      "Epoch [2884/5000] | Train Loss: 0.089529\n",
      "Validation AVG Loss:     0.000082 \n",
      "\n",
      "Epoch [2885/5000] | Train Loss: 0.089454\n",
      "Validation AVG Loss:     0.000082 \n",
      "\n",
      "Epoch [2886/5000] | Train Loss: 0.089378\n",
      "Validation AVG Loss:     0.000081 \n",
      "\n",
      "Epoch [2887/5000] | Train Loss: 0.089303\n",
      "Validation AVG Loss:     0.000081 \n",
      "\n",
      "Epoch [2888/5000] | Train Loss: 0.089228\n",
      "Validation AVG Loss:     0.000081 \n",
      "\n",
      "Epoch [2889/5000] | Train Loss: 0.089153\n",
      "Validation AVG Loss:     0.000081 \n",
      "\n",
      "Epoch [2890/5000] | Train Loss: 0.089078\n",
      "Validation AVG Loss:     0.000081 \n",
      "\n",
      "Epoch [2891/5000] | Train Loss: 0.089003\n",
      "Validation AVG Loss:     0.000081 \n",
      "\n",
      "Epoch [2892/5000] | Train Loss: 0.088928\n",
      "Validation AVG Loss:     0.000081 \n",
      "\n",
      "Epoch [2893/5000] | Train Loss: 0.088853\n",
      "Validation AVG Loss:     0.000081 \n",
      "\n",
      "Epoch [2894/5000] | Train Loss: 0.088778\n",
      "Validation AVG Loss:     0.000081 \n",
      "\n",
      "Epoch [2895/5000] | Train Loss: 0.088703\n",
      "Validation AVG Loss:     0.000081 \n",
      "\n",
      "Epoch [2896/5000] | Train Loss: 0.088628\n",
      "Validation AVG Loss:     0.000081 \n",
      "\n",
      "Epoch [2897/5000] | Train Loss: 0.088553\n",
      "Validation AVG Loss:     0.000081 \n",
      "\n",
      "Epoch [2898/5000] | Train Loss: 0.088479\n",
      "Validation AVG Loss:     0.000081 \n",
      "\n",
      "Epoch [2899/5000] | Train Loss: 0.088404\n",
      "Validation AVG Loss:     0.000081 \n",
      "\n",
      "Epoch [2900/5000] | Train Loss: 0.088329\n",
      "Validation AVG Loss:     0.000080 \n",
      "\n",
      "Epoch [2901/5000] | Train Loss: 0.088255\n",
      "Validation AVG Loss:     0.000080 \n",
      "\n",
      "Epoch [2902/5000] | Train Loss: 0.088180\n",
      "Validation AVG Loss:     0.000080 \n",
      "\n",
      "Epoch [2903/5000] | Train Loss: 0.088105\n",
      "Validation AVG Loss:     0.000080 \n",
      "\n",
      "Epoch [2904/5000] | Train Loss: 0.088031\n",
      "Validation AVG Loss:     0.000080 \n",
      "\n",
      "Epoch [2905/5000] | Train Loss: 0.087956\n",
      "Validation AVG Loss:     0.000080 \n",
      "\n",
      "Epoch [2906/5000] | Train Loss: 0.087882\n",
      "Validation AVG Loss:     0.000080 \n",
      "\n",
      "Epoch [2907/5000] | Train Loss: 0.087807\n",
      "Validation AVG Loss:     0.000080 \n",
      "\n",
      "Epoch [2908/5000] | Train Loss: 0.087733\n",
      "Validation AVG Loss:     0.000080 \n",
      "\n",
      "Epoch [2909/5000] | Train Loss: 0.087659\n",
      "Validation AVG Loss:     0.000080 \n",
      "\n",
      "Epoch [2910/5000] | Train Loss: 0.087584\n",
      "Validation AVG Loss:     0.000080 \n",
      "\n",
      "Epoch [2911/5000] | Train Loss: 0.087510\n",
      "Validation AVG Loss:     0.000080 \n",
      "\n",
      "Epoch [2912/5000] | Train Loss: 0.087436\n",
      "Validation AVG Loss:     0.000080 \n",
      "\n",
      "Epoch [2913/5000] | Train Loss: 0.087362\n",
      "Validation AVG Loss:     0.000080 \n",
      "\n",
      "Epoch [2914/5000] | Train Loss: 0.087287\n",
      "Validation AVG Loss:     0.000080 \n",
      "\n",
      "Epoch [2915/5000] | Train Loss: 0.087213\n",
      "Validation AVG Loss:     0.000079 \n",
      "\n",
      "Epoch [2916/5000] | Train Loss: 0.087139\n",
      "Validation AVG Loss:     0.000079 \n",
      "\n",
      "Epoch [2917/5000] | Train Loss: 0.087065\n",
      "Validation AVG Loss:     0.000079 \n",
      "\n",
      "Epoch [2918/5000] | Train Loss: 0.086991\n",
      "Validation AVG Loss:     0.000079 \n",
      "\n",
      "Epoch [2919/5000] | Train Loss: 0.086917\n",
      "Validation AVG Loss:     0.000079 \n",
      "\n",
      "Epoch [2920/5000] | Train Loss: 0.086843\n",
      "Validation AVG Loss:     0.000079 \n",
      "\n",
      "Epoch [2921/5000] | Train Loss: 0.086769\n",
      "Validation AVG Loss:     0.000079 \n",
      "\n",
      "Epoch [2922/5000] | Train Loss: 0.086695\n",
      "Validation AVG Loss:     0.000079 \n",
      "\n",
      "Epoch [2923/5000] | Train Loss: 0.086621\n",
      "Validation AVG Loss:     0.000079 \n",
      "\n",
      "Epoch [2924/5000] | Train Loss: 0.086548\n",
      "Validation AVG Loss:     0.000079 \n",
      "\n",
      "Epoch [2925/5000] | Train Loss: 0.086474\n",
      "Validation AVG Loss:     0.000079 \n",
      "\n",
      "Epoch [2926/5000] | Train Loss: 0.086400\n",
      "Validation AVG Loss:     0.000079 \n",
      "\n",
      "Epoch [2927/5000] | Train Loss: 0.086326\n",
      "Validation AVG Loss:     0.000079 \n",
      "\n",
      "Epoch [2928/5000] | Train Loss: 0.086253\n",
      "Validation AVG Loss:     0.000079 \n",
      "\n",
      "Epoch [2929/5000] | Train Loss: 0.086179\n",
      "Validation AVG Loss:     0.000078 \n",
      "\n",
      "Epoch [2930/5000] | Train Loss: 0.086106\n",
      "Validation AVG Loss:     0.000078 \n",
      "\n",
      "Epoch [2931/5000] | Train Loss: 0.086032\n",
      "Validation AVG Loss:     0.000078 \n",
      "\n",
      "Epoch [2932/5000] | Train Loss: 0.085958\n",
      "Validation AVG Loss:     0.000078 \n",
      "\n",
      "Epoch [2933/5000] | Train Loss: 0.085885\n",
      "Validation AVG Loss:     0.000078 \n",
      "\n",
      "Epoch [2934/5000] | Train Loss: 0.085812\n",
      "Validation AVG Loss:     0.000078 \n",
      "\n",
      "Epoch [2935/5000] | Train Loss: 0.085738\n",
      "Validation AVG Loss:     0.000078 \n",
      "\n",
      "Epoch [2936/5000] | Train Loss: 0.085665\n",
      "Validation AVG Loss:     0.000078 \n",
      "\n",
      "Epoch [2937/5000] | Train Loss: 0.085591\n",
      "Validation AVG Loss:     0.000078 \n",
      "\n",
      "Epoch [2938/5000] | Train Loss: 0.085518\n",
      "Validation AVG Loss:     0.000078 \n",
      "\n",
      "Epoch [2939/5000] | Train Loss: 0.085445\n",
      "Validation AVG Loss:     0.000078 \n",
      "\n",
      "Epoch [2940/5000] | Train Loss: 0.085372\n",
      "Validation AVG Loss:     0.000078 \n",
      "\n",
      "Epoch [2941/5000] | Train Loss: 0.085299\n",
      "Validation AVG Loss:     0.000078 \n",
      "\n",
      "Epoch [2942/5000] | Train Loss: 0.085225\n",
      "Validation AVG Loss:     0.000078 \n",
      "\n",
      "Epoch [2943/5000] | Train Loss: 0.085152\n",
      "Validation AVG Loss:     0.000077 \n",
      "\n",
      "Epoch [2944/5000] | Train Loss: 0.085079\n",
      "Validation AVG Loss:     0.000077 \n",
      "\n",
      "Epoch [2945/5000] | Train Loss: 0.085006\n",
      "Validation AVG Loss:     0.000077 \n",
      "\n",
      "Epoch [2946/5000] | Train Loss: 0.084933\n",
      "Validation AVG Loss:     0.000077 \n",
      "\n",
      "Epoch [2947/5000] | Train Loss: 0.084860\n",
      "Validation AVG Loss:     0.000077 \n",
      "\n",
      "Epoch [2948/5000] | Train Loss: 0.084788\n",
      "Validation AVG Loss:     0.000077 \n",
      "\n",
      "Epoch [2949/5000] | Train Loss: 0.084715\n",
      "Validation AVG Loss:     0.000077 \n",
      "\n",
      "Epoch [2950/5000] | Train Loss: 0.084642\n",
      "Validation AVG Loss:     0.000077 \n",
      "\n",
      "Epoch [2951/5000] | Train Loss: 0.084569\n",
      "Validation AVG Loss:     0.000077 \n",
      "\n",
      "Epoch [2952/5000] | Train Loss: 0.084496\n",
      "Validation AVG Loss:     0.000077 \n",
      "\n",
      "Epoch [2953/5000] | Train Loss: 0.084424\n",
      "Validation AVG Loss:     0.000077 \n",
      "\n",
      "Epoch [2954/5000] | Train Loss: 0.084351\n",
      "Validation AVG Loss:     0.000077 \n",
      "\n",
      "Epoch [2955/5000] | Train Loss: 0.084278\n",
      "Validation AVG Loss:     0.000077 \n",
      "\n",
      "Epoch [2956/5000] | Train Loss: 0.084206\n",
      "Validation AVG Loss:     0.000077 \n",
      "\n",
      "Epoch [2957/5000] | Train Loss: 0.084133\n",
      "Validation AVG Loss:     0.000077 \n",
      "\n",
      "Epoch [2958/5000] | Train Loss: 0.084061\n",
      "Validation AVG Loss:     0.000076 \n",
      "\n",
      "Epoch [2959/5000] | Train Loss: 0.083988\n",
      "Validation AVG Loss:     0.000076 \n",
      "\n",
      "Epoch [2960/5000] | Train Loss: 0.083916\n",
      "Validation AVG Loss:     0.000076 \n",
      "\n",
      "Epoch [2961/5000] | Train Loss: 0.083843\n",
      "Validation AVG Loss:     0.000076 \n",
      "\n",
      "Epoch [2962/5000] | Train Loss: 0.083771\n",
      "Validation AVG Loss:     0.000076 \n",
      "\n",
      "Epoch [2963/5000] | Train Loss: 0.083699\n",
      "Validation AVG Loss:     0.000076 \n",
      "\n",
      "Epoch [2964/5000] | Train Loss: 0.083627\n",
      "Validation AVG Loss:     0.000076 \n",
      "\n",
      "Epoch [2965/5000] | Train Loss: 0.083554\n",
      "Validation AVG Loss:     0.000076 \n",
      "\n",
      "Epoch [2966/5000] | Train Loss: 0.083482\n",
      "Validation AVG Loss:     0.000076 \n",
      "\n",
      "Epoch [2967/5000] | Train Loss: 0.083410\n",
      "Validation AVG Loss:     0.000076 \n",
      "\n",
      "Epoch [2968/5000] | Train Loss: 0.083338\n",
      "Validation AVG Loss:     0.000076 \n",
      "\n",
      "Epoch [2969/5000] | Train Loss: 0.083266\n",
      "Validation AVG Loss:     0.000076 \n",
      "\n",
      "Epoch [2970/5000] | Train Loss: 0.083194\n",
      "Validation AVG Loss:     0.000076 \n",
      "\n",
      "Epoch [2971/5000] | Train Loss: 0.083122\n",
      "Validation AVG Loss:     0.000076 \n",
      "\n",
      "Epoch [2972/5000] | Train Loss: 0.083050\n",
      "Validation AVG Loss:     0.000076 \n",
      "\n",
      "Epoch [2973/5000] | Train Loss: 0.082978\n",
      "Validation AVG Loss:     0.000075 \n",
      "\n",
      "Epoch [2974/5000] | Train Loss: 0.082906\n",
      "Validation AVG Loss:     0.000075 \n",
      "\n",
      "Epoch [2975/5000] | Train Loss: 0.082834\n",
      "Validation AVG Loss:     0.000075 \n",
      "\n",
      "Epoch [2976/5000] | Train Loss: 0.082762\n",
      "Validation AVG Loss:     0.000075 \n",
      "\n",
      "Epoch [2977/5000] | Train Loss: 0.082690\n",
      "Validation AVG Loss:     0.000075 \n",
      "\n",
      "Epoch [2978/5000] | Train Loss: 0.082619\n",
      "Validation AVG Loss:     0.000075 \n",
      "\n",
      "Epoch [2979/5000] | Train Loss: 0.082547\n",
      "Validation AVG Loss:     0.000075 \n",
      "\n",
      "Epoch [2980/5000] | Train Loss: 0.082475\n",
      "Validation AVG Loss:     0.000075 \n",
      "\n",
      "Epoch [2981/5000] | Train Loss: 0.082403\n",
      "Validation AVG Loss:     0.000075 \n",
      "\n",
      "Epoch [2982/5000] | Train Loss: 0.082332\n",
      "Validation AVG Loss:     0.000075 \n",
      "\n",
      "Epoch [2983/5000] | Train Loss: 0.082260\n",
      "Validation AVG Loss:     0.000075 \n",
      "\n",
      "Epoch [2984/5000] | Train Loss: 0.082189\n",
      "Validation AVG Loss:     0.000075 \n",
      "\n",
      "Epoch [2985/5000] | Train Loss: 0.082117\n",
      "Validation AVG Loss:     0.000075 \n",
      "\n",
      "Epoch [2986/5000] | Train Loss: 0.082046\n",
      "Validation AVG Loss:     0.000075 \n",
      "\n",
      "Epoch [2987/5000] | Train Loss: 0.081974\n",
      "Validation AVG Loss:     0.000074 \n",
      "\n",
      "Epoch [2988/5000] | Train Loss: 0.081903\n",
      "Validation AVG Loss:     0.000074 \n",
      "\n",
      "Epoch [2989/5000] | Train Loss: 0.081832\n",
      "Validation AVG Loss:     0.000074 \n",
      "\n",
      "Epoch [2990/5000] | Train Loss: 0.081761\n",
      "Validation AVG Loss:     0.000074 \n",
      "\n",
      "Epoch [2991/5000] | Train Loss: 0.081689\n",
      "Validation AVG Loss:     0.000074 \n",
      "\n",
      "Epoch [2992/5000] | Train Loss: 0.081618\n",
      "Validation AVG Loss:     0.000074 \n",
      "\n",
      "Epoch [2993/5000] | Train Loss: 0.081547\n",
      "Validation AVG Loss:     0.000074 \n",
      "\n",
      "Epoch [2994/5000] | Train Loss: 0.081476\n",
      "Validation AVG Loss:     0.000074 \n",
      "\n",
      "Epoch [2995/5000] | Train Loss: 0.081405\n",
      "Validation AVG Loss:     0.000074 \n",
      "\n",
      "Epoch [2996/5000] | Train Loss: 0.081334\n",
      "Validation AVG Loss:     0.000074 \n",
      "\n",
      "Epoch [2997/5000] | Train Loss: 0.081263\n",
      "Validation AVG Loss:     0.000074 \n",
      "\n",
      "Epoch [2998/5000] | Train Loss: 0.081192\n",
      "Validation AVG Loss:     0.000074 \n",
      "\n",
      "Epoch [2999/5000] | Train Loss: 0.081121\n",
      "Validation AVG Loss:     0.000074 \n",
      "\n",
      "Epoch [3000/5000] | Train Loss: 0.081050\n",
      "Validation AVG Loss:     0.000074 \n",
      "\n",
      "Epoch [3001/5000] | Train Loss: 0.080979\n",
      "Validation AVG Loss:     0.000074 \n",
      "\n",
      "Epoch [3002/5000] | Train Loss: 0.080908\n",
      "Validation AVG Loss:     0.000073 \n",
      "\n",
      "Epoch [3003/5000] | Train Loss: 0.080837\n",
      "Validation AVG Loss:     0.000073 \n",
      "\n",
      "Epoch [3004/5000] | Train Loss: 0.080767\n",
      "Validation AVG Loss:     0.000073 \n",
      "\n",
      "Epoch [3005/5000] | Train Loss: 0.080696\n",
      "Validation AVG Loss:     0.000073 \n",
      "\n",
      "Epoch [3006/5000] | Train Loss: 0.080625\n",
      "Validation AVG Loss:     0.000073 \n",
      "\n",
      "Epoch [3007/5000] | Train Loss: 0.080555\n",
      "Validation AVG Loss:     0.000073 \n",
      "\n",
      "Epoch [3008/5000] | Train Loss: 0.080484\n",
      "Validation AVG Loss:     0.000073 \n",
      "\n",
      "Epoch [3009/5000] | Train Loss: 0.080414\n",
      "Validation AVG Loss:     0.000073 \n",
      "\n",
      "Epoch [3010/5000] | Train Loss: 0.080343\n",
      "Validation AVG Loss:     0.000073 \n",
      "\n",
      "Epoch [3011/5000] | Train Loss: 0.080273\n",
      "Validation AVG Loss:     0.000073 \n",
      "\n",
      "Epoch [3012/5000] | Train Loss: 0.080202\n",
      "Validation AVG Loss:     0.000073 \n",
      "\n",
      "Epoch [3013/5000] | Train Loss: 0.080132\n",
      "Validation AVG Loss:     0.000073 \n",
      "\n",
      "Epoch [3014/5000] | Train Loss: 0.080062\n",
      "Validation AVG Loss:     0.000073 \n",
      "\n",
      "Epoch [3015/5000] | Train Loss: 0.079991\n",
      "Validation AVG Loss:     0.000073 \n",
      "\n",
      "Epoch [3016/5000] | Train Loss: 0.079921\n",
      "Validation AVG Loss:     0.000073 \n",
      "\n",
      "Epoch [3017/5000] | Train Loss: 0.079851\n",
      "Validation AVG Loss:     0.000073 \n",
      "\n",
      "Epoch [3018/5000] | Train Loss: 0.079781\n",
      "Validation AVG Loss:     0.000072 \n",
      "\n",
      "Epoch [3019/5000] | Train Loss: 0.079711\n",
      "Validation AVG Loss:     0.000072 \n",
      "\n",
      "Epoch [3020/5000] | Train Loss: 0.079640\n",
      "Validation AVG Loss:     0.000072 \n",
      "\n",
      "Epoch [3021/5000] | Train Loss: 0.079570\n",
      "Validation AVG Loss:     0.000072 \n",
      "\n",
      "Epoch [3022/5000] | Train Loss: 0.079500\n",
      "Validation AVG Loss:     0.000072 \n",
      "\n",
      "Epoch [3023/5000] | Train Loss: 0.079430\n",
      "Validation AVG Loss:     0.000072 \n",
      "\n",
      "Epoch [3024/5000] | Train Loss: 0.079360\n",
      "Validation AVG Loss:     0.000072 \n",
      "\n",
      "Epoch [3025/5000] | Train Loss: 0.079291\n",
      "Validation AVG Loss:     0.000072 \n",
      "\n",
      "Epoch [3026/5000] | Train Loss: 0.079221\n",
      "Validation AVG Loss:     0.000072 \n",
      "\n",
      "Epoch [3027/5000] | Train Loss: 0.079151\n",
      "Validation AVG Loss:     0.000072 \n",
      "\n",
      "Epoch [3028/5000] | Train Loss: 0.079081\n",
      "Validation AVG Loss:     0.000072 \n",
      "\n",
      "Epoch [3029/5000] | Train Loss: 0.079011\n",
      "Validation AVG Loss:     0.000072 \n",
      "\n",
      "Epoch [3030/5000] | Train Loss: 0.078942\n",
      "Validation AVG Loss:     0.000072 \n",
      "\n",
      "Epoch [3031/5000] | Train Loss: 0.078872\n",
      "Validation AVG Loss:     0.000072 \n",
      "\n",
      "Epoch [3032/5000] | Train Loss: 0.078802\n",
      "Validation AVG Loss:     0.000072 \n",
      "\n",
      "Epoch [3033/5000] | Train Loss: 0.078733\n",
      "Validation AVG Loss:     0.000071 \n",
      "\n",
      "Epoch [3034/5000] | Train Loss: 0.078663\n",
      "Validation AVG Loss:     0.000071 \n",
      "\n",
      "Epoch [3035/5000] | Train Loss: 0.078594\n",
      "Validation AVG Loss:     0.000071 \n",
      "\n",
      "Epoch [3036/5000] | Train Loss: 0.078524\n",
      "Validation AVG Loss:     0.000071 \n",
      "\n",
      "Epoch [3037/5000] | Train Loss: 0.078455\n",
      "Validation AVG Loss:     0.000071 \n",
      "\n",
      "Epoch [3038/5000] | Train Loss: 0.078385\n",
      "Validation AVG Loss:     0.000071 \n",
      "\n",
      "Epoch [3039/5000] | Train Loss: 0.078316\n",
      "Validation AVG Loss:     0.000071 \n",
      "\n",
      "Epoch [3040/5000] | Train Loss: 0.078247\n",
      "Validation AVG Loss:     0.000071 \n",
      "\n",
      "Epoch [3041/5000] | Train Loss: 0.078177\n",
      "Validation AVG Loss:     0.000071 \n",
      "\n",
      "Epoch [3042/5000] | Train Loss: 0.078108\n",
      "Validation AVG Loss:     0.000071 \n",
      "\n",
      "Epoch [3043/5000] | Train Loss: 0.078039\n",
      "Validation AVG Loss:     0.000071 \n",
      "\n",
      "Epoch [3044/5000] | Train Loss: 0.077970\n",
      "Validation AVG Loss:     0.000071 \n",
      "\n",
      "Epoch [3045/5000] | Train Loss: 0.077901\n",
      "Validation AVG Loss:     0.000071 \n",
      "\n",
      "Epoch [3046/5000] | Train Loss: 0.077832\n",
      "Validation AVG Loss:     0.000071 \n",
      "\n",
      "Epoch [3047/5000] | Train Loss: 0.077763\n",
      "Validation AVG Loss:     0.000071 \n",
      "\n",
      "Epoch [3048/5000] | Train Loss: 0.077694\n",
      "Validation AVG Loss:     0.000070 \n",
      "\n",
      "Epoch [3049/5000] | Train Loss: 0.077625\n",
      "Validation AVG Loss:     0.000070 \n",
      "\n",
      "Epoch [3050/5000] | Train Loss: 0.077556\n",
      "Validation AVG Loss:     0.000070 \n",
      "\n",
      "Epoch [3051/5000] | Train Loss: 0.077487\n",
      "Validation AVG Loss:     0.000070 \n",
      "\n",
      "Epoch [3052/5000] | Train Loss: 0.077418\n",
      "Validation AVG Loss:     0.000070 \n",
      "\n",
      "Epoch [3053/5000] | Train Loss: 0.077349\n",
      "Validation AVG Loss:     0.000070 \n",
      "\n",
      "Epoch [3054/5000] | Train Loss: 0.077280\n",
      "Validation AVG Loss:     0.000070 \n",
      "\n",
      "Epoch [3055/5000] | Train Loss: 0.077212\n",
      "Validation AVG Loss:     0.000070 \n",
      "\n",
      "Epoch [3056/5000] | Train Loss: 0.077143\n",
      "Validation AVG Loss:     0.000070 \n",
      "\n",
      "Epoch [3057/5000] | Train Loss: 0.077074\n",
      "Validation AVG Loss:     0.000070 \n",
      "\n",
      "Epoch [3058/5000] | Train Loss: 0.077006\n",
      "Validation AVG Loss:     0.000070 \n",
      "\n",
      "Epoch [3059/5000] | Train Loss: 0.076937\n",
      "Validation AVG Loss:     0.000070 \n",
      "\n",
      "Epoch [3060/5000] | Train Loss: 0.076869\n",
      "Validation AVG Loss:     0.000070 \n",
      "\n",
      "Epoch [3061/5000] | Train Loss: 0.076800\n",
      "Validation AVG Loss:     0.000070 \n",
      "\n",
      "Epoch [3062/5000] | Train Loss: 0.076732\n",
      "Validation AVG Loss:     0.000070 \n",
      "\n",
      "Epoch [3063/5000] | Train Loss: 0.076663\n",
      "Validation AVG Loss:     0.000070 \n",
      "\n",
      "Epoch [3064/5000] | Train Loss: 0.076595\n",
      "Validation AVG Loss:     0.000069 \n",
      "\n",
      "Epoch [3065/5000] | Train Loss: 0.076527\n",
      "Validation AVG Loss:     0.000069 \n",
      "\n",
      "Epoch [3066/5000] | Train Loss: 0.076459\n",
      "Validation AVG Loss:     0.000069 \n",
      "\n",
      "Epoch [3067/5000] | Train Loss: 0.076390\n",
      "Validation AVG Loss:     0.000069 \n",
      "\n",
      "Epoch [3068/5000] | Train Loss: 0.076322\n",
      "Validation AVG Loss:     0.000069 \n",
      "\n",
      "Epoch [3069/5000] | Train Loss: 0.076254\n",
      "Validation AVG Loss:     0.000069 \n",
      "\n",
      "Epoch [3070/5000] | Train Loss: 0.076186\n",
      "Validation AVG Loss:     0.000069 \n",
      "\n",
      "Epoch [3071/5000] | Train Loss: 0.076118\n",
      "Validation AVG Loss:     0.000069 \n",
      "\n",
      "Epoch [3072/5000] | Train Loss: 0.076050\n",
      "Validation AVG Loss:     0.000069 \n",
      "\n",
      "Epoch [3073/5000] | Train Loss: 0.075982\n",
      "Validation AVG Loss:     0.000069 \n",
      "\n",
      "Epoch [3074/5000] | Train Loss: 0.075914\n",
      "Validation AVG Loss:     0.000069 \n",
      "\n",
      "Epoch [3075/5000] | Train Loss: 0.075846\n",
      "Validation AVG Loss:     0.000069 \n",
      "\n",
      "Epoch [3076/5000] | Train Loss: 0.075778\n",
      "Validation AVG Loss:     0.000069 \n",
      "\n",
      "Epoch [3077/5000] | Train Loss: 0.075710\n",
      "Validation AVG Loss:     0.000069 \n",
      "\n",
      "Epoch [3078/5000] | Train Loss: 0.075642\n",
      "Validation AVG Loss:     0.000069 \n",
      "\n",
      "Epoch [3079/5000] | Train Loss: 0.075575\n",
      "Validation AVG Loss:     0.000068 \n",
      "\n",
      "Epoch [3080/5000] | Train Loss: 0.075507\n",
      "Validation AVG Loss:     0.000068 \n",
      "\n",
      "Epoch [3081/5000] | Train Loss: 0.075439\n",
      "Validation AVG Loss:     0.000068 \n",
      "\n",
      "Epoch [3082/5000] | Train Loss: 0.075372\n",
      "Validation AVG Loss:     0.000068 \n",
      "\n",
      "Epoch [3083/5000] | Train Loss: 0.075304\n",
      "Validation AVG Loss:     0.000068 \n",
      "\n",
      "Epoch [3084/5000] | Train Loss: 0.075236\n",
      "Validation AVG Loss:     0.000068 \n",
      "\n",
      "Epoch [3085/5000] | Train Loss: 0.075169\n",
      "Validation AVG Loss:     0.000068 \n",
      "\n",
      "Epoch [3086/5000] | Train Loss: 0.075101\n",
      "Validation AVG Loss:     0.000068 \n",
      "\n",
      "Epoch [3087/5000] | Train Loss: 0.075034\n",
      "Validation AVG Loss:     0.000068 \n",
      "\n",
      "Epoch [3088/5000] | Train Loss: 0.074967\n",
      "Validation AVG Loss:     0.000068 \n",
      "\n",
      "Epoch [3089/5000] | Train Loss: 0.074899\n",
      "Validation AVG Loss:     0.000068 \n",
      "\n",
      "Epoch [3090/5000] | Train Loss: 0.074832\n",
      "Validation AVG Loss:     0.000068 \n",
      "\n",
      "Epoch [3091/5000] | Train Loss: 0.074765\n",
      "Validation AVG Loss:     0.000068 \n",
      "\n",
      "Epoch [3092/5000] | Train Loss: 0.074697\n",
      "Validation AVG Loss:     0.000068 \n",
      "\n",
      "Epoch [3093/5000] | Train Loss: 0.074630\n",
      "Validation AVG Loss:     0.000068 \n",
      "\n",
      "Epoch [3094/5000] | Train Loss: 0.074563\n",
      "Validation AVG Loss:     0.000068 \n",
      "\n",
      "Epoch [3095/5000] | Train Loss: 0.074496\n",
      "Validation AVG Loss:     0.000067 \n",
      "\n",
      "Epoch [3096/5000] | Train Loss: 0.074429\n",
      "Validation AVG Loss:     0.000067 \n",
      "\n",
      "Epoch [3097/5000] | Train Loss: 0.074362\n",
      "Validation AVG Loss:     0.000067 \n",
      "\n",
      "Epoch [3098/5000] | Train Loss: 0.074295\n",
      "Validation AVG Loss:     0.000067 \n",
      "\n",
      "Epoch [3099/5000] | Train Loss: 0.074228\n",
      "Validation AVG Loss:     0.000067 \n",
      "\n",
      "Epoch [3100/5000] | Train Loss: 0.074161\n",
      "Validation AVG Loss:     0.000067 \n",
      "\n",
      "Epoch [3101/5000] | Train Loss: 0.074094\n",
      "Validation AVG Loss:     0.000067 \n",
      "\n",
      "Epoch [3102/5000] | Train Loss: 0.074027\n",
      "Validation AVG Loss:     0.000067 \n",
      "\n",
      "Epoch [3103/5000] | Train Loss: 0.073960\n",
      "Validation AVG Loss:     0.000067 \n",
      "\n",
      "Epoch [3104/5000] | Train Loss: 0.073894\n",
      "Validation AVG Loss:     0.000067 \n",
      "\n",
      "Epoch [3105/5000] | Train Loss: 0.073827\n",
      "Validation AVG Loss:     0.000067 \n",
      "\n",
      "Epoch [3106/5000] | Train Loss: 0.073760\n",
      "Validation AVG Loss:     0.000067 \n",
      "\n",
      "Epoch [3107/5000] | Train Loss: 0.073694\n",
      "Validation AVG Loss:     0.000067 \n",
      "\n",
      "Epoch [3108/5000] | Train Loss: 0.073627\n",
      "Validation AVG Loss:     0.000067 \n",
      "\n",
      "Epoch [3109/5000] | Train Loss: 0.073561\n",
      "Validation AVG Loss:     0.000067 \n",
      "\n",
      "Epoch [3110/5000] | Train Loss: 0.073494\n",
      "Validation AVG Loss:     0.000067 \n",
      "\n",
      "Epoch [3111/5000] | Train Loss: 0.073428\n",
      "Validation AVG Loss:     0.000066 \n",
      "\n",
      "Epoch [3112/5000] | Train Loss: 0.073361\n",
      "Validation AVG Loss:     0.000066 \n",
      "\n",
      "Epoch [3113/5000] | Train Loss: 0.073295\n",
      "Validation AVG Loss:     0.000066 \n",
      "\n",
      "Epoch [3114/5000] | Train Loss: 0.073228\n",
      "Validation AVG Loss:     0.000066 \n",
      "\n",
      "Epoch [3115/5000] | Train Loss: 0.073162\n",
      "Validation AVG Loss:     0.000066 \n",
      "\n",
      "Epoch [3116/5000] | Train Loss: 0.073096\n",
      "Validation AVG Loss:     0.000066 \n",
      "\n",
      "Epoch [3117/5000] | Train Loss: 0.073030\n",
      "Validation AVG Loss:     0.000066 \n",
      "\n",
      "Epoch [3118/5000] | Train Loss: 0.072964\n",
      "Validation AVG Loss:     0.000066 \n",
      "\n",
      "Epoch [3119/5000] | Train Loss: 0.072897\n",
      "Validation AVG Loss:     0.000066 \n",
      "\n",
      "Epoch [3120/5000] | Train Loss: 0.072831\n",
      "Validation AVG Loss:     0.000066 \n",
      "\n",
      "Epoch [3121/5000] | Train Loss: 0.072765\n",
      "Validation AVG Loss:     0.000066 \n",
      "\n",
      "Epoch [3122/5000] | Train Loss: 0.072699\n",
      "Validation AVG Loss:     0.000066 \n",
      "\n",
      "Epoch [3123/5000] | Train Loss: 0.072633\n",
      "Validation AVG Loss:     0.000066 \n",
      "\n",
      "Epoch [3124/5000] | Train Loss: 0.072567\n",
      "Validation AVG Loss:     0.000066 \n",
      "\n",
      "Epoch [3125/5000] | Train Loss: 0.072501\n",
      "Validation AVG Loss:     0.000066 \n",
      "\n",
      "Epoch [3126/5000] | Train Loss: 0.072436\n",
      "Validation AVG Loss:     0.000066 \n",
      "\n",
      "Epoch [3127/5000] | Train Loss: 0.072370\n",
      "Validation AVG Loss:     0.000065 \n",
      "\n",
      "Epoch [3128/5000] | Train Loss: 0.072304\n",
      "Validation AVG Loss:     0.000065 \n",
      "\n",
      "Epoch [3129/5000] | Train Loss: 0.072238\n",
      "Validation AVG Loss:     0.000065 \n",
      "\n",
      "Epoch [3130/5000] | Train Loss: 0.072173\n",
      "Validation AVG Loss:     0.000065 \n",
      "\n",
      "Epoch [3131/5000] | Train Loss: 0.072107\n",
      "Validation AVG Loss:     0.000065 \n",
      "\n",
      "Epoch [3132/5000] | Train Loss: 0.072041\n",
      "Validation AVG Loss:     0.000065 \n",
      "\n",
      "Epoch [3133/5000] | Train Loss: 0.071976\n",
      "Validation AVG Loss:     0.000065 \n",
      "\n",
      "Epoch [3134/5000] | Train Loss: 0.071910\n",
      "Validation AVG Loss:     0.000065 \n",
      "\n",
      "Epoch [3135/5000] | Train Loss: 0.071845\n",
      "Validation AVG Loss:     0.000065 \n",
      "\n",
      "Epoch [3136/5000] | Train Loss: 0.071779\n",
      "Validation AVG Loss:     0.000065 \n",
      "\n",
      "Epoch [3137/5000] | Train Loss: 0.071714\n",
      "Validation AVG Loss:     0.000065 \n",
      "\n",
      "Epoch [3138/5000] | Train Loss: 0.071649\n",
      "Validation AVG Loss:     0.000065 \n",
      "\n",
      "Epoch [3139/5000] | Train Loss: 0.071583\n",
      "Validation AVG Loss:     0.000065 \n",
      "\n",
      "Epoch [3140/5000] | Train Loss: 0.071518\n",
      "Validation AVG Loss:     0.000065 \n",
      "\n",
      "Epoch [3141/5000] | Train Loss: 0.071453\n",
      "Validation AVG Loss:     0.000065 \n",
      "\n",
      "Epoch [3142/5000] | Train Loss: 0.071388\n",
      "Validation AVG Loss:     0.000065 \n",
      "\n",
      "Epoch [3143/5000] | Train Loss: 0.071323\n",
      "Validation AVG Loss:     0.000064 \n",
      "\n",
      "Epoch [3144/5000] | Train Loss: 0.071257\n",
      "Validation AVG Loss:     0.000064 \n",
      "\n",
      "Epoch [3145/5000] | Train Loss: 0.071192\n",
      "Validation AVG Loss:     0.000064 \n",
      "\n",
      "Epoch [3146/5000] | Train Loss: 0.071127\n",
      "Validation AVG Loss:     0.000064 \n",
      "\n",
      "Epoch [3147/5000] | Train Loss: 0.071062\n",
      "Validation AVG Loss:     0.000064 \n",
      "\n",
      "Epoch [3148/5000] | Train Loss: 0.070997\n",
      "Validation AVG Loss:     0.000064 \n",
      "\n",
      "Epoch [3149/5000] | Train Loss: 0.070933\n",
      "Validation AVG Loss:     0.000064 \n",
      "\n",
      "Epoch [3150/5000] | Train Loss: 0.070868\n",
      "Validation AVG Loss:     0.000064 \n",
      "\n",
      "Epoch [3151/5000] | Train Loss: 0.070803\n",
      "Validation AVG Loss:     0.000064 \n",
      "\n",
      "Epoch [3152/5000] | Train Loss: 0.070738\n",
      "Validation AVG Loss:     0.000064 \n",
      "\n",
      "Epoch [3153/5000] | Train Loss: 0.070673\n",
      "Validation AVG Loss:     0.000064 \n",
      "\n",
      "Epoch [3154/5000] | Train Loss: 0.070609\n",
      "Validation AVG Loss:     0.000064 \n",
      "\n",
      "Epoch [3155/5000] | Train Loss: 0.070544\n",
      "Validation AVG Loss:     0.000064 \n",
      "\n",
      "Epoch [3156/5000] | Train Loss: 0.070479\n",
      "Validation AVG Loss:     0.000064 \n",
      "\n",
      "Epoch [3157/5000] | Train Loss: 0.070415\n",
      "Validation AVG Loss:     0.000064 \n",
      "\n",
      "Epoch [3158/5000] | Train Loss: 0.070350\n",
      "Validation AVG Loss:     0.000064 \n",
      "\n",
      "Epoch [3159/5000] | Train Loss: 0.070286\n",
      "Validation AVG Loss:     0.000064 \n",
      "\n",
      "Epoch [3160/5000] | Train Loss: 0.070222\n",
      "Validation AVG Loss:     0.000063 \n",
      "\n",
      "Epoch [3161/5000] | Train Loss: 0.070157\n",
      "Validation AVG Loss:     0.000063 \n",
      "\n",
      "Epoch [3162/5000] | Train Loss: 0.070093\n",
      "Validation AVG Loss:     0.000063 \n",
      "\n",
      "Epoch [3163/5000] | Train Loss: 0.070029\n",
      "Validation AVG Loss:     0.000063 \n",
      "\n",
      "Epoch [3164/5000] | Train Loss: 0.069964\n",
      "Validation AVG Loss:     0.000063 \n",
      "\n",
      "Epoch [3165/5000] | Train Loss: 0.069900\n",
      "Validation AVG Loss:     0.000063 \n",
      "\n",
      "Epoch [3166/5000] | Train Loss: 0.069836\n",
      "Validation AVG Loss:     0.000063 \n",
      "\n",
      "Epoch [3167/5000] | Train Loss: 0.069772\n",
      "Validation AVG Loss:     0.000063 \n",
      "\n",
      "Epoch [3168/5000] | Train Loss: 0.069708\n",
      "Validation AVG Loss:     0.000063 \n",
      "\n",
      "Epoch [3169/5000] | Train Loss: 0.069644\n",
      "Validation AVG Loss:     0.000063 \n",
      "\n",
      "Epoch [3170/5000] | Train Loss: 0.069580\n",
      "Validation AVG Loss:     0.000063 \n",
      "\n",
      "Epoch [3171/5000] | Train Loss: 0.069516\n",
      "Validation AVG Loss:     0.000063 \n",
      "\n",
      "Epoch [3172/5000] | Train Loss: 0.069452\n",
      "Validation AVG Loss:     0.000063 \n",
      "\n",
      "Epoch [3173/5000] | Train Loss: 0.069388\n",
      "Validation AVG Loss:     0.000063 \n",
      "\n",
      "Epoch [3174/5000] | Train Loss: 0.069324\n",
      "Validation AVG Loss:     0.000063 \n",
      "\n",
      "Epoch [3175/5000] | Train Loss: 0.069260\n",
      "Validation AVG Loss:     0.000063 \n",
      "\n",
      "Epoch [3176/5000] | Train Loss: 0.069196\n",
      "Validation AVG Loss:     0.000063 \n",
      "\n",
      "Epoch [3177/5000] | Train Loss: 0.069133\n",
      "Validation AVG Loss:     0.000062 \n",
      "\n",
      "Epoch [3178/5000] | Train Loss: 0.069069\n",
      "Validation AVG Loss:     0.000062 \n",
      "\n",
      "Epoch [3179/5000] | Train Loss: 0.069005\n",
      "Validation AVG Loss:     0.000062 \n",
      "\n",
      "Epoch [3180/5000] | Train Loss: 0.068942\n",
      "Validation AVG Loss:     0.000062 \n",
      "\n",
      "Epoch [3181/5000] | Train Loss: 0.068878\n",
      "Validation AVG Loss:     0.000062 \n",
      "\n",
      "Epoch [3182/5000] | Train Loss: 0.068815\n",
      "Validation AVG Loss:     0.000062 \n",
      "\n",
      "Epoch [3183/5000] | Train Loss: 0.068751\n",
      "Validation AVG Loss:     0.000062 \n",
      "\n",
      "Epoch [3184/5000] | Train Loss: 0.068688\n",
      "Validation AVG Loss:     0.000062 \n",
      "\n",
      "Epoch [3185/5000] | Train Loss: 0.068625\n",
      "Validation AVG Loss:     0.000062 \n",
      "\n",
      "Epoch [3186/5000] | Train Loss: 0.068561\n",
      "Validation AVG Loss:     0.000062 \n",
      "\n",
      "Epoch [3187/5000] | Train Loss: 0.068498\n",
      "Validation AVG Loss:     0.000062 \n",
      "\n",
      "Epoch [3188/5000] | Train Loss: 0.068435\n",
      "Validation AVG Loss:     0.000062 \n",
      "\n",
      "Epoch [3189/5000] | Train Loss: 0.068371\n",
      "Validation AVG Loss:     0.000062 \n",
      "\n",
      "Epoch [3190/5000] | Train Loss: 0.068308\n",
      "Validation AVG Loss:     0.000062 \n",
      "\n",
      "Epoch [3191/5000] | Train Loss: 0.068245\n",
      "Validation AVG Loss:     0.000062 \n",
      "\n",
      "Epoch [3192/5000] | Train Loss: 0.068182\n",
      "Validation AVG Loss:     0.000062 \n",
      "\n",
      "Epoch [3193/5000] | Train Loss: 0.068119\n",
      "Validation AVG Loss:     0.000062 \n",
      "\n",
      "Epoch [3194/5000] | Train Loss: 0.068056\n",
      "Validation AVG Loss:     0.000061 \n",
      "\n",
      "Epoch [3195/5000] | Train Loss: 0.067993\n",
      "Validation AVG Loss:     0.000061 \n",
      "\n",
      "Epoch [3196/5000] | Train Loss: 0.067930\n",
      "Validation AVG Loss:     0.000061 \n",
      "\n",
      "Epoch [3197/5000] | Train Loss: 0.067867\n",
      "Validation AVG Loss:     0.000061 \n",
      "\n",
      "Epoch [3198/5000] | Train Loss: 0.067805\n",
      "Validation AVG Loss:     0.000061 \n",
      "\n",
      "Epoch [3199/5000] | Train Loss: 0.067742\n",
      "Validation AVG Loss:     0.000061 \n",
      "\n",
      "Epoch [3200/5000] | Train Loss: 0.067679\n",
      "Validation AVG Loss:     0.000061 \n",
      "\n",
      "Epoch [3201/5000] | Train Loss: 0.067616\n",
      "Validation AVG Loss:     0.000061 \n",
      "\n",
      "Epoch [3202/5000] | Train Loss: 0.067554\n",
      "Validation AVG Loss:     0.000061 \n",
      "\n",
      "Epoch [3203/5000] | Train Loss: 0.067491\n",
      "Validation AVG Loss:     0.000061 \n",
      "\n",
      "Epoch [3204/5000] | Train Loss: 0.067428\n",
      "Validation AVG Loss:     0.000061 \n",
      "\n",
      "Epoch [3205/5000] | Train Loss: 0.067366\n",
      "Validation AVG Loss:     0.000061 \n",
      "\n",
      "Epoch [3206/5000] | Train Loss: 0.067303\n",
      "Validation AVG Loss:     0.000061 \n",
      "\n",
      "Epoch [3207/5000] | Train Loss: 0.067241\n",
      "Validation AVG Loss:     0.000061 \n",
      "\n",
      "Epoch [3208/5000] | Train Loss: 0.067179\n",
      "Validation AVG Loss:     0.000061 \n",
      "\n",
      "Epoch [3209/5000] | Train Loss: 0.067116\n",
      "Validation AVG Loss:     0.000061 \n",
      "\n",
      "Epoch [3210/5000] | Train Loss: 0.067054\n",
      "Validation AVG Loss:     0.000061 \n",
      "\n",
      "Epoch [3211/5000] | Train Loss: 0.066992\n",
      "Validation AVG Loss:     0.000060 \n",
      "\n",
      "Epoch [3212/5000] | Train Loss: 0.066929\n",
      "Validation AVG Loss:     0.000060 \n",
      "\n",
      "Epoch [3213/5000] | Train Loss: 0.066867\n",
      "Validation AVG Loss:     0.000060 \n",
      "\n",
      "Epoch [3214/5000] | Train Loss: 0.066805\n",
      "Validation AVG Loss:     0.000060 \n",
      "\n",
      "Epoch [3215/5000] | Train Loss: 0.066743\n",
      "Validation AVG Loss:     0.000060 \n",
      "\n",
      "Epoch [3216/5000] | Train Loss: 0.066681\n",
      "Validation AVG Loss:     0.000060 \n",
      "\n",
      "Epoch [3217/5000] | Train Loss: 0.066619\n",
      "Validation AVG Loss:     0.000060 \n",
      "\n",
      "Epoch [3218/5000] | Train Loss: 0.066557\n",
      "Validation AVG Loss:     0.000060 \n",
      "\n",
      "Epoch [3219/5000] | Train Loss: 0.066495\n",
      "Validation AVG Loss:     0.000060 \n",
      "\n",
      "Epoch [3220/5000] | Train Loss: 0.066433\n",
      "Validation AVG Loss:     0.000060 \n",
      "\n",
      "Epoch [3221/5000] | Train Loss: 0.066371\n",
      "Validation AVG Loss:     0.000060 \n",
      "\n",
      "Epoch [3222/5000] | Train Loss: 0.066309\n",
      "Validation AVG Loss:     0.000060 \n",
      "\n",
      "Epoch [3223/5000] | Train Loss: 0.066247\n",
      "Validation AVG Loss:     0.000060 \n",
      "\n",
      "Epoch [3224/5000] | Train Loss: 0.066186\n",
      "Validation AVG Loss:     0.000060 \n",
      "\n",
      "Epoch [3225/5000] | Train Loss: 0.066124\n",
      "Validation AVG Loss:     0.000060 \n",
      "\n",
      "Epoch [3226/5000] | Train Loss: 0.066062\n",
      "Validation AVG Loss:     0.000060 \n",
      "\n",
      "Epoch [3227/5000] | Train Loss: 0.066001\n",
      "Validation AVG Loss:     0.000060 \n",
      "\n",
      "Epoch [3228/5000] | Train Loss: 0.065939\n",
      "Validation AVG Loss:     0.000059 \n",
      "\n",
      "Epoch [3229/5000] | Train Loss: 0.065878\n",
      "Validation AVG Loss:     0.000059 \n",
      "\n",
      "Epoch [3230/5000] | Train Loss: 0.065816\n",
      "Validation AVG Loss:     0.000059 \n",
      "\n",
      "Epoch [3231/5000] | Train Loss: 0.065755\n",
      "Validation AVG Loss:     0.000059 \n",
      "\n",
      "Epoch [3232/5000] | Train Loss: 0.065693\n",
      "Validation AVG Loss:     0.000059 \n",
      "\n",
      "Epoch [3233/5000] | Train Loss: 0.065632\n",
      "Validation AVG Loss:     0.000059 \n",
      "\n",
      "Epoch [3234/5000] | Train Loss: 0.065571\n",
      "Validation AVG Loss:     0.000059 \n",
      "\n",
      "Epoch [3235/5000] | Train Loss: 0.065509\n",
      "Validation AVG Loss:     0.000059 \n",
      "\n",
      "Epoch [3236/5000] | Train Loss: 0.065448\n",
      "Validation AVG Loss:     0.000059 \n",
      "\n",
      "Epoch [3237/5000] | Train Loss: 0.065387\n",
      "Validation AVG Loss:     0.000059 \n",
      "\n",
      "Epoch [3238/5000] | Train Loss: 0.065326\n",
      "Validation AVG Loss:     0.000059 \n",
      "\n",
      "Epoch [3239/5000] | Train Loss: 0.065265\n",
      "Validation AVG Loss:     0.000059 \n",
      "\n",
      "Epoch [3240/5000] | Train Loss: 0.065204\n",
      "Validation AVG Loss:     0.000059 \n",
      "\n",
      "Epoch [3241/5000] | Train Loss: 0.065143\n",
      "Validation AVG Loss:     0.000059 \n",
      "\n",
      "Epoch [3242/5000] | Train Loss: 0.065082\n",
      "Validation AVG Loss:     0.000059 \n",
      "\n",
      "Epoch [3243/5000] | Train Loss: 0.065021\n",
      "Validation AVG Loss:     0.000059 \n",
      "\n",
      "Epoch [3244/5000] | Train Loss: 0.064960\n",
      "Validation AVG Loss:     0.000059 \n",
      "\n",
      "Epoch [3245/5000] | Train Loss: 0.064899\n",
      "Validation AVG Loss:     0.000058 \n",
      "\n",
      "Epoch [3246/5000] | Train Loss: 0.064838\n",
      "Validation AVG Loss:     0.000058 \n",
      "\n",
      "Epoch [3247/5000] | Train Loss: 0.064777\n",
      "Validation AVG Loss:     0.000058 \n",
      "\n",
      "Epoch [3248/5000] | Train Loss: 0.064717\n",
      "Validation AVG Loss:     0.000058 \n",
      "\n",
      "Epoch [3249/5000] | Train Loss: 0.064656\n",
      "Validation AVG Loss:     0.000058 \n",
      "\n",
      "Epoch [3250/5000] | Train Loss: 0.064595\n",
      "Validation AVG Loss:     0.000058 \n",
      "\n",
      "Epoch [3251/5000] | Train Loss: 0.064535\n",
      "Validation AVG Loss:     0.000058 \n",
      "\n",
      "Epoch [3252/5000] | Train Loss: 0.064474\n",
      "Validation AVG Loss:     0.000058 \n",
      "\n",
      "Epoch [3253/5000] | Train Loss: 0.064414\n",
      "Validation AVG Loss:     0.000058 \n",
      "\n",
      "Epoch [3254/5000] | Train Loss: 0.064353\n",
      "Validation AVG Loss:     0.000058 \n",
      "\n",
      "Epoch [3255/5000] | Train Loss: 0.064293\n",
      "Validation AVG Loss:     0.000058 \n",
      "\n",
      "Epoch [3256/5000] | Train Loss: 0.064232\n",
      "Validation AVG Loss:     0.000058 \n",
      "\n",
      "Epoch [3257/5000] | Train Loss: 0.064172\n",
      "Validation AVG Loss:     0.000058 \n",
      "\n",
      "Epoch [3258/5000] | Train Loss: 0.064112\n",
      "Validation AVG Loss:     0.000058 \n",
      "\n",
      "Epoch [3259/5000] | Train Loss: 0.064051\n",
      "Validation AVG Loss:     0.000058 \n",
      "\n",
      "Epoch [3260/5000] | Train Loss: 0.063991\n",
      "Validation AVG Loss:     0.000058 \n",
      "\n",
      "Epoch [3261/5000] | Train Loss: 0.063931\n",
      "Validation AVG Loss:     0.000058 \n",
      "\n",
      "Epoch [3262/5000] | Train Loss: 0.063871\n",
      "Validation AVG Loss:     0.000058 \n",
      "\n",
      "Epoch [3263/5000] | Train Loss: 0.063811\n",
      "Validation AVG Loss:     0.000057 \n",
      "\n",
      "Epoch [3264/5000] | Train Loss: 0.063751\n",
      "Validation AVG Loss:     0.000057 \n",
      "\n",
      "Epoch [3265/5000] | Train Loss: 0.063691\n",
      "Validation AVG Loss:     0.000057 \n",
      "\n",
      "Epoch [3266/5000] | Train Loss: 0.063631\n",
      "Validation AVG Loss:     0.000057 \n",
      "\n",
      "Epoch [3267/5000] | Train Loss: 0.063571\n",
      "Validation AVG Loss:     0.000057 \n",
      "\n",
      "Epoch [3268/5000] | Train Loss: 0.063511\n",
      "Validation AVG Loss:     0.000057 \n",
      "\n",
      "Epoch [3269/5000] | Train Loss: 0.063451\n",
      "Validation AVG Loss:     0.000057 \n",
      "\n",
      "Epoch [3270/5000] | Train Loss: 0.063391\n",
      "Validation AVG Loss:     0.000057 \n",
      "\n",
      "Epoch [3271/5000] | Train Loss: 0.063331\n",
      "Validation AVG Loss:     0.000057 \n",
      "\n",
      "Epoch [3272/5000] | Train Loss: 0.063272\n",
      "Validation AVG Loss:     0.000057 \n",
      "\n",
      "Epoch [3273/5000] | Train Loss: 0.063212\n",
      "Validation AVG Loss:     0.000057 \n",
      "\n",
      "Epoch [3274/5000] | Train Loss: 0.063152\n",
      "Validation AVG Loss:     0.000057 \n",
      "\n",
      "Epoch [3275/5000] | Train Loss: 0.063093\n",
      "Validation AVG Loss:     0.000057 \n",
      "\n",
      "Epoch [3276/5000] | Train Loss: 0.063033\n",
      "Validation AVG Loss:     0.000057 \n",
      "\n",
      "Epoch [3277/5000] | Train Loss: 0.062974\n",
      "Validation AVG Loss:     0.000057 \n",
      "\n",
      "Epoch [3278/5000] | Train Loss: 0.062914\n",
      "Validation AVG Loss:     0.000057 \n",
      "\n",
      "Epoch [3279/5000] | Train Loss: 0.062855\n",
      "Validation AVG Loss:     0.000057 \n",
      "\n",
      "Epoch [3280/5000] | Train Loss: 0.062795\n",
      "Validation AVG Loss:     0.000057 \n",
      "\n",
      "Epoch [3281/5000] | Train Loss: 0.062736\n",
      "Validation AVG Loss:     0.000056 \n",
      "\n",
      "Epoch [3282/5000] | Train Loss: 0.062677\n",
      "Validation AVG Loss:     0.000056 \n",
      "\n",
      "Epoch [3283/5000] | Train Loss: 0.062618\n",
      "Validation AVG Loss:     0.000056 \n",
      "\n",
      "Epoch [3284/5000] | Train Loss: 0.062558\n",
      "Validation AVG Loss:     0.000056 \n",
      "\n",
      "Epoch [3285/5000] | Train Loss: 0.062499\n",
      "Validation AVG Loss:     0.000056 \n",
      "\n",
      "Epoch [3286/5000] | Train Loss: 0.062440\n",
      "Validation AVG Loss:     0.000056 \n",
      "\n",
      "Epoch [3287/5000] | Train Loss: 0.062381\n",
      "Validation AVG Loss:     0.000056 \n",
      "\n",
      "Epoch [3288/5000] | Train Loss: 0.062322\n",
      "Validation AVG Loss:     0.000056 \n",
      "\n",
      "Epoch [3289/5000] | Train Loss: 0.062263\n",
      "Validation AVG Loss:     0.000056 \n",
      "\n",
      "Epoch [3290/5000] | Train Loss: 0.062204\n",
      "Validation AVG Loss:     0.000056 \n",
      "\n",
      "Epoch [3291/5000] | Train Loss: 0.062145\n",
      "Validation AVG Loss:     0.000056 \n",
      "\n",
      "Epoch [3292/5000] | Train Loss: 0.062086\n",
      "Validation AVG Loss:     0.000056 \n",
      "\n",
      "Epoch [3293/5000] | Train Loss: 0.062027\n",
      "Validation AVG Loss:     0.000056 \n",
      "\n",
      "Epoch [3294/5000] | Train Loss: 0.061969\n",
      "Validation AVG Loss:     0.000056 \n",
      "\n",
      "Epoch [3295/5000] | Train Loss: 0.061910\n",
      "Validation AVG Loss:     0.000056 \n",
      "\n",
      "Epoch [3296/5000] | Train Loss: 0.061851\n",
      "Validation AVG Loss:     0.000056 \n",
      "\n",
      "Epoch [3297/5000] | Train Loss: 0.061792\n",
      "Validation AVG Loss:     0.000056 \n",
      "\n",
      "Epoch [3298/5000] | Train Loss: 0.061734\n",
      "Validation AVG Loss:     0.000056 \n",
      "\n",
      "Epoch [3299/5000] | Train Loss: 0.061675\n",
      "Validation AVG Loss:     0.000055 \n",
      "\n",
      "Epoch [3300/5000] | Train Loss: 0.061617\n",
      "Validation AVG Loss:     0.000055 \n",
      "\n",
      "Epoch [3301/5000] | Train Loss: 0.061558\n",
      "Validation AVG Loss:     0.000055 \n",
      "\n",
      "Epoch [3302/5000] | Train Loss: 0.061500\n",
      "Validation AVG Loss:     0.000055 \n",
      "\n",
      "Epoch [3303/5000] | Train Loss: 0.061441\n",
      "Validation AVG Loss:     0.000055 \n",
      "\n",
      "Epoch [3304/5000] | Train Loss: 0.061383\n",
      "Validation AVG Loss:     0.000055 \n",
      "\n",
      "Epoch [3305/5000] | Train Loss: 0.061325\n",
      "Validation AVG Loss:     0.000055 \n",
      "\n",
      "Epoch [3306/5000] | Train Loss: 0.061266\n",
      "Validation AVG Loss:     0.000055 \n",
      "\n",
      "Epoch [3307/5000] | Train Loss: 0.061208\n",
      "Validation AVG Loss:     0.000055 \n",
      "\n",
      "Epoch [3308/5000] | Train Loss: 0.061150\n",
      "Validation AVG Loss:     0.000055 \n",
      "\n",
      "Epoch [3309/5000] | Train Loss: 0.061092\n",
      "Validation AVG Loss:     0.000055 \n",
      "\n",
      "Epoch [3310/5000] | Train Loss: 0.061034\n",
      "Validation AVG Loss:     0.000055 \n",
      "\n",
      "Epoch [3311/5000] | Train Loss: 0.060975\n",
      "Validation AVG Loss:     0.000055 \n",
      "\n",
      "Epoch [3312/5000] | Train Loss: 0.060917\n",
      "Validation AVG Loss:     0.000055 \n",
      "\n",
      "Epoch [3313/5000] | Train Loss: 0.060859\n",
      "Validation AVG Loss:     0.000055 \n",
      "\n",
      "Epoch [3314/5000] | Train Loss: 0.060801\n",
      "Validation AVG Loss:     0.000055 \n",
      "\n",
      "Epoch [3315/5000] | Train Loss: 0.060744\n",
      "Validation AVG Loss:     0.000055 \n",
      "\n",
      "Epoch [3316/5000] | Train Loss: 0.060686\n",
      "Validation AVG Loss:     0.000055 \n",
      "\n",
      "Epoch [3317/5000] | Train Loss: 0.060628\n",
      "Validation AVG Loss:     0.000055 \n",
      "\n",
      "Epoch [3318/5000] | Train Loss: 0.060570\n",
      "Validation AVG Loss:     0.000054 \n",
      "\n",
      "Epoch [3319/5000] | Train Loss: 0.060512\n",
      "Validation AVG Loss:     0.000054 \n",
      "\n",
      "Epoch [3320/5000] | Train Loss: 0.060455\n",
      "Validation AVG Loss:     0.000054 \n",
      "\n",
      "Epoch [3321/5000] | Train Loss: 0.060397\n",
      "Validation AVG Loss:     0.000054 \n",
      "\n",
      "Epoch [3322/5000] | Train Loss: 0.060339\n",
      "Validation AVG Loss:     0.000054 \n",
      "\n",
      "Epoch [3323/5000] | Train Loss: 0.060282\n",
      "Validation AVG Loss:     0.000054 \n",
      "\n",
      "Epoch [3324/5000] | Train Loss: 0.060224\n",
      "Validation AVG Loss:     0.000054 \n",
      "\n",
      "Epoch [3325/5000] | Train Loss: 0.060167\n",
      "Validation AVG Loss:     0.000054 \n",
      "\n",
      "Epoch [3326/5000] | Train Loss: 0.060109\n",
      "Validation AVG Loss:     0.000054 \n",
      "\n",
      "Epoch [3327/5000] | Train Loss: 0.060052\n",
      "Validation AVG Loss:     0.000054 \n",
      "\n",
      "Epoch [3328/5000] | Train Loss: 0.059995\n",
      "Validation AVG Loss:     0.000054 \n",
      "\n",
      "Epoch [3329/5000] | Train Loss: 0.059937\n",
      "Validation AVG Loss:     0.000054 \n",
      "\n",
      "Epoch [3330/5000] | Train Loss: 0.059880\n",
      "Validation AVG Loss:     0.000054 \n",
      "\n",
      "Epoch [3331/5000] | Train Loss: 0.059823\n",
      "Validation AVG Loss:     0.000054 \n",
      "\n",
      "Epoch [3332/5000] | Train Loss: 0.059765\n",
      "Validation AVG Loss:     0.000054 \n",
      "\n",
      "Epoch [3333/5000] | Train Loss: 0.059708\n",
      "Validation AVG Loss:     0.000054 \n",
      "\n",
      "Epoch [3334/5000] | Train Loss: 0.059651\n",
      "Validation AVG Loss:     0.000054 \n",
      "\n",
      "Epoch [3335/5000] | Train Loss: 0.059594\n",
      "Validation AVG Loss:     0.000054 \n",
      "\n",
      "Epoch [3336/5000] | Train Loss: 0.059537\n",
      "Validation AVG Loss:     0.000053 \n",
      "\n",
      "Epoch [3337/5000] | Train Loss: 0.059480\n",
      "Validation AVG Loss:     0.000053 \n",
      "\n",
      "Epoch [3338/5000] | Train Loss: 0.059423\n",
      "Validation AVG Loss:     0.000053 \n",
      "\n",
      "Epoch [3339/5000] | Train Loss: 0.059366\n",
      "Validation AVG Loss:     0.000053 \n",
      "\n",
      "Epoch [3340/5000] | Train Loss: 0.059309\n",
      "Validation AVG Loss:     0.000053 \n",
      "\n",
      "Epoch [3341/5000] | Train Loss: 0.059253\n",
      "Validation AVG Loss:     0.000053 \n",
      "\n",
      "Epoch [3342/5000] | Train Loss: 0.059196\n",
      "Validation AVG Loss:     0.000053 \n",
      "\n",
      "Epoch [3343/5000] | Train Loss: 0.059139\n",
      "Validation AVG Loss:     0.000053 \n",
      "\n",
      "Epoch [3344/5000] | Train Loss: 0.059082\n",
      "Validation AVG Loss:     0.000053 \n",
      "\n",
      "Epoch [3345/5000] | Train Loss: 0.059026\n",
      "Validation AVG Loss:     0.000053 \n",
      "\n",
      "Epoch [3346/5000] | Train Loss: 0.058969\n",
      "Validation AVG Loss:     0.000053 \n",
      "\n",
      "Epoch [3347/5000] | Train Loss: 0.058912\n",
      "Validation AVG Loss:     0.000053 \n",
      "\n",
      "Epoch [3348/5000] | Train Loss: 0.058856\n",
      "Validation AVG Loss:     0.000053 \n",
      "\n",
      "Epoch [3349/5000] | Train Loss: 0.058799\n",
      "Validation AVG Loss:     0.000053 \n",
      "\n",
      "Epoch [3350/5000] | Train Loss: 0.058743\n",
      "Validation AVG Loss:     0.000053 \n",
      "\n",
      "Epoch [3351/5000] | Train Loss: 0.058686\n",
      "Validation AVG Loss:     0.000053 \n",
      "\n",
      "Epoch [3352/5000] | Train Loss: 0.058630\n",
      "Validation AVG Loss:     0.000053 \n",
      "\n",
      "Epoch [3353/5000] | Train Loss: 0.058574\n",
      "Validation AVG Loss:     0.000053 \n",
      "\n",
      "Epoch [3354/5000] | Train Loss: 0.058517\n",
      "Validation AVG Loss:     0.000053 \n",
      "\n",
      "Epoch [3355/5000] | Train Loss: 0.058461\n",
      "Validation AVG Loss:     0.000052 \n",
      "\n",
      "Epoch [3356/5000] | Train Loss: 0.058405\n",
      "Validation AVG Loss:     0.000052 \n",
      "\n",
      "Epoch [3357/5000] | Train Loss: 0.058349\n",
      "Validation AVG Loss:     0.000052 \n",
      "\n",
      "Epoch [3358/5000] | Train Loss: 0.058293\n",
      "Validation AVG Loss:     0.000052 \n",
      "\n",
      "Epoch [3359/5000] | Train Loss: 0.058237\n",
      "Validation AVG Loss:     0.000052 \n",
      "\n",
      "Epoch [3360/5000] | Train Loss: 0.058181\n",
      "Validation AVG Loss:     0.000052 \n",
      "\n",
      "Epoch [3361/5000] | Train Loss: 0.058125\n",
      "Validation AVG Loss:     0.000052 \n",
      "\n",
      "Epoch [3362/5000] | Train Loss: 0.058069\n",
      "Validation AVG Loss:     0.000052 \n",
      "\n",
      "Epoch [3363/5000] | Train Loss: 0.058013\n",
      "Validation AVG Loss:     0.000052 \n",
      "\n",
      "Epoch [3364/5000] | Train Loss: 0.057957\n",
      "Validation AVG Loss:     0.000052 \n",
      "\n",
      "Epoch [3365/5000] | Train Loss: 0.057901\n",
      "Validation AVG Loss:     0.000052 \n",
      "\n",
      "Epoch [3366/5000] | Train Loss: 0.057845\n",
      "Validation AVG Loss:     0.000052 \n",
      "\n",
      "Epoch [3367/5000] | Train Loss: 0.057789\n",
      "Validation AVG Loss:     0.000052 \n",
      "\n",
      "Epoch [3368/5000] | Train Loss: 0.057734\n",
      "Validation AVG Loss:     0.000052 \n",
      "\n",
      "Epoch [3369/5000] | Train Loss: 0.057678\n",
      "Validation AVG Loss:     0.000052 \n",
      "\n",
      "Epoch [3370/5000] | Train Loss: 0.057622\n",
      "Validation AVG Loss:     0.000052 \n",
      "\n",
      "Epoch [3371/5000] | Train Loss: 0.057567\n",
      "Validation AVG Loss:     0.000052 \n",
      "\n",
      "Epoch [3372/5000] | Train Loss: 0.057511\n",
      "Validation AVG Loss:     0.000052 \n",
      "\n",
      "Epoch [3373/5000] | Train Loss: 0.057456\n",
      "Validation AVG Loss:     0.000052 \n",
      "\n",
      "Epoch [3374/5000] | Train Loss: 0.057400\n",
      "Validation AVG Loss:     0.000052 \n",
      "\n",
      "Epoch [3375/5000] | Train Loss: 0.057345\n",
      "Validation AVG Loss:     0.000051 \n",
      "\n",
      "Epoch [3376/5000] | Train Loss: 0.057290\n",
      "Validation AVG Loss:     0.000051 \n",
      "\n",
      "Epoch [3377/5000] | Train Loss: 0.057234\n",
      "Validation AVG Loss:     0.000051 \n",
      "\n",
      "Epoch [3378/5000] | Train Loss: 0.057179\n",
      "Validation AVG Loss:     0.000051 \n",
      "\n",
      "Epoch [3379/5000] | Train Loss: 0.057124\n",
      "Validation AVG Loss:     0.000051 \n",
      "\n",
      "Epoch [3380/5000] | Train Loss: 0.057069\n",
      "Validation AVG Loss:     0.000051 \n",
      "\n",
      "Epoch [3381/5000] | Train Loss: 0.057013\n",
      "Validation AVG Loss:     0.000051 \n",
      "\n",
      "Epoch [3382/5000] | Train Loss: 0.056958\n",
      "Validation AVG Loss:     0.000051 \n",
      "\n",
      "Epoch [3383/5000] | Train Loss: 0.056903\n",
      "Validation AVG Loss:     0.000051 \n",
      "\n",
      "Epoch [3384/5000] | Train Loss: 0.056848\n",
      "Validation AVG Loss:     0.000051 \n",
      "\n",
      "Epoch [3385/5000] | Train Loss: 0.056793\n",
      "Validation AVG Loss:     0.000051 \n",
      "\n",
      "Epoch [3386/5000] | Train Loss: 0.056738\n",
      "Validation AVG Loss:     0.000051 \n",
      "\n",
      "Epoch [3387/5000] | Train Loss: 0.056683\n",
      "Validation AVG Loss:     0.000051 \n",
      "\n",
      "Epoch [3388/5000] | Train Loss: 0.056629\n",
      "Validation AVG Loss:     0.000051 \n",
      "\n",
      "Epoch [3389/5000] | Train Loss: 0.056574\n",
      "Validation AVG Loss:     0.000051 \n",
      "\n",
      "Epoch [3390/5000] | Train Loss: 0.056519\n",
      "Validation AVG Loss:     0.000051 \n",
      "\n",
      "Epoch [3391/5000] | Train Loss: 0.056464\n",
      "Validation AVG Loss:     0.000051 \n",
      "\n",
      "Epoch [3392/5000] | Train Loss: 0.056409\n",
      "Validation AVG Loss:     0.000051 \n",
      "\n",
      "Epoch [3393/5000] | Train Loss: 0.056355\n",
      "Validation AVG Loss:     0.000051 \n",
      "\n",
      "Epoch [3394/5000] | Train Loss: 0.056300\n",
      "Validation AVG Loss:     0.000050 \n",
      "\n",
      "Epoch [3395/5000] | Train Loss: 0.056246\n",
      "Validation AVG Loss:     0.000050 \n",
      "\n",
      "Epoch [3396/5000] | Train Loss: 0.056191\n",
      "Validation AVG Loss:     0.000050 \n",
      "\n",
      "Epoch [3397/5000] | Train Loss: 0.056137\n",
      "Validation AVG Loss:     0.000050 \n",
      "\n",
      "Epoch [3398/5000] | Train Loss: 0.056082\n",
      "Validation AVG Loss:     0.000050 \n",
      "\n",
      "Epoch [3399/5000] | Train Loss: 0.056028\n",
      "Validation AVG Loss:     0.000050 \n",
      "\n",
      "Epoch [3400/5000] | Train Loss: 0.055974\n",
      "Validation AVG Loss:     0.000050 \n",
      "\n",
      "Epoch [3401/5000] | Train Loss: 0.055919\n",
      "Validation AVG Loss:     0.000050 \n",
      "\n",
      "Epoch [3402/5000] | Train Loss: 0.055865\n",
      "Validation AVG Loss:     0.000050 \n",
      "\n",
      "Epoch [3403/5000] | Train Loss: 0.055811\n",
      "Validation AVG Loss:     0.000050 \n",
      "\n",
      "Epoch [3404/5000] | Train Loss: 0.055757\n",
      "Validation AVG Loss:     0.000050 \n",
      "\n",
      "Epoch [3405/5000] | Train Loss: 0.055702\n",
      "Validation AVG Loss:     0.000050 \n",
      "\n",
      "Epoch [3406/5000] | Train Loss: 0.055648\n",
      "Validation AVG Loss:     0.000050 \n",
      "\n",
      "Epoch [3407/5000] | Train Loss: 0.055594\n",
      "Validation AVG Loss:     0.000050 \n",
      "\n",
      "Epoch [3408/5000] | Train Loss: 0.055540\n",
      "Validation AVG Loss:     0.000050 \n",
      "\n",
      "Epoch [3409/5000] | Train Loss: 0.055486\n",
      "Validation AVG Loss:     0.000050 \n",
      "\n",
      "Epoch [3410/5000] | Train Loss: 0.055432\n",
      "Validation AVG Loss:     0.000050 \n",
      "\n",
      "Epoch [3411/5000] | Train Loss: 0.055379\n",
      "Validation AVG Loss:     0.000050 \n",
      "\n",
      "Epoch [3412/5000] | Train Loss: 0.055325\n",
      "Validation AVG Loss:     0.000050 \n",
      "\n",
      "Epoch [3413/5000] | Train Loss: 0.055271\n",
      "Validation AVG Loss:     0.000050 \n",
      "\n",
      "Epoch [3414/5000] | Train Loss: 0.055217\n",
      "Validation AVG Loss:     0.000049 \n",
      "\n",
      "Epoch [3415/5000] | Train Loss: 0.055163\n",
      "Validation AVG Loss:     0.000049 \n",
      "\n",
      "Epoch [3416/5000] | Train Loss: 0.055110\n",
      "Validation AVG Loss:     0.000049 \n",
      "\n",
      "Epoch [3417/5000] | Train Loss: 0.055056\n",
      "Validation AVG Loss:     0.000049 \n",
      "\n",
      "Epoch [3418/5000] | Train Loss: 0.055002\n",
      "Validation AVG Loss:     0.000049 \n",
      "\n",
      "Epoch [3419/5000] | Train Loss: 0.054949\n",
      "Validation AVG Loss:     0.000049 \n",
      "\n",
      "Epoch [3420/5000] | Train Loss: 0.054895\n",
      "Validation AVG Loss:     0.000049 \n",
      "\n",
      "Epoch [3421/5000] | Train Loss: 0.054842\n",
      "Validation AVG Loss:     0.000049 \n",
      "\n",
      "Epoch [3422/5000] | Train Loss: 0.054789\n",
      "Validation AVG Loss:     0.000049 \n",
      "\n",
      "Epoch [3423/5000] | Train Loss: 0.054735\n",
      "Validation AVG Loss:     0.000049 \n",
      "\n",
      "Epoch [3424/5000] | Train Loss: 0.054682\n",
      "Validation AVG Loss:     0.000049 \n",
      "\n",
      "Epoch [3425/5000] | Train Loss: 0.054629\n",
      "Validation AVG Loss:     0.000049 \n",
      "\n",
      "Epoch [3426/5000] | Train Loss: 0.054575\n",
      "Validation AVG Loss:     0.000049 \n",
      "\n",
      "Epoch [3427/5000] | Train Loss: 0.054522\n",
      "Validation AVG Loss:     0.000049 \n",
      "\n",
      "Epoch [3428/5000] | Train Loss: 0.054469\n",
      "Validation AVG Loss:     0.000049 \n",
      "\n",
      "Epoch [3429/5000] | Train Loss: 0.054416\n",
      "Validation AVG Loss:     0.000049 \n",
      "\n",
      "Epoch [3430/5000] | Train Loss: 0.054363\n",
      "Validation AVG Loss:     0.000049 \n",
      "\n",
      "Epoch [3431/5000] | Train Loss: 0.054310\n",
      "Validation AVG Loss:     0.000049 \n",
      "\n",
      "Epoch [3432/5000] | Train Loss: 0.054257\n",
      "Validation AVG Loss:     0.000049 \n",
      "\n",
      "Epoch [3433/5000] | Train Loss: 0.054204\n",
      "Validation AVG Loss:     0.000049 \n",
      "\n",
      "Epoch [3434/5000] | Train Loss: 0.054151\n",
      "Validation AVG Loss:     0.000048 \n",
      "\n",
      "Epoch [3435/5000] | Train Loss: 0.054098\n",
      "Validation AVG Loss:     0.000048 \n",
      "\n",
      "Epoch [3436/5000] | Train Loss: 0.054045\n",
      "Validation AVG Loss:     0.000048 \n",
      "\n",
      "Epoch [3437/5000] | Train Loss: 0.053992\n",
      "Validation AVG Loss:     0.000048 \n",
      "\n",
      "Epoch [3438/5000] | Train Loss: 0.053940\n",
      "Validation AVG Loss:     0.000048 \n",
      "\n",
      "Epoch [3439/5000] | Train Loss: 0.053887\n",
      "Validation AVG Loss:     0.000048 \n",
      "\n",
      "Epoch [3440/5000] | Train Loss: 0.053834\n",
      "Validation AVG Loss:     0.000048 \n",
      "\n",
      "Epoch [3441/5000] | Train Loss: 0.053782\n",
      "Validation AVG Loss:     0.000048 \n",
      "\n",
      "Epoch [3442/5000] | Train Loss: 0.053729\n",
      "Validation AVG Loss:     0.000048 \n",
      "\n",
      "Epoch [3443/5000] | Train Loss: 0.053677\n",
      "Validation AVG Loss:     0.000048 \n",
      "\n",
      "Epoch [3444/5000] | Train Loss: 0.053624\n",
      "Validation AVG Loss:     0.000048 \n",
      "\n",
      "Epoch [3445/5000] | Train Loss: 0.053572\n",
      "Validation AVG Loss:     0.000048 \n",
      "\n",
      "Epoch [3446/5000] | Train Loss: 0.053519\n",
      "Validation AVG Loss:     0.000048 \n",
      "\n",
      "Epoch [3447/5000] | Train Loss: 0.053467\n",
      "Validation AVG Loss:     0.000048 \n",
      "\n",
      "Epoch [3448/5000] | Train Loss: 0.053415\n",
      "Validation AVG Loss:     0.000048 \n",
      "\n",
      "Epoch [3449/5000] | Train Loss: 0.053362\n",
      "Validation AVG Loss:     0.000048 \n",
      "\n",
      "Epoch [3450/5000] | Train Loss: 0.053310\n",
      "Validation AVG Loss:     0.000048 \n",
      "\n",
      "Epoch [3451/5000] | Train Loss: 0.053258\n",
      "Validation AVG Loss:     0.000048 \n",
      "\n",
      "Epoch [3452/5000] | Train Loss: 0.053206\n",
      "Validation AVG Loss:     0.000048 \n",
      "\n",
      "Epoch [3453/5000] | Train Loss: 0.053154\n",
      "Validation AVG Loss:     0.000048 \n",
      "\n",
      "Epoch [3454/5000] | Train Loss: 0.053102\n",
      "Validation AVG Loss:     0.000048 \n",
      "\n",
      "Epoch [3455/5000] | Train Loss: 0.053050\n",
      "Validation AVG Loss:     0.000047 \n",
      "\n",
      "Epoch [3456/5000] | Train Loss: 0.052998\n",
      "Validation AVG Loss:     0.000047 \n",
      "\n",
      "Epoch [3457/5000] | Train Loss: 0.052946\n",
      "Validation AVG Loss:     0.000047 \n",
      "\n",
      "Epoch [3458/5000] | Train Loss: 0.052894\n",
      "Validation AVG Loss:     0.000047 \n",
      "\n",
      "Epoch [3459/5000] | Train Loss: 0.052842\n",
      "Validation AVG Loss:     0.000047 \n",
      "\n",
      "Epoch [3460/5000] | Train Loss: 0.052790\n",
      "Validation AVG Loss:     0.000047 \n",
      "\n",
      "Epoch [3461/5000] | Train Loss: 0.052738\n",
      "Validation AVG Loss:     0.000047 \n",
      "\n",
      "Epoch [3462/5000] | Train Loss: 0.052687\n",
      "Validation AVG Loss:     0.000047 \n",
      "\n",
      "Epoch [3463/5000] | Train Loss: 0.052635\n",
      "Validation AVG Loss:     0.000047 \n",
      "\n",
      "Epoch [3464/5000] | Train Loss: 0.052583\n",
      "Validation AVG Loss:     0.000047 \n",
      "\n",
      "Epoch [3465/5000] | Train Loss: 0.052532\n",
      "Validation AVG Loss:     0.000047 \n",
      "\n",
      "Epoch [3466/5000] | Train Loss: 0.052480\n",
      "Validation AVG Loss:     0.000047 \n",
      "\n",
      "Epoch [3467/5000] | Train Loss: 0.052429\n",
      "Validation AVG Loss:     0.000047 \n",
      "\n",
      "Epoch [3468/5000] | Train Loss: 0.052377\n",
      "Validation AVG Loss:     0.000047 \n",
      "\n",
      "Epoch [3469/5000] | Train Loss: 0.052326\n",
      "Validation AVG Loss:     0.000047 \n",
      "\n",
      "Epoch [3470/5000] | Train Loss: 0.052274\n",
      "Validation AVG Loss:     0.000047 \n",
      "\n",
      "Epoch [3471/5000] | Train Loss: 0.052223\n",
      "Validation AVG Loss:     0.000047 \n",
      "\n",
      "Epoch [3472/5000] | Train Loss: 0.052172\n",
      "Validation AVG Loss:     0.000047 \n",
      "\n",
      "Epoch [3473/5000] | Train Loss: 0.052120\n",
      "Validation AVG Loss:     0.000047 \n",
      "\n",
      "Epoch [3474/5000] | Train Loss: 0.052069\n",
      "Validation AVG Loss:     0.000047 \n",
      "\n",
      "Epoch [3475/5000] | Train Loss: 0.052018\n",
      "Validation AVG Loss:     0.000047 \n",
      "\n",
      "Epoch [3476/5000] | Train Loss: 0.051967\n",
      "Validation AVG Loss:     0.000046 \n",
      "\n",
      "Epoch [3477/5000] | Train Loss: 0.051916\n",
      "Validation AVG Loss:     0.000046 \n",
      "\n",
      "Epoch [3478/5000] | Train Loss: 0.051865\n",
      "Validation AVG Loss:     0.000046 \n",
      "\n",
      "Epoch [3479/5000] | Train Loss: 0.051814\n",
      "Validation AVG Loss:     0.000046 \n",
      "\n",
      "Epoch [3480/5000] | Train Loss: 0.051763\n",
      "Validation AVG Loss:     0.000046 \n",
      "\n",
      "Epoch [3481/5000] | Train Loss: 0.051712\n",
      "Validation AVG Loss:     0.000046 \n",
      "\n",
      "Epoch [3482/5000] | Train Loss: 0.051661\n",
      "Validation AVG Loss:     0.000046 \n",
      "\n",
      "Epoch [3483/5000] | Train Loss: 0.051610\n",
      "Validation AVG Loss:     0.000046 \n",
      "\n",
      "Epoch [3484/5000] | Train Loss: 0.051559\n",
      "Validation AVG Loss:     0.000046 \n",
      "\n",
      "Epoch [3485/5000] | Train Loss: 0.051508\n",
      "Validation AVG Loss:     0.000046 \n",
      "\n",
      "Epoch [3486/5000] | Train Loss: 0.051458\n",
      "Validation AVG Loss:     0.000046 \n",
      "\n",
      "Epoch [3487/5000] | Train Loss: 0.051407\n",
      "Validation AVG Loss:     0.000046 \n",
      "\n",
      "Epoch [3488/5000] | Train Loss: 0.051356\n",
      "Validation AVG Loss:     0.000046 \n",
      "\n",
      "Epoch [3489/5000] | Train Loss: 0.051306\n",
      "Validation AVG Loss:     0.000046 \n",
      "\n",
      "Epoch [3490/5000] | Train Loss: 0.051255\n",
      "Validation AVG Loss:     0.000046 \n",
      "\n",
      "Epoch [3491/5000] | Train Loss: 0.051205\n",
      "Validation AVG Loss:     0.000046 \n",
      "\n",
      "Epoch [3492/5000] | Train Loss: 0.051154\n",
      "Validation AVG Loss:     0.000046 \n",
      "\n",
      "Epoch [3493/5000] | Train Loss: 0.051104\n",
      "Validation AVG Loss:     0.000046 \n",
      "\n",
      "Epoch [3494/5000] | Train Loss: 0.051053\n",
      "Validation AVG Loss:     0.000046 \n",
      "\n",
      "Epoch [3495/5000] | Train Loss: 0.051003\n",
      "Validation AVG Loss:     0.000046 \n",
      "\n",
      "Epoch [3496/5000] | Train Loss: 0.050953\n",
      "Validation AVG Loss:     0.000046 \n",
      "\n",
      "Epoch [3497/5000] | Train Loss: 0.050902\n",
      "Validation AVG Loss:     0.000045 \n",
      "\n",
      "Epoch [3498/5000] | Train Loss: 0.050852\n",
      "Validation AVG Loss:     0.000045 \n",
      "\n",
      "Epoch [3499/5000] | Train Loss: 0.050802\n",
      "Validation AVG Loss:     0.000045 \n",
      "\n",
      "Epoch [3500/5000] | Train Loss: 0.050752\n",
      "Validation AVG Loss:     0.000045 \n",
      "\n",
      "Epoch [3501/5000] | Train Loss: 0.050702\n",
      "Validation AVG Loss:     0.000045 \n",
      "\n",
      "Epoch [3502/5000] | Train Loss: 0.050652\n",
      "Validation AVG Loss:     0.000045 \n",
      "\n",
      "Epoch [3503/5000] | Train Loss: 0.050602\n",
      "Validation AVG Loss:     0.000045 \n",
      "\n",
      "Epoch [3504/5000] | Train Loss: 0.050552\n",
      "Validation AVG Loss:     0.000045 \n",
      "\n",
      "Epoch [3505/5000] | Train Loss: 0.050502\n",
      "Validation AVG Loss:     0.000045 \n",
      "\n",
      "Epoch [3506/5000] | Train Loss: 0.050452\n",
      "Validation AVG Loss:     0.000045 \n",
      "\n",
      "Epoch [3507/5000] | Train Loss: 0.050402\n",
      "Validation AVG Loss:     0.000045 \n",
      "\n",
      "Epoch [3508/5000] | Train Loss: 0.050352\n",
      "Validation AVG Loss:     0.000045 \n",
      "\n",
      "Epoch [3509/5000] | Train Loss: 0.050303\n",
      "Validation AVG Loss:     0.000045 \n",
      "\n",
      "Epoch [3510/5000] | Train Loss: 0.050253\n",
      "Validation AVG Loss:     0.000045 \n",
      "\n",
      "Epoch [3511/5000] | Train Loss: 0.050203\n",
      "Validation AVG Loss:     0.000045 \n",
      "\n",
      "Epoch [3512/5000] | Train Loss: 0.050153\n",
      "Validation AVG Loss:     0.000045 \n",
      "\n",
      "Epoch [3513/5000] | Train Loss: 0.050104\n",
      "Validation AVG Loss:     0.000045 \n",
      "\n",
      "Epoch [3514/5000] | Train Loss: 0.050054\n",
      "Validation AVG Loss:     0.000045 \n",
      "\n",
      "Epoch [3515/5000] | Train Loss: 0.050005\n",
      "Validation AVG Loss:     0.000045 \n",
      "\n",
      "Epoch [3516/5000] | Train Loss: 0.049955\n",
      "Validation AVG Loss:     0.000045 \n",
      "\n",
      "Epoch [3517/5000] | Train Loss: 0.049906\n",
      "Validation AVG Loss:     0.000045 \n",
      "\n",
      "Epoch [3518/5000] | Train Loss: 0.049857\n",
      "Validation AVG Loss:     0.000045 \n",
      "\n",
      "Epoch [3519/5000] | Train Loss: 0.049807\n",
      "Validation AVG Loss:     0.000044 \n",
      "\n",
      "Epoch [3520/5000] | Train Loss: 0.049758\n",
      "Validation AVG Loss:     0.000044 \n",
      "\n",
      "Epoch [3521/5000] | Train Loss: 0.049709\n",
      "Validation AVG Loss:     0.000044 \n",
      "\n",
      "Epoch [3522/5000] | Train Loss: 0.049659\n",
      "Validation AVG Loss:     0.000044 \n",
      "\n",
      "Epoch [3523/5000] | Train Loss: 0.049610\n",
      "Validation AVG Loss:     0.000044 \n",
      "\n",
      "Epoch [3524/5000] | Train Loss: 0.049561\n",
      "Validation AVG Loss:     0.000044 \n",
      "\n",
      "Epoch [3525/5000] | Train Loss: 0.049512\n",
      "Validation AVG Loss:     0.000044 \n",
      "\n",
      "Epoch [3526/5000] | Train Loss: 0.049463\n",
      "Validation AVG Loss:     0.000044 \n",
      "\n",
      "Epoch [3527/5000] | Train Loss: 0.049414\n",
      "Validation AVG Loss:     0.000044 \n",
      "\n",
      "Epoch [3528/5000] | Train Loss: 0.049365\n",
      "Validation AVG Loss:     0.000044 \n",
      "\n",
      "Epoch [3529/5000] | Train Loss: 0.049316\n",
      "Validation AVG Loss:     0.000044 \n",
      "\n",
      "Epoch [3530/5000] | Train Loss: 0.049267\n",
      "Validation AVG Loss:     0.000044 \n",
      "\n",
      "Epoch [3531/5000] | Train Loss: 0.049218\n",
      "Validation AVG Loss:     0.000044 \n",
      "\n",
      "Epoch [3532/5000] | Train Loss: 0.049170\n",
      "Validation AVG Loss:     0.000044 \n",
      "\n",
      "Epoch [3533/5000] | Train Loss: 0.049121\n",
      "Validation AVG Loss:     0.000044 \n",
      "\n",
      "Epoch [3534/5000] | Train Loss: 0.049072\n",
      "Validation AVG Loss:     0.000044 \n",
      "\n",
      "Epoch [3535/5000] | Train Loss: 0.049023\n",
      "Validation AVG Loss:     0.000044 \n",
      "\n",
      "Epoch [3536/5000] | Train Loss: 0.048975\n",
      "Validation AVG Loss:     0.000044 \n",
      "\n",
      "Epoch [3537/5000] | Train Loss: 0.048926\n",
      "Validation AVG Loss:     0.000044 \n",
      "\n",
      "Epoch [3538/5000] | Train Loss: 0.048878\n",
      "Validation AVG Loss:     0.000044 \n",
      "\n",
      "Epoch [3539/5000] | Train Loss: 0.048829\n",
      "Validation AVG Loss:     0.000044 \n",
      "\n",
      "Epoch [3540/5000] | Train Loss: 0.048781\n",
      "Validation AVG Loss:     0.000044 \n",
      "\n",
      "Epoch [3541/5000] | Train Loss: 0.048732\n",
      "Validation AVG Loss:     0.000043 \n",
      "\n",
      "Epoch [3542/5000] | Train Loss: 0.048684\n",
      "Validation AVG Loss:     0.000043 \n",
      "\n",
      "Epoch [3543/5000] | Train Loss: 0.048635\n",
      "Validation AVG Loss:     0.000043 \n",
      "\n",
      "Epoch [3544/5000] | Train Loss: 0.048587\n",
      "Validation AVG Loss:     0.000043 \n",
      "\n",
      "Epoch [3545/5000] | Train Loss: 0.048539\n",
      "Validation AVG Loss:     0.000043 \n",
      "\n",
      "Epoch [3546/5000] | Train Loss: 0.048491\n",
      "Validation AVG Loss:     0.000043 \n",
      "\n",
      "Epoch [3547/5000] | Train Loss: 0.048443\n",
      "Validation AVG Loss:     0.000043 \n",
      "\n",
      "Epoch [3548/5000] | Train Loss: 0.048394\n",
      "Validation AVG Loss:     0.000043 \n",
      "\n",
      "Epoch [3549/5000] | Train Loss: 0.048346\n",
      "Validation AVG Loss:     0.000043 \n",
      "\n",
      "Epoch [3550/5000] | Train Loss: 0.048298\n",
      "Validation AVG Loss:     0.000043 \n",
      "\n",
      "Epoch [3551/5000] | Train Loss: 0.048250\n",
      "Validation AVG Loss:     0.000043 \n",
      "\n",
      "Epoch [3552/5000] | Train Loss: 0.048202\n",
      "Validation AVG Loss:     0.000043 \n",
      "\n",
      "Epoch [3553/5000] | Train Loss: 0.048154\n",
      "Validation AVG Loss:     0.000043 \n",
      "\n",
      "Epoch [3554/5000] | Train Loss: 0.048107\n",
      "Validation AVG Loss:     0.000043 \n",
      "\n",
      "Epoch [3555/5000] | Train Loss: 0.048059\n",
      "Validation AVG Loss:     0.000043 \n",
      "\n",
      "Epoch [3556/5000] | Train Loss: 0.048011\n",
      "Validation AVG Loss:     0.000043 \n",
      "\n",
      "Epoch [3557/5000] | Train Loss: 0.047963\n",
      "Validation AVG Loss:     0.000043 \n",
      "\n",
      "Epoch [3558/5000] | Train Loss: 0.047915\n",
      "Validation AVG Loss:     0.000043 \n",
      "\n",
      "Epoch [3559/5000] | Train Loss: 0.047868\n",
      "Validation AVG Loss:     0.000043 \n",
      "\n",
      "Epoch [3560/5000] | Train Loss: 0.047820\n",
      "Validation AVG Loss:     0.000043 \n",
      "\n",
      "Epoch [3561/5000] | Train Loss: 0.047773\n",
      "Validation AVG Loss:     0.000043 \n",
      "\n",
      "Epoch [3562/5000] | Train Loss: 0.047725\n",
      "Validation AVG Loss:     0.000043 \n",
      "\n",
      "Epoch [3563/5000] | Train Loss: 0.047677\n",
      "Validation AVG Loss:     0.000042 \n",
      "\n",
      "Epoch [3564/5000] | Train Loss: 0.047630\n",
      "Validation AVG Loss:     0.000042 \n",
      "\n",
      "Epoch [3565/5000] | Train Loss: 0.047583\n",
      "Validation AVG Loss:     0.000042 \n",
      "\n",
      "Epoch [3566/5000] | Train Loss: 0.047535\n",
      "Validation AVG Loss:     0.000042 \n",
      "\n",
      "Epoch [3567/5000] | Train Loss: 0.047488\n",
      "Validation AVG Loss:     0.000042 \n",
      "\n",
      "Epoch [3568/5000] | Train Loss: 0.047441\n",
      "Validation AVG Loss:     0.000042 \n",
      "\n",
      "Epoch [3569/5000] | Train Loss: 0.047393\n",
      "Validation AVG Loss:     0.000042 \n",
      "\n",
      "Epoch [3570/5000] | Train Loss: 0.047346\n",
      "Validation AVG Loss:     0.000042 \n",
      "\n",
      "Epoch [3571/5000] | Train Loss: 0.047299\n",
      "Validation AVG Loss:     0.000042 \n",
      "\n",
      "Epoch [3572/5000] | Train Loss: 0.047252\n",
      "Validation AVG Loss:     0.000042 \n",
      "\n",
      "Epoch [3573/5000] | Train Loss: 0.047205\n",
      "Validation AVG Loss:     0.000042 \n",
      "\n",
      "Epoch [3574/5000] | Train Loss: 0.047158\n",
      "Validation AVG Loss:     0.000042 \n",
      "\n",
      "Epoch [3575/5000] | Train Loss: 0.047111\n",
      "Validation AVG Loss:     0.000042 \n",
      "\n",
      "Epoch [3576/5000] | Train Loss: 0.047064\n",
      "Validation AVG Loss:     0.000042 \n",
      "\n",
      "Epoch [3577/5000] | Train Loss: 0.047017\n",
      "Validation AVG Loss:     0.000042 \n",
      "\n",
      "Epoch [3578/5000] | Train Loss: 0.046970\n",
      "Validation AVG Loss:     0.000042 \n",
      "\n",
      "Epoch [3579/5000] | Train Loss: 0.046923\n",
      "Validation AVG Loss:     0.000042 \n",
      "\n",
      "Epoch [3580/5000] | Train Loss: 0.046876\n",
      "Validation AVG Loss:     0.000042 \n",
      "\n",
      "Epoch [3581/5000] | Train Loss: 0.046829\n",
      "Validation AVG Loss:     0.000042 \n",
      "\n",
      "Epoch [3582/5000] | Train Loss: 0.046783\n",
      "Validation AVG Loss:     0.000042 \n",
      "\n",
      "Epoch [3583/5000] | Train Loss: 0.046736\n",
      "Validation AVG Loss:     0.000042 \n",
      "\n",
      "Epoch [3584/5000] | Train Loss: 0.046689\n",
      "Validation AVG Loss:     0.000042 \n",
      "\n",
      "Epoch [3585/5000] | Train Loss: 0.046643\n",
      "Validation AVG Loss:     0.000042 \n",
      "\n",
      "Epoch [3586/5000] | Train Loss: 0.046596\n",
      "Validation AVG Loss:     0.000041 \n",
      "\n",
      "Epoch [3587/5000] | Train Loss: 0.046550\n",
      "Validation AVG Loss:     0.000041 \n",
      "\n",
      "Epoch [3588/5000] | Train Loss: 0.046503\n",
      "Validation AVG Loss:     0.000041 \n",
      "\n",
      "Epoch [3589/5000] | Train Loss: 0.046457\n",
      "Validation AVG Loss:     0.000041 \n",
      "\n",
      "Epoch [3590/5000] | Train Loss: 0.046411\n",
      "Validation AVG Loss:     0.000041 \n",
      "\n",
      "Epoch [3591/5000] | Train Loss: 0.046364\n",
      "Validation AVG Loss:     0.000041 \n",
      "\n",
      "Epoch [3592/5000] | Train Loss: 0.046318\n",
      "Validation AVG Loss:     0.000041 \n",
      "\n",
      "Epoch [3593/5000] | Train Loss: 0.046272\n",
      "Validation AVG Loss:     0.000041 \n",
      "\n",
      "Epoch [3594/5000] | Train Loss: 0.046225\n",
      "Validation AVG Loss:     0.000041 \n",
      "\n",
      "Epoch [3595/5000] | Train Loss: 0.046179\n",
      "Validation AVG Loss:     0.000041 \n",
      "\n",
      "Epoch [3596/5000] | Train Loss: 0.046133\n",
      "Validation AVG Loss:     0.000041 \n",
      "\n",
      "Epoch [3597/5000] | Train Loss: 0.046087\n",
      "Validation AVG Loss:     0.000041 \n",
      "\n",
      "Epoch [3598/5000] | Train Loss: 0.046041\n",
      "Validation AVG Loss:     0.000041 \n",
      "\n",
      "Epoch [3599/5000] | Train Loss: 0.045995\n",
      "Validation AVG Loss:     0.000041 \n",
      "\n",
      "Epoch [3600/5000] | Train Loss: 0.045949\n",
      "Validation AVG Loss:     0.000041 \n",
      "\n",
      "Epoch [3601/5000] | Train Loss: 0.045903\n",
      "Validation AVG Loss:     0.000041 \n",
      "\n",
      "Epoch [3602/5000] | Train Loss: 0.045857\n",
      "Validation AVG Loss:     0.000041 \n",
      "\n",
      "Epoch [3603/5000] | Train Loss: 0.045811\n",
      "Validation AVG Loss:     0.000041 \n",
      "\n",
      "Epoch [3604/5000] | Train Loss: 0.045766\n",
      "Validation AVG Loss:     0.000041 \n",
      "\n",
      "Epoch [3605/5000] | Train Loss: 0.045720\n",
      "Validation AVG Loss:     0.000041 \n",
      "\n",
      "Epoch [3606/5000] | Train Loss: 0.045674\n",
      "Validation AVG Loss:     0.000041 \n",
      "\n",
      "Epoch [3607/5000] | Train Loss: 0.045628\n",
      "Validation AVG Loss:     0.000041 \n",
      "\n",
      "Epoch [3608/5000] | Train Loss: 0.045583\n",
      "Validation AVG Loss:     0.000041 \n",
      "\n",
      "Epoch [3609/5000] | Train Loss: 0.045537\n",
      "Validation AVG Loss:     0.000041 \n",
      "\n",
      "Epoch [3610/5000] | Train Loss: 0.045492\n",
      "Validation AVG Loss:     0.000040 \n",
      "\n",
      "Epoch [3611/5000] | Train Loss: 0.045446\n",
      "Validation AVG Loss:     0.000040 \n",
      "\n",
      "Epoch [3612/5000] | Train Loss: 0.045401\n",
      "Validation AVG Loss:     0.000040 \n",
      "\n",
      "Epoch [3613/5000] | Train Loss: 0.045355\n",
      "Validation AVG Loss:     0.000040 \n",
      "\n",
      "Epoch [3614/5000] | Train Loss: 0.045310\n",
      "Validation AVG Loss:     0.000040 \n",
      "\n",
      "Epoch [3615/5000] | Train Loss: 0.045264\n",
      "Validation AVG Loss:     0.000040 \n",
      "\n",
      "Epoch [3616/5000] | Train Loss: 0.045219\n",
      "Validation AVG Loss:     0.000040 \n",
      "\n",
      "Epoch [3617/5000] | Train Loss: 0.045174\n",
      "Validation AVG Loss:     0.000040 \n",
      "\n",
      "Epoch [3618/5000] | Train Loss: 0.045129\n",
      "Validation AVG Loss:     0.000040 \n",
      "\n",
      "Epoch [3619/5000] | Train Loss: 0.045083\n",
      "Validation AVG Loss:     0.000040 \n",
      "\n",
      "Epoch [3620/5000] | Train Loss: 0.045038\n",
      "Validation AVG Loss:     0.000040 \n",
      "\n",
      "Epoch [3621/5000] | Train Loss: 0.044993\n",
      "Validation AVG Loss:     0.000040 \n",
      "\n",
      "Epoch [3622/5000] | Train Loss: 0.044948\n",
      "Validation AVG Loss:     0.000040 \n",
      "\n",
      "Epoch [3623/5000] | Train Loss: 0.044903\n",
      "Validation AVG Loss:     0.000040 \n",
      "\n",
      "Epoch [3624/5000] | Train Loss: 0.044858\n",
      "Validation AVG Loss:     0.000040 \n",
      "\n",
      "Epoch [3625/5000] | Train Loss: 0.044813\n",
      "Validation AVG Loss:     0.000040 \n",
      "\n",
      "Epoch [3626/5000] | Train Loss: 0.044768\n",
      "Validation AVG Loss:     0.000040 \n",
      "\n",
      "Epoch [3627/5000] | Train Loss: 0.044723\n",
      "Validation AVG Loss:     0.000040 \n",
      "\n",
      "Epoch [3628/5000] | Train Loss: 0.044679\n",
      "Validation AVG Loss:     0.000040 \n",
      "\n",
      "Epoch [3629/5000] | Train Loss: 0.044634\n",
      "Validation AVG Loss:     0.000040 \n",
      "\n",
      "Epoch [3630/5000] | Train Loss: 0.044589\n",
      "Validation AVG Loss:     0.000040 \n",
      "\n",
      "Epoch [3631/5000] | Train Loss: 0.044544\n",
      "Validation AVG Loss:     0.000040 \n",
      "\n",
      "Epoch [3632/5000] | Train Loss: 0.044500\n",
      "Validation AVG Loss:     0.000040 \n",
      "\n",
      "Epoch [3633/5000] | Train Loss: 0.044455\n",
      "Validation AVG Loss:     0.000040 \n",
      "\n",
      "Epoch [3634/5000] | Train Loss: 0.044410\n",
      "Validation AVG Loss:     0.000039 \n",
      "\n",
      "Epoch [3635/5000] | Train Loss: 0.044366\n",
      "Validation AVG Loss:     0.000039 \n",
      "\n",
      "Epoch [3636/5000] | Train Loss: 0.044321\n",
      "Validation AVG Loss:     0.000039 \n",
      "\n",
      "Epoch [3637/5000] | Train Loss: 0.044277\n",
      "Validation AVG Loss:     0.000039 \n",
      "\n",
      "Epoch [3638/5000] | Train Loss: 0.044233\n",
      "Validation AVG Loss:     0.000039 \n",
      "\n",
      "Epoch [3639/5000] | Train Loss: 0.044188\n",
      "Validation AVG Loss:     0.000039 \n",
      "\n",
      "Epoch [3640/5000] | Train Loss: 0.044144\n",
      "Validation AVG Loss:     0.000039 \n",
      "\n",
      "Epoch [3641/5000] | Train Loss: 0.044100\n",
      "Validation AVG Loss:     0.000039 \n",
      "\n",
      "Epoch [3642/5000] | Train Loss: 0.044055\n",
      "Validation AVG Loss:     0.000039 \n",
      "\n",
      "Epoch [3643/5000] | Train Loss: 0.044011\n",
      "Validation AVG Loss:     0.000039 \n",
      "\n",
      "Epoch [3644/5000] | Train Loss: 0.043967\n",
      "Validation AVG Loss:     0.000039 \n",
      "\n",
      "Epoch [3645/5000] | Train Loss: 0.043923\n",
      "Validation AVG Loss:     0.000039 \n",
      "\n",
      "Epoch [3646/5000] | Train Loss: 0.043879\n",
      "Validation AVG Loss:     0.000039 \n",
      "\n",
      "Epoch [3647/5000] | Train Loss: 0.043835\n",
      "Validation AVG Loss:     0.000039 \n",
      "\n",
      "Epoch [3648/5000] | Train Loss: 0.043791\n",
      "Validation AVG Loss:     0.000039 \n",
      "\n",
      "Epoch [3649/5000] | Train Loss: 0.043747\n",
      "Validation AVG Loss:     0.000039 \n",
      "\n",
      "Epoch [3650/5000] | Train Loss: 0.043703\n",
      "Validation AVG Loss:     0.000039 \n",
      "\n",
      "Epoch [3651/5000] | Train Loss: 0.043659\n",
      "Validation AVG Loss:     0.000039 \n",
      "\n",
      "Epoch [3652/5000] | Train Loss: 0.043615\n",
      "Validation AVG Loss:     0.000039 \n",
      "\n",
      "Epoch [3653/5000] | Train Loss: 0.043571\n",
      "Validation AVG Loss:     0.000039 \n",
      "\n",
      "Epoch [3654/5000] | Train Loss: 0.043527\n",
      "Validation AVG Loss:     0.000039 \n",
      "\n",
      "Epoch [3655/5000] | Train Loss: 0.043484\n",
      "Validation AVG Loss:     0.000039 \n",
      "\n",
      "Epoch [3656/5000] | Train Loss: 0.043440\n",
      "Validation AVG Loss:     0.000039 \n",
      "\n",
      "Epoch [3657/5000] | Train Loss: 0.043396\n",
      "Validation AVG Loss:     0.000039 \n",
      "\n",
      "Epoch [3658/5000] | Train Loss: 0.043353\n",
      "Validation AVG Loss:     0.000039 \n",
      "\n",
      "Epoch [3659/5000] | Train Loss: 0.043309\n",
      "Validation AVG Loss:     0.000038 \n",
      "\n",
      "Epoch [3660/5000] | Train Loss: 0.043266\n",
      "Validation AVG Loss:     0.000038 \n",
      "\n",
      "Epoch [3661/5000] | Train Loss: 0.043222\n",
      "Validation AVG Loss:     0.000038 \n",
      "\n",
      "Epoch [3662/5000] | Train Loss: 0.043179\n",
      "Validation AVG Loss:     0.000038 \n",
      "\n",
      "Epoch [3663/5000] | Train Loss: 0.043135\n",
      "Validation AVG Loss:     0.000038 \n",
      "\n",
      "Epoch [3664/5000] | Train Loss: 0.043092\n",
      "Validation AVG Loss:     0.000038 \n",
      "\n",
      "Epoch [3665/5000] | Train Loss: 0.043049\n",
      "Validation AVG Loss:     0.000038 \n",
      "\n",
      "Epoch [3666/5000] | Train Loss: 0.043005\n",
      "Validation AVG Loss:     0.000038 \n",
      "\n",
      "Epoch [3667/5000] | Train Loss: 0.042962\n",
      "Validation AVG Loss:     0.000038 \n",
      "\n",
      "Epoch [3668/5000] | Train Loss: 0.042919\n",
      "Validation AVG Loss:     0.000038 \n",
      "\n",
      "Epoch [3669/5000] | Train Loss: 0.042876\n",
      "Validation AVG Loss:     0.000038 \n",
      "\n",
      "Epoch [3670/5000] | Train Loss: 0.042833\n",
      "Validation AVG Loss:     0.000038 \n",
      "\n",
      "Epoch [3671/5000] | Train Loss: 0.042789\n",
      "Validation AVG Loss:     0.000038 \n",
      "\n",
      "Epoch [3672/5000] | Train Loss: 0.042746\n",
      "Validation AVG Loss:     0.000038 \n",
      "\n",
      "Epoch [3673/5000] | Train Loss: 0.042703\n",
      "Validation AVG Loss:     0.000038 \n",
      "\n",
      "Epoch [3674/5000] | Train Loss: 0.042660\n",
      "Validation AVG Loss:     0.000038 \n",
      "\n",
      "Epoch [3675/5000] | Train Loss: 0.042618\n",
      "Validation AVG Loss:     0.000038 \n",
      "\n",
      "Epoch [3676/5000] | Train Loss: 0.042575\n",
      "Validation AVG Loss:     0.000038 \n",
      "\n",
      "Epoch [3677/5000] | Train Loss: 0.042532\n",
      "Validation AVG Loss:     0.000038 \n",
      "\n",
      "Epoch [3678/5000] | Train Loss: 0.042489\n",
      "Validation AVG Loss:     0.000038 \n",
      "\n",
      "Epoch [3679/5000] | Train Loss: 0.042446\n",
      "Validation AVG Loss:     0.000038 \n",
      "\n",
      "Epoch [3680/5000] | Train Loss: 0.042404\n",
      "Validation AVG Loss:     0.000038 \n",
      "\n",
      "Epoch [3681/5000] | Train Loss: 0.042361\n",
      "Validation AVG Loss:     0.000038 \n",
      "\n",
      "Epoch [3682/5000] | Train Loss: 0.042318\n",
      "Validation AVG Loss:     0.000038 \n",
      "\n",
      "Epoch [3683/5000] | Train Loss: 0.042276\n",
      "Validation AVG Loss:     0.000038 \n",
      "\n",
      "Epoch [3684/5000] | Train Loss: 0.042233\n",
      "Validation AVG Loss:     0.000037 \n",
      "\n",
      "Epoch [3685/5000] | Train Loss: 0.042191\n",
      "Validation AVG Loss:     0.000037 \n",
      "\n",
      "Epoch [3686/5000] | Train Loss: 0.042148\n",
      "Validation AVG Loss:     0.000037 \n",
      "\n",
      "Epoch [3687/5000] | Train Loss: 0.042106\n",
      "Validation AVG Loss:     0.000037 \n",
      "\n",
      "Epoch [3688/5000] | Train Loss: 0.042063\n",
      "Validation AVG Loss:     0.000037 \n",
      "\n",
      "Epoch [3689/5000] | Train Loss: 0.042021\n",
      "Validation AVG Loss:     0.000037 \n",
      "\n",
      "Epoch [3690/5000] | Train Loss: 0.041979\n",
      "Validation AVG Loss:     0.000037 \n",
      "\n",
      "Epoch [3691/5000] | Train Loss: 0.041936\n",
      "Validation AVG Loss:     0.000037 \n",
      "\n",
      "Epoch [3692/5000] | Train Loss: 0.041894\n",
      "Validation AVG Loss:     0.000037 \n",
      "\n",
      "Epoch [3693/5000] | Train Loss: 0.041852\n",
      "Validation AVG Loss:     0.000037 \n",
      "\n",
      "Epoch [3694/5000] | Train Loss: 0.041810\n",
      "Validation AVG Loss:     0.000037 \n",
      "\n",
      "Epoch [3695/5000] | Train Loss: 0.041768\n",
      "Validation AVG Loss:     0.000037 \n",
      "\n",
      "Epoch [3696/5000] | Train Loss: 0.041726\n",
      "Validation AVG Loss:     0.000037 \n",
      "\n",
      "Epoch [3697/5000] | Train Loss: 0.041684\n",
      "Validation AVG Loss:     0.000037 \n",
      "\n",
      "Epoch [3698/5000] | Train Loss: 0.041642\n",
      "Validation AVG Loss:     0.000037 \n",
      "\n",
      "Epoch [3699/5000] | Train Loss: 0.041600\n",
      "Validation AVG Loss:     0.000037 \n",
      "\n",
      "Epoch [3700/5000] | Train Loss: 0.041558\n",
      "Validation AVG Loss:     0.000037 \n",
      "\n",
      "Epoch [3701/5000] | Train Loss: 0.041516\n",
      "Validation AVG Loss:     0.000037 \n",
      "\n",
      "Epoch [3702/5000] | Train Loss: 0.041474\n",
      "Validation AVG Loss:     0.000037 \n",
      "\n",
      "Epoch [3703/5000] | Train Loss: 0.041432\n",
      "Validation AVG Loss:     0.000037 \n",
      "\n",
      "Epoch [3704/5000] | Train Loss: 0.041390\n",
      "Validation AVG Loss:     0.000037 \n",
      "\n",
      "Epoch [3705/5000] | Train Loss: 0.041349\n",
      "Validation AVG Loss:     0.000037 \n",
      "\n",
      "Epoch [3706/5000] | Train Loss: 0.041307\n",
      "Validation AVG Loss:     0.000037 \n",
      "\n",
      "Epoch [3707/5000] | Train Loss: 0.041265\n",
      "Validation AVG Loss:     0.000037 \n",
      "\n",
      "Epoch [3708/5000] | Train Loss: 0.041224\n",
      "Validation AVG Loss:     0.000037 \n",
      "\n",
      "Epoch [3709/5000] | Train Loss: 0.041182\n",
      "Validation AVG Loss:     0.000037 \n",
      "\n",
      "Epoch [3710/5000] | Train Loss: 0.041141\n",
      "Validation AVG Loss:     0.000036 \n",
      "\n",
      "Epoch [3711/5000] | Train Loss: 0.041099\n",
      "Validation AVG Loss:     0.000036 \n",
      "\n",
      "Epoch [3712/5000] | Train Loss: 0.041058\n",
      "Validation AVG Loss:     0.000036 \n",
      "\n",
      "Epoch [3713/5000] | Train Loss: 0.041017\n",
      "Validation AVG Loss:     0.000036 \n",
      "\n",
      "Epoch [3714/5000] | Train Loss: 0.040975\n",
      "Validation AVG Loss:     0.000036 \n",
      "\n",
      "Epoch [3715/5000] | Train Loss: 0.040934\n",
      "Validation AVG Loss:     0.000036 \n",
      "\n",
      "Epoch [3716/5000] | Train Loss: 0.040893\n",
      "Validation AVG Loss:     0.000036 \n",
      "\n",
      "Epoch [3717/5000] | Train Loss: 0.040851\n",
      "Validation AVG Loss:     0.000036 \n",
      "\n",
      "Epoch [3718/5000] | Train Loss: 0.040810\n",
      "Validation AVG Loss:     0.000036 \n",
      "\n",
      "Epoch [3719/5000] | Train Loss: 0.040769\n",
      "Validation AVG Loss:     0.000036 \n",
      "\n",
      "Epoch [3720/5000] | Train Loss: 0.040728\n",
      "Validation AVG Loss:     0.000036 \n",
      "\n",
      "Epoch [3721/5000] | Train Loss: 0.040687\n",
      "Validation AVG Loss:     0.000036 \n",
      "\n",
      "Epoch [3722/5000] | Train Loss: 0.040646\n",
      "Validation AVG Loss:     0.000036 \n",
      "\n",
      "Epoch [3723/5000] | Train Loss: 0.040605\n",
      "Validation AVG Loss:     0.000036 \n",
      "\n",
      "Epoch [3724/5000] | Train Loss: 0.040564\n",
      "Validation AVG Loss:     0.000036 \n",
      "\n",
      "Epoch [3725/5000] | Train Loss: 0.040523\n",
      "Validation AVG Loss:     0.000036 \n",
      "\n",
      "Epoch [3726/5000] | Train Loss: 0.040482\n",
      "Validation AVG Loss:     0.000036 \n",
      "\n",
      "Epoch [3727/5000] | Train Loss: 0.040441\n",
      "Validation AVG Loss:     0.000036 \n",
      "\n",
      "Epoch [3728/5000] | Train Loss: 0.040400\n",
      "Validation AVG Loss:     0.000036 \n",
      "\n",
      "Epoch [3729/5000] | Train Loss: 0.040360\n",
      "Validation AVG Loss:     0.000036 \n",
      "\n",
      "Epoch [3730/5000] | Train Loss: 0.040319\n",
      "Validation AVG Loss:     0.000036 \n",
      "\n",
      "Epoch [3731/5000] | Train Loss: 0.040278\n",
      "Validation AVG Loss:     0.000036 \n",
      "\n",
      "Epoch [3732/5000] | Train Loss: 0.040238\n",
      "Validation AVG Loss:     0.000036 \n",
      "\n",
      "Epoch [3733/5000] | Train Loss: 0.040197\n",
      "Validation AVG Loss:     0.000036 \n",
      "\n",
      "Epoch [3734/5000] | Train Loss: 0.040157\n",
      "Validation AVG Loss:     0.000036 \n",
      "\n",
      "Epoch [3735/5000] | Train Loss: 0.040116\n",
      "Validation AVG Loss:     0.000036 \n",
      "\n",
      "Epoch [3736/5000] | Train Loss: 0.040076\n",
      "Validation AVG Loss:     0.000036 \n",
      "\n",
      "Epoch [3737/5000] | Train Loss: 0.040035\n",
      "Validation AVG Loss:     0.000035 \n",
      "\n",
      "Epoch [3738/5000] | Train Loss: 0.039995\n",
      "Validation AVG Loss:     0.000035 \n",
      "\n",
      "Epoch [3739/5000] | Train Loss: 0.039954\n",
      "Validation AVG Loss:     0.000035 \n",
      "\n",
      "Epoch [3740/5000] | Train Loss: 0.039914\n",
      "Validation AVG Loss:     0.000035 \n",
      "\n",
      "Epoch [3741/5000] | Train Loss: 0.039874\n",
      "Validation AVG Loss:     0.000035 \n",
      "\n",
      "Epoch [3742/5000] | Train Loss: 0.039834\n",
      "Validation AVG Loss:     0.000035 \n",
      "\n",
      "Epoch [3743/5000] | Train Loss: 0.039793\n",
      "Validation AVG Loss:     0.000035 \n",
      "\n",
      "Epoch [3744/5000] | Train Loss: 0.039753\n",
      "Validation AVG Loss:     0.000035 \n",
      "\n",
      "Epoch [3745/5000] | Train Loss: 0.039713\n",
      "Validation AVG Loss:     0.000035 \n",
      "\n",
      "Epoch [3746/5000] | Train Loss: 0.039673\n",
      "Validation AVG Loss:     0.000035 \n",
      "\n",
      "Epoch [3747/5000] | Train Loss: 0.039633\n",
      "Validation AVG Loss:     0.000035 \n",
      "\n",
      "Epoch [3748/5000] | Train Loss: 0.039593\n",
      "Validation AVG Loss:     0.000035 \n",
      "\n",
      "Epoch [3749/5000] | Train Loss: 0.039553\n",
      "Validation AVG Loss:     0.000035 \n",
      "\n",
      "Epoch [3750/5000] | Train Loss: 0.039513\n",
      "Validation AVG Loss:     0.000035 \n",
      "\n",
      "Epoch [3751/5000] | Train Loss: 0.039473\n",
      "Validation AVG Loss:     0.000035 \n",
      "\n",
      "Epoch [3752/5000] | Train Loss: 0.039433\n",
      "Validation AVG Loss:     0.000035 \n",
      "\n",
      "Epoch [3753/5000] | Train Loss: 0.039394\n",
      "Validation AVG Loss:     0.000035 \n",
      "\n",
      "Epoch [3754/5000] | Train Loss: 0.039354\n",
      "Validation AVG Loss:     0.000035 \n",
      "\n",
      "Epoch [3755/5000] | Train Loss: 0.039314\n",
      "Validation AVG Loss:     0.000035 \n",
      "\n",
      "Epoch [3756/5000] | Train Loss: 0.039274\n",
      "Validation AVG Loss:     0.000035 \n",
      "\n",
      "Epoch [3757/5000] | Train Loss: 0.039235\n",
      "Validation AVG Loss:     0.000035 \n",
      "\n",
      "Epoch [3758/5000] | Train Loss: 0.039195\n",
      "Validation AVG Loss:     0.000035 \n",
      "\n",
      "Epoch [3759/5000] | Train Loss: 0.039156\n",
      "Validation AVG Loss:     0.000035 \n",
      "\n",
      "Epoch [3760/5000] | Train Loss: 0.039116\n",
      "Validation AVG Loss:     0.000035 \n",
      "\n",
      "Epoch [3761/5000] | Train Loss: 0.039076\n",
      "Validation AVG Loss:     0.000035 \n",
      "\n",
      "Epoch [3762/5000] | Train Loss: 0.039037\n",
      "Validation AVG Loss:     0.000035 \n",
      "\n",
      "Epoch [3763/5000] | Train Loss: 0.038998\n",
      "Validation AVG Loss:     0.000035 \n",
      "\n",
      "Epoch [3764/5000] | Train Loss: 0.038958\n",
      "Validation AVG Loss:     0.000034 \n",
      "\n",
      "Epoch [3765/5000] | Train Loss: 0.038919\n",
      "Validation AVG Loss:     0.000034 \n",
      "\n",
      "Epoch [3766/5000] | Train Loss: 0.038880\n",
      "Validation AVG Loss:     0.000034 \n",
      "\n",
      "Epoch [3767/5000] | Train Loss: 0.038840\n",
      "Validation AVG Loss:     0.000034 \n",
      "\n",
      "Epoch [3768/5000] | Train Loss: 0.038801\n",
      "Validation AVG Loss:     0.000034 \n",
      "\n",
      "Epoch [3769/5000] | Train Loss: 0.038762\n",
      "Validation AVG Loss:     0.000034 \n",
      "\n",
      "Epoch [3770/5000] | Train Loss: 0.038723\n",
      "Validation AVG Loss:     0.000034 \n",
      "\n",
      "Epoch [3771/5000] | Train Loss: 0.038684\n",
      "Validation AVG Loss:     0.000034 \n",
      "\n",
      "Epoch [3772/5000] | Train Loss: 0.038645\n",
      "Validation AVG Loss:     0.000034 \n",
      "\n",
      "Epoch [3773/5000] | Train Loss: 0.038606\n",
      "Validation AVG Loss:     0.000034 \n",
      "\n",
      "Epoch [3774/5000] | Train Loss: 0.038567\n",
      "Validation AVG Loss:     0.000034 \n",
      "\n",
      "Epoch [3775/5000] | Train Loss: 0.038528\n",
      "Validation AVG Loss:     0.000034 \n",
      "\n",
      "Epoch [3776/5000] | Train Loss: 0.038489\n",
      "Validation AVG Loss:     0.000034 \n",
      "\n",
      "Epoch [3777/5000] | Train Loss: 0.038450\n",
      "Validation AVG Loss:     0.000034 \n",
      "\n",
      "Epoch [3778/5000] | Train Loss: 0.038411\n",
      "Validation AVG Loss:     0.000034 \n",
      "\n",
      "Epoch [3779/5000] | Train Loss: 0.038372\n",
      "Validation AVG Loss:     0.000034 \n",
      "\n",
      "Epoch [3780/5000] | Train Loss: 0.038334\n",
      "Validation AVG Loss:     0.000034 \n",
      "\n",
      "Epoch [3781/5000] | Train Loss: 0.038295\n",
      "Validation AVG Loss:     0.000034 \n",
      "\n",
      "Epoch [3782/5000] | Train Loss: 0.038256\n",
      "Validation AVG Loss:     0.000034 \n",
      "\n",
      "Epoch [3783/5000] | Train Loss: 0.038218\n",
      "Validation AVG Loss:     0.000034 \n",
      "\n",
      "Epoch [3784/5000] | Train Loss: 0.038179\n",
      "Validation AVG Loss:     0.000034 \n",
      "\n",
      "Epoch [3785/5000] | Train Loss: 0.038140\n",
      "Validation AVG Loss:     0.000034 \n",
      "\n",
      "Epoch [3786/5000] | Train Loss: 0.038102\n",
      "Validation AVG Loss:     0.000034 \n",
      "\n",
      "Epoch [3787/5000] | Train Loss: 0.038063\n",
      "Validation AVG Loss:     0.000034 \n",
      "\n",
      "Epoch [3788/5000] | Train Loss: 0.038025\n",
      "Validation AVG Loss:     0.000034 \n",
      "\n",
      "Epoch [3789/5000] | Train Loss: 0.037987\n",
      "Validation AVG Loss:     0.000034 \n",
      "\n",
      "Epoch [3790/5000] | Train Loss: 0.037948\n",
      "Validation AVG Loss:     0.000034 \n",
      "\n",
      "Epoch [3791/5000] | Train Loss: 0.037910\n",
      "Validation AVG Loss:     0.000034 \n",
      "\n",
      "Epoch [3792/5000] | Train Loss: 0.037872\n",
      "Validation AVG Loss:     0.000033 \n",
      "\n",
      "Epoch [3793/5000] | Train Loss: 0.037833\n",
      "Validation AVG Loss:     0.000033 \n",
      "\n",
      "Epoch [3794/5000] | Train Loss: 0.037795\n",
      "Validation AVG Loss:     0.000033 \n",
      "\n",
      "Epoch [3795/5000] | Train Loss: 0.037757\n",
      "Validation AVG Loss:     0.000033 \n",
      "\n",
      "Epoch [3796/5000] | Train Loss: 0.037719\n",
      "Validation AVG Loss:     0.000033 \n",
      "\n",
      "Epoch [3797/5000] | Train Loss: 0.037681\n",
      "Validation AVG Loss:     0.000033 \n",
      "\n",
      "Epoch [3798/5000] | Train Loss: 0.037643\n",
      "Validation AVG Loss:     0.000033 \n",
      "\n",
      "Epoch [3799/5000] | Train Loss: 0.037605\n",
      "Validation AVG Loss:     0.000033 \n",
      "\n",
      "Epoch [3800/5000] | Train Loss: 0.037567\n",
      "Validation AVG Loss:     0.000033 \n",
      "\n",
      "Epoch [3801/5000] | Train Loss: 0.037529\n",
      "Validation AVG Loss:     0.000033 \n",
      "\n",
      "Epoch [3802/5000] | Train Loss: 0.037491\n",
      "Validation AVG Loss:     0.000033 \n",
      "\n",
      "Epoch [3803/5000] | Train Loss: 0.037453\n",
      "Validation AVG Loss:     0.000033 \n",
      "\n",
      "Epoch [3804/5000] | Train Loss: 0.037415\n",
      "Validation AVG Loss:     0.000033 \n",
      "\n",
      "Epoch [3805/5000] | Train Loss: 0.037377\n",
      "Validation AVG Loss:     0.000033 \n",
      "\n",
      "Epoch [3806/5000] | Train Loss: 0.037340\n",
      "Validation AVG Loss:     0.000033 \n",
      "\n",
      "Epoch [3807/5000] | Train Loss: 0.037302\n",
      "Validation AVG Loss:     0.000033 \n",
      "\n",
      "Epoch [3808/5000] | Train Loss: 0.037264\n",
      "Validation AVG Loss:     0.000033 \n",
      "\n",
      "Epoch [3809/5000] | Train Loss: 0.037227\n",
      "Validation AVG Loss:     0.000033 \n",
      "\n",
      "Epoch [3810/5000] | Train Loss: 0.037189\n",
      "Validation AVG Loss:     0.000033 \n",
      "\n",
      "Epoch [3811/5000] | Train Loss: 0.037152\n",
      "Validation AVG Loss:     0.000033 \n",
      "\n",
      "Epoch [3812/5000] | Train Loss: 0.037114\n",
      "Validation AVG Loss:     0.000033 \n",
      "\n",
      "Epoch [3813/5000] | Train Loss: 0.037077\n",
      "Validation AVG Loss:     0.000033 \n",
      "\n",
      "Epoch [3814/5000] | Train Loss: 0.037039\n",
      "Validation AVG Loss:     0.000033 \n",
      "\n",
      "Epoch [3815/5000] | Train Loss: 0.037002\n",
      "Validation AVG Loss:     0.000033 \n",
      "\n",
      "Epoch [3816/5000] | Train Loss: 0.036964\n",
      "Validation AVG Loss:     0.000033 \n",
      "\n",
      "Epoch [3817/5000] | Train Loss: 0.036927\n",
      "Validation AVG Loss:     0.000033 \n",
      "\n",
      "Epoch [3818/5000] | Train Loss: 0.036890\n",
      "Validation AVG Loss:     0.000033 \n",
      "\n",
      "Epoch [3819/5000] | Train Loss: 0.036853\n",
      "Validation AVG Loss:     0.000033 \n",
      "\n",
      "Epoch [3820/5000] | Train Loss: 0.036815\n",
      "Validation AVG Loss:     0.000033 \n",
      "\n",
      "Epoch [3821/5000] | Train Loss: 0.036778\n",
      "Validation AVG Loss:     0.000032 \n",
      "\n",
      "Epoch [3822/5000] | Train Loss: 0.036741\n",
      "Validation AVG Loss:     0.000032 \n",
      "\n",
      "Epoch [3823/5000] | Train Loss: 0.036704\n",
      "Validation AVG Loss:     0.000032 \n",
      "\n",
      "Epoch [3824/5000] | Train Loss: 0.036667\n",
      "Validation AVG Loss:     0.000032 \n",
      "\n",
      "Epoch [3825/5000] | Train Loss: 0.036630\n",
      "Validation AVG Loss:     0.000032 \n",
      "\n",
      "Epoch [3826/5000] | Train Loss: 0.036593\n",
      "Validation AVG Loss:     0.000032 \n",
      "\n",
      "Epoch [3827/5000] | Train Loss: 0.036556\n",
      "Validation AVG Loss:     0.000032 \n",
      "\n",
      "Epoch [3828/5000] | Train Loss: 0.036519\n",
      "Validation AVG Loss:     0.000032 \n",
      "\n",
      "Epoch [3829/5000] | Train Loss: 0.036482\n",
      "Validation AVG Loss:     0.000032 \n",
      "\n",
      "Epoch [3830/5000] | Train Loss: 0.036446\n",
      "Validation AVG Loss:     0.000032 \n",
      "\n",
      "Epoch [3831/5000] | Train Loss: 0.036409\n",
      "Validation AVG Loss:     0.000032 \n",
      "\n",
      "Epoch [3832/5000] | Train Loss: 0.036372\n",
      "Validation AVG Loss:     0.000032 \n",
      "\n",
      "Epoch [3833/5000] | Train Loss: 0.036335\n",
      "Validation AVG Loss:     0.000032 \n",
      "\n",
      "Epoch [3834/5000] | Train Loss: 0.036299\n",
      "Validation AVG Loss:     0.000032 \n",
      "\n",
      "Epoch [3835/5000] | Train Loss: 0.036262\n",
      "Validation AVG Loss:     0.000032 \n",
      "\n",
      "Epoch [3836/5000] | Train Loss: 0.036225\n",
      "Validation AVG Loss:     0.000032 \n",
      "\n",
      "Epoch [3837/5000] | Train Loss: 0.036189\n",
      "Validation AVG Loss:     0.000032 \n",
      "\n",
      "Epoch [3838/5000] | Train Loss: 0.036152\n",
      "Validation AVG Loss:     0.000032 \n",
      "\n",
      "Epoch [3839/5000] | Train Loss: 0.036116\n",
      "Validation AVG Loss:     0.000032 \n",
      "\n",
      "Epoch [3840/5000] | Train Loss: 0.036079\n",
      "Validation AVG Loss:     0.000032 \n",
      "\n",
      "Epoch [3841/5000] | Train Loss: 0.036043\n",
      "Validation AVG Loss:     0.000032 \n",
      "\n",
      "Epoch [3842/5000] | Train Loss: 0.036007\n",
      "Validation AVG Loss:     0.000032 \n",
      "\n",
      "Epoch [3843/5000] | Train Loss: 0.035970\n",
      "Validation AVG Loss:     0.000032 \n",
      "\n",
      "Epoch [3844/5000] | Train Loss: 0.035934\n",
      "Validation AVG Loss:     0.000032 \n",
      "\n",
      "Epoch [3845/5000] | Train Loss: 0.035898\n",
      "Validation AVG Loss:     0.000032 \n",
      "\n",
      "Epoch [3846/5000] | Train Loss: 0.035862\n",
      "Validation AVG Loss:     0.000032 \n",
      "\n",
      "Epoch [3847/5000] | Train Loss: 0.035825\n",
      "Validation AVG Loss:     0.000032 \n",
      "\n",
      "Epoch [3848/5000] | Train Loss: 0.035789\n",
      "Validation AVG Loss:     0.000032 \n",
      "\n",
      "Epoch [3849/5000] | Train Loss: 0.035753\n",
      "Validation AVG Loss:     0.000032 \n",
      "\n",
      "Epoch [3850/5000] | Train Loss: 0.035717\n",
      "Validation AVG Loss:     0.000032 \n",
      "\n",
      "Epoch [3851/5000] | Train Loss: 0.035681\n",
      "Validation AVG Loss:     0.000031 \n",
      "\n",
      "Epoch [3852/5000] | Train Loss: 0.035645\n",
      "Validation AVG Loss:     0.000031 \n",
      "\n",
      "Epoch [3853/5000] | Train Loss: 0.035609\n",
      "Validation AVG Loss:     0.000031 \n",
      "\n",
      "Epoch [3854/5000] | Train Loss: 0.035573\n",
      "Validation AVG Loss:     0.000031 \n",
      "\n",
      "Epoch [3855/5000] | Train Loss: 0.035537\n",
      "Validation AVG Loss:     0.000031 \n",
      "\n",
      "Epoch [3856/5000] | Train Loss: 0.035502\n",
      "Validation AVG Loss:     0.000031 \n",
      "\n",
      "Epoch [3857/5000] | Train Loss: 0.035466\n",
      "Validation AVG Loss:     0.000031 \n",
      "\n",
      "Epoch [3858/5000] | Train Loss: 0.035430\n",
      "Validation AVG Loss:     0.000031 \n",
      "\n",
      "Epoch [3859/5000] | Train Loss: 0.035394\n",
      "Validation AVG Loss:     0.000031 \n",
      "\n",
      "Epoch [3860/5000] | Train Loss: 0.035359\n",
      "Validation AVG Loss:     0.000031 \n",
      "\n",
      "Epoch [3861/5000] | Train Loss: 0.035323\n",
      "Validation AVG Loss:     0.000031 \n",
      "\n",
      "Epoch [3862/5000] | Train Loss: 0.035287\n",
      "Validation AVG Loss:     0.000031 \n",
      "\n",
      "Epoch [3863/5000] | Train Loss: 0.035252\n",
      "Validation AVG Loss:     0.000031 \n",
      "\n",
      "Epoch [3864/5000] | Train Loss: 0.035216\n",
      "Validation AVG Loss:     0.000031 \n",
      "\n",
      "Epoch [3865/5000] | Train Loss: 0.035181\n",
      "Validation AVG Loss:     0.000031 \n",
      "\n",
      "Epoch [3866/5000] | Train Loss: 0.035145\n",
      "Validation AVG Loss:     0.000031 \n",
      "\n",
      "Epoch [3867/5000] | Train Loss: 0.035110\n",
      "Validation AVG Loss:     0.000031 \n",
      "\n",
      "Epoch [3868/5000] | Train Loss: 0.035074\n",
      "Validation AVG Loss:     0.000031 \n",
      "\n",
      "Epoch [3869/5000] | Train Loss: 0.035039\n",
      "Validation AVG Loss:     0.000031 \n",
      "\n",
      "Epoch [3870/5000] | Train Loss: 0.035004\n",
      "Validation AVG Loss:     0.000031 \n",
      "\n",
      "Epoch [3871/5000] | Train Loss: 0.034968\n",
      "Validation AVG Loss:     0.000031 \n",
      "\n",
      "Epoch [3872/5000] | Train Loss: 0.034933\n",
      "Validation AVG Loss:     0.000031 \n",
      "\n",
      "Epoch [3873/5000] | Train Loss: 0.034898\n",
      "Validation AVG Loss:     0.000031 \n",
      "\n",
      "Epoch [3874/5000] | Train Loss: 0.034863\n",
      "Validation AVG Loss:     0.000031 \n",
      "\n",
      "Epoch [3875/5000] | Train Loss: 0.034828\n",
      "Validation AVG Loss:     0.000031 \n",
      "\n",
      "Epoch [3876/5000] | Train Loss: 0.034793\n",
      "Validation AVG Loss:     0.000031 \n",
      "\n",
      "Epoch [3877/5000] | Train Loss: 0.034758\n",
      "Validation AVG Loss:     0.000031 \n",
      "\n",
      "Epoch [3878/5000] | Train Loss: 0.034723\n",
      "Validation AVG Loss:     0.000031 \n",
      "\n",
      "Epoch [3879/5000] | Train Loss: 0.034688\n",
      "Validation AVG Loss:     0.000031 \n",
      "\n",
      "Epoch [3880/5000] | Train Loss: 0.034653\n",
      "Validation AVG Loss:     0.000031 \n",
      "\n",
      "Epoch [3881/5000] | Train Loss: 0.034618\n",
      "Validation AVG Loss:     0.000031 \n",
      "\n",
      "Epoch [3882/5000] | Train Loss: 0.034583\n",
      "Validation AVG Loss:     0.000030 \n",
      "\n",
      "Epoch [3883/5000] | Train Loss: 0.034548\n",
      "Validation AVG Loss:     0.000030 \n",
      "\n",
      "Epoch [3884/5000] | Train Loss: 0.034513\n",
      "Validation AVG Loss:     0.000030 \n",
      "\n",
      "Epoch [3885/5000] | Train Loss: 0.034478\n",
      "Validation AVG Loss:     0.000030 \n",
      "\n",
      "Epoch [3886/5000] | Train Loss: 0.034444\n",
      "Validation AVG Loss:     0.000030 \n",
      "\n",
      "Epoch [3887/5000] | Train Loss: 0.034409\n",
      "Validation AVG Loss:     0.000030 \n",
      "\n",
      "Epoch [3888/5000] | Train Loss: 0.034374\n",
      "Validation AVG Loss:     0.000030 \n",
      "\n",
      "Epoch [3889/5000] | Train Loss: 0.034340\n",
      "Validation AVG Loss:     0.000030 \n",
      "\n",
      "Epoch [3890/5000] | Train Loss: 0.034305\n",
      "Validation AVG Loss:     0.000030 \n",
      "\n",
      "Epoch [3891/5000] | Train Loss: 0.034271\n",
      "Validation AVG Loss:     0.000030 \n",
      "\n",
      "Epoch [3892/5000] | Train Loss: 0.034236\n",
      "Validation AVG Loss:     0.000030 \n",
      "\n",
      "Epoch [3893/5000] | Train Loss: 0.034202\n",
      "Validation AVG Loss:     0.000030 \n",
      "\n",
      "Epoch [3894/5000] | Train Loss: 0.034167\n",
      "Validation AVG Loss:     0.000030 \n",
      "\n",
      "Epoch [3895/5000] | Train Loss: 0.034133\n",
      "Validation AVG Loss:     0.000030 \n",
      "\n",
      "Epoch [3896/5000] | Train Loss: 0.034099\n",
      "Validation AVG Loss:     0.000030 \n",
      "\n",
      "Epoch [3897/5000] | Train Loss: 0.034064\n",
      "Validation AVG Loss:     0.000030 \n",
      "\n",
      "Epoch [3898/5000] | Train Loss: 0.034030\n",
      "Validation AVG Loss:     0.000030 \n",
      "\n",
      "Epoch [3899/5000] | Train Loss: 0.033996\n",
      "Validation AVG Loss:     0.000030 \n",
      "\n",
      "Epoch [3900/5000] | Train Loss: 0.033961\n",
      "Validation AVG Loss:     0.000030 \n",
      "\n",
      "Epoch [3901/5000] | Train Loss: 0.033927\n",
      "Validation AVG Loss:     0.000030 \n",
      "\n",
      "Epoch [3902/5000] | Train Loss: 0.033893\n",
      "Validation AVG Loss:     0.000030 \n",
      "\n",
      "Epoch [3903/5000] | Train Loss: 0.033859\n",
      "Validation AVG Loss:     0.000030 \n",
      "\n",
      "Epoch [3904/5000] | Train Loss: 0.033825\n",
      "Validation AVG Loss:     0.000030 \n",
      "\n",
      "Epoch [3905/5000] | Train Loss: 0.033791\n",
      "Validation AVG Loss:     0.000030 \n",
      "\n",
      "Epoch [3906/5000] | Train Loss: 0.033757\n",
      "Validation AVG Loss:     0.000030 \n",
      "\n",
      "Epoch [3907/5000] | Train Loss: 0.033723\n",
      "Validation AVG Loss:     0.000030 \n",
      "\n",
      "Epoch [3908/5000] | Train Loss: 0.033689\n",
      "Validation AVG Loss:     0.000030 \n",
      "\n",
      "Epoch [3909/5000] | Train Loss: 0.033655\n",
      "Validation AVG Loss:     0.000030 \n",
      "\n",
      "Epoch [3910/5000] | Train Loss: 0.033621\n",
      "Validation AVG Loss:     0.000030 \n",
      "\n",
      "Epoch [3911/5000] | Train Loss: 0.033588\n",
      "Validation AVG Loss:     0.000030 \n",
      "\n",
      "Epoch [3912/5000] | Train Loss: 0.033554\n",
      "Validation AVG Loss:     0.000030 \n",
      "\n",
      "Epoch [3913/5000] | Train Loss: 0.033520\n",
      "Validation AVG Loss:     0.000030 \n",
      "\n",
      "Epoch [3914/5000] | Train Loss: 0.033486\n",
      "Validation AVG Loss:     0.000029 \n",
      "\n",
      "Epoch [3915/5000] | Train Loss: 0.033453\n",
      "Validation AVG Loss:     0.000029 \n",
      "\n",
      "Epoch [3916/5000] | Train Loss: 0.033419\n",
      "Validation AVG Loss:     0.000029 \n",
      "\n",
      "Epoch [3917/5000] | Train Loss: 0.033385\n",
      "Validation AVG Loss:     0.000029 \n",
      "\n",
      "Epoch [3918/5000] | Train Loss: 0.033352\n",
      "Validation AVG Loss:     0.000029 \n",
      "\n",
      "Epoch [3919/5000] | Train Loss: 0.033318\n",
      "Validation AVG Loss:     0.000029 \n",
      "\n",
      "Epoch [3920/5000] | Train Loss: 0.033285\n",
      "Validation AVG Loss:     0.000029 \n",
      "\n",
      "Epoch [3921/5000] | Train Loss: 0.033251\n",
      "Validation AVG Loss:     0.000029 \n",
      "\n",
      "Epoch [3922/5000] | Train Loss: 0.033218\n",
      "Validation AVG Loss:     0.000029 \n",
      "\n",
      "Epoch [3923/5000] | Train Loss: 0.033185\n",
      "Validation AVG Loss:     0.000029 \n",
      "\n",
      "Epoch [3924/5000] | Train Loss: 0.033151\n",
      "Validation AVG Loss:     0.000029 \n",
      "\n",
      "Epoch [3925/5000] | Train Loss: 0.033118\n",
      "Validation AVG Loss:     0.000029 \n",
      "\n",
      "Epoch [3926/5000] | Train Loss: 0.033085\n",
      "Validation AVG Loss:     0.000029 \n",
      "\n",
      "Epoch [3927/5000] | Train Loss: 0.033052\n",
      "Validation AVG Loss:     0.000029 \n",
      "\n",
      "Epoch [3928/5000] | Train Loss: 0.033018\n",
      "Validation AVG Loss:     0.000029 \n",
      "\n",
      "Epoch [3929/5000] | Train Loss: 0.032985\n",
      "Validation AVG Loss:     0.000029 \n",
      "\n",
      "Epoch [3930/5000] | Train Loss: 0.032952\n",
      "Validation AVG Loss:     0.000029 \n",
      "\n",
      "Epoch [3931/5000] | Train Loss: 0.032919\n",
      "Validation AVG Loss:     0.000029 \n",
      "\n",
      "Epoch [3932/5000] | Train Loss: 0.032886\n",
      "Validation AVG Loss:     0.000029 \n",
      "\n",
      "Epoch [3933/5000] | Train Loss: 0.032853\n",
      "Validation AVG Loss:     0.000029 \n",
      "\n",
      "Epoch [3934/5000] | Train Loss: 0.032820\n",
      "Validation AVG Loss:     0.000029 \n",
      "\n",
      "Epoch [3935/5000] | Train Loss: 0.032787\n",
      "Validation AVG Loss:     0.000029 \n",
      "\n",
      "Epoch [3936/5000] | Train Loss: 0.032754\n",
      "Validation AVG Loss:     0.000029 \n",
      "\n",
      "Epoch [3937/5000] | Train Loss: 0.032721\n",
      "Validation AVG Loss:     0.000029 \n",
      "\n",
      "Epoch [3938/5000] | Train Loss: 0.032688\n",
      "Validation AVG Loss:     0.000029 \n",
      "\n",
      "Epoch [3939/5000] | Train Loss: 0.032656\n",
      "Validation AVG Loss:     0.000029 \n",
      "\n",
      "Epoch [3940/5000] | Train Loss: 0.032623\n",
      "Validation AVG Loss:     0.000029 \n",
      "\n",
      "Epoch [3941/5000] | Train Loss: 0.032590\n",
      "Validation AVG Loss:     0.000029 \n",
      "\n",
      "Epoch [3942/5000] | Train Loss: 0.032558\n",
      "Validation AVG Loss:     0.000029 \n",
      "\n",
      "Epoch [3943/5000] | Train Loss: 0.032525\n",
      "Validation AVG Loss:     0.000029 \n",
      "\n",
      "Epoch [3944/5000] | Train Loss: 0.032492\n",
      "Validation AVG Loss:     0.000029 \n",
      "\n",
      "Epoch [3945/5000] | Train Loss: 0.032460\n",
      "Validation AVG Loss:     0.000029 \n",
      "\n",
      "Epoch [3946/5000] | Train Loss: 0.032427\n",
      "Validation AVG Loss:     0.000029 \n",
      "\n",
      "Epoch [3947/5000] | Train Loss: 0.032395\n",
      "Validation AVG Loss:     0.000029 \n",
      "\n",
      "Epoch [3948/5000] | Train Loss: 0.032362\n",
      "Validation AVG Loss:     0.000028 \n",
      "\n",
      "Epoch [3949/5000] | Train Loss: 0.032330\n",
      "Validation AVG Loss:     0.000028 \n",
      "\n",
      "Epoch [3950/5000] | Train Loss: 0.032297\n",
      "Validation AVG Loss:     0.000028 \n",
      "\n",
      "Epoch [3951/5000] | Train Loss: 0.032265\n",
      "Validation AVG Loss:     0.000028 \n",
      "\n",
      "Epoch [3952/5000] | Train Loss: 0.032233\n",
      "Validation AVG Loss:     0.000028 \n",
      "\n",
      "Epoch [3953/5000] | Train Loss: 0.032200\n",
      "Validation AVG Loss:     0.000028 \n",
      "\n",
      "Epoch [3954/5000] | Train Loss: 0.032168\n",
      "Validation AVG Loss:     0.000028 \n",
      "\n",
      "Epoch [3955/5000] | Train Loss: 0.032136\n",
      "Validation AVG Loss:     0.000028 \n",
      "\n",
      "Epoch [3956/5000] | Train Loss: 0.032104\n",
      "Validation AVG Loss:     0.000028 \n",
      "\n",
      "Epoch [3957/5000] | Train Loss: 0.032071\n",
      "Validation AVG Loss:     0.000028 \n",
      "\n",
      "Epoch [3958/5000] | Train Loss: 0.032039\n",
      "Validation AVG Loss:     0.000028 \n",
      "\n",
      "Epoch [3959/5000] | Train Loss: 0.032007\n",
      "Validation AVG Loss:     0.000028 \n",
      "\n",
      "Epoch [3960/5000] | Train Loss: 0.031975\n",
      "Validation AVG Loss:     0.000028 \n",
      "\n",
      "Epoch [3961/5000] | Train Loss: 0.031943\n",
      "Validation AVG Loss:     0.000028 \n",
      "\n",
      "Epoch [3962/5000] | Train Loss: 0.031911\n",
      "Validation AVG Loss:     0.000028 \n",
      "\n",
      "Epoch [3963/5000] | Train Loss: 0.031879\n",
      "Validation AVG Loss:     0.000028 \n",
      "\n",
      "Epoch [3964/5000] | Train Loss: 0.031847\n",
      "Validation AVG Loss:     0.000028 \n",
      "\n",
      "Epoch [3965/5000] | Train Loss: 0.031815\n",
      "Validation AVG Loss:     0.000028 \n",
      "\n",
      "Epoch [3966/5000] | Train Loss: 0.031784\n",
      "Validation AVG Loss:     0.000028 \n",
      "\n",
      "Epoch [3967/5000] | Train Loss: 0.031752\n",
      "Validation AVG Loss:     0.000028 \n",
      "\n",
      "Epoch [3968/5000] | Train Loss: 0.031720\n",
      "Validation AVG Loss:     0.000028 \n",
      "\n",
      "Epoch [3969/5000] | Train Loss: 0.031688\n",
      "Validation AVG Loss:     0.000028 \n",
      "\n",
      "Epoch [3970/5000] | Train Loss: 0.031657\n",
      "Validation AVG Loss:     0.000028 \n",
      "\n",
      "Epoch [3971/5000] | Train Loss: 0.031625\n",
      "Validation AVG Loss:     0.000028 \n",
      "\n",
      "Epoch [3972/5000] | Train Loss: 0.031593\n",
      "Validation AVG Loss:     0.000028 \n",
      "\n",
      "Epoch [3973/5000] | Train Loss: 0.031562\n",
      "Validation AVG Loss:     0.000028 \n",
      "\n",
      "Epoch [3974/5000] | Train Loss: 0.031530\n",
      "Validation AVG Loss:     0.000028 \n",
      "\n",
      "Epoch [3975/5000] | Train Loss: 0.031499\n",
      "Validation AVG Loss:     0.000028 \n",
      "\n",
      "Epoch [3976/5000] | Train Loss: 0.031467\n",
      "Validation AVG Loss:     0.000028 \n",
      "\n",
      "Epoch [3977/5000] | Train Loss: 0.031436\n",
      "Validation AVG Loss:     0.000028 \n",
      "\n",
      "Epoch [3978/5000] | Train Loss: 0.031404\n",
      "Validation AVG Loss:     0.000028 \n",
      "\n",
      "Epoch [3979/5000] | Train Loss: 0.031373\n",
      "Validation AVG Loss:     0.000028 \n",
      "\n",
      "Epoch [3980/5000] | Train Loss: 0.031342\n",
      "Validation AVG Loss:     0.000028 \n",
      "\n",
      "Epoch [3981/5000] | Train Loss: 0.031310\n",
      "Validation AVG Loss:     0.000028 \n",
      "\n",
      "Epoch [3982/5000] | Train Loss: 0.031279\n",
      "Validation AVG Loss:     0.000027 \n",
      "\n",
      "Epoch [3983/5000] | Train Loss: 0.031248\n",
      "Validation AVG Loss:     0.000027 \n",
      "\n",
      "Epoch [3984/5000] | Train Loss: 0.031216\n",
      "Validation AVG Loss:     0.000027 \n",
      "\n",
      "Epoch [3985/5000] | Train Loss: 0.031185\n",
      "Validation AVG Loss:     0.000027 \n",
      "\n",
      "Epoch [3986/5000] | Train Loss: 0.031154\n",
      "Validation AVG Loss:     0.000027 \n",
      "\n",
      "Epoch [3987/5000] | Train Loss: 0.031123\n",
      "Validation AVG Loss:     0.000027 \n",
      "\n",
      "Epoch [3988/5000] | Train Loss: 0.031092\n",
      "Validation AVG Loss:     0.000027 \n",
      "\n",
      "Epoch [3989/5000] | Train Loss: 0.031061\n",
      "Validation AVG Loss:     0.000027 \n",
      "\n",
      "Epoch [3990/5000] | Train Loss: 0.031030\n",
      "Validation AVG Loss:     0.000027 \n",
      "\n",
      "Epoch [3991/5000] | Train Loss: 0.030999\n",
      "Validation AVG Loss:     0.000027 \n",
      "\n",
      "Epoch [3992/5000] | Train Loss: 0.030968\n",
      "Validation AVG Loss:     0.000027 \n",
      "\n",
      "Epoch [3993/5000] | Train Loss: 0.030937\n",
      "Validation AVG Loss:     0.000027 \n",
      "\n",
      "Epoch [3994/5000] | Train Loss: 0.030906\n",
      "Validation AVG Loss:     0.000027 \n",
      "\n",
      "Epoch [3995/5000] | Train Loss: 0.030875\n",
      "Validation AVG Loss:     0.000027 \n",
      "\n",
      "Epoch [3996/5000] | Train Loss: 0.030845\n",
      "Validation AVG Loss:     0.000027 \n",
      "\n",
      "Epoch [3997/5000] | Train Loss: 0.030814\n",
      "Validation AVG Loss:     0.000027 \n",
      "\n",
      "Epoch [3998/5000] | Train Loss: 0.030783\n",
      "Validation AVG Loss:     0.000027 \n",
      "\n",
      "Epoch [3999/5000] | Train Loss: 0.030753\n",
      "Validation AVG Loss:     0.000027 \n",
      "\n",
      "Epoch [4000/5000] | Train Loss: 0.030722\n",
      "Validation AVG Loss:     0.000027 \n",
      "\n",
      "Epoch [4001/5000] | Train Loss: 0.030691\n",
      "Validation AVG Loss:     0.000027 \n",
      "\n",
      "Epoch [4002/5000] | Train Loss: 0.030661\n",
      "Validation AVG Loss:     0.000027 \n",
      "\n",
      "Epoch [4003/5000] | Train Loss: 0.030630\n",
      "Validation AVG Loss:     0.000027 \n",
      "\n",
      "Epoch [4004/5000] | Train Loss: 0.030600\n",
      "Validation AVG Loss:     0.000027 \n",
      "\n",
      "Epoch [4005/5000] | Train Loss: 0.030569\n",
      "Validation AVG Loss:     0.000027 \n",
      "\n",
      "Epoch [4006/5000] | Train Loss: 0.030539\n",
      "Validation AVG Loss:     0.000027 \n",
      "\n",
      "Epoch [4007/5000] | Train Loss: 0.030508\n",
      "Validation AVG Loss:     0.000027 \n",
      "\n",
      "Epoch [4008/5000] | Train Loss: 0.030478\n",
      "Validation AVG Loss:     0.000027 \n",
      "\n",
      "Epoch [4009/5000] | Train Loss: 0.030448\n",
      "Validation AVG Loss:     0.000027 \n",
      "\n",
      "Epoch [4010/5000] | Train Loss: 0.030417\n",
      "Validation AVG Loss:     0.000027 \n",
      "\n",
      "Epoch [4011/5000] | Train Loss: 0.030387\n",
      "Validation AVG Loss:     0.000027 \n",
      "\n",
      "Epoch [4012/5000] | Train Loss: 0.030357\n",
      "Validation AVG Loss:     0.000027 \n",
      "\n",
      "Epoch [4013/5000] | Train Loss: 0.030327\n",
      "Validation AVG Loss:     0.000027 \n",
      "\n",
      "Epoch [4014/5000] | Train Loss: 0.030296\n",
      "Validation AVG Loss:     0.000027 \n",
      "\n",
      "Epoch [4015/5000] | Train Loss: 0.030266\n",
      "Validation AVG Loss:     0.000027 \n",
      "\n",
      "Epoch [4016/5000] | Train Loss: 0.030236\n",
      "Validation AVG Loss:     0.000027 \n",
      "\n",
      "Epoch [4017/5000] | Train Loss: 0.030206\n",
      "Validation AVG Loss:     0.000027 \n",
      "\n",
      "Epoch [4018/5000] | Train Loss: 0.030176\n",
      "Validation AVG Loss:     0.000026 \n",
      "\n",
      "Epoch [4019/5000] | Train Loss: 0.030146\n",
      "Validation AVG Loss:     0.000026 \n",
      "\n",
      "Epoch [4020/5000] | Train Loss: 0.030116\n",
      "Validation AVG Loss:     0.000026 \n",
      "\n",
      "Epoch [4021/5000] | Train Loss: 0.030086\n",
      "Validation AVG Loss:     0.000026 \n",
      "\n",
      "Epoch [4022/5000] | Train Loss: 0.030056\n",
      "Validation AVG Loss:     0.000026 \n",
      "\n",
      "Epoch [4023/5000] | Train Loss: 0.030026\n",
      "Validation AVG Loss:     0.000026 \n",
      "\n",
      "Epoch [4024/5000] | Train Loss: 0.029997\n",
      "Validation AVG Loss:     0.000026 \n",
      "\n",
      "Epoch [4025/5000] | Train Loss: 0.029967\n",
      "Validation AVG Loss:     0.000026 \n",
      "\n",
      "Epoch [4026/5000] | Train Loss: 0.029937\n",
      "Validation AVG Loss:     0.000026 \n",
      "\n",
      "Epoch [4027/5000] | Train Loss: 0.029907\n",
      "Validation AVG Loss:     0.000026 \n",
      "\n",
      "Epoch [4028/5000] | Train Loss: 0.029878\n",
      "Validation AVG Loss:     0.000026 \n",
      "\n",
      "Epoch [4029/5000] | Train Loss: 0.029848\n",
      "Validation AVG Loss:     0.000026 \n",
      "\n",
      "Epoch [4030/5000] | Train Loss: 0.029818\n",
      "Validation AVG Loss:     0.000026 \n",
      "\n",
      "Epoch [4031/5000] | Train Loss: 0.029789\n",
      "Validation AVG Loss:     0.000026 \n",
      "\n",
      "Epoch [4032/5000] | Train Loss: 0.029759\n",
      "Validation AVG Loss:     0.000026 \n",
      "\n",
      "Epoch [4033/5000] | Train Loss: 0.029730\n",
      "Validation AVG Loss:     0.000026 \n",
      "\n",
      "Epoch [4034/5000] | Train Loss: 0.029700\n",
      "Validation AVG Loss:     0.000026 \n",
      "\n",
      "Epoch [4035/5000] | Train Loss: 0.029671\n",
      "Validation AVG Loss:     0.000026 \n",
      "\n",
      "Epoch [4036/5000] | Train Loss: 0.029641\n",
      "Validation AVG Loss:     0.000026 \n",
      "\n",
      "Epoch [4037/5000] | Train Loss: 0.029612\n",
      "Validation AVG Loss:     0.000026 \n",
      "\n",
      "Epoch [4038/5000] | Train Loss: 0.029583\n",
      "Validation AVG Loss:     0.000026 \n",
      "\n",
      "Epoch [4039/5000] | Train Loss: 0.029553\n",
      "Validation AVG Loss:     0.000026 \n",
      "\n",
      "Epoch [4040/5000] | Train Loss: 0.029524\n",
      "Validation AVG Loss:     0.000026 \n",
      "\n",
      "Epoch [4041/5000] | Train Loss: 0.029495\n",
      "Validation AVG Loss:     0.000026 \n",
      "\n",
      "Epoch [4042/5000] | Train Loss: 0.029465\n",
      "Validation AVG Loss:     0.000026 \n",
      "\n",
      "Epoch [4043/5000] | Train Loss: 0.029436\n",
      "Validation AVG Loss:     0.000026 \n",
      "\n",
      "Epoch [4044/5000] | Train Loss: 0.029407\n",
      "Validation AVG Loss:     0.000026 \n",
      "\n",
      "Epoch [4045/5000] | Train Loss: 0.029378\n",
      "Validation AVG Loss:     0.000026 \n",
      "\n",
      "Epoch [4046/5000] | Train Loss: 0.029349\n",
      "Validation AVG Loss:     0.000026 \n",
      "\n",
      "Epoch [4047/5000] | Train Loss: 0.029320\n",
      "Validation AVG Loss:     0.000026 \n",
      "\n",
      "Epoch [4048/5000] | Train Loss: 0.029291\n",
      "Validation AVG Loss:     0.000026 \n",
      "\n",
      "Epoch [4049/5000] | Train Loss: 0.029262\n",
      "Validation AVG Loss:     0.000026 \n",
      "\n",
      "Epoch [4050/5000] | Train Loss: 0.029233\n",
      "Validation AVG Loss:     0.000026 \n",
      "\n",
      "Epoch [4051/5000] | Train Loss: 0.029204\n",
      "Validation AVG Loss:     0.000026 \n",
      "\n",
      "Epoch [4052/5000] | Train Loss: 0.029175\n",
      "Validation AVG Loss:     0.000026 \n",
      "\n",
      "Epoch [4053/5000] | Train Loss: 0.029146\n",
      "Validation AVG Loss:     0.000026 \n",
      "\n",
      "Epoch [4054/5000] | Train Loss: 0.029117\n",
      "Validation AVG Loss:     0.000026 \n",
      "\n",
      "Epoch [4055/5000] | Train Loss: 0.029089\n",
      "Validation AVG Loss:     0.000026 \n",
      "\n",
      "Epoch [4056/5000] | Train Loss: 0.029060\n",
      "Validation AVG Loss:     0.000025 \n",
      "\n",
      "Epoch [4057/5000] | Train Loss: 0.029031\n",
      "Validation AVG Loss:     0.000025 \n",
      "\n",
      "Epoch [4058/5000] | Train Loss: 0.029002\n",
      "Validation AVG Loss:     0.000025 \n",
      "\n",
      "Epoch [4059/5000] | Train Loss: 0.028974\n",
      "Validation AVG Loss:     0.000025 \n",
      "\n",
      "Epoch [4060/5000] | Train Loss: 0.028945\n",
      "Validation AVG Loss:     0.000025 \n",
      "\n",
      "Epoch [4061/5000] | Train Loss: 0.028917\n",
      "Validation AVG Loss:     0.000025 \n",
      "\n",
      "Epoch [4062/5000] | Train Loss: 0.028888\n",
      "Validation AVG Loss:     0.000025 \n",
      "\n",
      "Epoch [4063/5000] | Train Loss: 0.028859\n",
      "Validation AVG Loss:     0.000025 \n",
      "\n",
      "Epoch [4064/5000] | Train Loss: 0.028831\n",
      "Validation AVG Loss:     0.000025 \n",
      "\n",
      "Epoch [4065/5000] | Train Loss: 0.028802\n",
      "Validation AVG Loss:     0.000025 \n",
      "\n",
      "Epoch [4066/5000] | Train Loss: 0.028774\n",
      "Validation AVG Loss:     0.000025 \n",
      "\n",
      "Epoch [4067/5000] | Train Loss: 0.028746\n",
      "Validation AVG Loss:     0.000025 \n",
      "\n",
      "Epoch [4068/5000] | Train Loss: 0.028717\n",
      "Validation AVG Loss:     0.000025 \n",
      "\n",
      "Epoch [4069/5000] | Train Loss: 0.028689\n",
      "Validation AVG Loss:     0.000025 \n",
      "\n",
      "Epoch [4070/5000] | Train Loss: 0.028661\n",
      "Validation AVG Loss:     0.000025 \n",
      "\n",
      "Epoch [4071/5000] | Train Loss: 0.028632\n",
      "Validation AVG Loss:     0.000025 \n",
      "\n",
      "Epoch [4072/5000] | Train Loss: 0.028604\n",
      "Validation AVG Loss:     0.000025 \n",
      "\n",
      "Epoch [4073/5000] | Train Loss: 0.028576\n",
      "Validation AVG Loss:     0.000025 \n",
      "\n",
      "Epoch [4074/5000] | Train Loss: 0.028548\n",
      "Validation AVG Loss:     0.000025 \n",
      "\n",
      "Epoch [4075/5000] | Train Loss: 0.028520\n",
      "Validation AVG Loss:     0.000025 \n",
      "\n",
      "Epoch [4076/5000] | Train Loss: 0.028492\n",
      "Validation AVG Loss:     0.000025 \n",
      "\n",
      "Epoch [4077/5000] | Train Loss: 0.028464\n",
      "Validation AVG Loss:     0.000025 \n",
      "\n",
      "Epoch [4078/5000] | Train Loss: 0.028436\n",
      "Validation AVG Loss:     0.000025 \n",
      "\n",
      "Epoch [4079/5000] | Train Loss: 0.028408\n",
      "Validation AVG Loss:     0.000025 \n",
      "\n",
      "Epoch [4080/5000] | Train Loss: 0.028380\n",
      "Validation AVG Loss:     0.000025 \n",
      "\n",
      "Epoch [4081/5000] | Train Loss: 0.028352\n",
      "Validation AVG Loss:     0.000025 \n",
      "\n",
      "Epoch [4082/5000] | Train Loss: 0.028324\n",
      "Validation AVG Loss:     0.000025 \n",
      "\n",
      "Epoch [4083/5000] | Train Loss: 0.028296\n",
      "Validation AVG Loss:     0.000025 \n",
      "\n",
      "Epoch [4084/5000] | Train Loss: 0.028268\n",
      "Validation AVG Loss:     0.000025 \n",
      "\n",
      "Epoch [4085/5000] | Train Loss: 0.028240\n",
      "Validation AVG Loss:     0.000025 \n",
      "\n",
      "Epoch [4086/5000] | Train Loss: 0.028213\n",
      "Validation AVG Loss:     0.000025 \n",
      "\n",
      "Epoch [4087/5000] | Train Loss: 0.028185\n",
      "Validation AVG Loss:     0.000025 \n",
      "\n",
      "Epoch [4088/5000] | Train Loss: 0.028157\n",
      "Validation AVG Loss:     0.000025 \n",
      "\n",
      "Epoch [4089/5000] | Train Loss: 0.028129\n",
      "Validation AVG Loss:     0.000025 \n",
      "\n",
      "Epoch [4090/5000] | Train Loss: 0.028102\n",
      "Validation AVG Loss:     0.000025 \n",
      "\n",
      "Epoch [4091/5000] | Train Loss: 0.028074\n",
      "Validation AVG Loss:     0.000025 \n",
      "\n",
      "Epoch [4092/5000] | Train Loss: 0.028047\n",
      "Validation AVG Loss:     0.000025 \n",
      "\n",
      "Epoch [4093/5000] | Train Loss: 0.028019\n",
      "Validation AVG Loss:     0.000025 \n",
      "\n",
      "Epoch [4094/5000] | Train Loss: 0.027992\n",
      "Validation AVG Loss:     0.000025 \n",
      "\n",
      "Epoch [4095/5000] | Train Loss: 0.027964\n",
      "Validation AVG Loss:     0.000025 \n",
      "\n",
      "Epoch [4096/5000] | Train Loss: 0.027937\n",
      "Validation AVG Loss:     0.000024 \n",
      "\n",
      "Epoch [4097/5000] | Train Loss: 0.027909\n",
      "Validation AVG Loss:     0.000024 \n",
      "\n",
      "Epoch [4098/5000] | Train Loss: 0.027882\n",
      "Validation AVG Loss:     0.000024 \n",
      "\n",
      "Epoch [4099/5000] | Train Loss: 0.027855\n",
      "Validation AVG Loss:     0.000024 \n",
      "\n",
      "Epoch [4100/5000] | Train Loss: 0.027827\n",
      "Validation AVG Loss:     0.000024 \n",
      "\n",
      "Epoch [4101/5000] | Train Loss: 0.027800\n",
      "Validation AVG Loss:     0.000024 \n",
      "\n",
      "Epoch [4102/5000] | Train Loss: 0.027773\n",
      "Validation AVG Loss:     0.000024 \n",
      "\n",
      "Epoch [4103/5000] | Train Loss: 0.027746\n",
      "Validation AVG Loss:     0.000024 \n",
      "\n",
      "Epoch [4104/5000] | Train Loss: 0.027718\n",
      "Validation AVG Loss:     0.000024 \n",
      "\n",
      "Epoch [4105/5000] | Train Loss: 0.027691\n",
      "Validation AVG Loss:     0.000024 \n",
      "\n",
      "Epoch [4106/5000] | Train Loss: 0.027664\n",
      "Validation AVG Loss:     0.000024 \n",
      "\n",
      "Epoch [4107/5000] | Train Loss: 0.027637\n",
      "Validation AVG Loss:     0.000024 \n",
      "\n",
      "Epoch [4108/5000] | Train Loss: 0.027610\n",
      "Validation AVG Loss:     0.000024 \n",
      "\n",
      "Epoch [4109/5000] | Train Loss: 0.027583\n",
      "Validation AVG Loss:     0.000024 \n",
      "\n",
      "Epoch [4110/5000] | Train Loss: 0.027556\n",
      "Validation AVG Loss:     0.000024 \n",
      "\n",
      "Epoch [4111/5000] | Train Loss: 0.027529\n",
      "Validation AVG Loss:     0.000024 \n",
      "\n",
      "Epoch [4112/5000] | Train Loss: 0.027502\n",
      "Validation AVG Loss:     0.000024 \n",
      "\n",
      "Epoch [4113/5000] | Train Loss: 0.027475\n",
      "Validation AVG Loss:     0.000024 \n",
      "\n",
      "Epoch [4114/5000] | Train Loss: 0.027448\n",
      "Validation AVG Loss:     0.000024 \n",
      "\n",
      "Epoch [4115/5000] | Train Loss: 0.027422\n",
      "Validation AVG Loss:     0.000024 \n",
      "\n",
      "Epoch [4116/5000] | Train Loss: 0.027395\n",
      "Validation AVG Loss:     0.000024 \n",
      "\n",
      "Epoch [4117/5000] | Train Loss: 0.027368\n",
      "Validation AVG Loss:     0.000024 \n",
      "\n",
      "Epoch [4118/5000] | Train Loss: 0.027341\n",
      "Validation AVG Loss:     0.000024 \n",
      "\n",
      "Epoch [4119/5000] | Train Loss: 0.027315\n",
      "Validation AVG Loss:     0.000024 \n",
      "\n",
      "Epoch [4120/5000] | Train Loss: 0.027288\n",
      "Validation AVG Loss:     0.000024 \n",
      "\n",
      "Epoch [4121/5000] | Train Loss: 0.027261\n",
      "Validation AVG Loss:     0.000024 \n",
      "\n",
      "Epoch [4122/5000] | Train Loss: 0.027235\n",
      "Validation AVG Loss:     0.000024 \n",
      "\n",
      "Epoch [4123/5000] | Train Loss: 0.027208\n",
      "Validation AVG Loss:     0.000024 \n",
      "\n",
      "Epoch [4124/5000] | Train Loss: 0.027182\n",
      "Validation AVG Loss:     0.000024 \n",
      "\n",
      "Epoch [4125/5000] | Train Loss: 0.027155\n",
      "Validation AVG Loss:     0.000024 \n",
      "\n",
      "Epoch [4126/5000] | Train Loss: 0.027129\n",
      "Validation AVG Loss:     0.000024 \n",
      "\n",
      "Epoch [4127/5000] | Train Loss: 0.027102\n",
      "Validation AVG Loss:     0.000024 \n",
      "\n",
      "Epoch [4128/5000] | Train Loss: 0.027076\n",
      "Validation AVG Loss:     0.000024 \n",
      "\n",
      "Epoch [4129/5000] | Train Loss: 0.027049\n",
      "Validation AVG Loss:     0.000024 \n",
      "\n",
      "Epoch [4130/5000] | Train Loss: 0.027023\n",
      "Validation AVG Loss:     0.000024 \n",
      "\n",
      "Epoch [4131/5000] | Train Loss: 0.026997\n",
      "Validation AVG Loss:     0.000024 \n",
      "\n",
      "Epoch [4132/5000] | Train Loss: 0.026970\n",
      "Validation AVG Loss:     0.000024 \n",
      "\n",
      "Epoch [4133/5000] | Train Loss: 0.026944\n",
      "Validation AVG Loss:     0.000024 \n",
      "\n",
      "Epoch [4134/5000] | Train Loss: 0.026918\n",
      "Validation AVG Loss:     0.000024 \n",
      "\n",
      "Epoch [4135/5000] | Train Loss: 0.026892\n",
      "Validation AVG Loss:     0.000024 \n",
      "\n",
      "Epoch [4136/5000] | Train Loss: 0.026865\n",
      "Validation AVG Loss:     0.000024 \n",
      "\n",
      "Epoch [4137/5000] | Train Loss: 0.026839\n",
      "Validation AVG Loss:     0.000023 \n",
      "\n",
      "Epoch [4138/5000] | Train Loss: 0.026813\n",
      "Validation AVG Loss:     0.000023 \n",
      "\n",
      "Epoch [4139/5000] | Train Loss: 0.026787\n",
      "Validation AVG Loss:     0.000023 \n",
      "\n",
      "Epoch [4140/5000] | Train Loss: 0.026761\n",
      "Validation AVG Loss:     0.000023 \n",
      "\n",
      "Epoch [4141/5000] | Train Loss: 0.026735\n",
      "Validation AVG Loss:     0.000023 \n",
      "\n",
      "Epoch [4142/5000] | Train Loss: 0.026709\n",
      "Validation AVG Loss:     0.000023 \n",
      "\n",
      "Epoch [4143/5000] | Train Loss: 0.026683\n",
      "Validation AVG Loss:     0.000023 \n",
      "\n",
      "Epoch [4144/5000] | Train Loss: 0.026657\n",
      "Validation AVG Loss:     0.000023 \n",
      "\n",
      "Epoch [4145/5000] | Train Loss: 0.026631\n",
      "Validation AVG Loss:     0.000023 \n",
      "\n",
      "Epoch [4146/5000] | Train Loss: 0.026606\n",
      "Validation AVG Loss:     0.000023 \n",
      "\n",
      "Epoch [4147/5000] | Train Loss: 0.026580\n",
      "Validation AVG Loss:     0.000023 \n",
      "\n",
      "Epoch [4148/5000] | Train Loss: 0.026554\n",
      "Validation AVG Loss:     0.000023 \n",
      "\n",
      "Epoch [4149/5000] | Train Loss: 0.026528\n",
      "Validation AVG Loss:     0.000023 \n",
      "\n",
      "Epoch [4150/5000] | Train Loss: 0.026502\n",
      "Validation AVG Loss:     0.000023 \n",
      "\n",
      "Epoch [4151/5000] | Train Loss: 0.026477\n",
      "Validation AVG Loss:     0.000023 \n",
      "\n",
      "Epoch [4152/5000] | Train Loss: 0.026451\n",
      "Validation AVG Loss:     0.000023 \n",
      "\n",
      "Epoch [4153/5000] | Train Loss: 0.026425\n",
      "Validation AVG Loss:     0.000023 \n",
      "\n",
      "Epoch [4154/5000] | Train Loss: 0.026400\n",
      "Validation AVG Loss:     0.000023 \n",
      "\n",
      "Epoch [4155/5000] | Train Loss: 0.026374\n",
      "Validation AVG Loss:     0.000023 \n",
      "\n",
      "Epoch [4156/5000] | Train Loss: 0.026349\n",
      "Validation AVG Loss:     0.000023 \n",
      "\n",
      "Epoch [4157/5000] | Train Loss: 0.026323\n",
      "Validation AVG Loss:     0.000023 \n",
      "\n",
      "Epoch [4158/5000] | Train Loss: 0.026298\n",
      "Validation AVG Loss:     0.000023 \n",
      "\n",
      "Epoch [4159/5000] | Train Loss: 0.026272\n",
      "Validation AVG Loss:     0.000023 \n",
      "\n",
      "Epoch [4160/5000] | Train Loss: 0.026247\n",
      "Validation AVG Loss:     0.000023 \n",
      "\n",
      "Epoch [4161/5000] | Train Loss: 0.026221\n",
      "Validation AVG Loss:     0.000023 \n",
      "\n",
      "Epoch [4162/5000] | Train Loss: 0.026196\n",
      "Validation AVG Loss:     0.000023 \n",
      "\n",
      "Epoch [4163/5000] | Train Loss: 0.026171\n",
      "Validation AVG Loss:     0.000023 \n",
      "\n",
      "Epoch [4164/5000] | Train Loss: 0.026145\n",
      "Validation AVG Loss:     0.000023 \n",
      "\n",
      "Epoch [4165/5000] | Train Loss: 0.026120\n",
      "Validation AVG Loss:     0.000023 \n",
      "\n",
      "Epoch [4166/5000] | Train Loss: 0.026095\n",
      "Validation AVG Loss:     0.000023 \n",
      "\n",
      "Epoch [4167/5000] | Train Loss: 0.026070\n",
      "Validation AVG Loss:     0.000023 \n",
      "\n",
      "Epoch [4168/5000] | Train Loss: 0.026045\n",
      "Validation AVG Loss:     0.000023 \n",
      "\n",
      "Epoch [4169/5000] | Train Loss: 0.026019\n",
      "Validation AVG Loss:     0.000023 \n",
      "\n",
      "Epoch [4170/5000] | Train Loss: 0.025994\n",
      "Validation AVG Loss:     0.000023 \n",
      "\n",
      "Epoch [4171/5000] | Train Loss: 0.025969\n",
      "Validation AVG Loss:     0.000023 \n",
      "\n",
      "Epoch [4172/5000] | Train Loss: 0.025944\n",
      "Validation AVG Loss:     0.000023 \n",
      "\n",
      "Epoch [4173/5000] | Train Loss: 0.025919\n",
      "Validation AVG Loss:     0.000023 \n",
      "\n",
      "Epoch [4174/5000] | Train Loss: 0.025894\n",
      "Validation AVG Loss:     0.000023 \n",
      "\n",
      "Epoch [4175/5000] | Train Loss: 0.025869\n",
      "Validation AVG Loss:     0.000023 \n",
      "\n",
      "Epoch [4176/5000] | Train Loss: 0.025844\n",
      "Validation AVG Loss:     0.000023 \n",
      "\n",
      "Epoch [4177/5000] | Train Loss: 0.025819\n",
      "Validation AVG Loss:     0.000023 \n",
      "\n",
      "Epoch [4178/5000] | Train Loss: 0.025794\n",
      "Validation AVG Loss:     0.000023 \n",
      "\n",
      "Epoch [4179/5000] | Train Loss: 0.025770\n",
      "Validation AVG Loss:     0.000023 \n",
      "\n",
      "Epoch [4180/5000] | Train Loss: 0.025745\n",
      "Validation AVG Loss:     0.000023 \n",
      "\n",
      "Epoch [4181/5000] | Train Loss: 0.025720\n",
      "Validation AVG Loss:     0.000022 \n",
      "\n",
      "Epoch [4182/5000] | Train Loss: 0.025695\n",
      "Validation AVG Loss:     0.000022 \n",
      "\n",
      "Epoch [4183/5000] | Train Loss: 0.025671\n",
      "Validation AVG Loss:     0.000022 \n",
      "\n",
      "Epoch [4184/5000] | Train Loss: 0.025646\n",
      "Validation AVG Loss:     0.000022 \n",
      "\n",
      "Epoch [4185/5000] | Train Loss: 0.025621\n",
      "Validation AVG Loss:     0.000022 \n",
      "\n",
      "Epoch [4186/5000] | Train Loss: 0.025597\n",
      "Validation AVG Loss:     0.000022 \n",
      "\n",
      "Epoch [4187/5000] | Train Loss: 0.025572\n",
      "Validation AVG Loss:     0.000022 \n",
      "\n",
      "Epoch [4188/5000] | Train Loss: 0.025547\n",
      "Validation AVG Loss:     0.000022 \n",
      "\n",
      "Epoch [4189/5000] | Train Loss: 0.025523\n",
      "Validation AVG Loss:     0.000022 \n",
      "\n",
      "Epoch [4190/5000] | Train Loss: 0.025498\n",
      "Validation AVG Loss:     0.000022 \n",
      "\n",
      "Epoch [4191/5000] | Train Loss: 0.025474\n",
      "Validation AVG Loss:     0.000022 \n",
      "\n",
      "Epoch [4192/5000] | Train Loss: 0.025449\n",
      "Validation AVG Loss:     0.000022 \n",
      "\n",
      "Epoch [4193/5000] | Train Loss: 0.025425\n",
      "Validation AVG Loss:     0.000022 \n",
      "\n",
      "Epoch [4194/5000] | Train Loss: 0.025401\n",
      "Validation AVG Loss:     0.000022 \n",
      "\n",
      "Epoch [4195/5000] | Train Loss: 0.025376\n",
      "Validation AVG Loss:     0.000022 \n",
      "\n",
      "Epoch [4196/5000] | Train Loss: 0.025352\n",
      "Validation AVG Loss:     0.000022 \n",
      "\n",
      "Epoch [4197/5000] | Train Loss: 0.025328\n",
      "Validation AVG Loss:     0.000022 \n",
      "\n",
      "Epoch [4198/5000] | Train Loss: 0.025303\n",
      "Validation AVG Loss:     0.000022 \n",
      "\n",
      "Epoch [4199/5000] | Train Loss: 0.025279\n",
      "Validation AVG Loss:     0.000022 \n",
      "\n",
      "Epoch [4200/5000] | Train Loss: 0.025255\n",
      "Validation AVG Loss:     0.000022 \n",
      "\n",
      "Epoch [4201/5000] | Train Loss: 0.025231\n",
      "Validation AVG Loss:     0.000022 \n",
      "\n",
      "Epoch [4202/5000] | Train Loss: 0.025206\n",
      "Validation AVG Loss:     0.000022 \n",
      "\n",
      "Epoch [4203/5000] | Train Loss: 0.025182\n",
      "Validation AVG Loss:     0.000022 \n",
      "\n",
      "Epoch [4204/5000] | Train Loss: 0.025158\n",
      "Validation AVG Loss:     0.000022 \n",
      "\n",
      "Epoch [4205/5000] | Train Loss: 0.025134\n",
      "Validation AVG Loss:     0.000022 \n",
      "\n",
      "Epoch [4206/5000] | Train Loss: 0.025110\n",
      "Validation AVG Loss:     0.000022 \n",
      "\n",
      "Epoch [4207/5000] | Train Loss: 0.025086\n",
      "Validation AVG Loss:     0.000022 \n",
      "\n",
      "Epoch [4208/5000] | Train Loss: 0.025062\n",
      "Validation AVG Loss:     0.000022 \n",
      "\n",
      "Epoch [4209/5000] | Train Loss: 0.025038\n",
      "Validation AVG Loss:     0.000022 \n",
      "\n",
      "Epoch [4210/5000] | Train Loss: 0.025014\n",
      "Validation AVG Loss:     0.000022 \n",
      "\n",
      "Epoch [4211/5000] | Train Loss: 0.024990\n",
      "Validation AVG Loss:     0.000022 \n",
      "\n",
      "Epoch [4212/5000] | Train Loss: 0.024966\n",
      "Validation AVG Loss:     0.000022 \n",
      "\n",
      "Epoch [4213/5000] | Train Loss: 0.024943\n",
      "Validation AVG Loss:     0.000022 \n",
      "\n",
      "Epoch [4214/5000] | Train Loss: 0.024919\n",
      "Validation AVG Loss:     0.000022 \n",
      "\n",
      "Epoch [4215/5000] | Train Loss: 0.024895\n",
      "Validation AVG Loss:     0.000022 \n",
      "\n",
      "Epoch [4216/5000] | Train Loss: 0.024871\n",
      "Validation AVG Loss:     0.000022 \n",
      "\n",
      "Epoch [4217/5000] | Train Loss: 0.024848\n",
      "Validation AVG Loss:     0.000022 \n",
      "\n",
      "Epoch [4218/5000] | Train Loss: 0.024824\n",
      "Validation AVG Loss:     0.000022 \n",
      "\n",
      "Epoch [4219/5000] | Train Loss: 0.024800\n",
      "Validation AVG Loss:     0.000022 \n",
      "\n",
      "Epoch [4220/5000] | Train Loss: 0.024777\n",
      "Validation AVG Loss:     0.000022 \n",
      "\n",
      "Epoch [4221/5000] | Train Loss: 0.024753\n",
      "Validation AVG Loss:     0.000022 \n",
      "\n",
      "Epoch [4222/5000] | Train Loss: 0.024729\n",
      "Validation AVG Loss:     0.000022 \n",
      "\n",
      "Epoch [4223/5000] | Train Loss: 0.024706\n",
      "Validation AVG Loss:     0.000022 \n",
      "\n",
      "Epoch [4224/5000] | Train Loss: 0.024682\n",
      "Validation AVG Loss:     0.000022 \n",
      "\n",
      "Epoch [4225/5000] | Train Loss: 0.024659\n",
      "Validation AVG Loss:     0.000022 \n",
      "\n",
      "Epoch [4226/5000] | Train Loss: 0.024635\n",
      "Validation AVG Loss:     0.000022 \n",
      "\n",
      "Epoch [4227/5000] | Train Loss: 0.024612\n",
      "Validation AVG Loss:     0.000021 \n",
      "\n",
      "Epoch [4228/5000] | Train Loss: 0.024589\n",
      "Validation AVG Loss:     0.000021 \n",
      "\n",
      "Epoch [4229/5000] | Train Loss: 0.024565\n",
      "Validation AVG Loss:     0.000021 \n",
      "\n",
      "Epoch [4230/5000] | Train Loss: 0.024542\n",
      "Validation AVG Loss:     0.000021 \n",
      "\n",
      "Epoch [4231/5000] | Train Loss: 0.024518\n",
      "Validation AVG Loss:     0.000021 \n",
      "\n",
      "Epoch [4232/5000] | Train Loss: 0.024495\n",
      "Validation AVG Loss:     0.000021 \n",
      "\n",
      "Epoch [4233/5000] | Train Loss: 0.024472\n",
      "Validation AVG Loss:     0.000021 \n",
      "\n",
      "Epoch [4234/5000] | Train Loss: 0.024449\n",
      "Validation AVG Loss:     0.000021 \n",
      "\n",
      "Epoch [4235/5000] | Train Loss: 0.024426\n",
      "Validation AVG Loss:     0.000021 \n",
      "\n",
      "Epoch [4236/5000] | Train Loss: 0.024402\n",
      "Validation AVG Loss:     0.000021 \n",
      "\n",
      "Epoch [4237/5000] | Train Loss: 0.024379\n",
      "Validation AVG Loss:     0.000021 \n",
      "\n",
      "Epoch [4238/5000] | Train Loss: 0.024356\n",
      "Validation AVG Loss:     0.000021 \n",
      "\n",
      "Epoch [4239/5000] | Train Loss: 0.024333\n",
      "Validation AVG Loss:     0.000021 \n",
      "\n",
      "Epoch [4240/5000] | Train Loss: 0.024310\n",
      "Validation AVG Loss:     0.000021 \n",
      "\n",
      "Epoch [4241/5000] | Train Loss: 0.024287\n",
      "Validation AVG Loss:     0.000021 \n",
      "\n",
      "Epoch [4242/5000] | Train Loss: 0.024264\n",
      "Validation AVG Loss:     0.000021 \n",
      "\n",
      "Epoch [4243/5000] | Train Loss: 0.024241\n",
      "Validation AVG Loss:     0.000021 \n",
      "\n",
      "Epoch [4244/5000] | Train Loss: 0.024218\n",
      "Validation AVG Loss:     0.000021 \n",
      "\n",
      "Epoch [4245/5000] | Train Loss: 0.024195\n",
      "Validation AVG Loss:     0.000021 \n",
      "\n",
      "Epoch [4246/5000] | Train Loss: 0.024172\n",
      "Validation AVG Loss:     0.000021 \n",
      "\n",
      "Epoch [4247/5000] | Train Loss: 0.024149\n",
      "Validation AVG Loss:     0.000021 \n",
      "\n",
      "Epoch [4248/5000] | Train Loss: 0.024127\n",
      "Validation AVG Loss:     0.000021 \n",
      "\n",
      "Epoch [4249/5000] | Train Loss: 0.024104\n",
      "Validation AVG Loss:     0.000021 \n",
      "\n",
      "Epoch [4250/5000] | Train Loss: 0.024081\n",
      "Validation AVG Loss:     0.000021 \n",
      "\n",
      "Epoch [4251/5000] | Train Loss: 0.024058\n",
      "Validation AVG Loss:     0.000021 \n",
      "\n",
      "Epoch [4252/5000] | Train Loss: 0.024036\n",
      "Validation AVG Loss:     0.000021 \n",
      "\n",
      "Epoch [4253/5000] | Train Loss: 0.024013\n",
      "Validation AVG Loss:     0.000021 \n",
      "\n",
      "Epoch [4254/5000] | Train Loss: 0.023990\n",
      "Validation AVG Loss:     0.000021 \n",
      "\n",
      "Epoch [4255/5000] | Train Loss: 0.023968\n",
      "Validation AVG Loss:     0.000021 \n",
      "\n",
      "Epoch [4256/5000] | Train Loss: 0.023945\n",
      "Validation AVG Loss:     0.000021 \n",
      "\n",
      "Epoch [4257/5000] | Train Loss: 0.023922\n",
      "Validation AVG Loss:     0.000021 \n",
      "\n",
      "Epoch [4258/5000] | Train Loss: 0.023900\n",
      "Validation AVG Loss:     0.000021 \n",
      "\n",
      "Epoch [4259/5000] | Train Loss: 0.023877\n",
      "Validation AVG Loss:     0.000021 \n",
      "\n",
      "Epoch [4260/5000] | Train Loss: 0.023855\n",
      "Validation AVG Loss:     0.000021 \n",
      "\n",
      "Epoch [4261/5000] | Train Loss: 0.023832\n",
      "Validation AVG Loss:     0.000021 \n",
      "\n",
      "Epoch [4262/5000] | Train Loss: 0.023810\n",
      "Validation AVG Loss:     0.000021 \n",
      "\n",
      "Epoch [4263/5000] | Train Loss: 0.023787\n",
      "Validation AVG Loss:     0.000021 \n",
      "\n",
      "Epoch [4264/5000] | Train Loss: 0.023765\n",
      "Validation AVG Loss:     0.000021 \n",
      "\n",
      "Epoch [4265/5000] | Train Loss: 0.023743\n",
      "Validation AVG Loss:     0.000021 \n",
      "\n",
      "Epoch [4266/5000] | Train Loss: 0.023720\n",
      "Validation AVG Loss:     0.000021 \n",
      "\n",
      "Epoch [4267/5000] | Train Loss: 0.023698\n",
      "Validation AVG Loss:     0.000021 \n",
      "\n",
      "Epoch [4268/5000] | Train Loss: 0.023676\n",
      "Validation AVG Loss:     0.000021 \n",
      "\n",
      "Epoch [4269/5000] | Train Loss: 0.023654\n",
      "Validation AVG Loss:     0.000021 \n",
      "\n",
      "Epoch [4270/5000] | Train Loss: 0.023631\n",
      "Validation AVG Loss:     0.000021 \n",
      "\n",
      "Epoch [4271/5000] | Train Loss: 0.023609\n",
      "Validation AVG Loss:     0.000021 \n",
      "\n",
      "Epoch [4272/5000] | Train Loss: 0.023587\n",
      "Validation AVG Loss:     0.000021 \n",
      "\n",
      "Epoch [4273/5000] | Train Loss: 0.023565\n",
      "Validation AVG Loss:     0.000021 \n",
      "\n",
      "Epoch [4274/5000] | Train Loss: 0.023543\n",
      "Validation AVG Loss:     0.000021 \n",
      "\n",
      "Epoch [4275/5000] | Train Loss: 0.023521\n",
      "Validation AVG Loss:     0.000021 \n",
      "\n",
      "Epoch [4276/5000] | Train Loss: 0.023499\n",
      "Validation AVG Loss:     0.000021 \n",
      "\n",
      "Epoch [4277/5000] | Train Loss: 0.023477\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4278/5000] | Train Loss: 0.023455\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4279/5000] | Train Loss: 0.023433\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4280/5000] | Train Loss: 0.023411\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4281/5000] | Train Loss: 0.023389\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4282/5000] | Train Loss: 0.023367\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4283/5000] | Train Loss: 0.023345\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4284/5000] | Train Loss: 0.023323\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4285/5000] | Train Loss: 0.023302\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4286/5000] | Train Loss: 0.023280\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4287/5000] | Train Loss: 0.023258\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4288/5000] | Train Loss: 0.023236\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4289/5000] | Train Loss: 0.023215\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4290/5000] | Train Loss: 0.023193\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4291/5000] | Train Loss: 0.023171\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4292/5000] | Train Loss: 0.023150\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4293/5000] | Train Loss: 0.023128\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4294/5000] | Train Loss: 0.023107\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4295/5000] | Train Loss: 0.023085\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4296/5000] | Train Loss: 0.023064\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4297/5000] | Train Loss: 0.023042\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4298/5000] | Train Loss: 0.023021\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4299/5000] | Train Loss: 0.022999\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4300/5000] | Train Loss: 0.022978\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4301/5000] | Train Loss: 0.022957\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4302/5000] | Train Loss: 0.022935\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4303/5000] | Train Loss: 0.022914\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4304/5000] | Train Loss: 0.022893\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4305/5000] | Train Loss: 0.022871\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4306/5000] | Train Loss: 0.022850\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4307/5000] | Train Loss: 0.022829\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4308/5000] | Train Loss: 0.022808\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4309/5000] | Train Loss: 0.022787\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4310/5000] | Train Loss: 0.022765\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4311/5000] | Train Loss: 0.022744\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4312/5000] | Train Loss: 0.022723\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4313/5000] | Train Loss: 0.022702\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4314/5000] | Train Loss: 0.022681\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4315/5000] | Train Loss: 0.022660\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4316/5000] | Train Loss: 0.022639\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4317/5000] | Train Loss: 0.022618\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4318/5000] | Train Loss: 0.022598\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4319/5000] | Train Loss: 0.022577\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4320/5000] | Train Loss: 0.022556\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4321/5000] | Train Loss: 0.022535\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4322/5000] | Train Loss: 0.022514\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4323/5000] | Train Loss: 0.022493\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4324/5000] | Train Loss: 0.022473\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4325/5000] | Train Loss: 0.022452\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4326/5000] | Train Loss: 0.022431\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4327/5000] | Train Loss: 0.022411\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4328/5000] | Train Loss: 0.022390\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4329/5000] | Train Loss: 0.022369\n",
      "Validation AVG Loss:     0.000020 \n",
      "\n",
      "Epoch [4330/5000] | Train Loss: 0.022349\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4331/5000] | Train Loss: 0.022328\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4332/5000] | Train Loss: 0.022308\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4333/5000] | Train Loss: 0.022287\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4334/5000] | Train Loss: 0.022267\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4335/5000] | Train Loss: 0.022246\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4336/5000] | Train Loss: 0.022226\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4337/5000] | Train Loss: 0.022205\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4338/5000] | Train Loss: 0.022185\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4339/5000] | Train Loss: 0.022165\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4340/5000] | Train Loss: 0.022144\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4341/5000] | Train Loss: 0.022124\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4342/5000] | Train Loss: 0.022104\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4343/5000] | Train Loss: 0.022084\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4344/5000] | Train Loss: 0.022063\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4345/5000] | Train Loss: 0.022043\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4346/5000] | Train Loss: 0.022023\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4347/5000] | Train Loss: 0.022003\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4348/5000] | Train Loss: 0.021983\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4349/5000] | Train Loss: 0.021963\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4350/5000] | Train Loss: 0.021943\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4351/5000] | Train Loss: 0.021923\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4352/5000] | Train Loss: 0.021903\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4353/5000] | Train Loss: 0.021883\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4354/5000] | Train Loss: 0.021863\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4355/5000] | Train Loss: 0.021843\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4356/5000] | Train Loss: 0.021823\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4357/5000] | Train Loss: 0.021803\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4358/5000] | Train Loss: 0.021783\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4359/5000] | Train Loss: 0.021763\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4360/5000] | Train Loss: 0.021743\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4361/5000] | Train Loss: 0.021724\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4362/5000] | Train Loss: 0.021704\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4363/5000] | Train Loss: 0.021684\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4364/5000] | Train Loss: 0.021664\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4365/5000] | Train Loss: 0.021645\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4366/5000] | Train Loss: 0.021625\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4367/5000] | Train Loss: 0.021605\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4368/5000] | Train Loss: 0.021586\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4369/5000] | Train Loss: 0.021566\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4370/5000] | Train Loss: 0.021547\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4371/5000] | Train Loss: 0.021527\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4372/5000] | Train Loss: 0.021508\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4373/5000] | Train Loss: 0.021488\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4374/5000] | Train Loss: 0.021469\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4375/5000] | Train Loss: 0.021449\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4376/5000] | Train Loss: 0.021430\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4377/5000] | Train Loss: 0.021411\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4378/5000] | Train Loss: 0.021391\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4379/5000] | Train Loss: 0.021372\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4380/5000] | Train Loss: 0.021353\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4381/5000] | Train Loss: 0.021333\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4382/5000] | Train Loss: 0.021314\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4383/5000] | Train Loss: 0.021295\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4384/5000] | Train Loss: 0.021276\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4385/5000] | Train Loss: 0.021256\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4386/5000] | Train Loss: 0.021237\n",
      "Validation AVG Loss:     0.000019 \n",
      "\n",
      "Epoch [4387/5000] | Train Loss: 0.021218\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4388/5000] | Train Loss: 0.021199\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4389/5000] | Train Loss: 0.021180\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4390/5000] | Train Loss: 0.021161\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4391/5000] | Train Loss: 0.021142\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4392/5000] | Train Loss: 0.021123\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4393/5000] | Train Loss: 0.021104\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4394/5000] | Train Loss: 0.021085\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4395/5000] | Train Loss: 0.021066\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4396/5000] | Train Loss: 0.021047\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4397/5000] | Train Loss: 0.021028\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4398/5000] | Train Loss: 0.021009\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4399/5000] | Train Loss: 0.020991\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4400/5000] | Train Loss: 0.020972\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4401/5000] | Train Loss: 0.020953\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4402/5000] | Train Loss: 0.020934\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4403/5000] | Train Loss: 0.020916\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4404/5000] | Train Loss: 0.020897\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4405/5000] | Train Loss: 0.020878\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4406/5000] | Train Loss: 0.020860\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4407/5000] | Train Loss: 0.020841\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4408/5000] | Train Loss: 0.020822\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4409/5000] | Train Loss: 0.020804\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4410/5000] | Train Loss: 0.020785\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4411/5000] | Train Loss: 0.020767\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4412/5000] | Train Loss: 0.020748\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4413/5000] | Train Loss: 0.020730\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4414/5000] | Train Loss: 0.020711\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4415/5000] | Train Loss: 0.020693\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4416/5000] | Train Loss: 0.020674\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4417/5000] | Train Loss: 0.020656\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4418/5000] | Train Loss: 0.020637\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4419/5000] | Train Loss: 0.020619\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4420/5000] | Train Loss: 0.020601\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4421/5000] | Train Loss: 0.020583\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4422/5000] | Train Loss: 0.020564\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4423/5000] | Train Loss: 0.020546\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4424/5000] | Train Loss: 0.020528\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4425/5000] | Train Loss: 0.020510\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4426/5000] | Train Loss: 0.020491\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4427/5000] | Train Loss: 0.020473\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4428/5000] | Train Loss: 0.020455\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4429/5000] | Train Loss: 0.020437\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4430/5000] | Train Loss: 0.020419\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4431/5000] | Train Loss: 0.020401\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4432/5000] | Train Loss: 0.020383\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4433/5000] | Train Loss: 0.020365\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4434/5000] | Train Loss: 0.020347\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4435/5000] | Train Loss: 0.020329\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4436/5000] | Train Loss: 0.020311\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4437/5000] | Train Loss: 0.020293\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4438/5000] | Train Loss: 0.020275\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4439/5000] | Train Loss: 0.020257\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4440/5000] | Train Loss: 0.020239\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4441/5000] | Train Loss: 0.020222\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4442/5000] | Train Loss: 0.020204\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4443/5000] | Train Loss: 0.020186\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4444/5000] | Train Loss: 0.020168\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4445/5000] | Train Loss: 0.020151\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4446/5000] | Train Loss: 0.020133\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4447/5000] | Train Loss: 0.020115\n",
      "Validation AVG Loss:     0.000018 \n",
      "\n",
      "Epoch [4448/5000] | Train Loss: 0.020097\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4449/5000] | Train Loss: 0.020080\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4450/5000] | Train Loss: 0.020062\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4451/5000] | Train Loss: 0.020045\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4452/5000] | Train Loss: 0.020027\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4453/5000] | Train Loss: 0.020010\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4454/5000] | Train Loss: 0.019992\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4455/5000] | Train Loss: 0.019975\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4456/5000] | Train Loss: 0.019957\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4457/5000] | Train Loss: 0.019940\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4458/5000] | Train Loss: 0.019922\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4459/5000] | Train Loss: 0.019905\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4460/5000] | Train Loss: 0.019887\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4461/5000] | Train Loss: 0.019870\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4462/5000] | Train Loss: 0.019853\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4463/5000] | Train Loss: 0.019835\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4464/5000] | Train Loss: 0.019818\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4465/5000] | Train Loss: 0.019801\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4466/5000] | Train Loss: 0.019784\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4467/5000] | Train Loss: 0.019766\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4468/5000] | Train Loss: 0.019749\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4469/5000] | Train Loss: 0.019732\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4470/5000] | Train Loss: 0.019715\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4471/5000] | Train Loss: 0.019698\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4472/5000] | Train Loss: 0.019681\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4473/5000] | Train Loss: 0.019664\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4474/5000] | Train Loss: 0.019647\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4475/5000] | Train Loss: 0.019630\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4476/5000] | Train Loss: 0.019613\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4477/5000] | Train Loss: 0.019596\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4478/5000] | Train Loss: 0.019579\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4479/5000] | Train Loss: 0.019562\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4480/5000] | Train Loss: 0.019545\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4481/5000] | Train Loss: 0.019528\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4482/5000] | Train Loss: 0.019511\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4483/5000] | Train Loss: 0.019494\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4484/5000] | Train Loss: 0.019477\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4485/5000] | Train Loss: 0.019460\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4486/5000] | Train Loss: 0.019444\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4487/5000] | Train Loss: 0.019427\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4488/5000] | Train Loss: 0.019410\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4489/5000] | Train Loss: 0.019393\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4490/5000] | Train Loss: 0.019377\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4491/5000] | Train Loss: 0.019360\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4492/5000] | Train Loss: 0.019343\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4493/5000] | Train Loss: 0.019327\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4494/5000] | Train Loss: 0.019310\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4495/5000] | Train Loss: 0.019294\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4496/5000] | Train Loss: 0.019277\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4497/5000] | Train Loss: 0.019261\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4498/5000] | Train Loss: 0.019244\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4499/5000] | Train Loss: 0.019228\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4500/5000] | Train Loss: 0.019211\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4501/5000] | Train Loss: 0.019195\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4502/5000] | Train Loss: 0.019178\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4503/5000] | Train Loss: 0.019162\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4504/5000] | Train Loss: 0.019145\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4505/5000] | Train Loss: 0.019129\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4506/5000] | Train Loss: 0.019113\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4507/5000] | Train Loss: 0.019096\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4508/5000] | Train Loss: 0.019080\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4509/5000] | Train Loss: 0.019064\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4510/5000] | Train Loss: 0.019048\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4511/5000] | Train Loss: 0.019031\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4512/5000] | Train Loss: 0.019015\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4513/5000] | Train Loss: 0.018999\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4514/5000] | Train Loss: 0.018983\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4515/5000] | Train Loss: 0.018967\n",
      "Validation AVG Loss:     0.000017 \n",
      "\n",
      "Epoch [4516/5000] | Train Loss: 0.018950\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4517/5000] | Train Loss: 0.018934\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4518/5000] | Train Loss: 0.018918\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4519/5000] | Train Loss: 0.018902\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4520/5000] | Train Loss: 0.018886\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4521/5000] | Train Loss: 0.018870\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4522/5000] | Train Loss: 0.018854\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4523/5000] | Train Loss: 0.018838\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4524/5000] | Train Loss: 0.018822\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4525/5000] | Train Loss: 0.018806\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4526/5000] | Train Loss: 0.018790\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4527/5000] | Train Loss: 0.018775\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4528/5000] | Train Loss: 0.018759\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4529/5000] | Train Loss: 0.018743\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4530/5000] | Train Loss: 0.018727\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4531/5000] | Train Loss: 0.018711\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4532/5000] | Train Loss: 0.018695\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4533/5000] | Train Loss: 0.018680\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4534/5000] | Train Loss: 0.018664\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4535/5000] | Train Loss: 0.018648\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4536/5000] | Train Loss: 0.018633\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4537/5000] | Train Loss: 0.018617\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4538/5000] | Train Loss: 0.018601\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4539/5000] | Train Loss: 0.018586\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4540/5000] | Train Loss: 0.018570\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4541/5000] | Train Loss: 0.018554\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4542/5000] | Train Loss: 0.018539\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4543/5000] | Train Loss: 0.018523\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4544/5000] | Train Loss: 0.018508\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4545/5000] | Train Loss: 0.018492\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4546/5000] | Train Loss: 0.018477\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4547/5000] | Train Loss: 0.018461\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4548/5000] | Train Loss: 0.018446\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4549/5000] | Train Loss: 0.018430\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4550/5000] | Train Loss: 0.018415\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4551/5000] | Train Loss: 0.018400\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4552/5000] | Train Loss: 0.018384\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4553/5000] | Train Loss: 0.018369\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4554/5000] | Train Loss: 0.018354\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4555/5000] | Train Loss: 0.018338\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4556/5000] | Train Loss: 0.018323\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4557/5000] | Train Loss: 0.018308\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4558/5000] | Train Loss: 0.018293\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4559/5000] | Train Loss: 0.018277\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4560/5000] | Train Loss: 0.018262\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4561/5000] | Train Loss: 0.018247\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4562/5000] | Train Loss: 0.018232\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4563/5000] | Train Loss: 0.018217\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4564/5000] | Train Loss: 0.018202\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4565/5000] | Train Loss: 0.018187\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4566/5000] | Train Loss: 0.018171\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4567/5000] | Train Loss: 0.018156\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4568/5000] | Train Loss: 0.018141\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4569/5000] | Train Loss: 0.018126\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4570/5000] | Train Loss: 0.018111\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4571/5000] | Train Loss: 0.018096\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4572/5000] | Train Loss: 0.018082\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4573/5000] | Train Loss: 0.018067\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4574/5000] | Train Loss: 0.018052\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4575/5000] | Train Loss: 0.018037\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4576/5000] | Train Loss: 0.018022\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4577/5000] | Train Loss: 0.018007\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4578/5000] | Train Loss: 0.017992\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4579/5000] | Train Loss: 0.017977\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4580/5000] | Train Loss: 0.017963\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4581/5000] | Train Loss: 0.017948\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4582/5000] | Train Loss: 0.017933\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4583/5000] | Train Loss: 0.017919\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4584/5000] | Train Loss: 0.017904\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4585/5000] | Train Loss: 0.017889\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4586/5000] | Train Loss: 0.017874\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4587/5000] | Train Loss: 0.017860\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4588/5000] | Train Loss: 0.017845\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4589/5000] | Train Loss: 0.017831\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4590/5000] | Train Loss: 0.017816\n",
      "Validation AVG Loss:     0.000016 \n",
      "\n",
      "Epoch [4591/5000] | Train Loss: 0.017801\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4592/5000] | Train Loss: 0.017787\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4593/5000] | Train Loss: 0.017772\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4594/5000] | Train Loss: 0.017758\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4595/5000] | Train Loss: 0.017743\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4596/5000] | Train Loss: 0.017729\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4597/5000] | Train Loss: 0.017715\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4598/5000] | Train Loss: 0.017700\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4599/5000] | Train Loss: 0.017686\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4600/5000] | Train Loss: 0.017671\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4601/5000] | Train Loss: 0.017657\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4602/5000] | Train Loss: 0.017643\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4603/5000] | Train Loss: 0.017628\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4604/5000] | Train Loss: 0.017614\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4605/5000] | Train Loss: 0.017600\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4606/5000] | Train Loss: 0.017585\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4607/5000] | Train Loss: 0.017571\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4608/5000] | Train Loss: 0.017557\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4609/5000] | Train Loss: 0.017543\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4610/5000] | Train Loss: 0.017529\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4611/5000] | Train Loss: 0.017514\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4612/5000] | Train Loss: 0.017500\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4613/5000] | Train Loss: 0.017486\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4614/5000] | Train Loss: 0.017472\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4615/5000] | Train Loss: 0.017458\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4616/5000] | Train Loss: 0.017444\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4617/5000] | Train Loss: 0.017430\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4618/5000] | Train Loss: 0.017416\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4619/5000] | Train Loss: 0.017402\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4620/5000] | Train Loss: 0.017388\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4621/5000] | Train Loss: 0.017374\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4622/5000] | Train Loss: 0.017360\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4623/5000] | Train Loss: 0.017346\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4624/5000] | Train Loss: 0.017332\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4625/5000] | Train Loss: 0.017318\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4626/5000] | Train Loss: 0.017304\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4627/5000] | Train Loss: 0.017290\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4628/5000] | Train Loss: 0.017277\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4629/5000] | Train Loss: 0.017263\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4630/5000] | Train Loss: 0.017249\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4631/5000] | Train Loss: 0.017235\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4632/5000] | Train Loss: 0.017221\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4633/5000] | Train Loss: 0.017208\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4634/5000] | Train Loss: 0.017194\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4635/5000] | Train Loss: 0.017180\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4636/5000] | Train Loss: 0.017166\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4637/5000] | Train Loss: 0.017153\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4638/5000] | Train Loss: 0.017139\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4639/5000] | Train Loss: 0.017126\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4640/5000] | Train Loss: 0.017112\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4641/5000] | Train Loss: 0.017098\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4642/5000] | Train Loss: 0.017085\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4643/5000] | Train Loss: 0.017071\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4644/5000] | Train Loss: 0.017058\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4645/5000] | Train Loss: 0.017044\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4646/5000] | Train Loss: 0.017031\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4647/5000] | Train Loss: 0.017017\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4648/5000] | Train Loss: 0.017004\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4649/5000] | Train Loss: 0.016990\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4650/5000] | Train Loss: 0.016977\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4651/5000] | Train Loss: 0.016963\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4652/5000] | Train Loss: 0.016950\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4653/5000] | Train Loss: 0.016937\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4654/5000] | Train Loss: 0.016923\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4655/5000] | Train Loss: 0.016910\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4656/5000] | Train Loss: 0.016897\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4657/5000] | Train Loss: 0.016883\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4658/5000] | Train Loss: 0.016870\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4659/5000] | Train Loss: 0.016857\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4660/5000] | Train Loss: 0.016844\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4661/5000] | Train Loss: 0.016830\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4662/5000] | Train Loss: 0.016817\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4663/5000] | Train Loss: 0.016804\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4664/5000] | Train Loss: 0.016791\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4665/5000] | Train Loss: 0.016778\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4666/5000] | Train Loss: 0.016765\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4667/5000] | Train Loss: 0.016751\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4668/5000] | Train Loss: 0.016738\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4669/5000] | Train Loss: 0.016725\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4670/5000] | Train Loss: 0.016712\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4671/5000] | Train Loss: 0.016699\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4672/5000] | Train Loss: 0.016686\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4673/5000] | Train Loss: 0.016673\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4674/5000] | Train Loss: 0.016660\n",
      "Validation AVG Loss:     0.000015 \n",
      "\n",
      "Epoch [4675/5000] | Train Loss: 0.016647\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4676/5000] | Train Loss: 0.016634\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4677/5000] | Train Loss: 0.016621\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4678/5000] | Train Loss: 0.016608\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4679/5000] | Train Loss: 0.016596\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4680/5000] | Train Loss: 0.016583\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4681/5000] | Train Loss: 0.016570\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4682/5000] | Train Loss: 0.016557\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4683/5000] | Train Loss: 0.016544\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4684/5000] | Train Loss: 0.016531\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4685/5000] | Train Loss: 0.016519\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4686/5000] | Train Loss: 0.016506\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4687/5000] | Train Loss: 0.016493\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4688/5000] | Train Loss: 0.016480\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4689/5000] | Train Loss: 0.016468\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4690/5000] | Train Loss: 0.016455\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4691/5000] | Train Loss: 0.016442\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4692/5000] | Train Loss: 0.016430\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4693/5000] | Train Loss: 0.016417\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4694/5000] | Train Loss: 0.016404\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4695/5000] | Train Loss: 0.016392\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4696/5000] | Train Loss: 0.016379\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4697/5000] | Train Loss: 0.016366\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4698/5000] | Train Loss: 0.016354\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4699/5000] | Train Loss: 0.016341\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4700/5000] | Train Loss: 0.016329\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4701/5000] | Train Loss: 0.016316\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4702/5000] | Train Loss: 0.016304\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4703/5000] | Train Loss: 0.016291\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4704/5000] | Train Loss: 0.016279\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4705/5000] | Train Loss: 0.016267\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4706/5000] | Train Loss: 0.016254\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4707/5000] | Train Loss: 0.016242\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4708/5000] | Train Loss: 0.016229\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4709/5000] | Train Loss: 0.016217\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4710/5000] | Train Loss: 0.016205\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4711/5000] | Train Loss: 0.016192\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4712/5000] | Train Loss: 0.016180\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4713/5000] | Train Loss: 0.016168\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4714/5000] | Train Loss: 0.016155\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4715/5000] | Train Loss: 0.016143\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4716/5000] | Train Loss: 0.016131\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4717/5000] | Train Loss: 0.016119\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4718/5000] | Train Loss: 0.016106\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4719/5000] | Train Loss: 0.016094\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4720/5000] | Train Loss: 0.016082\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4721/5000] | Train Loss: 0.016070\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4722/5000] | Train Loss: 0.016058\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4723/5000] | Train Loss: 0.016046\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4724/5000] | Train Loss: 0.016034\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4725/5000] | Train Loss: 0.016021\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4726/5000] | Train Loss: 0.016009\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4727/5000] | Train Loss: 0.015997\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4728/5000] | Train Loss: 0.015985\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4729/5000] | Train Loss: 0.015973\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4730/5000] | Train Loss: 0.015961\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4731/5000] | Train Loss: 0.015949\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4732/5000] | Train Loss: 0.015937\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4733/5000] | Train Loss: 0.015925\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4734/5000] | Train Loss: 0.015913\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4735/5000] | Train Loss: 0.015901\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4736/5000] | Train Loss: 0.015890\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4737/5000] | Train Loss: 0.015878\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4738/5000] | Train Loss: 0.015866\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4739/5000] | Train Loss: 0.015854\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4740/5000] | Train Loss: 0.015842\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4741/5000] | Train Loss: 0.015830\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4742/5000] | Train Loss: 0.015818\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4743/5000] | Train Loss: 0.015807\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4744/5000] | Train Loss: 0.015795\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4745/5000] | Train Loss: 0.015783\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4746/5000] | Train Loss: 0.015771\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4747/5000] | Train Loss: 0.015760\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4748/5000] | Train Loss: 0.015748\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4749/5000] | Train Loss: 0.015736\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4750/5000] | Train Loss: 0.015725\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4751/5000] | Train Loss: 0.015713\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4752/5000] | Train Loss: 0.015701\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4753/5000] | Train Loss: 0.015690\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4754/5000] | Train Loss: 0.015678\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4755/5000] | Train Loss: 0.015666\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4756/5000] | Train Loss: 0.015655\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4757/5000] | Train Loss: 0.015643\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4758/5000] | Train Loss: 0.015632\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4759/5000] | Train Loss: 0.015620\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4760/5000] | Train Loss: 0.015609\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4761/5000] | Train Loss: 0.015597\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4762/5000] | Train Loss: 0.015586\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4763/5000] | Train Loss: 0.015574\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4764/5000] | Train Loss: 0.015563\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4765/5000] | Train Loss: 0.015551\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4766/5000] | Train Loss: 0.015540\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4767/5000] | Train Loss: 0.015529\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4768/5000] | Train Loss: 0.015517\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4769/5000] | Train Loss: 0.015506\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4770/5000] | Train Loss: 0.015494\n",
      "Validation AVG Loss:     0.000014 \n",
      "\n",
      "Epoch [4771/5000] | Train Loss: 0.015483\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4772/5000] | Train Loss: 0.015472\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4773/5000] | Train Loss: 0.015461\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4774/5000] | Train Loss: 0.015449\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4775/5000] | Train Loss: 0.015438\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4776/5000] | Train Loss: 0.015427\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4777/5000] | Train Loss: 0.015415\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4778/5000] | Train Loss: 0.015404\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4779/5000] | Train Loss: 0.015393\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4780/5000] | Train Loss: 0.015382\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4781/5000] | Train Loss: 0.015371\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4782/5000] | Train Loss: 0.015359\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4783/5000] | Train Loss: 0.015348\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4784/5000] | Train Loss: 0.015337\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4785/5000] | Train Loss: 0.015326\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4786/5000] | Train Loss: 0.015315\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4787/5000] | Train Loss: 0.015304\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4788/5000] | Train Loss: 0.015293\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4789/5000] | Train Loss: 0.015282\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4790/5000] | Train Loss: 0.015271\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4791/5000] | Train Loss: 0.015260\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4792/5000] | Train Loss: 0.015249\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4793/5000] | Train Loss: 0.015238\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4794/5000] | Train Loss: 0.015227\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4795/5000] | Train Loss: 0.015216\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4796/5000] | Train Loss: 0.015205\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4797/5000] | Train Loss: 0.015194\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4798/5000] | Train Loss: 0.015183\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4799/5000] | Train Loss: 0.015172\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4800/5000] | Train Loss: 0.015161\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4801/5000] | Train Loss: 0.015150\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4802/5000] | Train Loss: 0.015140\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4803/5000] | Train Loss: 0.015129\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4804/5000] | Train Loss: 0.015118\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4805/5000] | Train Loss: 0.015107\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4806/5000] | Train Loss: 0.015096\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4807/5000] | Train Loss: 0.015086\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4808/5000] | Train Loss: 0.015075\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4809/5000] | Train Loss: 0.015064\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4810/5000] | Train Loss: 0.015053\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4811/5000] | Train Loss: 0.015043\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4812/5000] | Train Loss: 0.015032\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4813/5000] | Train Loss: 0.015021\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4814/5000] | Train Loss: 0.015011\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4815/5000] | Train Loss: 0.015000\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4816/5000] | Train Loss: 0.014989\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4817/5000] | Train Loss: 0.014979\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4818/5000] | Train Loss: 0.014968\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4819/5000] | Train Loss: 0.014957\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4820/5000] | Train Loss: 0.014947\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4821/5000] | Train Loss: 0.014936\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4822/5000] | Train Loss: 0.014926\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4823/5000] | Train Loss: 0.014915\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4824/5000] | Train Loss: 0.014905\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4825/5000] | Train Loss: 0.014894\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4826/5000] | Train Loss: 0.014884\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4827/5000] | Train Loss: 0.014873\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4828/5000] | Train Loss: 0.014863\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4829/5000] | Train Loss: 0.014852\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4830/5000] | Train Loss: 0.014842\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4831/5000] | Train Loss: 0.014832\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4832/5000] | Train Loss: 0.014821\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4833/5000] | Train Loss: 0.014811\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4834/5000] | Train Loss: 0.014800\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4835/5000] | Train Loss: 0.014790\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4836/5000] | Train Loss: 0.014780\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4837/5000] | Train Loss: 0.014769\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4838/5000] | Train Loss: 0.014759\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4839/5000] | Train Loss: 0.014749\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4840/5000] | Train Loss: 0.014739\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4841/5000] | Train Loss: 0.014728\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4842/5000] | Train Loss: 0.014718\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4843/5000] | Train Loss: 0.014708\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4844/5000] | Train Loss: 0.014698\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4845/5000] | Train Loss: 0.014687\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4846/5000] | Train Loss: 0.014677\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4847/5000] | Train Loss: 0.014667\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4848/5000] | Train Loss: 0.014657\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4849/5000] | Train Loss: 0.014647\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4850/5000] | Train Loss: 0.014637\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4851/5000] | Train Loss: 0.014626\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4852/5000] | Train Loss: 0.014616\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4853/5000] | Train Loss: 0.014606\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4854/5000] | Train Loss: 0.014596\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4855/5000] | Train Loss: 0.014586\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4856/5000] | Train Loss: 0.014576\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4857/5000] | Train Loss: 0.014566\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4858/5000] | Train Loss: 0.014556\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4859/5000] | Train Loss: 0.014546\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4860/5000] | Train Loss: 0.014536\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4861/5000] | Train Loss: 0.014526\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4862/5000] | Train Loss: 0.014516\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4863/5000] | Train Loss: 0.014506\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4864/5000] | Train Loss: 0.014496\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4865/5000] | Train Loss: 0.014486\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4866/5000] | Train Loss: 0.014476\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4867/5000] | Train Loss: 0.014467\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4868/5000] | Train Loss: 0.014457\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4869/5000] | Train Loss: 0.014447\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4870/5000] | Train Loss: 0.014437\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4871/5000] | Train Loss: 0.014427\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4872/5000] | Train Loss: 0.014417\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4873/5000] | Train Loss: 0.014408\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4874/5000] | Train Loss: 0.014398\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4875/5000] | Train Loss: 0.014388\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4876/5000] | Train Loss: 0.014378\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4877/5000] | Train Loss: 0.014368\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4878/5000] | Train Loss: 0.014359\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4879/5000] | Train Loss: 0.014349\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4880/5000] | Train Loss: 0.014339\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4881/5000] | Train Loss: 0.014330\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4882/5000] | Train Loss: 0.014320\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4883/5000] | Train Loss: 0.014310\n",
      "Validation AVG Loss:     0.000013 \n",
      "\n",
      "Epoch [4884/5000] | Train Loss: 0.014301\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4885/5000] | Train Loss: 0.014291\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4886/5000] | Train Loss: 0.014281\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4887/5000] | Train Loss: 0.014272\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4888/5000] | Train Loss: 0.014262\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4889/5000] | Train Loss: 0.014253\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4890/5000] | Train Loss: 0.014243\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4891/5000] | Train Loss: 0.014233\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4892/5000] | Train Loss: 0.014224\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4893/5000] | Train Loss: 0.014214\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4894/5000] | Train Loss: 0.014205\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4895/5000] | Train Loss: 0.014195\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4896/5000] | Train Loss: 0.014186\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4897/5000] | Train Loss: 0.014176\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4898/5000] | Train Loss: 0.014167\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4899/5000] | Train Loss: 0.014157\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4900/5000] | Train Loss: 0.014148\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4901/5000] | Train Loss: 0.014139\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4902/5000] | Train Loss: 0.014129\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4903/5000] | Train Loss: 0.014120\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4904/5000] | Train Loss: 0.014110\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4905/5000] | Train Loss: 0.014101\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4906/5000] | Train Loss: 0.014092\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4907/5000] | Train Loss: 0.014082\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4908/5000] | Train Loss: 0.014073\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4909/5000] | Train Loss: 0.014064\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4910/5000] | Train Loss: 0.014054\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4911/5000] | Train Loss: 0.014045\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4912/5000] | Train Loss: 0.014036\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4913/5000] | Train Loss: 0.014027\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4914/5000] | Train Loss: 0.014017\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4915/5000] | Train Loss: 0.014008\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4916/5000] | Train Loss: 0.013999\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4917/5000] | Train Loss: 0.013990\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4918/5000] | Train Loss: 0.013981\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4919/5000] | Train Loss: 0.013971\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4920/5000] | Train Loss: 0.013962\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4921/5000] | Train Loss: 0.013953\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4922/5000] | Train Loss: 0.013944\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4923/5000] | Train Loss: 0.013935\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4924/5000] | Train Loss: 0.013926\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4925/5000] | Train Loss: 0.013917\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4926/5000] | Train Loss: 0.013908\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4927/5000] | Train Loss: 0.013898\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4928/5000] | Train Loss: 0.013889\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4929/5000] | Train Loss: 0.013880\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4930/5000] | Train Loss: 0.013871\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4931/5000] | Train Loss: 0.013862\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4932/5000] | Train Loss: 0.013853\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4933/5000] | Train Loss: 0.013844\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4934/5000] | Train Loss: 0.013835\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4935/5000] | Train Loss: 0.013826\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4936/5000] | Train Loss: 0.013817\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4937/5000] | Train Loss: 0.013808\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4938/5000] | Train Loss: 0.013799\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4939/5000] | Train Loss: 0.013791\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4940/5000] | Train Loss: 0.013782\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4941/5000] | Train Loss: 0.013773\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4942/5000] | Train Loss: 0.013764\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4943/5000] | Train Loss: 0.013755\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4944/5000] | Train Loss: 0.013746\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4945/5000] | Train Loss: 0.013737\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4946/5000] | Train Loss: 0.013729\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4947/5000] | Train Loss: 0.013720\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4948/5000] | Train Loss: 0.013711\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4949/5000] | Train Loss: 0.013702\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4950/5000] | Train Loss: 0.013693\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4951/5000] | Train Loss: 0.013685\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4952/5000] | Train Loss: 0.013676\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4953/5000] | Train Loss: 0.013667\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4954/5000] | Train Loss: 0.013658\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4955/5000] | Train Loss: 0.013650\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4956/5000] | Train Loss: 0.013641\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4957/5000] | Train Loss: 0.013632\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4958/5000] | Train Loss: 0.013624\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4959/5000] | Train Loss: 0.013615\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4960/5000] | Train Loss: 0.013606\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4961/5000] | Train Loss: 0.013598\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4962/5000] | Train Loss: 0.013589\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4963/5000] | Train Loss: 0.013580\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4964/5000] | Train Loss: 0.013572\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4965/5000] | Train Loss: 0.013563\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4966/5000] | Train Loss: 0.013555\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4967/5000] | Train Loss: 0.013546\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4968/5000] | Train Loss: 0.013537\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4969/5000] | Train Loss: 0.013529\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4970/5000] | Train Loss: 0.013520\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4971/5000] | Train Loss: 0.013512\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4972/5000] | Train Loss: 0.013503\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4973/5000] | Train Loss: 0.013495\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4974/5000] | Train Loss: 0.013486\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4975/5000] | Train Loss: 0.013478\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4976/5000] | Train Loss: 0.013470\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4977/5000] | Train Loss: 0.013461\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4978/5000] | Train Loss: 0.013453\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4979/5000] | Train Loss: 0.013444\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4980/5000] | Train Loss: 0.013436\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4981/5000] | Train Loss: 0.013427\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4982/5000] | Train Loss: 0.013419\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4983/5000] | Train Loss: 0.013411\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4984/5000] | Train Loss: 0.013402\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4985/5000] | Train Loss: 0.013394\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4986/5000] | Train Loss: 0.013386\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4987/5000] | Train Loss: 0.013377\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4988/5000] | Train Loss: 0.013369\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4989/5000] | Train Loss: 0.013361\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4990/5000] | Train Loss: 0.013352\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4991/5000] | Train Loss: 0.013344\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4992/5000] | Train Loss: 0.013336\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4993/5000] | Train Loss: 0.013328\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4994/5000] | Train Loss: 0.013319\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4995/5000] | Train Loss: 0.013311\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4996/5000] | Train Loss: 0.013303\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4997/5000] | Train Loss: 0.013295\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4998/5000] | Train Loss: 0.013287\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [4999/5000] | Train Loss: 0.013278\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Epoch [5000/5000] | Train Loss: 0.013270\n",
      "Validation AVG Loss:     0.000012 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "trainer_1 = Trainer(\n",
    "    data=dataset,\n",
    "    input_colums=['criteria1', 'criteria2'],\n",
    "    output_colums=['parameter1', 'parameter2'],\n",
    "    batch_size=1000,\n",
    "    learning_rate=0.0005,\n",
    "    shuffle=False,\n",
    "    test_size=0.2,\n",
    "    random_state=30,\n",
    "    save_path='saved_model/',\n",
    "    model_middle_layers=256,\n",
    ")\n",
    "trainer_1.run(5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_1.plot_train_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Входные данные: [  38. -716.]\n",
      "Нормализованные: [-0.79310345 -0.02448273]\n",
      "Вывод модели: [0.02600483 0.04913327]\n",
      "Денормализованные данные: [54.63121 55.6373 ]\n",
      "{'criteria1': {'max': 194.0, 'min': 20.0}, 'criteria2': {'max': 29245.1, 'min': -29245.1}, 'parameter1': {'max': 97.0, 'min': 10.0}, 'parameter2': {'max': 97.0, 'min': 10.0}}\n"
     ]
    }
   ],
   "source": [
    "trainer_1.save_model()\n",
    "trainer_1.predict(np.array([38.,\t-716.]))\n",
    "\n",
    "print(trainer_1.normalize_param)\n",
    "\n",
    "# # Next starts\n",
    "# load_model = LoadModel(\n",
    "#     'saved_model/model_weights.pth',\n",
    "#     'saved_model/normalize_params.pkl',\n",
    "#     input_colums=['criteria1', 'criteria2'],\n",
    "#     output_colums=['parameter1', 'parameter2']\n",
    "# )\n",
    "# print(load_model.predict(np.array([47,\t3100.75])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parameter1</th>\n",
       "      <th>parameter2</th>\n",
       "      <th>criteria1</th>\n",
       "      <th>criteria2</th>\n",
       "      <th>constraint1</th>\n",
       "      <th>constraint2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>22.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>-716.283</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>22.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>-386.416</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>22.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>442.965</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>22.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>942.478</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>22.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1498.540</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     parameter1  parameter2  criteria1  criteria2  constraint1  constraint2\n",
       "122        22.0        16.0       38.0   -716.283         True        False\n",
       "123        22.0        19.0       41.0   -386.416         True        False\n",
       "124        22.0        22.0       44.0      0.000         True        False\n",
       "125        22.0        25.0       47.0    442.965         True         True\n",
       "126        22.0        28.0       50.0    942.478         True         True\n",
       "127        22.0        31.0       53.0   1498.540         True         True"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.iloc[122:128]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Визуальное сравнение\n",
    "Таблица сверху тестовые данные, снизу можно оценить примерную точность, взять значения из criteria1\tcriteria2 и получатся параметры parameter1\tparameter2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Входные данные: [70. 82.]\n",
      "Нормализованные: [-0.42528737  0.00280389]\n",
      "Вывод модели: [-0.05525138 -0.07415187]\n",
      "Денормализованные данные: [35.       53.621967]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([35.      , 53.621967], dtype=float32)"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.predict(np.array([70,\t82], dtype=np.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Входные данные: [34. 25.]\n",
      "Нормализованные: [-0.83908046  0.00085484]\n",
      "Вывод модели: [-0.09794222 -0.11397348]\n",
      "Денормализованные данные: [17.       53.537186]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([17.      , 53.537186], dtype=float32)"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.predict(np.array([34., 25.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Входные данные: [  47.   3100.75]\n",
      "Нормализованные: [-0.68965517  0.10602631]\n",
      "Вывод модели: [-0.10213335 -0.08918881]\n",
      "Денормализованные данные: [23.5      58.112144]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trainer.predict(np.array([47,\t3100.75])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best result\n",
    "Test Error: Avg loss: 0.001735 \n",
    "\n",
    "learning rate 0.0005\n",
    "\n",
    "Epoch = 10000\n",
    "\n",
    "batch_size = 120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <class '__main__.NeuralNetwork'>: it's not the same object as __main__.NeuralNetwork",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[448], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[266], line 156\u001b[0m, in \u001b[0;36mTrainer.save_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_model\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 156\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muniq_name\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_model_weights.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Projects\\ML\\.venv\\lib\\site-packages\\torch\\serialization.py:619\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[0;32m    617\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m    618\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m--> 619\u001b[0m         \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_disable_byteorder_record\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    620\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    621\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Projects\\ML\\.venv\\lib\\site-packages\\torch\\serialization.py:831\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[0;32m    829\u001b[0m pickler \u001b[38;5;241m=\u001b[39m pickle_module\u001b[38;5;241m.\u001b[39mPickler(data_buf, protocol\u001b[38;5;241m=\u001b[39mpickle_protocol)\n\u001b[0;32m    830\u001b[0m pickler\u001b[38;5;241m.\u001b[39mpersistent_id \u001b[38;5;241m=\u001b[39m persistent_id\n\u001b[1;32m--> 831\u001b[0m \u001b[43mpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    832\u001b[0m data_value \u001b[38;5;241m=\u001b[39m data_buf\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[0;32m    833\u001b[0m zip_file\u001b[38;5;241m.\u001b[39mwrite_record(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, data_value, \u001b[38;5;28mlen\u001b[39m(data_value))\n",
      "\u001b[1;31mPicklingError\u001b[0m: Can't pickle <class '__main__.NeuralNetwork'>: it's not the same object as __main__.NeuralNetwork"
     ]
    }
   ],
   "source": [
    "trainer.save_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load  model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

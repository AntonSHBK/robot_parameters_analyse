# Разработка и анализ нейронной сети для обработки данных кинематики роботов

![Фон](https://github.com/AntonSHBK/simple_robot_parameters_analyse/blob/main/article_imgs/face.webp?raw=true)

**Содержание:**

- [Разработка и анализ нейронной сети для обработки данных кинематики роботов](#разработка-и-анализ-нейронной-сети-для-обработки-данных-кинематики-роботов)
  - [Аннотация](#аннотация)
  - [Общее описание Machine Learning (ML)](#общее-описание-machine-learning-ml)
  - [Применение ML в робототехнике](#применение-ml-в-робототехнике)
  - [Описание задачи](#описание-задачи)
  - [Описание модели](#описание-модели)
  - [Описание класса Trainer:](#описание-класса-trainer)
  - [Анализ результатов](#анализ-результатов)
  - [Вывод](#вывод)
  - [Используемая литература](#используемая-литература)
- [Контакты](#контакты)

## Аннотация

В данной работе представлена разработка и тестирование модели машинного обучения, основанной на нейронных сетях, для анализа данных кинематики простого робота. Используя библиотеку PyTorch, была создана и обучена модель, способная обрабатывать численные и булевые параметры, полученные в результате кинематических расчётов. Основная цель исследования заключалась в разработке надёжной и точной модели, которая могла бы способствовать улучшению проектирования и анализа в робототехнике.

Процесс обучения модели был подробно описан, включая конфигурацию, методы обучения и валидации, а также вспомогательные функции для визуализации результатов и сохранения модели. Модель обучалась на стандартизированных данных, что позволило достичь высокой точности предсказаний, как подтверждается значениями потерь и средней абсолютной ошибки (MAE) на этапах обучения и валидации.

Результаты работы демонстрируют, что предложенная модель эффективно справляется с задачей анализа кинематических данных и может быть использована для дальнейшего исследования и разработки в области робототехники. Также были обсуждены возможности дальнейшего улучшения модели, включая тестирование на более сложных датасетах и оптимизацию гиперпараметров. Это исследование может быть полезным при изучении нейронных сетей, а также при их разработке.

## Общее описание Machine Learning (ML)

В эпоху цифровых технологий машинное обучение (ML) выступает как ключевой элемент прогресса в сфере робототехники и искусственного интеллекта (ИИ). Эта наука, на пересечении математической статистики, теории сигналов, оптимизационных алгоритмов и теории управления, открывает новые горизонты в понимании и обработке данных.

<details>
  <summary>Подробнее</summary>
Машинное обучение предполагает создание моделей, способных адаптироваться и улучшаться благодаря взаимодействию с данными, процесс схож с обучением в природе и основан на принципах алгоритмического анализа и обработки информации.

В рамках ML модели анализируют входные данные, которые могут быть как исходными, так и специально подготовленными признаками, и на их основе формируют выводы или прогнозы. До широкого распространения глубокого обучения, задача инженерии признаков часто выполнялась вручную. Сейчас же благодаря развитию глубоких нейронных сетей, этот процесс стал автоматизированным, обеспечивая более глубокое и комплексное изучение данных. Наряду с нейронными сетями, в машинном обучении также активно используются линейные, квадратичные модели и вероятностные распределения, включая гауссово распределение [2].

Многообразие типов нейронных сетей, таких как конволюционные (CNN) [3], рекуррентные (RNN) [4] и графовые нейронные сети (GNN) [5], позволяет подходить к решению задач глубокого обучения с большим выбором инструментария. Выбор модели зависит от специфики задачи и характеристик данных. В сложных случаях предпочтение отдается нейронным сетям из-за их способности аппроксимировать сложные нелинейные взаимосвязи, что особенно важно при работе с большими объемами данных, например, в области обработки изображений.

Ключевым элементом в процессе машинного обучения является оптимизация параметров модели для достижения наилучших результатов на основе имеющихся данных. Это включает в себя выбор типа модели, настройку внутренних параметров и определение оптимальных гиперпараметров, таких как количество слоев в нейронной сети или типы используемых распределений. Данные для обучения и тестирования могут представлять собой различные типы информации, от числовых массивов до текстов и изображений, а результаты могут варьироваться в зависимости от задачи, в том числе использование вариативных автоэнкодеров (VAE) [8] и генеративных состязательных сетей (GAN) [9].

Машинное обучение находит применение в самых разнообразных областях, от автоматического распознавания образов до создания алгоритмов принятия решений, где традиционные подходы могут оказаться неэффективными. Оно стремится не просто имитировать человеческое восприятие и аналитические способности, но и разрабатывать новые методы для обработки и интерпретации данных, обеспечивая нахождение оптимальных решений на основе глубокого анализа и накопления опыта [12].

Методы машинного обучения можно классифицировать по типу обучения на обучение с учителем, без учителя и с подкреплением. Каждый из этих подходов предлагает уникальные стратегии для обработки данных и адаптации моделей, используя различные алгоритмы, в том числе методы градиентного спуска, для оптимизации параметров моделей [2].

Обучение с учителем включает в себя модели, обучаемые на основе заранее определенных пар "вход-выход", что позволяет модели научиться предсказывать результаты на новых данных. Неконтролируемое обучение, напротив, исследует скрытые структуры в неразмеченных данных, такие как кластеризация или снижение размерности. Обучение с подкреплением фокусируется на том, чтобы научить модель принимать решения через серию испытаний и ошибок, стимулируя ее достигать определенной цели [38].

Таким образом, машинное обучение представляет собой мощный инструмент, позволяющий расширить границы возможного в обработке и анализе данных, создавая новые подходы к решению задач и обеспечивая прогресс в различных сферах научных исследований и практического применения.

</details>

## Применение ML в робототехнике

Современная промышленность не может обойтись без использования роботов: они выполняют такие операции, как фрезерование, сверление, покраска, а также задачи по сортировке и перемещению предметов. Сложность промышленных задач требует от роботов всё более продвинутой архитектуры и систем управления.

<details>
  <summary>Подробнее</summary>

Машинное обучение не просто играет ключевую роль в развитии современной робототехники; оно является движущей силой инноваций, позволяя роботам адаптироваться к разнообразным условиям и выполнять задачи с необходимой гибкостью и интеллектом. 

Применение ML в робототехнике охватывает широкий спектр направлений:
- **Зрение роботов** обеспечивает машинам способность "видеть" и интерпретировать окружающий мир, что необходимо для ряда задач, от сортировки объектов до навигации в пространстве [13];
- **Навигация** позволяет роботам самостоятельно передвигаться в пространстве, избегая препятствий и оптимизируя маршруты, что критически важно для доставки, разведения и спасательных операций [14];
- **Полевая робототехника**, которая включает в себя автономные машины, работающие в сельском хозяйстве, экологическом мониторинге и исследованиях на открытом воздухе [15];
- **Медицинская робототехника** преобразовывает здравоохранение, обеспечивая выполнение сложных хирургических операций с высокой точностью и минимальным вмешательством [19];
- **Навигация в условиях пересеченной местности** открывает новые возможности для использования роботов в сложных условиях, таких как поисково-спасательные операции в горной местности или на разрушенных после стихийных бедствий территориях [20].

Машинное обучение нашло широкое применение в анализе кинематики роботов, позволяя оценить и управлять их движением с высокой точностью. Использование нейронных сетей для кинематического анализа робота предложено в исследовании [22], где авторы демонстрируют преимущества перед традиционными методами, такими как алгоритм Ньютона-Рапсона, особенно в аспекте выявления множественных решений для обобщенных координат.

Примеры успешного применения ML в робототехнике демонстрируют его потенциал в создании новых возможностей. Один из таких примеров — разработка роботов-сортировщиков на складах, которые используют машинное зрение для идентификации и сортировки товаров. Это не только существенно увеличивает скорость обработки заказов, но и минимизирует ошибки, связанные с человеческим фактором [39].

В другой работе группа учёных [24] описала подход к решению обратной кинематической задачи для серийных роботов с помощью нейронной сети, обученной учитывать ошибки сборки в шарнирах. 

Анализ кинематики роботов параллельной структуры, оснащенных шестью прямолинейными приводами, был проведен в работе [26] с использованием различных методов машинного обучения, включая линейную регрессию, многомерную полиномиальную регрессию, векторную регрессию с поддержкой, регрессию на основе деревьев решений и регрессию случайного леса.

Что касается точного определения рабочего пространства по прежнему широко используется метод Монте-Карло для определения достижимых положений робота [27, 28], а также разрабатываются точные интерпретируемые модели [29]. Определение рабочей области тесно взаимосвязано с решением кинематики робота (прямая и обратная задачи кинематики). Хорошее понимание этих двух аспектов способствует решению другой задачи в роботехнике - оптимизации параметров робота. Существует множество работ представляющих решение оптимизации параметров робота, как численные методы, так и графические. В этом контексте, машинное обучение предлагает новые подходы, включая использование генетических алгоритмов [41], для решения задач оптимизации параметров роботов.

Таким образом, интеграция машинного обучения в робототехнику открывает новые возможности для разработки и управления роботами, делая их более адаптивными, интеллектуальными и способными к выполнению широкого спектра задач в различных условиях.

</details>

## Описание задачи

В рамках данного исследования ставится задача разработки и реализации модели машинного обучения с использованием нейронных сетей на платформе PyTorch для анализа данных, полученных в результате кинематических расчётов простого робота. В основу модели ложатся данные, содержащие шесть ключевых параметров, отражающих поведение кинематической структуры робота.

**Параметры данных:**
1. **Входные параметры (2 численных):** Представляют собой специфические характеристики робота, определяющие его конфигурацию и начальное состояние.
2. **Выходные параметры (2 численных):** Это значения, рассчитываемые на основе кинематики, которые определяют окончательное состояние структуры робота после выполнения заданной операции.
3. **Условные параметры (2 булевых):** Они выражают выполнение или невыполнение определенных условий в процессе работы кинематической структуры.

[Исходный датасет](https://github.com/AntonSHBK/simple_robot_parameters_analyse/blob/main/data/DataSet900.csv)

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>parameter1</th>
      <th>parameter2</th>
      <th>criteria1</th>
      <th>criteria2</th>
      <th>constraint1</th>
      <th>constraint2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>10</td>
      <td>10</td>
      <td>20</td>
      <td>0.000</td>
      <td>True</td>
      <td>False</td>
    </tr>
    <tr>
      <th>1</th>
      <td>10</td>
      <td>13</td>
      <td>23</td>
      <td>216.770</td>
      <td>True</td>
      <td>True</td>
    </tr>
    <tr>
      <th>2</th>
      <td>10</td>
      <td>16</td>
      <td>26</td>
      <td>490.088</td>
      <td>True</td>
      <td>True</td>
    </tr>
    <tr>
      <th>3</th>
      <td>10</td>
      <td>19</td>
      <td>29</td>
      <td>819.956</td>
      <td>False</td>
      <td>True</td>
    </tr>
    <tr>
      <th>4</th>
      <td>10</td>
      <td>22</td>
      <td>32</td>
      <td>1206.370</td>
      <td>False</td>
      <td>True</td>
    </tr>
  </tbody>
</table>
</div>

**Цель исследования:** Разработать нейронную сеть, способную анализировать указанные параметры и выдавать точные и проверяемые результаты, например по входным параметрам определять выходные. Это необходимо для того, чтобы повысить понимание динамики работы кинематических структур и улучшить проектирование робототехнических систем.

**Практическая значимость:** Разработанная модель будет способствовать автоматизации процессов анализа кинематических данных, что ускорит и упростит процесс разработки и тестирования робототехнических систем, а также повысит их надежность и эффективность.

**Ожидаемые результаты:** Модель должна обеспечить точное предсказание выходных и условных параметров на основе заданных входных данных, демонстрируя высокую степень корреляции с реальным поведением кинематических структур.

## Описание модели

В результате выполнения кинематики был создан набор данных, содержащий значения параметров робота и  соответствующих значений обобщенных координат. Полученные данные разделены на тренировочный набор и проверочный набор в соотношении 80% тренировочный набор и 20% проверочный. Тренировочные данные перемешаны.

На основе кинематического анализа были сгенерированы данные о рабочем пространстве. В научной литературе предлагается несколько методов оценки рабочего пространства.  Предыдущие работы на эту тему представлены в [40, 41].

Процесс определения параметров нейронной сети является сложной и важной задачей, как правило нет какого то обязательного правила составления нейронных сетей, зачастую параметры нейронных сейте подбираются эмпирические в процессе тестирования или основываясь на личностном опыте.

В качестве библиотеки проектирования нейронных сетей используем распространённую библиотеку Pytorch [31]. Выходные параметры модели:
- `input_size`: Размер входного слоя, который должен соответствовать количеству признаков в ваших данных.
- `output_size`: Размер выходного слоя, который определяет количество целевых переменных, которые модель будет предсказывать. Для одномерной регрессии это будет 1.
- `layer_sizes`: Список, определяющий размеры скрытых слоёв. Каждый элемент списка указывает на количество нейронов в соответствующем слое. По умолчанию зададим один скрытый слой размером 64 нейрона.
- `activation_fn`: Функция активации, применяемая к выходам каждого скрытого слоя. По умолчанию используем функцию активации ReLU [32].

[Исходный код](https://github.com/AntonSHBK/simple_robot_parameters_analyse/blob/main/analise.ipynb)

```python
import torch.nn as nn
import torch.nn.functional as F

class RegressionModel(nn.Module):
    def __init__(self, 
                 input_size, 
                 output_size,
                 layer_sizes=[64], 
                 activation_fn=F.relu):
        super(RegressionModel, self).__init__()
        self.input_size = input_size
        self.output_size = output_size
        self.layer_sizes = layer_sizes
        self.activation_fn = activation_fn        
        self.layers = nn.ModuleList()        
        prev_size = input_size
        for size in layer_sizes:
            self.layers.append(nn.Linear(prev_size, size))
            prev_size = size        
        self.layers.append(nn.Linear(prev_size, output_size))
        self.activation_fn = activation_fn

    def forward(self, x):
        for layer in self.layers[:-1]:
            x = self.activation_fn(layer(x))
        x = self.layers[-1](x)
        return x

```

Принцип работы:
1. Входной вектор данных `x` последовательно проходит через все слои модели.
2. На выходе каждого скрытого слоя применяется функция активации (по умолчанию `F.relu` [32]), что позволяет модели изучать нелинейные зависимости между входными и выходными данными.
3. Последний слой (выходной слой) возвращает линейный выход, который может интерпретироваться как прогнозируемое значение целевой переменной для задачи регрессии.

Основной метод:
- `forward(x)`: Определяет прямой проход (forward pass) через модель. Для каждого слоя, кроме последнего, применяется функция активации к его выходу. Выход последнего слоя возвращается напрямую, что характерно для задач регрессии, где мы хотим получить непрерывное значение без применения функции активации.
  
Эта модель представляет собой гибкий инструмент для построения нейронных сетей различной архитектуры для решения регрессионных задач, позволяя экспериментировать с различным количеством слоёв и функциями активации.

Функция ReLU (Rectified Linear Unit) — это функция активации, широко используемая в нейронных сетях, особенно в глубоком обучении. Функция ReLU и её производные помогают решать проблемы, связанные с градиентным спуском, такие как затухание или взрыв градиента, ускоряя процесс обучения моделей глубокого обучения [32].

<details>
  <summary>Подробнее о ReLU</summary>

Функция ReLU определяется следующим образом для входа $x$:

$$ \text{ReLU}(x) = \max(0, x) $$

Это означает, что если вход $x$ положителен, функция возвращает $x$, а если $x$ отрицательный — возвращает 0.

График функции ReLU прост: для отрицательных значений $x$ функция принимает значение 0, а для положительных значений $x$ функция линейно возрастает с угловым коэффициентом 1.

Производная функции ReLU используется в процессе обратного распространения ошибки (backpropagation [33]) для обновления весов нейронной сети. Она определяется следующим образом:

$$ \text{ReLU}'(x) = 
   \begin{cases} 
   0 & \text{if } x \leq 0 \\
   1 & \text{if } x > 0 
   \end{cases}
$$

Преимущества:
- **Простота вычисления**: Поскольку ReLU является кусочно-линейной функцией, она требует меньше вычислительных ресурсов по сравнению с другими функциями активации, такими как сигмоид или гиперболический тангенс.
- **Решение проблемы затухания градиента**: В отличие от сигмоидальных функций, градиент ReLU не затухает для большого диапазона положительных значений, что облегчает обучение глубоких нейронных сетей.
- **Способствует разреженности активаций**: Поскольку ReLU возвращает 0 для всех отрицательных значений входа, это приводит к тому, что в любой момент активны только часть нейронов. Это повышает эффективность и облегчает получение разреженных представлений данных.

Недостатки:
- **Проблема "затухания"**: Если нейрон начинает выдавать отрицательные значения для всех входов в датасете, он может "затухнуть", то есть перестать вносить какой-либо вклад в адаптацию сети, поскольку его градиент будет нулевым. Решениями этой проблемы являются варианты ReLU, такие как Leaky ReLU или Parametric ReLU [34], которые позволяют передавать небольшой градиент, даже когда вход отрицателен.

</details>

В целях  обеспечения масштабируемости и гибкости регулирования модели обучения используем методы декомпозиции процесса обучения (помести процесс обучения в отдельный класс Trainer, это общепринятая практика). Этот класс инкапсулирует логику обучения, включая итерации по эпохам, обработку пакетов данных, вычисление функции потерь, выполнение шагов оптимизации, а также валидацию модели.

## Описание класса Trainer:

Этот класс предназначен для обучения, валидации и визуализации результатов работы модели машинного обучения.

[Исходный код](https://github.com/AntonSHBK/simple_robot_parameters_analyse/blob/main/analise.ipynb)

**Конструктор** `__init__`
Принимает следующие параметры:
- `model`: экземпляр модели, которую необходимо обучить.
- `criterion`: функция потерь, по умолчанию используется `torch.nn.MSELoss`.
- `optimizer`: оптимизатор, по умолчанию используется `torch.optim.Adam` с шагом обучения 0.001.
- `device`: устройство, на котором будет происходить обучение ('cpu' или 'gpu').
- `print_every`: частота вывода информации о процессе обучения (каждые `print_every` эпох).
- `verbose`: если `True`, будет выводиться дополнительная информация в процессе обучения.

Класс хранит списки потерь и ошибок на этапах обучения и валидации, которые могут быть использованы для анализа процесса обучения.

<details>
  <summary>Подробнее о методах</summary>

**Метод `_train`**

Принимает один параметр:
- `train_dataloader`: загрузчик данных для обучения.

Метод проходит по всем данным обучения, вычисляет потери и обновляет параметры модели. В конце каждой эпохи вычисляет среднюю потерю и среднюю абсолютную ошибку (MAE).

**Метод `_eval`**

Принимает один параметр:
- `val_dataloader`: загрузчик данных для валидации.

Метод проходит по всем данным валидации, вычисляет потери и сохраняет результаты без обновления параметров модели.

**Метод `fit`**

Принимает параметры:
- `n_epochs`: количество эпох обучения.
- `train_dataloader`: загрузчик данных для обучения.
- `val_dataloader`: загрузчик данных для валидации.

Метод организует полный цикл обучения и валидации модели, выводит результаты после каждой `print_every` эпохи.

**Метод `plot_metrics`**

Визуализирует динамику изменения потерь и MAE во время обучения и валидации, используя библиотеку Matplotlib.

**Метод `predict`**

Принимает `inputs` — данные для предсказания.
Возвращает предсказания модели.

**Метод `save_model`**

Сохраняет текущее состояние модели и её конфигурацию в файл.

**Метод `load_model`**

Загружает модель из файла.

</details>

**Основные входные параметры:**

- **model**: Экземпляр модели, которую нужно обучить.
- **criterion**: Функция потерь, используемая для оценки ошибки модели. По умолчанию зададим `MSELoss` [35], подходящий для задач регрессии.
- **optimizer**: Оптимизатор для обновления весов модели на основе градиентов. По умолчанию задаётся оптимизатор Adam [36] с скоростью обучения 0.001.
- **device**: Устройство, на котором будут выполняться вычисления (`cpu` или `cuda`).

**Особенности:**

- Этот класс обеспечивает удобную обёртку для стандартного цикла обучения модели с возможностью валидации.
- Использование DataLoader в методах `_train` и `_eval` позволяет эффективно обрабатывать данные пакетами, что важно для обучения на больших наборах данных.
- Поддержка гибкой конфигурации оптимизатора и функции потерь делает класс универсальным для различных задач машинного обучения.
- Встроенная поддержка визуализации процесса обучения с помощью `plot_metrics` позволяет наглядно отслеживать прогресс.

В качестве оптимизатора был выбран Adam (Adaptive Moment Estimation) — это метод стохастической оптимизации, который применяется для обновления весов нейронной сети в процессе обучения. Он сочетает в себе идеи двух других методов оптимизации: RMSprop и стохастического градиентного спуска с моментом. Adam адаптирует скорость обучения для каждого параметра индивидуально, используя оценки первого и второго моментов градиентов [36].

<details>
  <summary>Подробнее о Adam</summary>

Пусть $g_t$ обозначает градиент в момент времени $t$, $m_t$ и $v_t$ — оценки первого и второго моментов градиентов соответственно. Тогда шаги алгоритма Adam можно описать следующими формулами:

1. **Вычисление градиентов для каждого параметра:**
   $$g_t = \nabla_{\theta}f_t(\theta_{t-1})$$

2. **Обновление оценок первого момента (аналогично моменту в стохастическом градиентном спуске):**
   $$m_t = \beta_1 \cdot m_{t-1} + (1 - \beta_1) \cdot g_t$$

3. **Обновление оценок второго момента (аналогично RMSprop):**
   $$v_t = \beta_2 \cdot v_{t-1} + (1 - \beta_2) \cdot g_t^2$$

4. **Коррекция оценок моментов для учета их инициализации в нуле:**
   $$ \hat{m}_t = \frac{m_t}{1 - \beta_1^t} $$
   $$ \hat{v}_t = \frac{v_t}{1 - \beta_2^t} $$

5. **Обновление параметров:**
   $$ \theta_t = \theta_{t-1} - \frac{\alpha \cdot \hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon} $$

где:
- $\theta_t$ — параметры модели на шаге $t$,
- $\alpha$ — скорость обучения,
- $\beta_1$ и $\beta_2$ — коэффициенты экспоненциального затухания для оценок моментов (обычно выбираются близко к 1),
- $\epsilon$ — малое положительное число, добавляемое для устойчивости деления (чтобы избежать деления на ноль).

Adam популярен благодаря своей эффективности в широком диапазоне задач машинного обучения и его способности адаптироваться к различным условиям задачи

На этом этапе еще одним важным аспектом является критерий сходимости. Это может быть максимальное количество оценок функции, конкретное минимальное значение средней квадратичной ошибки (`MSE`) или подтверждение эффективности работы обученной сети на основе данных, зарезервированных для валидации. Этот критерий накладывается пользователем, определяющим сеть, но может зависеть от области применения, для которой используется нейронная сеть. В данной ситуации в качестве критерия принята функция `MSE`.

Функция потерь среднеквадратичной ошибки (MSE, Mean Squared Error Loss) — это стандартная мера, используемая для оценки разности между предсказанными значениями модели и фактическими значениями. Она часто применяется в задачах регрессии для оптимизации параметров модели. Формула MSE вычисляется как среднее квадратов разностей между целевыми значениями и значениями, предсказанными моделью [35].

Если обозначить целевые значения как $y_i$ и соответствующие им предсказанные значения как $\hat{y}_i$ для $i$-го примера в наборе данных, то MSE вычисляется по формуле:

$$ \text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (\hat{y}_i - y_i)^2 $$

где:
- $n$ — количество примеров в наборе данных,
- $y_i$ — фактическое значение цели для $i$-го примера,
- $\hat{y}_i$ — предсказанное значение для $i$-го примера.

</details>

Цель оптимизации с использованием функции потерь MSE — минимизировать среднеквадратичное отклонение между предсказанными и реальными значениями, тем самым улучшая точность модели. В контексте обучения нейронной сети, это означает адаптацию весов сети таким образом, чтобы минимизировать значение `MSE` через процесс обратного распространения ошибки и градиентного спуска.

Последнее что хочется отметить, что для данные предварительно нормализованы, для этого использован удобный инструмент библиотеки `Scikit Learn` - `StandardScaler` [37].

<details>
  <summary>Подробнее о StandardScaler</summary>

Это метод предварительной обработки данных, который часто используется для нормализации характеристик (признаков) в машинном обучении перед обучением модели. Он преобразует данные так, чтобы их распределение имело среднее значение, равное 0, и стандартное отклонение, равное 1. Этот процесс известен также как стандартизация или z-оценка.

Стандартизация данных помогает улучшить процесс обучения, делая его более стабильным и ускоряя сходимость в алгоритмах, чувствительных к масштабу признаков, таких как линейная регрессия, логистическая регрессия, и методы, использующие градиентный спуск.

Допустим, у нас есть набор данных $X$, состоящий из $n$ признаков (характеристик), и мы хотим стандартизировать один из признаков. Пусть $x$ будет вектором значений этого признака для всех примеров в наборе данных. Тогда процесс стандартизации можно описать следующими шагами:

1. **Вычисление среднего значения ($\mu$) для признака $x$:**
   $$ \mu = \frac{1}{n} \sum_{i=1}^{n} x_i $$
   
   где $x_i$ — значение $i$-го примера для признака $x$, а $n$ — общее количество примеров.

2. **Вычисление стандартного отклонения ($\sigma$) для признака $x$:**
   $$ \sigma = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (x_i - \mu)^2} $$
   
3. **Стандартизация значения признака для каждого примера:**
   $$ x'_i = \frac{x_i - \mu}{\sigma} $$
   
   где $x'_i$ — стандартизированное значение признака $x$ для $i$-го примера.

После применения `StandardScaler`, каждый признак в новом наборе данных будет иметь среднее значение, равное 0, и стандартное отклонение, равное 1. Это делает признаки более сопоставимыми и упрощает обучение моделей машинного обучения.

</details>

## Анализ результатов

В качестве входных  параметров модели были выбраны: `parameter1`, `parameter2`, `constraint1`, `constraint2`. качестве выходных параметров были выбраны: `criteria1`, `criteria2`.

![Анализ обучения](https://github.com/AntonSHBK/simple_robot_parameters_analyse/blob/main/article_imgs/MAE_metrics.png?raw=true)

```txt
Epoch 10, Loss: 0.2909, MAE: 0.4163, Val Loss: 0.2987, Val MAE: 0.4313
Epoch 20, Loss: 0.0782, MAE: 0.2165, Val Loss: 0.0852, Val MAE: 0.2287
Epoch 30, Loss: 0.0275, MAE: 0.1166, Val Loss: 0.0326, Val MAE: 0.1259
Epoch 40, Loss: 0.0143, MAE: 0.0862, Val Loss: 0.0168, Val MAE: 0.0893
Epoch 50, Loss: 0.0083, MAE: 0.0653, Val Loss: 0.0098, Val MAE: 0.0685
Epoch 60, Loss: 0.0052, MAE: 0.0519, Val Loss: 0.0063, Val MAE: 0.0544
Epoch 70, Loss: 0.0035, MAE: 0.0423, Val Loss: 0.0045, Val MAE: 0.0463
Epoch 80, Loss: 0.0026, MAE: 0.0371, Val Loss: 0.0035, Val MAE: 0.0414
Epoch 90, Loss: 0.0020, MAE: 0.0330, Val Loss: 0.0028, Val MAE: 0.0376
Epoch 100, Loss: 0.0016, MAE: 0.0298, Val Loss: 0.0023, Val MAE: 0.0348

```

В результате тестирования модели на простом датасете были получены следующие показатели на последней, стой эпохе обучения:

- **Потери при обучении (Training Loss):** 0.0016
- **Средняя абсолютная ошибка при обучении (MAE):** 0.0298
- **Потери при валидации (Validation Loss):** 0.0023
- **Средняя абсолютная ошибка при валидации (Val MAE):** 0.0348

Эти результаты позволяют сделать несколько ключевых выводов о работе и эффективности модели:

**Эффективность модели**

На основе полученных метрик можно утверждать, что модель достаточно хорошо справляется с поставленной задачей. Маленькие значения потерь и средней абсолютной ошибки указывают на высокую точность предсказаний модели. Низкое значение потерь на этапе обучения и валидации также свидетельствует о том, что модель хорошо обобщает данные, не демонстрируя признаков переобучения.

**Стабильность модели**

Сравнение значений потерь и MAE между тренировочным и валидационным наборами данных показывает, что результаты довольно стабильны и модель не испытывает значительных колебаний производительности, что является хорошим признаком надежности модели.

**Влияние простоты датасета**

Важно отметить, что датасет, используемый в этом исследовании, является относительно простым. Это может влиять на обобщающую способность модели при работе с более сложными или разнообразными данными. Возможно, потребуется провести дополнительные тесты на более сложных наборах данных, чтобы лучше понять, как модель будет вести себя в различных условиях.

**Рекомендации**

1. **Тестирование на более сложных датасетах:** Для дальнейшей оценки обобщающей способности модели рекомендуется провести тестирование на более сложных и разнообразных датасетах.
2. **Эксперименты с гиперпараметрами:** Рассмотреть возможность оптимизации гиперпараметров модели, таких как скорость обучения или архитектура сети, для улучшения её производительности.
3. **Анализ ошибок:** Провести анализ типов ошибок, которые совершает модель, что может помочь в дальнейшем улучшении алгоритмов и предобработки данных.

Таким образом, исходя из анализа текущих результатов, модель демонстрирует хорошую производительность на представленных данных. Однако для полноценной оценки её потенциала необходимо провести дополнительные исследования и тесты.

## Вывод

В рамках данного исследования была успешно разработана и реализована модель машинного обучения на базе нейронных сетей с использованием библиотеки PyTorch для анализа данных, полученных в результате кинематических расчётов простого робота. В процессе работы была создана структура нейронной сети, способная обрабатывать численные и булевые параметры и выдавать точные предсказания, оптимизированная с помощью Adam и функции потерь MSELoss. Особое внимание уделено подробному описанию всех компонентов реализации модели, включая инициализацию класса тренера, методы обучения и валидации, а также вспомогательные методы для визуализации результатов и сохранения/загрузки модели. Для обучения и тестирования модели был подготовлен специализированный датасет с кинематическими данными, который был стандартизирован для улучшения сходимости процесса обучения. 

Обучение модели проходило на протяжении многих эпох, в ходе которых потери уменьшались, а точность предсказаний улучшалась, что свидетельствует о правильности выбора архитектуры и эффективности процесса обучения. Тщательный анализ результатов показал, что модель достигла высокой точности как на тренировочных, так и на валидационных данных, подтвердив свою стабильность и надежность. 

В целом, проделанная работа позволяет сделать вывод о том, что разработанная модель является функциональной и может служить как практическому применению, так и научному сообществу в области робототехники и машинного обучения.

## Используемая литература

<details>
  <summary>Раскрыть список литературы</summary>

1. Connell, J.H., Mahadevan, S.: Robot Learning. Springer Science & Business Media (2012)
2. Nielsen, M.A. Neural Networks and Deep Learning. Determination Press. 2015. https://books.google.com.mt/books?id=STDBswEACAAJ
3. Venkatesan, Ragav; Li, Baoxin. Convolutional Neural Networks in Visual Computing: A Concise Guide. CRC Press. 2017. ISBN 978-1-351-65032-8.
4. Abiodun OI, Jantan A, Omolara AE, Dada KV, Mohamed NA, Arshad H. State-of-the-art in artificial neural network applications: A survey. Heliyon. 2018 Nov 23;4(11):e00938. doi: 10.1016/j.heliyon.2018.e00938. PMID: 30519653; PMCID: PMC6260436.
5. L. Wu, P. Cui, J. Pei, and L. Zhao. Graph Neural Networks: Foundations, Frontiers, and Applications. Springer, Singapore, 2022
6. Y. LeCun, Y. Bengio, G. Hinton, Deep learning, Nature 521 (2015) 436–444, https://doi.org/10.1038/nature14539.
7. K. Hornik, M. Stinchcombe, H. White, Multilayer feedforward networks are universal approximators, Neural Netw. 2 (1989) 359–366, https://doi.org/10.1016/0893-6080(89)90020-8.
8. Y. Pu, Z. Gan, R. Henao, X. Yuan, C. Li, A. Stevens, et al., Variational autoencoder for deep learning of images, labels and captions, in: 30th Annual Conference on Neural Information Processing Systems (NeurIPS), 2016.
9. I.J. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, et al., Generative adversarial nets, in: 28th Annual Conference on Neural Information Processing Systems (NeurIPS), 2014.
10.  D. Silver, S. Singh, D. Precup, R.S. Sutton, Reward is enough, Artif. Intell. 299 (2021), 103535, https://doi.org/10.1016/j.artint.2021.103535.
11.  Battiti. R., Brunato. M.: Reactive search optimization: learning while optimizing. In: Handbook of Metaheuristics, pp. 543–571. Springer, US (2010)
12.  Murphy, R.R.: Human-robot interaction in rescue robotics. Syst. Man Cybernetics Appl. Rev. IEEE Trans. 34(2), 138–153 (2004)
13.  Wang, Tianhai & Chen, Bin & Zhang, Zhenqian & Li, Han & Zhang, Man. (2022). Applications of machine vision in agricultural robot navigation: A review. Computers and Electronics in Agriculture. 198. 107085. 10.1016/j.compag.2022.107085.
14.  Sofman, B., et al.: Improving robot navigation through self-supervised online learning. J. Field Robotics. 23, 59–75 (2006)
15.  Moysiadis, Vasileios & Tsolakis, Naoum & Katikaridis, Dimitris & Sørensen, Claus & Pearson, Simon & Bochtis, Dionysis. (2020). Mobile Robotics in Agricultural Operations: A Narrative Review on Planning Aspects. Applied Sciences. 10. 3453. 10.3390/app10103453.
16. Goodfellow, Ian; Pouget-Abadie, Jean; Mirza, Mehdi; Xu, Bing; Warde-Farley, David; Ozair, Sherjil; Courville, Aaron; Bengio, Yoshua (2014). Generative Adversarial Nets. Proceedings of the International Conference on Neural Information Processing Systems (NIPS 2014). pp. 2672–2680.
17. Kohl, N., Stone, P.: Machine learning for fast quadrupedal locomotion. In: AAAI, pp. 611–616 (2004)
18. Popp, K., Schiehlen, W.: Ground Vehicle Dynamics. Springer, Berlin (2010)
19. Payne, Christopher & Yang, Guang-Zhong. (2014). Hand-Held Medical Robots. Annals of biomedical engineering. 42. 10.1007/s10439-014-1042-4.
20. Krüsi, Philipp & Furgale, Paul & Bosse, Michael & Siegwart, Roland. (2016). Driving on Point Clouds: Motion Planning, Trajectory Optimization, and Terrain Assessment in Generic Nonplanar Environments: Driving on Point Clouds. Journal of Field Robotics. 34. 10.1002/rob.21700. 
21. Mosavi, Amir & Varkonyi-Koczy, Annamaria. (2017). Integration of Machine Learning and Optimization for Robot Learning. Advances in Intelligent Systems and Computing.
22. Gholami, A.; Homayouni, T.; Ehsani, R.; Sun, J.Q. Inverse Kinematic Control of a Delta Robot Using Neural Networks in Real-Time. Robotics 2021, 10, 115.
23. López, E.J.; De La Mora-Pulido, D.S.; De La Mora-Pulido, R.S.; Ochoa-Estrella, F.J.; Flores, M.A.; Luna-Sandoval, G. Modeling in Two Configurations of a 5R 2-DoF Planar Parallel Mechanism and Solution to the Inverse Kinematic Modeling Using Artificial Neural Network. IEEE Access 2021, 9, 68583–6859.
24. Csiszar, A.; Eilers, J.; Verl, A. On solving the inverse kinematics problem using neural networks. In Proceedings of the 2017 24th International Conference on Mechatronics and Machine Vision in Practice (M2VIP), Auckland, New Zealand, 21–23 November2017; pp. 1–6.
25. Ren, H.; Ben-Tzvi, P. Learning inverse kinematics and dynamics of a robotic manipulator using generative adversarial networks. Robot. Auton. Syst. 2020, 124, 103386.
26. Zhang, D.; Lei, J. Kinematic analysis of a novel 3-DOF actuation redundant parallel manipulator using artificial intelligence approach. Robot. Comput. Integr. Manuf. 2011, 27, 157–163. 
27. Stejskal, Tomáš & Svetlik, Jozef & Ondocko, Stefan. (2022). Mapping Robot Singularities through the Monte Carlo Method. Applied Sciences. 12. 8330. 10.3390/app12168330. 
28. Aboelnasr, Mohamed & Baha, Hussein & Mokhiamar, Ossama. (2021). Novel use of the Monte-Carlo methods to visualize singularity configurations in serial manipulators. Journal of Mechanical Engineering and Sciences. 15. 7948-7963. 10.15282/jmes.15.2.2021.02.0627. 
29. Zhi, Xin & Bai, Weibang & Yeatman, Eric. (2021). Kinematic Parameter Optimization of a Miniaturized Surgical Instrument Based on Dexterous Workspace Determination. 
30. Galan-Uribe, Ervin & Morales-Velazquez, Luis. (2022). Kinematic Optimization of 6DOF Serial Robot Arms by Bio-Inspired Algorithms. IEEE Access. PP. 1-1. 10.1109/ACCESS.2022.3214850. 
31. Meta AI, «PyTorch,» Meta AI, 2016. [В Интернете]. Available: https://pytorch.org/.
32. Fukushima, K. (1969). "Visual feature extraction by a multilayered network of analog threshold elements". IEEE Transactions on Systems Science and Cybernetics. 5 (4): 322–333. doi:10.1109/TSSC.1969.300225
33. Галушкин А. И. Синтез многослойных систем распознавания образов. — М.: «Энергия», 1974.
34. Brownlee, Jason (8 January 2019). "A Gentle Introduction to the Rectified Linear Unit (ReLU)". Machine Learning Mastery. Retrieved 8 April 2021.
35. Bickel, Peter J.; Doksum, Kjell A. (2015). Mathematical Statistics: Basic Ideas and Selected Topics. Vol. I (Second ed.). p. 20. If we use quadratic loss, our risk function is called the mean squared error (MSE).
36. Diederik P. Kingma and Jimmy Ba. Adam: A Method for Stochastic Optimization. arXiv. 2017.1412.6980. cs.LG.
37. Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V. and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P. and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E. Scikit-learn: Machine Learning in {P}ython. Journal of Machine Learning Research. 12. 2825--2830. 2011.
38. van Otterlo, M.; Wiering, M. (2012). "Reinforcement Learning and Markov Decision Processes". Reinforcement Learning. Adaptation, Learning, and Optimization. Vol. 12. pp. 3–42. doi:10.1007/978-3-642-27645-3_1. ISBN 978-3-642-27644-6
39. Habib, Hasan & Waseem, Saad & Ghafoor, Abdul. (2019). Development and Implementation of Enhanced Shortest Path Algorithm for Navigation of Mobile Robot for Warehouse Automation (MRWA). 1-4. 10.1109/iEECON45304.2019.8938954. 
40. Pisarenko, A., Malyshev, D., Rybak, L., Perevuznik, V. (2024). Application of Recursive Algorithms for Optimization and Approximation of Workspace of Parallel Robots. In: Olenev, N., Evtushenko, Y., Jaćimović, M., Khachay, M., Malkova, V. (eds) Advances in Optimization and Applications. OPTIMA 2023. Communications in Computer and Information Science, vol 1913. Springer, Cham. https://doi.org/10.1007/978-3-031-48751-4_19
41. Anton Pisarenko, Dmitry Malyshev, Larisa Rybak, Vladislav Cherkasov, Valeria Skitova, Application of evolutionary PSO algorithms to the problem of optimization of 6-6 UPU mobility platform geometric parameters,Procedia Computer Science, Volume 213, 2022, Pages 643-650, ISSN 1877-0509, https://doi.org/10.1016/j.procs.2022.11.116.

</details>

<!-- # Цитирование

Если материавл вам  показался полезным, будем признательны если вы нас процитируете в своих работах.

Latex:

```tex

``` -->

# Контакты

Telegramm: [antonSHBK](https://t.me/antonSHBK).
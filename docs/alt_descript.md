# Основа

## Общее описание ML

В эпоху цифровых технологий машинное обучение (ML) выступает как ключевой элемент прогресса в сфере робототехники и искусственного интеллекта (ИИ). Эта наука, на пересечении математической статистики, теории сигналов, оптимизационных алгоритмов и теории управления, открывает новые горизонты в понимании и обработке данных.

Машинное обучение предполагает создание моделей, способных адаптироваться и улучшаться благодаря взаимодействию с данными, процесс схож с обучением в природе и основан на принципах алгоритмического анализа и обработки информации.

В рамках ML модели анализируют входные данные, которые могут быть как исходными, так и специально подготовленными признаками, и на их основе формируют выводы или прогнозы. До широкого распространения глубокого обучения, задача инженерии признаков часто выполнялась вручную. Сейчас же благодаря развитию глубоких нейронных сетей, этот процесс стал автоматизированным, обеспечивая более глубокое и комплексное изучение данных. Наряду с нейронными сетями, в машинном обучении также активно используются линейные, квадратичные модели и вероятностные распределения, включая гауссово распределение [2].

Многообразие типов нейронных сетей, таких как конволюционные (CNN) [3], рекуррентные (RNN) [4] и графовые нейронные сети (GNN) [5], позволяет подходить к решению задач глубокого обучения с большим выбором инструментария. Выбор модели зависит от специфики задачи и характеристик данных. В сложных случаях предпочтение отдается нейронным сетям из-за их способности аппроксимировать сложные нелинейные взаимосвязи, что особенно важно при работе с большими объемами данных, например, в области обработки изображений.

Ключевым элементом в процессе машинного обучения является оптимизация параметров модели для достижения наилучших результатов на основе имеющихся данных. Это включает в себя выбор типа модели, настройку внутренних параметров и определение оптимальных гиперпараметров, таких как количество слоев в нейронной сети или типы используемых распределений. Данные для обучения и тестирования могут представлять собой различные типы информации, от числовых массивов до текстов и изображений, а результаты могут варьироваться в зависимости от задачи, в том числе использование вариативных автоэнкодеров (VAE) [8] и генеративных состязательных сетей (GAN) [9].

Машинное обучение находит применение в самых разнообразных областях, от автоматического распознавания образов до создания алгоритмов принятия решений, где традиционные подходы могут оказаться неэффективными. Оно стремится не просто имитировать человеческое восприятие и аналитические способности, но и разрабатывать новые методы для обработки и интерпретации данных, обеспечивая нахождение оптимальных решений на основе глубокого анализа и накопления опыта [12].

Методы машинного обучения можно классифицировать по типу обучения на обучение с учителем, без учителя и с подкреплением. Каждый из этих подходов предлагает уникальные стратегии для обработки данных и адаптации моделей, используя различные алгоритмы, в том числе методы градиентного спуска, для оптимизации параметров моделей [2].

Обучение с учителем включает в себя модели, обучаемые на основе заранее определенных пар "вход-выход", что позволяет модели научиться предсказывать результаты на новых данных. Неконтролируемое обучение, напротив, исследует скрытые структуры в неразмеченных данных, такие как кластеризация или снижение размерности. Обучение с подкреплением фокусируется на том, чтобы научить модель принимать решения через серию испытаний и ошибок, стимулируя ее достигать определенной цели [38].

Таким образом, машинное обучение представляет собой мощный инструмент, позволяющий расширить границы возможного в обработке и анализе данных, создавая новые подходы к решению задач и обеспечивая прогресс в различных сферах научных исследований и практического применения.

## Применение ML в робототехнике

Современная промышленность не может обойтись без использования роботов: они выполняют такие операции, как фрезерование, сверление, покраска, а также задачи по сортировке и перемещению предметов. Сложность промышленных задач требует от роботов всё более продвинутой архитектуры и систем управления.

Машинное обучение не просто играет ключевую роль в развитии современной робототехники; оно является движущей силой инноваций, позволяя роботам адаптироваться к разнообразным условиям и выполнять задачи с необходимой гибкостью и интеллектом. 

Применение ML в робототехнике охватывает широкий спектр направлений:
- **Зрение роботов** обеспечивает машинам способность "видеть" и интерпретировать окружающий мир, что необходимо для ряда задач, от сортировки объектов до навигации в пространстве [13];
- **Навигация** позволяет роботам самостоятельно передвигаться в пространстве, избегая препятствий и оптимизируя маршруты, что критически важно для доставки, разведения и спасательных операций [14];
- **Полевая робототехника**, которая включает в себя автономные машины, работающие в сельском хозяйстве, экологическом мониторинге и исследованиях на открытом воздухе [15];
- **Медицинская робототехника** преобразовывает здравоохранение, обеспечивая выполнение сложных хирургических операций с высокой точностью и минимальным вмешательством [19];
- **Навигация в условиях пересеченной местности** открывает новые возможности для использования роботов в сложных условиях, таких как поисково-спасательные операции в горной местности или на разрушенных после стихийных бедствий территориях [20].

Машинное обучение нашло широкое применение в анализе кинематики роботов, позволяя оценить и управлять их движением с высокой точностью. Использование нейронных сетей для кинематического анализа робота предложено в исследовании [22], где авторы демонстрируют преимущества перед традиционными методами, такими как алгоритм Ньютона-Рапсона, особенно в аспекте выявления множественных решений для обобщенных координат.

Примеры успешного применения ML в робототехнике демонстрируют его потенциал в создании новых возможностей. Один из таких примеров — разработка роботов-сортировщиков на складах, которые используют машинное зрение для идентификации и сортировки товаров. Это не только существенно увеличивает скорость обработки заказов, но и минимизирует ошибки, связанные с человеческим фактором [39].

В другой работе группа учёных [24] описала подход к решению обратной кинематической задачи для серийных роботов с помощью нейронной сети, обученной учитывать ошибки сборки в шарнирах. 

Анализ кинематики роботов параллельной структуры, оснащенных шестью прямолинейными приводами, был проведен в работе [26] с использованием различных методов машинного обучения, включая линейную регрессию, многомерную полиномиальную регрессию, векторную регрессию с поддержкой, регрессию на основе деревьев решений и регрессию случайного леса.

Что касается точного определения рабочего пространства по прежнему широко используется метод Монте-Карло для определения достижимых положений робота [27, 28], а также разрабатываются точные интерпретируемые модели [29]. Определение рабочей области тесно взаимосвязано с решением кинематики робота (прямая и обратная задачи кинематики). Хорошее понимание этих двух аспектов способствует решению другой задачи в роботехнике - оптимизации параметров робота. Существует множество работ представляющих решение оптимизации параметров робота, как численные методы, так и графические. В этом контексте, машинное обучение предлагает новые подходы, включая использование генетических алгоритмов [41], для решения задач оптимизации параметров роботов.

Таким образом, интеграция машинного обучения в робототехнику открывает новые возможности для разработки и управления роботами, делая их более адаптивными, интеллектуальными и способными к выполнению широкого спектра задач в различных условиях.

## О работе

В данной работе мы рассмотрим другой способ анализа оптимизации параметров. Проанализируем накопленные знания, результаты вычислений рабочих областей традиционными интерпретируемыми алгоритмами. Попробуем определить скрытые взаимосвязи и корреляцию  параметров. Для этого спроектируем нейронную модель и обучим её на данных.

В результате выполнения кинематики был создан набор данных, содержащий значения параметров робота и  соответствующих значений обобщенных координат. Полученные данные разделены на тренировочный набор и проверочный набор в соотношении 80% тренировочный набор и 20% проверочный.

На основе кинематического анализа были сгенерированы данные о рабочем пространстве. В научной литературе предлагается несколько методов оценки рабочего пространства.  Предыдущие работы на эту тему представлены в [40, 41].

Процесс определения параметров нейронной сети является сложной и важной задачей, как правило нет какого то обязательного правила составления нейронных сетей, зачастую параметры нейронных сейте подбираются эмпирические в процессе тестирования или основываясь на личностном опыте.

В качестве библиотеки проектирования нейронных сетей используем распространённую библиотеку Pytorch [31]. Выходные параметры модели:
- `input_size`: Размер входного слоя, который должен соответствовать количеству признаков в ваших данных.
- `output_size`: Размер выходного слоя, который определяет количество целевых переменных, которые модель будет предсказывать. Для одномерной регрессии это будет 1.
- `layer_sizes`: Список, определяющий размеры скрытых слоёв. Каждый элемент списка указывает на количество нейронов в соответствующем слое. По умолчанию зададим один скрытый слой размером 64 нейрона.
- `activation_fn`: Функция активации, применяемая к выходам каждого скрытого слоя. По умолчанию используем функцию активации ReLU [32].

```python
import torch.nn as nn
import torch.nn.functional as F

class RegressionModel(nn.Module):
    def __init__(self, 
                 input_size, 
                 output_size,
                 layer_sizes=[64], 
                 activation_fn=F.relu):
        super(RegressionModel, self).__init__()
        self.input_size = input_size
        self.output_size = output_size
        self.layer_sizes = layer_sizes
        self.activation_fn = activation_fn        
        self.layers = nn.ModuleList()        
        prev_size = input_size
        for size in layer_sizes:
            self.layers.append(nn.Linear(prev_size, size))
            prev_size = size        
        self.layers.append(nn.Linear(prev_size, output_size))
        self.activation_fn = activation_fn

    def forward(self, x):
        for layer in self.layers[:-1]:
            x = self.activation_fn(layer(x))
        x = self.layers[-1](x)
        return x

```

Принцип работы:
1. Входной вектор данных `x` последовательно проходит через все слои модели.
2. На выходе каждого скрытого слоя применяется функция активации (по умолчанию `F.relu` [32]), что позволяет модели изучать нелинейные зависимости между входными и выходными данными.
3. Последний слой (выходной слой) возвращает линейный выход, который может интерпретироваться как прогнозируемое значение целевой переменной для задачи регрессии.

Основной метод:
- `forward(x)`: Определяет прямой проход (forward pass) через модель. Для каждого слоя, кроме последнего, применяется функция активации к его выходу. Выход последнего слоя возвращается напрямую, что характерно для задач регрессии, где мы хотим получить непрерывное значение без применения функции активации.
  
Эта модель представляет собой гибкий инструмент для построения нейронных сетей различной архитектуры для решения регрессионных задач, позволяя экспериментировать с различным количеством слоёв и функциями активации.

Функция ReLU (Rectified Linear Unit) — это функция активации, широко используемая в нейронных сетях, особенно в глубоком обучении. Функция ReLU и её производные помогают решать проблемы, связанные с градиентным спуском, такие как затухание или взрыв градиента, ускоряя процесс обучения моделей глубокого обучения [32].

Функция ReLU определяется следующим образом для входа $x$:

$$ \text{ReLU}(x) = \max(0, x) $$

Это означает, что если вход $x$ положителен, функция возвращает $x$, а если $x$ отрицательный — возвращает 0.

График функции ReLU прост: для отрицательных значений $x$ функция принимает значение 0, а для положительных значений $x$ функция линейно возрастает с угловым коэффициентом 1.

Производная функции ReLU используется в процессе обратного распространения ошибки (backpropagation [33]) для обновления весов нейронной сети. Она определяется следующим образом:

$$ \text{ReLU}'(x) = 
   \begin{cases} 
   0 & \text{if } x \leq 0 \\
   1 & \text{if } x > 0 
   \end{cases}
$$

Преимущества:
- **Простота вычисления**: Поскольку ReLU является кусочно-линейной функцией, она требует меньше вычислительных ресурсов по сравнению с другими функциями активации, такими как сигмоид или гиперболический тангенс.
- **Решение проблемы затухания градиента**: В отличие от сигмоидальных функций, градиент ReLU не затухает для большого диапазона положительных значений, что облегчает обучение глубоких нейронных сетей.
- **Способствует разреженности активаций**: Поскольку ReLU возвращает 0 для всех отрицательных значений входа, это приводит к тому, что в любой момент активны только часть нейронов. Это повышает эффективность и облегчает получение разреженных представлений данных.

Недостатки:
- **Проблема "затухания"**: Если нейрон начинает выдавать отрицательные значения для всех входов в датасете, он может "затухнуть", то есть перестать вносить какой-либо вклад в адаптацию сети, поскольку его градиент будет нулевым. Решениями этой проблемы являются варианты ReLU, такие как Leaky ReLU или Parametric ReLU [34], которые позволяют передавать небольшой градиент, даже когда вход отрицателен.

В целях  обеспечения масштабируемости и гибкости регулирования модели обучения используем методы декомпозиции процесса обучения (помести процесс обучения в отдельный класс Trainer, это общепринятая практика). Этот класс инкапсулирует логику обучения, включая итерации по эпохам, обработку пакетов данных, вычисление функции потерь, выполнение шагов оптимизации, а также валидацию модели.

Основные входные параметры:
- **model**: Экземпляр модели, которую нужно обучить.
- **criterion**: Функция потерь, используемая для оценки ошибки модели. По умолчанию зададим `MSELoss` [35], подходящий для задач регрессии.
- **optimizer**: Оптимизатор для обновления весов модели на основе градиентов. По умолчанию задаётся оптимизатор Adam [36] с скоростью обучения 0.001.
- **device**: Устройство, на котором будут выполняться вычисления (`cpu` или `cuda`).

Методы класса:
- **_train**: Приватный метод для выполнения одной эпохи обучения модели на тренировочных данных.
- **_eval**: Приватный метод для оценки модели на валидационных данных.
- **fit**: Публичный метод для запуска процесса обучения, который последовательно вызывает `_train` и `_eval` для каждой эпохи.
- **plot_metrics**: Визуализирует графики потерь и MAE для тренировочных и валидационных данных по эпохам.
- **predict**: Предсказывает выходные данные для входных данных после обучения модели.
- **save_model**: Сохраняет состояние модели и конфигурацию тренера в файл.
- **load_model**: Загружает модель и конфигурацию тренера из файла.

Особенности:
- Этот класс обеспечивает удобную обёртку для стандартного цикла обучения модели с возможностью валидации.
- Использование DataLoader в методах `_train` и `_eval` позволяет эффективно обрабатывать данные пакетами, что важно для обучения на больших наборах данных.
- Поддержка гибкой конфигурации оптимизатора и функции потерь делает класс универсальным для различных задач машинного обучения.
- Встроенная поддержка визуализации процесса обучения с помощью `plot_metrics` позволяет наглядно отслеживать прогресс.

В целом, класс `Trainer` представляет собой мощный инструмент для разработки и тестирования моделей машинного обучения, облегчая процесс обучения за счёт автоматизации рутинных задач.

В качестве оптимизатора был выбран Adam (Adaptive Moment Estimation) — это метод стохастической оптимизации, который применяется для обновления весов нейронной сети в процессе обучения. Он сочетает в себе идеи двух других методов оптимизации: RMSprop и стохастического градиентного спуска с моментом. Adam адаптирует скорость обучения для каждого параметра индивидуально, используя оценки первого и второго моментов градиентов [36].

Пусть $g_t$ обозначает градиент в момент времени $t$, $m_t$ и $v_t$ — оценки первого и второго моментов градиентов соответственно. Тогда шаги алгоритма Adam можно описать следующими формулами:

1. **Вычисление градиентов для каждого параметра:**
   $$g_t = \nabla_{\theta}f_t(\theta_{t-1})$$

2. **Обновление оценок первого момента (аналогично моменту в стохастическом градиентном спуске):**
   $$m_t = \beta_1 \cdot m_{t-1} + (1 - \beta_1) \cdot g_t$$

3. **Обновление оценок второго момента (аналогично RMSprop):**
   $$v_t = \beta_2 \cdot v_{t-1} + (1 - \beta_2) \cdot g_t^2$$

4. **Коррекция оценок моментов для учета их инициализации в нуле:**
   $$ \hat{m}_t = \frac{m_t}{1 - \beta_1^t} $$
   $$ \hat{v}_t = \frac{v_t}{1 - \beta_2^t} $$

5. **Обновление параметров:**
   $$ \theta_t = \theta_{t-1} - \frac{\alpha \cdot \hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon} $$

где:
- $\theta_t$ — параметры модели на шаге $t$,
- $\alpha$ — скорость обучения,
- $\beta_1$ и $\beta_2$ — коэффициенты экспоненциального затухания для оценок моментов (обычно выбираются близко к 1),
- $\epsilon$ — малое положительное число, добавляемое для устойчивости деления (чтобы избежать деления на ноль).

Adam популярен благодаря своей эффективности в широком диапазоне задач машинного обучения и его способности адаптироваться к различным условиям задачи

На этом этапе еще одним важным аспектом является критерий сходимости. Это может быть максимальное количество оценок функции, конкретное минимальное значение средней квадратичной ошибки (`MSE`) или подтверждение эффективности работы обученной сети на основе данных, зарезервированных для валидации. Этот критерий накладывается пользователем, определяющим сеть, но может зависеть от области применения, для которой используется нейронная сеть. В данной ситуации в качестве критерия принята функция `MSE`.

Функция потерь среднеквадратичной ошибки (MSE, Mean Squared Error Loss) — это стандартная мера, используемая для оценки разности между предсказанными значениями модели и фактическими значениями. Она часто применяется в задачах регрессии для оптимизации параметров модели. Формула MSE вычисляется как среднее квадратов разностей между целевыми значениями и значениями, предсказанными моделью [35].

Если обозначить целевые значения как $y_i$ и соответствующие им предсказанные значения как $\hat{y}_i$ для $i$-го примера в наборе данных, то MSE вычисляется по формуле:

$$ \text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (\hat{y}_i - y_i)^2 $$

где:
- $n$ — количество примеров в наборе данных,
- $y_i$ — фактическое значение цели для $i$-го примера,
- $\hat{y}_i$ — предсказанное значение для $i$-го примера.

Цель оптимизации с использованием функции потерь MSE — минимизировать среднеквадратичное отклонение между предсказанными и реальными значениями, тем самым улучшая точность модели. В контексте обучения нейронной сети, это означает адаптацию весов сети таким образом, чтобы минимизировать значение `MSE` через процесс обратного распространения ошибки и градиентного спуска.

Последнее что хочется отметить, что для данные предварительно нормализованы, для этого использован удобный инструмент библиотеки `Scikit Learn` - `StandardScaler` [37].

Это метод предварительной обработки данных, который часто используется для нормализации характеристик (признаков) в машинном обучении перед обучением модели. Он преобразует данные так, чтобы их распределение имело среднее значение, равное 0, и стандартное отклонение, равное 1. Этот процесс известен также как стандартизация или z-оценка.

Стандартизация данных помогает улучшить процесс обучения, делая его более стабильным и ускоряя сходимость в алгоритмах, чувствительных к масштабу признаков, таких как линейная регрессия, логистическая регрессия, и методы, использующие градиентный спуск.

Допустим, у нас есть набор данных $X$, состоящий из $n$ признаков (характеристик), и мы хотим стандартизировать один из признаков. Пусть $x$ будет вектором значений этого признака для всех примеров в наборе данных. Тогда процесс стандартизации можно описать следующими шагами:

1. **Вычисление среднего значения ($\mu$) для признака $x$:**
   $$ \mu = \frac{1}{n} \sum_{i=1}^{n} x_i $$
   
   где $x_i$ — значение $i$-го примера для признака $x$, а $n$ — общее количество примеров.

2. **Вычисление стандартного отклонения ($\sigma$) для признака $x$:**
   $$ \sigma = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (x_i - \mu)^2} $$
   
3. **Стандартизация значения признака для каждого примера:**
   $$ x'_i = \frac{x_i - \mu}{\sigma} $$
   
   где $x'_i$ — стандартизированное значение признака $x$ для $i$-го примера.

После применения `StandardScaler`, каждый признак в новом наборе данных будет иметь среднее значение, равное 0, и стандартное отклонение, равное 1. Это делает признаки более сопоставимыми и упрощает обучение моделей машинного обучения.

Далее идёт процесс обучения нейронной сети.

После обучения нейронных сетей, проведенного на третьем этапе, производительность сети была оценена на валидационных наборах данных (с использованием 20% доли, зарезервированной на 20% от каждого набора данных, зарезервированных на первом этапе). 

<!-- ![Анализ обучения](../imgs/MAE_metrics.png) -->

# Литература

1. Connell, J.H., Mahadevan, S.: Robot Learning. Springer Science & Business Media (2012)
2. Nielsen, M.A. Neural Networks and Deep Learning. Determination Press. 2015. https://books.google.com.mt/books?id=STDBswEACAAJ
3. Venkatesan, Ragav; Li, Baoxin. Convolutional Neural Networks in Visual Computing: A Concise Guide. CRC Press. 2017. ISBN 978-1-351-65032-8.
4. Abiodun OI, Jantan A, Omolara AE, Dada KV, Mohamed NA, Arshad H. State-of-the-art in artificial neural network applications: A survey. Heliyon. 2018 Nov 23;4(11):e00938. doi: 10.1016/j.heliyon.2018.e00938. PMID: 30519653; PMCID: PMC6260436.
5. L. Wu, P. Cui, J. Pei, and L. Zhao. Graph Neural Networks: Foundations, Frontiers, and Applications. Springer, Singapore, 2022
6. Y. LeCun, Y. Bengio, G. Hinton, Deep learning, Nature 521 (2015) 436–444, https://doi.org/10.1038/nature14539.
7. K. Hornik, M. Stinchcombe, H. White, Multilayer feedforward networks are universal approximators, Neural Netw. 2 (1989) 359–366, https://doi.org/10.1016/0893-6080(89)90020-8.
8. Y. Pu, Z. Gan, R. Henao, X. Yuan, C. Li, A. Stevens, et al., Variational autoencoder for deep learning of images, labels and captions, in: 30th Annual Conference on Neural Information Processing Systems (NeurIPS), 2016.
9. I.J. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, et al., Generative adversarial nets, in: 28th Annual Conference on Neural Information Processing Systems (NeurIPS), 2014.
10.  D. Silver, S. Singh, D. Precup, R.S. Sutton, Reward is enough, Artif. Intell. 299 (2021), 103535, https://doi.org/10.1016/j.artint.2021.103535.
11.  Battiti. R., Brunato. M.: Reactive search optimization: learning while optimizing. In: Handbook of Metaheuristics, pp. 543–571. Springer, US (2010)
12.  Murphy, R.R.: Human-robot interaction in rescue robotics. Syst. Man Cybernetics Appl. Rev. IEEE Trans. 34(2), 138–153 (2004)
13.  Wang, Tianhai & Chen, Bin & Zhang, Zhenqian & Li, Han & Zhang, Man. (2022). Applications of machine vision in agricultural robot navigation: A review. Computers and Electronics in Agriculture. 198. 107085. 10.1016/j.compag.2022.107085.
14.  Sofman, B., et al.: Improving robot navigation through self-supervised online learning. J. Field Robotics. 23, 59–75 (2006)
15.  Moysiadis, Vasileios & Tsolakis, Naoum & Katikaridis, Dimitris & Sørensen, Claus & Pearson, Simon & Bochtis, Dionysis. (2020). Mobile Robotics in Agricultural Operations: A Narrative Review on Planning Aspects. Applied Sciences. 10. 3453. 10.3390/app10103453.
16. Goodfellow, Ian; Pouget-Abadie, Jean; Mirza, Mehdi; Xu, Bing; Warde-Farley, David; Ozair, Sherjil; Courville, Aaron; Bengio, Yoshua (2014). Generative Adversarial Nets. Proceedings of the International Conference on Neural Information Processing Systems (NIPS 2014). pp. 2672–2680.
17. Kohl, N., Stone, P.: Machine learning for fast quadrupedal locomotion. In: AAAI, pp. 611–616 (2004)
18. Popp, K., Schiehlen, W.: Ground Vehicle Dynamics. Springer, Berlin (2010)
19. Payne, Christopher & Yang, Guang-Zhong. (2014). Hand-Held Medical Robots. Annals of biomedical engineering. 42. 10.1007/s10439-014-1042-4.
20. Krüsi, Philipp & Furgale, Paul & Bosse, Michael & Siegwart, Roland. (2016). Driving on Point Clouds: Motion Planning, Trajectory Optimization, and Terrain Assessment in Generic Nonplanar Environments: Driving on Point Clouds. Journal of Field Robotics. 34. 10.1002/rob.21700. 
21. Mosavi, Amir & Varkonyi-Koczy, Annamaria. (2017). Integration of Machine Learning and Optimization for Robot Learning. Advances in Intelligent Systems and Computing.
22. Gholami, A.; Homayouni, T.; Ehsani, R.; Sun, J.Q. Inverse Kinematic Control of a Delta Robot Using Neural Networks in Real-Time. Robotics 2021, 10, 115.
23. López, E.J.; De La Mora-Pulido, D.S.; De La Mora-Pulido, R.S.; Ochoa-Estrella, F.J.; Flores, M.A.; Luna-Sandoval, G. Modeling in Two Configurations of a 5R 2-DoF Planar Parallel Mechanism and Solution to the Inverse Kinematic Modeling Using Artificial Neural Network. IEEE Access 2021, 9, 68583–6859.
24. Csiszar, A.; Eilers, J.; Verl, A. On solving the inverse kinematics problem using neural networks. In Proceedings of the 2017 24th International Conference on Mechatronics and Machine Vision in Practice (M2VIP), Auckland, New Zealand, 21–23 November2017; pp. 1–6.
25. Ren, H.; Ben-Tzvi, P. Learning inverse kinematics and dynamics of a robotic manipulator using generative adversarial networks. Robot. Auton. Syst. 2020, 124, 103386.
26. Zhang, D.; Lei, J. Kinematic analysis of a novel 3-DOF actuation redundant parallel manipulator using artificial intelligence approach. Robot. Comput. Integr. Manuf. 2011, 27, 157–163. 
27. Stejskal, Tomáš & Svetlik, Jozef & Ondocko, Stefan. (2022). Mapping Robot Singularities through the Monte Carlo Method. Applied Sciences. 12. 8330. 10.3390/app12168330. 
28. Aboelnasr, Mohamed & Baha, Hussein & Mokhiamar, Ossama. (2021). Novel use of the Monte-Carlo methods to visualize singularity configurations in serial manipulators. Journal of Mechanical Engineering and Sciences. 15. 7948-7963. 10.15282/jmes.15.2.2021.02.0627. 
29. Zhi, Xin & Bai, Weibang & Yeatman, Eric. (2021). Kinematic Parameter Optimization of a Miniaturized Surgical Instrument Based on Dexterous Workspace Determination. 
30. Galan-Uribe, Ervin & Morales-Velazquez, Luis. (2022). Kinematic Optimization of 6DOF Serial Robot Arms by Bio-Inspired Algorithms. IEEE Access. PP. 1-1. 10.1109/ACCESS.2022.3214850. 
31. Meta AI, «PyTorch,» Meta AI, 2016. [В Интернете]. Available: https://pytorch.org/.
32. Fukushima, K. (1969). "Visual feature extraction by a multilayered network of analog threshold elements". IEEE Transactions on Systems Science and Cybernetics. 5 (4): 322–333. doi:10.1109/TSSC.1969.300225
33. Галушкин А. И. Синтез многослойных систем распознавания образов. — М.: «Энергия», 1974.
34. Brownlee, Jason (8 January 2019). "A Gentle Introduction to the Rectified Linear Unit (ReLU)". Machine Learning Mastery. Retrieved 8 April 2021.
35. Bickel, Peter J.; Doksum, Kjell A. (2015). Mathematical Statistics: Basic Ideas and Selected Topics. Vol. I (Second ed.). p. 20. If we use quadratic loss, our risk function is called the mean squared error (MSE).
36. Diederik P. Kingma and Jimmy Ba. Adam: A Method for Stochastic Optimization. arXiv. 2017.1412.6980. cs.LG.
37. Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V. and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P. and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E. Scikit-learn: Machine Learning in {P}ython. Journal of Machine Learning Research. 12. 2825--2830. 2011.
38. van Otterlo, M.; Wiering, M. (2012). "Reinforcement Learning and Markov Decision Processes". Reinforcement Learning. Adaptation, Learning, and Optimization. Vol. 12. pp. 3–42. doi:10.1007/978-3-642-27645-3_1. ISBN 978-3-642-27644-6
39. Habib, Hasan & Waseem, Saad & Ghafoor, Abdul. (2019). Development and Implementation of Enhanced Shortest Path Algorithm for Navigation of Mobile Robot for Warehouse Automation (MRWA). 1-4. 10.1109/iEECON45304.2019.8938954. 
40. Pisarenko, A., Malyshev, D., Rybak, L., Perevuznik, V. (2024). Application of Recursive Algorithms for Optimization and Approximation of Workspace of Parallel Robots. In: Olenev, N., Evtushenko, Y., Jaćimović, M., Khachay, M., Malkova, V. (eds) Advances in Optimization and Applications. OPTIMA 2023. Communications in Computer and Information Science, vol 1913. Springer, Cham. https://doi.org/10.1007/978-3-031-48751-4_19
41. Anton Pisarenko, Dmitry Malyshev, Larisa Rybak, Vladislav Cherkasov, Valeria Skitova, Application of evolutionary PSO algorithms to the problem of optimization of 6-6 UPU mobility platform geometric parameters,Procedia Computer Science, Volume 213, 2022, Pages 643-650, ISSN 1877-0509, https://doi.org/10.1016/j.procs.2022.11.116.
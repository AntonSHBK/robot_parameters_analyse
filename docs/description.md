# Основа

## Общее описание ML

В настоящее время машинное обучение (ML) стало основой исследований в области робототехники [1]. Как наука, машинное обучение - это область, объединяющая математическую статистику с обработкой сигналов, алгоритмами оптимизации и теорией управления. На сегодняшний день она стало одной из самых перспективных областей искусственного интеллекта.

Парадигма машинного обучения предполагает подгонку функций под данные, а затем использование этих обученных функций для аппроксимации новых данных. Этот процесс превращения слабой функции в более сильную на основе заданных данных называется "обучением" и похож на то, как учатся животные. Поскольку этот процесс обычно выполняется машинами, например компьютерами, был придуман термин "машинное обучение".

В машинном обучении подогнанная функция принимает на вход исходные данные или созданные вручную признаки и генерирует выходные данные, пропуская информацию через себя. До появления глубокого обучения инженерия признаков представляла собой процесс ручного извлечения признаков из данных или использования заранее заданных правил для извлечения признаков. На смену этому процессу пришли более сложные модели, такие как глубокие нейронные сети, которые обладают более сильным представлением [2]. Однако нейронные сети - не единственный тип моделей, которые можно использовать для этой цели. Также часто используются линейные модели, квадратичные модели и выражения вероятностных распределений (распределение Гауса). 

Что касается нейронных сетей, то существуют различные типы сетей, такие как конволюционные нейронные сети (CNN) [3], рекуррентные нейронные сети (RNN)[4] и графовые нейронные сети (GNN)[5]. Эти сети могут использоваться вместо плотных нейронных сетей в глубоком обучении [6]. Выбор модели зависит от решаемой задачи. Если проблема легко моделируется или известны распределения вероятностей, которые можно применить, то можно выбрать модели с обучаемыми параметрами. Для сложных задач часто предпочитают использовать нейронные сети, поскольку теоретически доказано, что они могут представлять любую нелинейную функцию [7]. Эффективность модели часто зависит от объема данных. Например, для извлечения семантической информации из изображений требуется аппроксиматор с большей емкостью, такой как глубокие нейронные сети, поскольку изображения обычно содержат больше данных, чем типичные числовые данные.

Нейронные сети также различаются в зависимости от задачи, для которой они предназначены. Конволюционные нейронные сети (CNN) предназначены для работы с данными, организованными в геометрические фигуры, такие как изображения. Рекуррентные нейронные сети (RNN) лучше подходят для последовательных данных, таких как текст и звук.

Независимо от того, какая модель выбрана для машинного обучения, целью процесса обучения является оценка параметров модели на основе предоставленных данных. Эти элементы, такие как тип модели и внутренние настройки (например, функции активации и скорость обучения), играют решающую роль в определении успеха модели. Комбинация нескольких гауссовых распределений и количество слоев в нейронной сети - это так называемые гиперпараметры. Входные данные могут быть скалярными, векторными, матричными или тензорными в математических определениях. В реальности это может быть числовой массив, абзац текста, фрагмент аудиозаписи или картинка. Выходные данные также могут иметь различную размерность в зависимости от требований пользователя, а иногда даже совпадать с входными данными, как, например, в вариативном автоэнкодере (VAE)[8] и генеративных состязательных сетях (GAN)[9]. По сути, машинное обучение использует свою функцию для отображения данных с входа на выход. Различные отображения приводят к различным приложениям. Например, отображение изображения на метку - это распознавание, отображение предложения с одного языка на другой - машинный перевод, а отображение любых данных из себя в себя может быть использовано для машинного создания (например, художника или поэта) или уменьшения размерности. Поиск параметров функции - это именно тот процесс, с помощью которого машина обучается. Однако настройка параметров тесно связана с типом метода машинного обучения. Методы машинного обучения часто делятся на три основные группы: обучение без надзора, обучение с надзором и обучение с подкреплением.

Неконтролируемое обучение направлено на обработку информации без сигналов контроля, например, кластеризация. Обучение с учителем предоставляет такие сигналы, которые могут быть использованы для вычисления функций потерь. Параметры функции настраиваются на основе оптимизации функции затрат. Методы градиентного спуска - наиболее часто используемые методы оптимизации, поскольку они могут быть эффективно рассчитаны на аппаратных средствах.

Машинное часто используется в ряде задач, где разработка точных алгоритмов нецелесообразно. В этом смысле оно может заменить человеческий опыт в обработке информации [11], для которого предоставляет алгоритмические инструменты для работы с наборами данных и получения прогнозов. Фактически Машинное обучение стремится имитировать человеческие навыки, которые в большинстве случаев оказываются исключительными в определении удовлетворительных решений на основе теоретических или основанных на опыте соображений [12]. 

## Применение ML в робототехнике

В настоящее время промышленные роботы являются практически обязательным условием применения в промышленности:  фрезерование, сверление, покраска, обработка или подбор и перемещение. С увеличением сложности промышленных операций, а также для того чтобы соответствовать специфике технологических операций, роботы постоянно усложняются в направлении  архитектуры и системы управления. 

Области применения ML в робототехнике, которые в значительной степени способствуют обучению роботов, обширны и все еще развивается быстрыми темпами [21]. Зрение роботов [13], навигация роботов [14], полевая робототехника [15], гуманоидная робототехника [16], локомоция ног [17], моделирование динамики транспортных средств [18], медицинская и хирургическая робототехника [19], навигация внедорожных мобильных роботов на пересеченной местности [20]. 

Таким образом, становится очевидным, что в последние годы ОД стали неотъемлемой частью робототехники. И это, по сути, стало ответом на неудовлетворенность проблемами, для которых оказалось трудно найти традиционные интерпретируемые решения. 

Машинное обучение также нашло применение в расчёте кинематики роботов. Авторы работы [22] предложили использовать нейронные сети  для оценки кинематического анализа робота и управления траекторией. Многослойная нейронная сеть была обучена  в [23] для решения задачи кинематического анализа плоскопараллельного механизма. Предложенное  решение преодолевает некоторые ограничения численного алгоритма Ньютона-Рапсона в части что касается получения множества решений для обобщенных координат. 

Другим примером является работа [24], в которой предложена нейронная сеть с контролируемым обучением для  решения обратной кинематической задачи серийных роботов с учетом ошибок сборки  ошибки сборки в шарнирах. В [25] авторы предложили состязательную нейронную сеть для решения обратных кинематических и динамических задач. 

В работе [26] предложена оценка кинематического анализа робота параллельной структуры, содержащего шесть прямолинейных  приводов, с помощью нескольких методов машинного обучения, таких как: линейная регрессия, многомерная полиномиальная регрессия, векторная регрессия с поддержкой, регрессия дерева решений и регрессия случайного леса. 

Что касается точного определения рабочего пространства по прежнему широко используется метод Монте-Карло для определения достижимых положений робота [27, 28], а также разрабатываются точные интерпретируемые модели [29]. Определение рабочей области тесно взаимосвязано с решением кинематики робота (прямая и обратная задачи кинематики). Хорошее понимание этих двух аспектов способствует решению другой задачи в роботехнике - оптимизации параметров робота. Существует множество работ представляющих решение оптимизации параметров робота, как численные методы, так и графические. К численным методам можно отнести методы машинного обучения, например применение генетических алгоритмов [30]. 

## О работе

В данной работе мы рассмотрим другой способ анализа оптимизации параметров. Проанализируем накопленные знания, результаты вычислений рабочих областей традиционными интерпретируемыми алгоритмами. Попробуем определить скрытые взаимосвязи и корреляцию  параметров. Для этого спроектируем нейронную модель и обучим её на данных.

В результате выполнения кинематики был создан набор данных, содержащий значения параметров робота и  соответствующих значений обобщенных координат. Полученные данные разделены на тренировочный набор и проверочный набор в соотношении 80% тренировочный набор и 20% проверочный.

На основе кинематического анализа были сгенерированы данные о рабочем пространстве. В научной литературе предлагается несколько методов оценки рабочего пространства.  Предыдущие работы на эту тему представлены в [????]. Во-первых, для оценки рабочего пространства используется трехмерное пространство (параллелепипеды).

Процесс определения параметров нейронной сети является сложной и важной задачей, как правило нет какого то обязательного правила составления нейронных сетей, зачастую параметры нейронных сейте подбираются эмпирические в процессе тестирования или основываясь на личностном опыте.

В качестве библиотеки проектирования нейронных сетей используем распространённую библиотеку Pytorch[31]. Выходные параметры модели:
- `input_size`: Размер входного слоя, который должен соответствовать количеству признаков в ваших данных.
- `output_size`: Размер выходного слоя, который определяет количество целевых переменных, которые модель будет предсказывать. Для одномерной регрессии это будет 1.
- `layer_sizes`: Список, определяющий размеры скрытых слоёв. Каждый элемент списка указывает на количество нейронов в соответствующем слое. По умолчанию зададим один скрытый слой размером 64 нейрона.
- `activation_fn`: Функция активации, применяемая к выходам каждого скрытого слоя. По умолчанию используем функцию активации ReLU[32].

```python
import torch.nn as nn
import torch.nn.functional as F

class RegressionModel(nn.Module):
    def __init__(self, 
                 input_size, 
                 output_size,
                 layer_sizes=[64], 
                 activation_fn=F.relu):
        super(RegressionModel, self).__init__()
        self.input_size = input_size
        self.output_size = output_size
        self.layer_sizes = layer_sizes
        self.activation_fn = activation_fn        
        self.layers = nn.ModuleList()        
        prev_size = input_size
        for size in layer_sizes:
            self.layers.append(nn.Linear(prev_size, size))
            prev_size = size        
        self.layers.append(nn.Linear(prev_size, output_size))
        self.activation_fn = activation_fn

    def forward(self, x):
        for layer in self.layers[:-1]:
            x = self.activation_fn(layer(x))
        x = self.layers[-1](x)
        return x

```

Принцип работы:
1. Входной вектор данных `x` последовательно проходит через все слои модели.
2. На выходе каждого скрытого слоя применяется функция активации (по умолчанию `F.relu`[32]), что позволяет модели изучать нелинейные зависимости между входными и выходными данными.
3. Последний слой (выходной слой) возвращает линейный выход, который может интерпретироваться как прогнозируемое значение целевой переменной для задачи регрессии.

Основной метод:
- `forward(x)`: Определяет прямой проход (forward pass) через модель. Для каждого слоя, кроме последнего, применяется функция активации к его выходу. Выход последнего слоя возвращается напрямую, что характерно для задач регрессии, где мы хотим получить непрерывное значение без применения функции активации.
  
Эта модель представляет собой гибкий инструмент для построения нейронных сетей различной архитектуры для решения регрессионных задач, позволяя экспериментировать с различным количеством слоёв и функциями активации.

Функция ReLU (Rectified Linear Unit) — это функция активации, широко используемая в нейронных сетях, особенно в глубоком обучении. Функция ReLU и её производные помогают решать проблемы, связанные с градиентным спуском, такие как затухание или взрыв градиента, ускоряя процесс обучения моделей глубокого обучения[32].

Функция ReLU определяется следующим образом для входа $x$:

$$ \text{ReLU}(x) = \max(0, x) $$

Это означает, что если вход $x$ положителен, функция возвращает $x$, а если $x$ отрицательный — возвращает 0.

График функции ReLU прост: для отрицательных значений $x$ функция принимает значение 0, а для положительных значений $x$ функция линейно возрастает с угловым коэффициентом 1.

Производная функции ReLU используется в процессе обратного распространения ошибки (backpropagation [33]) для обновления весов нейронной сети. Она определяется следующим образом:

$$ \text{ReLU}'(x) = 
   \begin{cases} 
   0 & \text{if } x \leq 0 \\
   1 & \text{if } x > 0 
   \end{cases}
$$

Преимущества:
- **Простота вычисления**: Поскольку ReLU является кусочно-линейной функцией, она требует меньше вычислительных ресурсов по сравнению с другими функциями активации, такими как сигмоид или гиперболический тангенс.
- **Решение проблемы затухания градиента**: В отличие от сигмоидальных функций, градиент ReLU не затухает для большого диапазона положительных значений, что облегчает обучение глубоких нейронных сетей.
- **Способствует разреженности активаций**: Поскольку ReLU возвращает 0 для всех отрицательных значений входа, это приводит к тому, что в любой момент активны только часть нейронов. Это повышает эффективность и облегчает получение разреженных представлений данных.

Недостатки:
- **Проблема "затухания"**: Если нейрон начинает выдавать отрицательные значения для всех входов в датасете, он может "затухнуть", то есть перестать вносить какой-либо вклад в адаптацию сети, поскольку его градиент будет нулевым. Решениями этой проблемы являются варианты ReLU, такие как Leaky ReLU или Parametric ReLU[34], которые позволяют передавать небольшой градиент, даже когда вход отрицателен.

В целях  обеспечения масштабируемости и гибкости регулирования модели обучения используем методы декомпозиции процесса обучения (помести процесс обучения в отдельный класс Trainer, это общепринятая практика). Этот класс инкапсулирует логику обучения, включая итерации по эпохам, обработку пакетов данных, вычисление функции потерь, выполнение шагов оптимизации, а также валидацию модели.

Основные входные параметры:
- **model**: Экземпляр модели, которую нужно обучить.
- **criterion**: Функция потерь, используемая для оценки ошибки модели. По умолчанию зададим `MSELoss` [35], подходящий для задач регрессии.
- **optimizer**: Оптимизатор для обновления весов модели на основе градиентов. По умолчанию задаётся оптимизатор Adam[36] с скоростью обучения 0.001.
- **device**: Устройство, на котором будут выполняться вычисления (`cpu` или `cuda`).

Методы класса:
- **_train**: Приватный метод для выполнения одной эпохи обучения модели на тренировочных данных.
- **_eval**: Приватный метод для оценки модели на валидационных данных.
- **fit**: Публичный метод для запуска процесса обучения, который последовательно вызывает `_train` и `_eval` для каждой эпохи.
- **plot_metrics**: Визуализирует графики потерь и MAE для тренировочных и валидационных данных по эпохам.
- **predict**: Предсказывает выходные данные для входных данных после обучения модели.
- **save_model**: Сохраняет состояние модели и конфигурацию тренера в файл.
- **load_model**: Загружает модель и конфигурацию тренера из файла.

Особенности:
- Этот класс обеспечивает удобную обёртку для стандартного цикла обучения модели с возможностью валидации.
- Использование DataLoader в методах `_train` и `_eval` позволяет эффективно обрабатывать данные пакетами, что важно для обучения на больших наборах данных.
- Поддержка гибкой конфигурации оптимизатора и функции потерь делает класс универсальным для различных задач машинного обучения.
- Встроенная поддержка визуализации процесса обучения с помощью `plot_metrics` позволяет наглядно отслеживать прогресс.

В целом, класс `Trainer` представляет собой мощный инструмент для разработки и тестирования моделей машинного обучения, облегчая процесс обучения за счёт автоматизации рутинных задач.

В качестве оптимизатора был выбран Adam (Adaptive Moment Estimation) — это метод стохастической оптимизации, который применяется для обновления весов нейронной сети в процессе обучения. Он сочетает в себе идеи двух других методов оптимизации: RMSprop и стохастического градиентного спуска с моментом. Adam адаптирует скорость обучения для каждого параметра индивидуально, используя оценки первого и второго моментов градиентов [36].

Пусть $g_t$ обозначает градиент в момент времени $t$, $m_t$ и $v_t$ — оценки первого и второго моментов градиентов соответственно. Тогда шаги алгоритма Adam можно описать следующими формулами:

1. **Вычисление градиентов для каждого параметра:**
   $$g_t = \nabla_{\theta}f_t(\theta_{t-1})$$

2. **Обновление оценок первого момента (аналогично моменту в стохастическом градиентном спуске):**
   $$m_t = \beta_1 \cdot m_{t-1} + (1 - \beta_1) \cdot g_t$$

3. **Обновление оценок второго момента (аналогично RMSprop):**
   $$v_t = \beta_2 \cdot v_{t-1} + (1 - \beta_2) \cdot g_t^2$$

4. **Коррекция оценок моментов для учета их инициализации в нуле:**
   $$ \hat{m}_t = \frac{m_t}{1 - \beta_1^t} $$
   $$ \hat{v}_t = \frac{v_t}{1 - \beta_2^t} $$

5. **Обновление параметров:**
   $$ \theta_t = \theta_{t-1} - \frac{\alpha \cdot \hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon} $$

где:
- $\theta_t$ — параметры модели на шаге $t$,
- $\alpha$ — скорость обучения,
- $\beta_1$ и $\beta_2$ — коэффициенты экспоненциального затухания для оценок моментов (обычно выбираются близко к 1),
- $\epsilon$ — малое положительное число, добавляемое для устойчивости деления (чтобы избежать деления на ноль).

Adam популярен благодаря своей эффективности в широком диапазоне задач машинного обучения и его способности адаптироваться к различным условиям задачи

На этом этапе еще одним важным аспектом является критерий сходимости. Это может быть максимальное количество оценок функции, конкретное минимальное значение средней квадратичной ошибки (`MSE`) или подтверждение эффективности работы обученной сети на основе данных, зарезервированных для валидации. Этот критерий накладывается пользователем, определяющим сеть, но может зависеть от области применения, для которой используется нейронная сеть. В данной ситуации в качестве критерия принята функция `MSE`.

Функция потерь среднеквадратичной ошибки (MSE, Mean Squared Error Loss) — это стандартная мера, используемая для оценки разности между предсказанными значениями модели и фактическими значениями. Она часто применяется в задачах регрессии для оптимизации параметров модели. Формула MSE вычисляется как среднее квадратов разностей между целевыми значениями и значениями, предсказанными моделью[35].

Если обозначить целевые значения как $y_i$ и соответствующие им предсказанные значения как $\hat{y}_i$ для $i$-го примера в наборе данных, то MSE вычисляется по формуле:

$$ \text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (\hat{y}_i - y_i)^2 $$

где:
- $n$ — количество примеров в наборе данных,
- $y_i$ — фактическое значение цели для $i$-го примера,
- $\hat{y}_i$ — предсказанное значение для $i$-го примера.

Цель оптимизации с использованием функции потерь MSE — минимизировать среднеквадратичное отклонение между предсказанными и реальными значениями, тем самым улучшая точность модели. В контексте обучения нейронной сети, это означает адаптацию весов сети таким образом, чтобы минимизировать значение `MSE` через процесс обратного распространения ошибки и градиентного спуска.

Последнее что хочется отметить, что для данные предварительно нормализованы, для этого использован удобный инструмент библиотеки `Scikit Learn` - `StandardScaler`[37].

Это метод предварительной обработки данных, который часто используется для нормализации характеристик (признаков) в машинном обучении перед обучением модели. Он преобразует данные так, чтобы их распределение имело среднее значение, равное 0, и стандартное отклонение, равное 1. Этот процесс известен также как стандартизация или z-оценка.

Стандартизация данных помогает улучшить процесс обучения, делая его более стабильным и ускоряя сходимость в алгоритмах, чувствительных к масштабу признаков, таких как линейная регрессия, логистическая регрессия, и методы, использующие градиентный спуск.

Допустим, у нас есть набор данных $X$, состоящий из $n$ признаков (характеристик), и мы хотим стандартизировать один из признаков. Пусть $x$ будет вектором значений этого признака для всех примеров в наборе данных. Тогда процесс стандартизации можно описать следующими шагами:

1. **Вычисление среднего значения ($\mu$) для признака $x$:**
   $$ \mu = \frac{1}{n} \sum_{i=1}^{n} x_i $$
   
   где $x_i$ — значение $i$-го примера для признака $x$, а $n$ — общее количество примеров.

2. **Вычисление стандартного отклонения ($\sigma$) для признака $x$:**
   $$ \sigma = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (x_i - \mu)^2} $$
   
3. **Стандартизация значения признака для каждого примера:**
   $$ x'_i = \frac{x_i - \mu}{\sigma} $$
   
   где $x'_i$ — стандартизированное значение признака $x$ для $i$-го примера.

После применения `StandardScaler`, каждый признак в новом наборе данных будет иметь среднее значение, равное 0, и стандартное отклонение, равное 1. Это делает признаки более сопоставимыми и упрощает обучение моделей машинного обучения.

Далее идёт процесс обучения нейронной сети.

После обучения нейронных сетей, проведенного на третьем этапе, производительность сети была оценена на валидационных наборах данных (с использованием 20% доли, зарезервированной на 20% от каждого набора данных, зарезервированных на первом этапе). 

<!-- ![Анализ обучения](../imgs/MAE_metrics.png) -->

# Литература

1. Connell, J.H., Mahadevan, S.: Robot Learning. Springer Science & Business Media (2012)
2. Liu, Zhihao & Liu, Quan & Xu, Wenjun & Wang, Lihui & Zhou, Zude. (2022). Robot learning towards smart robotic manufacturing: A review. Robotics and Computer-Integrated Manufacturing. 77. 1-21. 10.1016/j.rcim.2022.102360. 
3. Y. LeCun, L. Bottou, Y. Bengio, P. Haffner, Gradient-based learning applied to document recognition, Proc. IEEE 86 (1998) 2278–2324, https://doi.org/10.1109/5.726791.
4. D.E. Rumelhart, G.E. Hinton, R.J. Williams, Learning Internal Representations by Error Propagation, California University San Diego La Jolla Institute for CognitiveScience, 1985.
5. F. Scarselli, M. Gori, A.C. Tsoi, M. Hagenbuchner, G. Monfardini, The graph neural network model, IEEE Trans. Neural Networks 20 (2008) 61–80, https://doi.org/10.1109/TNN.2008.2005605.
6. Y. LeCun, Y. Bengio, G. Hinton, Deep learning, Nature 521 (2015) 436–444, https://doi.org/10.1038/nature14539.
7. K. Hornik, M. Stinchcombe, H. White, Multilayer feedforward networks are universal approximators, Neural Netw. 2 (1989) 359–366, https://doi.org/10.1016/0893-6080(89)90020-8.
8. Y. Pu, Z. Gan, R. Henao, X. Yuan, C. Li, A. Stevens, et al., Variational autoencoder for deep learning of images, labels and captions, in: 30th Annual Conference on Neural Information Processing Systems (NeurIPS), 2016.
9. I.J. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, et al., Generative adversarial nets, in: 28th Annual Conference on Neural Information Processing Systems (NeurIPS), 2014.
10. D. Silver, S. Singh, D. Precup, R.S. Sutton, Reward is enough, Artif. Intell. 299 (2021), 103535, https://doi.org/10.1016/j.artint.2021.103535.
11. Battiti. R., Brunato. M.: Reactive search optimization: learning while optimizing. In: Handbook of Metaheuristics, pp. 543–571. Springer, US (2010)
12. Murphy, R.R.: Human-robot interaction in rescue robotics. Syst. Man Cybernetics Appl. Rev. IEEE Trans. 34(2), 138–153 (2004)
13. Rosten, E., Drummond, T.: Machine learning for high-speed corner detection. In: Computer Vision–ECCV, pp. 430–443. Springer, Berlin (2006)
14. Sofman, B., et al.: Improving robot navigation through self-supervised online learning. J. Field Robotics. 23, 59–75 (2006)
15. Yang, S.Y., Jin, S.M., Kwon, S.K.: Remote control system of industrial field robot. In: 6th IEEE International Conference on Industrial Informatics, pp. 442–447 (2008)
16. Peters, J., Vijayakumar, S., Schaal, S.: Reinforcement learning for humanoid robotics. In: Proceedings of the Third IEEE-RAS International Conference on Humanoid Robots (2003)
17. Kohl, N., Stone, P.: Machine learning for fast quadrupedal locomotion. In: AAAI, pp. 611–616 (2004)
18. Popp, K., Schiehlen, W.: Ground Vehicle Dynamics. Springer, Berlin (2010)
19. Taylor, R.H., Menciassi, A., Fichtinger, G., Dario, P.: Medical robotics andcomputer-integrated surgery. In: Handbook of Robotics, pp. 1199–1222. Springer, Berlin(2008)
20. Stavens, D., Thrun, S. A.: self-supervised terrain roughness estimator for off-road autonomous driving. arXiv preprint arXiv:1206.6872 (2012)
21. Mosavi, Amir & Varkonyi-Koczy, Annamaria. (2017). Integration of Machine Learning and Optimization for Robot Learning. Advances in Intelligent Systems and Computing.
22. Gholami, A.; Homayouni, T.; Ehsani, R.; Sun, J.Q. Inverse Kinematic Control of a Delta Robot Using Neural Networks in Real-Time. Robotics 2021, 10, 115.
23. López, E.J.; De La Mora-Pulido, D.S.; De La Mora-Pulido, R.S.; Ochoa-Estrella, F.J.; Flores, M.A.; Luna-Sandoval, G. Modeling in Two Configurations of a 5R 2-DoF Planar Parallel Mechanism and Solution to the Inverse Kinematic Modeling Using Artificial Neural Network. IEEE Access 2021, 9, 68583–6859.
24. Csiszar, A.; Eilers, J.; Verl, A. On solving the inverse kinematics problem using neural networks. In Proceedings of the 2017 24th International Conference on Mechatronics and Machine Vision in Practice (M2VIP), Auckland, New Zealand, 21–23 November2017; pp. 1–6.
25. Ren, H.; Ben-Tzvi, P. Learning inverse kinematics and dynamics of a robotic manipulator using generative adversarial networks. Robot. Auton. Syst. 2020, 124, 103386.
26. Zhang, D.; Lei, J. Kinematic analysis of a novel 3-DOF actuation redundant parallel manipulator using artificial intelligence approach. Robot. Comput. Integr. Manuf. 2011, 27, 157–163. 
27. Stejskal, Tomáš & Svetlik, Jozef & Ondocko, Stefan. (2022). Mapping Robot Singularities through the Monte Carlo Method. Applied Sciences. 12. 8330. 10.3390/app12168330. 
28. Aboelnasr, Mohamed & Baha, Hussein & Mokhiamar, Ossama. (2021). Novel use of the Monte-Carlo methods to visualize singularity configurations in serial manipulators. Journal of Mechanical Engineering and Sciences. 15. 7948-7963. 10.15282/jmes.15.2.2021.02.0627. 
29. Zhi, Xin & Bai, Weibang & Yeatman, Eric. (2021). Kinematic Parameter Optimization of a Miniaturized Surgical Instrument Based on Dexterous Workspace Determination. 
30. Galan-Uribe, Ervin & Morales-Velazquez, Luis. (2022). Kinematic Optimization of 6DOF Serial Robot Arms by Bio-Inspired Algorithms. IEEE Access. PP. 1-1. 10.1109/ACCESS.2022.3214850. 
31. Meta AI, «PyTorch,» Meta AI, 2016. [В Интернете]. Available: https://pytorch.org/.
32. Fukushima, K. (1969). "Visual feature extraction by a multilayered network of analog threshold elements". IEEE Transactions on Systems Science and Cybernetics. 5 (4): 322–333. doi:10.1109/TSSC.1969.300225
33. Галушкин А. И. Синтез многослойных систем распознавания образов. — М.: «Энергия», 1974.
34. Brownlee, Jason (8 January 2019). "A Gentle Introduction to the Rectified Linear Unit (ReLU)". Machine Learning Mastery. Retrieved 8 April 2021.
35. Bickel, Peter J.; Doksum, Kjell A. (2015). Mathematical Statistics: Basic Ideas and Selected Topics. Vol. I (Second ed.). p. 20. If we use quadratic loss, our risk function is called the mean squared error (MSE).
36. Diederik P. Kingma and Jimmy Ba. Adam: A Method for Stochastic Optimization. arXiv. 2017.1412.6980. cs.LG.
37. Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V. and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P. and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E. Scikit-learn: Machine Learning in {P}ython. Journal of Machine Learning Research. 12. 2825--2830. 2011.

